{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import bloscpack as bp\n",
    "\n",
    "from tsfresh.feature_extraction import feature_calculators\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold, GroupKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from NNs import Wave_Classifier, WaveTRSFM_Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f98f1c7acb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda:0'\n",
    "EPOCHS = 128\n",
    "BATCHSIZE = 32\n",
    "SEED = 19550423\n",
    "LR = 0.001\n",
    "SPLITS = 5\n",
    "\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "step_tag = 's1000'\n",
    "wndw_tag = 's1000'\n",
    "vers_tag = 'final' # basicwithnew3\n",
    "trn_fs = sorted([f for f in os.listdir('../input/feats_srs') if (('trn_srs_dat' in f) and (step_tag in f) and (wndw_tag in f) and (vers_tag in f))])\n",
    "lbl_fs = sorted([f for f in os.listdir('../input/feats_srs') if ('trn_srs_lbl' in f) and (step_tag in f) and (wndw_tag in f) and (vers_tag in f)])\n",
    "\n",
    "tst_fs = sorted([f for f in os.listdir('../input/feats_srs') if (('tst_srs_dat' in f) and (step_tag in f) and (wndw_tag in f) and (vers_tag in f))])\n",
    "tst_fs = [tst_fs[i] for i in [0, 11, 12, 13, 14, 15, 16, 17, 18, 19]] + tst_fs[1:11]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "series_trn = np.concatenate(\n",
    "    [bp.unpack_ndarray_from_file(os.path.join('../input/feats_srs', f)) for f in trn_fs],\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "series_lbl = [bp.unpack_ndarray_from_file(os.path.join('../input/feats_srs', f)) for f in lbl_fs]\n",
    "\n",
    "series_grp = np.concatenate(\n",
    "    [np.ones(shape=(arr.shape[0],)) * i for i, arr in zip([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], series_lbl)],\n",
    "    axis=0\n",
    ").astype(int)\n",
    "\n",
    "series_lbl = np.concatenate(\n",
    "    series_lbl,\n",
    "    axis=0\n",
    ")[:, :, None]\n",
    "\n",
    "series_tst = np.concatenate(\n",
    "    [bp.unpack_ndarray_from_file(os.path.join('../input/feats_srs', f)) for f in tst_fs],\n",
    "    axis=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_trn = pd.read_pickle('../input/train_clean_encoded.pkl')\n",
    "\n",
    "series_lbl = bp.unpack_ndarray_from_file(os.path.join('../input/feats_srs', 'trn_srs_lbl_all_s500_w500_feat_target_encoded.bp'))\n",
    "\n",
    "series_grp = np.concatenate(\n",
    "    [np.ones(shape=(series_lbl.shape[0] // 10,)) * i for i in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]],\n",
    "    axis=0\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>signal</th>\n",
       "      <th>open_channels</th>\n",
       "      <th>signal_0</th>\n",
       "      <th>signal_1</th>\n",
       "      <th>signal_2</th>\n",
       "      <th>signal_3</th>\n",
       "      <th>signal_4</th>\n",
       "      <th>signal_5</th>\n",
       "      <th>signal_6</th>\n",
       "      <th>...</th>\n",
       "      <th>signal_39</th>\n",
       "      <th>signal_40</th>\n",
       "      <th>signal_41</th>\n",
       "      <th>signal_42</th>\n",
       "      <th>signal_43</th>\n",
       "      <th>signal_44</th>\n",
       "      <th>signal_45</th>\n",
       "      <th>signal_46</th>\n",
       "      <th>signal_47</th>\n",
       "      <th>signal_48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>-2.760000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.435937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.453637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.462303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470284</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.673797</td>\n",
       "      <td>0.008540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>-2.855700</td>\n",
       "      <td>0</td>\n",
       "      <td>0.292407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.308404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335668</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.566845</td>\n",
       "      <td>0.003701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>-2.407400</td>\n",
       "      <td>0</td>\n",
       "      <td>0.897187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.902944</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.908428</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.885295</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.898396</td>\n",
       "      <td>0.063194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0004</td>\n",
       "      <td>-3.140400</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066310</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.310160</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>-3.152500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061386</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.301248</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999995</th>\n",
       "      <td>499.9996</td>\n",
       "      <td>2.919274</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990843</td>\n",
       "      <td>0.267996</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999996</th>\n",
       "      <td>499.9997</td>\n",
       "      <td>2.697906</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966391</td>\n",
       "      <td>0.124179</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999997</th>\n",
       "      <td>499.9998</td>\n",
       "      <td>4.516337</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999254</td>\n",
       "      <td>0.604478</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999998</th>\n",
       "      <td>499.9999</td>\n",
       "      <td>5.639669</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998614</td>\n",
       "      <td>0.500105</td>\n",
       "      <td>0.001428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999999</th>\n",
       "      <td>500.0000</td>\n",
       "      <td>5.379200</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990241</td>\n",
       "      <td>0.264886</td>\n",
       "      <td>0.000286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000000 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             time    signal  open_channels  signal_0  signal_1  signal_2  \\\n",
       "0          0.0001 -2.760000              0  0.435937       0.0  0.453637   \n",
       "1          0.0002 -2.855700              0  0.292407       0.0  0.308404   \n",
       "2          0.0003 -2.407400              0  0.897187       0.0  0.902944   \n",
       "3          0.0004 -3.140400              0  0.045574       0.0  0.050236   \n",
       "4          0.0005 -3.152500              0  0.041195       0.0  0.045377   \n",
       "...           ...       ...            ...       ...       ...       ...   \n",
       "4999995  499.9996  2.919274              7  0.999996       1.0  1.000000   \n",
       "4999996  499.9997  2.697906              7  0.999996       1.0  1.000000   \n",
       "4999997  499.9998  4.516337              8  0.999998       1.0  1.000000   \n",
       "4999998  499.9999  5.639669              9  1.000000       1.0  1.000000   \n",
       "4999999  500.0000  5.379200              9  1.000000       1.0  1.000000   \n",
       "\n",
       "         signal_3  signal_4  signal_5  signal_6  ...  signal_39  signal_40  \\\n",
       "0        0.000000  0.462303  0.000000  0.470284  ...        1.0   0.673797   \n",
       "1        0.000000  0.315577  0.000000  0.335668  ...        1.0   0.566845   \n",
       "2        0.000259  0.908428  0.000139  0.885295  ...        1.0   0.898396   \n",
       "3        0.000000  0.051367  0.000000  0.066310  ...        1.0   0.310160   \n",
       "4        0.000000  0.046395  0.000000  0.061386  ...        1.0   0.301248   \n",
       "...           ...       ...       ...       ...  ...        ...        ...   \n",
       "4999995  1.000000  1.000000  1.000000  1.000000  ...        1.0   1.000000   \n",
       "4999996  1.000000  1.000000  1.000000  1.000000  ...        1.0   1.000000   \n",
       "4999997  1.000000  1.000000  1.000000  1.000000  ...        1.0   1.000000   \n",
       "4999998  1.000000  1.000000  1.000000  1.000000  ...        1.0   1.000000   \n",
       "4999999  1.000000  1.000000  1.000000  1.000000  ...        1.0   1.000000   \n",
       "\n",
       "         signal_41  signal_42  signal_43  signal_44  signal_45  signal_46  \\\n",
       "0         0.008540        0.0        0.0   0.000000   0.000000   0.000000   \n",
       "1         0.003701        0.0        0.0   0.000000   0.000000   0.000000   \n",
       "2         0.063194        0.0        0.0   0.000000   0.000000   0.000000   \n",
       "3         0.000569        0.0        0.0   0.000000   0.000000   0.000000   \n",
       "4         0.000569        0.0        0.0   0.000000   0.000000   0.000000   \n",
       "...            ...        ...        ...        ...        ...        ...   \n",
       "4999995   1.000000        1.0        1.0   0.990843   0.267996   0.000131   \n",
       "4999996   1.000000        1.0        1.0   0.966391   0.124179   0.000008   \n",
       "4999997   1.000000        1.0        1.0   1.000000   0.999254   0.604478   \n",
       "4999998   1.000000        1.0        1.0   1.000000   1.000000   0.998614   \n",
       "4999999   1.000000        1.0        1.0   1.000000   1.000000   0.990241   \n",
       "\n",
       "         signal_47  signal_48  \n",
       "0         0.000000   0.000000  \n",
       "1         0.000000   0.000000  \n",
       "2         0.000000   0.000000  \n",
       "3         0.000000   0.000000  \n",
       "4         0.000000   0.000000  \n",
       "...            ...        ...  \n",
       "4999995   0.000000   0.000000  \n",
       "4999996   0.000000   0.000000  \n",
       "4999997   0.003535   0.000000  \n",
       "4999998   0.500105   0.001428  \n",
       "4999999   0.264886   0.000286  \n",
       "\n",
       "[5000000 rows x 52 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " array([1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(series_grp, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(500,),\n",
       " (500,),\n",
       " (500,),\n",
       " (500,),\n",
       " (500,),\n",
       " (500,),\n",
       " (500,),\n",
       " (500,),\n",
       " (500,),\n",
       " (500,)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 9, 9, 9])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_grp"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(series_trn.shape[-1]):\n",
    "    \n",
    "#     high= max(series_trn[:, :, i].max(), series_tst[:, :, i].max())\n",
    "#     low = min(series_trn[:, :, i].min(), series_tst[:, :, i].min())\n",
    "#     series_trn[:, :, i] = 2 * (series_trn[:, :, i] - low) / (high - low) - 1\n",
    "#     series_tst[:, :, i] = 2 * (series_tst[:, :, i] - low) / (high - low) - 1\n",
    "\n",
    "    avg = series_trn[:, :, i].mean()\n",
    "    std = series_trn[:, :, i].std()\n",
    "    series_trn[:, :, i] = (series_trn[:, :, i] - avg) / std\n",
    "    series_tst[:, :, i] = (series_tst[:, :, i] - avg) / std\n",
    "    \n",
    "    print(\n",
    "        'progress: {:02d} / {:02d}; trn max {:.3f}; trn min {:.3f}; tst max {:.3f}; tst min {:.3f}; '.format(\n",
    "            i+1, series_trn.shape[-1], series_trn[:, :, i].max(), series_trn[:, :, i].min(), series_tst[:, :, i].max(), series_tst[:, :, i].min()\n",
    "        ), \n",
    "        end='\\r'\n",
    "    )\n",
    "#     print(series_trn[:, :, i].max(), series_trn[:, :, i].min(), series_trn[:, :, i].std())\n",
    "#     print(series_tst[:, :, i].max(), series_tst[:, :, i].min(), series_tst[:, :, i].std())\n",
    "#     print('{:d} - max {:.3f}; min {:.3f};'.format(i, series_trn[:, :, i].max(), series_trn[:, :, i].min()))\n",
    "#     print('{:d} - max {:.3f}; min {:.3f};'.format(i, series_tst[:, :, i].max(), series_tst[:, :, i].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_skewness = [feature_calculators.binned_entropy(lst, max_bins=20) for lst in series_trn[:, :, 0].tolist()]\n",
    "\n",
    "lbl_skewness = pd.qcut(pd.Series(lbl_skewness), q=10, duplicates='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf_grp = [str(a) + '_' + str(b) for a, b in zip(series_grp, lbl_skewness)]\n",
    "us = np.unique(skf_grp)\n",
    "umap = {u: i for u, i in zip(us, range(len(us)))}\n",
    "skf_grp = [umap[u] for u in skf_grp]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "us, cs = np.unique(skf_grp, return_counts=True)\n",
    "for u, c in zip(us, cs):\n",
    "    print(u, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Waveset(Dataset):\n",
    "    def __init__(self, data, labels=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "        \n",
    "        if self.labels is None:\n",
    "            return data.astype(np.float32)\n",
    "        else:\n",
    "            labels = self.labels[idx]\n",
    "            return (data.astype(np.float32), labels.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_train_validate(model, optimizer, criterion, scheduler, training_loader, validation_loader, fold_number, save_path='./saved_models/wavenet_model_fold{:03d}_checkpoint.pth'):\n",
    "\n",
    "    trn_losses = [np.nan]\n",
    "    vld_losses = [np.nan]\n",
    "    vld_f1s = [np.nan]\n",
    "\n",
    "    for epc in range(EPOCHS):\n",
    "        print('===========================================================')\n",
    "\n",
    "        epoch_trn_losses = []\n",
    "        epoch_trn_lbls = []\n",
    "        epoch_trn_prds = []\n",
    "        epoch_vld_losses = []\n",
    "        epoch_vld_lbls = []\n",
    "        epoch_vld_prds = []\n",
    "\n",
    "        # ------ training ------\n",
    "        model.train()\n",
    "        for i, (trn_batch_dat, trn_batch_lbl) in enumerate(training_loader):\n",
    "            trn_batch_dat, trn_batch_lbl = trn_batch_dat.to(DEVICE), trn_batch_lbl.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            trn_batch_prd = model(trn_batch_dat)\n",
    "            trn_batch_prd = trn_batch_prd.view(-1, trn_batch_prd.size(-1))\n",
    "            trn_batch_lbl = trn_batch_lbl.view(-1)\n",
    "            loss = criterion(trn_batch_prd, trn_batch_lbl)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_trn_losses.append(loss.item())\n",
    "            epoch_trn_lbls.append(trn_batch_lbl.detach().cpu().numpy())\n",
    "            epoch_trn_prds.append(trn_batch_prd.detach().cpu().numpy())\n",
    "\n",
    "#             print(\n",
    "#                 'Epoch {:03d}/{:03d} - Training batch {:04d}/{:04d}: Training loss {:.6f};'.format(\n",
    "#                     epc + 1, EPOCHS, i + 1, len(training_loader), epoch_trn_losses[-1],\n",
    "#                 ), \n",
    "#                 end='\\r'\n",
    "#             )\n",
    "\n",
    "        # ------ validation ------\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (vld_batch_dat, vld_batch_lbl) in enumerate(validation_loader):\n",
    "                vld_batch_dat, vld_batch_lbl = vld_batch_dat.to(DEVICE), vld_batch_lbl.to(DEVICE)\n",
    "\n",
    "                vld_batch_prd = model(vld_batch_dat)\n",
    "                vld_batch_prd = vld_batch_prd.view(-1, vld_batch_prd.size(-1))\n",
    "                vld_batch_lbl = vld_batch_lbl.view(-1)\n",
    "                loss = criterion(trn_batch_prd, trn_batch_lbl)\n",
    "\n",
    "                epoch_vld_losses.append(loss.item())\n",
    "                epoch_vld_lbls.append(vld_batch_lbl.detach().cpu().numpy())\n",
    "                epoch_vld_prds.append(vld_batch_prd.detach().cpu().numpy())\n",
    "\n",
    "#                 print(\n",
    "#                     'Epoch {:03d}/{:03d} - Validation batch {:04d}/{:04d}: Validation loss {:.6f};'.format(\n",
    "#                         epc + 1, EPOCHS, i + 1, len(validation_loader), epoch_vld_losses[-1],\n",
    "#                     ), \n",
    "#                     end='\\r'\n",
    "#                 )\n",
    "\n",
    "        # ------ epoch end ------\n",
    "        f1_trn = f1_score(\n",
    "            np.concatenate(epoch_trn_lbls, axis=0), \n",
    "            np.concatenate(epoch_trn_prds, axis=0).argmax(1),\n",
    "            labels=list(range(11)), \n",
    "            average='macro'\n",
    "        )\n",
    "        f1_vld = f1_score(\n",
    "            np.concatenate(epoch_vld_lbls, axis=0), \n",
    "            np.concatenate(epoch_vld_prds, axis=0).argmax(1),\n",
    "            labels=list(range(11)), \n",
    "            average='macro'\n",
    "        )\n",
    "\n",
    "\n",
    "        print(\n",
    "            'Epoch {:03d}/{:03d} - Mean training loss {:.6f}; Mean training F1 {:.6f}; Mean validation loss {:.6f}; Mean validation F1 {:.6f}; Learning rate {:.6f};'.format(\n",
    "                epc + 1, EPOCHS, np.mean(epoch_trn_losses), f1_trn, np.mean(epoch_vld_losses), f1_vld, scheduler.get_lr()[0],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if f1_vld > np.nanmax(vld_f1s):\n",
    "            torch.save(\n",
    "                {\n",
    "                    'epoch': epc + 1,\n",
    "                    'model': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'f1': f1_vld,\n",
    "                    'loss': np.mean(epoch_vld_losses),\n",
    "                }, \n",
    "                save_path.format(fold_number)\n",
    "            )\n",
    "\n",
    "        vld_f1s.append(f1_vld)\n",
    "\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FOLDS = 5\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################\n",
      "Training/validation for fold 1/5;\n",
      "===========================================================\n",
      "Epoch 001/128 - Mean training loss 0.454704; Mean training F1 0.752384; Mean validation loss 0.235655; Mean validation F1 0.868708; Learning rate 0.001000;\n",
      "===========================================================\n",
      "Epoch 002/128 - Mean training loss 0.183747; Mean training F1 0.904458; Mean validation loss 0.114920; Mean validation F1 0.910588; Learning rate 0.001000;\n",
      "===========================================================\n",
      "Epoch 003/128 - Mean training loss 0.142105; Mean training F1 0.920413; Mean validation loss 0.116121; Mean validation F1 0.930021; Learning rate 0.000999;\n",
      "===========================================================\n",
      "Epoch 004/128 - Mean training loss 0.127167; Mean training F1 0.925275; Mean validation loss 0.108196; Mean validation F1 0.922306; Learning rate 0.000998;\n",
      "===========================================================\n",
      "Epoch 005/128 - Mean training loss 0.120072; Mean training F1 0.927495; Mean validation loss 0.114903; Mean validation F1 0.883737; Learning rate 0.000997;\n",
      "===========================================================\n",
      "Epoch 006/128 - Mean training loss 0.118646; Mean training F1 0.927288; Mean validation loss 0.110621; Mean validation F1 0.904925; Learning rate 0.000995;\n",
      "===========================================================\n",
      "Epoch 007/128 - Mean training loss 0.117540; Mean training F1 0.927981; Mean validation loss 0.058156; Mean validation F1 0.905910; Learning rate 0.000993;\n",
      "===========================================================\n",
      "Epoch 008/128 - Mean training loss 0.107561; Mean training F1 0.931490; Mean validation loss 0.091307; Mean validation F1 0.927151; Learning rate 0.000991;\n",
      "===========================================================\n",
      "Epoch 009/128 - Mean training loss 0.104918; Mean training F1 0.932114; Mean validation loss 0.161435; Mean validation F1 0.925600; Learning rate 0.000988;\n",
      "===========================================================\n",
      "Epoch 010/128 - Mean training loss 0.102040; Mean training F1 0.932888; Mean validation loss 0.076517; Mean validation F1 0.925991; Learning rate 0.000985;\n",
      "===========================================================\n",
      "Epoch 011/128 - Mean training loss 0.102571; Mean training F1 0.932163; Mean validation loss 0.085483; Mean validation F1 0.932345; Learning rate 0.000982;\n",
      "===========================================================\n",
      "Epoch 012/128 - Mean training loss 0.098115; Mean training F1 0.933974; Mean validation loss 0.068902; Mean validation F1 0.909787; Learning rate 0.000979;\n",
      "===========================================================\n",
      "Epoch 013/128 - Mean training loss 0.099437; Mean training F1 0.933384; Mean validation loss 0.090788; Mean validation F1 0.932568; Learning rate 0.000975;\n",
      "===========================================================\n",
      "Epoch 014/128 - Mean training loss 0.098342; Mean training F1 0.933530; Mean validation loss 0.130543; Mean validation F1 0.934069; Learning rate 0.000971;\n",
      "===========================================================\n",
      "Epoch 015/128 - Mean training loss 0.095612; Mean training F1 0.934539; Mean validation loss 0.102148; Mean validation F1 0.934021; Learning rate 0.000967;\n",
      "===========================================================\n",
      "Epoch 016/128 - Mean training loss 0.098209; Mean training F1 0.933430; Mean validation loss 0.125616; Mean validation F1 0.933060; Learning rate 0.000963;\n",
      "===========================================================\n",
      "Epoch 017/128 - Mean training loss 0.093998; Mean training F1 0.934764; Mean validation loss 0.078069; Mean validation F1 0.933238; Learning rate 0.000958;\n",
      "===========================================================\n",
      "Epoch 018/128 - Mean training loss 0.094000; Mean training F1 0.934649; Mean validation loss 0.121015; Mean validation F1 0.915134; Learning rate 0.000953;\n",
      "===========================================================\n",
      "Epoch 019/128 - Mean training loss 0.093265; Mean training F1 0.935001; Mean validation loss 0.101662; Mean validation F1 0.934048; Learning rate 0.000947;\n",
      "===========================================================\n",
      "Epoch 020/128 - Mean training loss 0.092863; Mean training F1 0.935057; Mean validation loss 0.098181; Mean validation F1 0.934806; Learning rate 0.000942;\n",
      "===========================================================\n",
      "Epoch 021/128 - Mean training loss 0.090990; Mean training F1 0.935748; Mean validation loss 0.098333; Mean validation F1 0.926582; Learning rate 0.000936;\n",
      "===========================================================\n",
      "Epoch 022/128 - Mean training loss 0.091293; Mean training F1 0.935687; Mean validation loss 0.091133; Mean validation F1 0.934688; Learning rate 0.000930;\n",
      "===========================================================\n",
      "Epoch 023/128 - Mean training loss 0.092811; Mean training F1 0.934635; Mean validation loss 0.090174; Mean validation F1 0.926278; Learning rate 0.000923;\n",
      "===========================================================\n",
      "Epoch 024/128 - Mean training loss 0.089991; Mean training F1 0.936024; Mean validation loss 0.082043; Mean validation F1 0.934512; Learning rate 0.000917;\n",
      "===========================================================\n",
      "Epoch 025/128 - Mean training loss 0.089285; Mean training F1 0.936309; Mean validation loss 0.081368; Mean validation F1 0.936317; Learning rate 0.000910;\n",
      "===========================================================\n",
      "Epoch 026/128 - Mean training loss 0.089004; Mean training F1 0.936419; Mean validation loss 0.080213; Mean validation F1 0.931341; Learning rate 0.000903;\n",
      "===========================================================\n",
      "Epoch 027/128 - Mean training loss 0.089217; Mean training F1 0.935964; Mean validation loss 0.063795; Mean validation F1 0.930727; Learning rate 0.000896;\n",
      "===========================================================\n",
      "Epoch 028/128 - Mean training loss 0.088362; Mean training F1 0.936556; Mean validation loss 0.083947; Mean validation F1 0.927748; Learning rate 0.000888;\n",
      "===========================================================\n",
      "Epoch 029/128 - Mean training loss 0.088878; Mean training F1 0.936554; Mean validation loss 0.085267; Mean validation F1 0.931984; Learning rate 0.000880;\n",
      "===========================================================\n",
      "Epoch 030/128 - Mean training loss 0.087548; Mean training F1 0.937072; Mean validation loss 0.093391; Mean validation F1 0.935788; Learning rate 0.000872;\n",
      "===========================================================\n",
      "Epoch 031/128 - Mean training loss 0.088213; Mean training F1 0.936616; Mean validation loss 0.088954; Mean validation F1 0.933682; Learning rate 0.000864;\n",
      "===========================================================\n",
      "Epoch 032/128 - Mean training loss 0.087435; Mean training F1 0.937087; Mean validation loss 0.059772; Mean validation F1 0.931670; Learning rate 0.000855;\n",
      "===========================================================\n",
      "Epoch 033/128 - Mean training loss 0.087555; Mean training F1 0.936735; Mean validation loss 0.146057; Mean validation F1 0.934528; Learning rate 0.000847;\n",
      "===========================================================\n",
      "Epoch 034/128 - Mean training loss 0.086577; Mean training F1 0.937451; Mean validation loss 0.097235; Mean validation F1 0.928573; Learning rate 0.000838;\n",
      "===========================================================\n",
      "Epoch 035/128 - Mean training loss 0.087228; Mean training F1 0.936935; Mean validation loss 0.068145; Mean validation F1 0.931849; Learning rate 0.000829;\n",
      "===========================================================\n",
      "Epoch 036/128 - Mean training loss 0.085898; Mean training F1 0.937272; Mean validation loss 0.069215; Mean validation F1 0.937502; Learning rate 0.000819;\n",
      "===========================================================\n",
      "Epoch 037/128 - Mean training loss 0.085950; Mean training F1 0.937504; Mean validation loss 0.072610; Mean validation F1 0.936290; Learning rate 0.000810;\n",
      "===========================================================\n",
      "Epoch 038/128 - Mean training loss 0.085768; Mean training F1 0.937622; Mean validation loss 0.088761; Mean validation F1 0.930907; Learning rate 0.000800;\n",
      "===========================================================\n",
      "Epoch 039/128 - Mean training loss 0.119161; Mean training F1 0.924352; Mean validation loss 0.131309; Mean validation F1 0.934308; Learning rate 0.000790;\n",
      "===========================================================\n",
      "Epoch 040/128 - Mean training loss 0.092500; Mean training F1 0.935131; Mean validation loss 0.060064; Mean validation F1 0.934954; Learning rate 0.000780;\n",
      "===========================================================\n",
      "Epoch 041/128 - Mean training loss 0.088713; Mean training F1 0.936471; Mean validation loss 0.100460; Mean validation F1 0.936653; Learning rate 0.000770;\n",
      "===========================================================\n",
      "Epoch 042/128 - Mean training loss 0.087567; Mean training F1 0.936958; Mean validation loss 0.105487; Mean validation F1 0.936554; Learning rate 0.000760;\n",
      "===========================================================\n",
      "Epoch 043/128 - Mean training loss 0.087004; Mean training F1 0.937271; Mean validation loss 0.078490; Mean validation F1 0.937646; Learning rate 0.000749;\n",
      "===========================================================\n",
      "Epoch 044/128 - Mean training loss 0.085826; Mean training F1 0.937345; Mean validation loss 0.068538; Mean validation F1 0.936423; Learning rate 0.000739;\n",
      "===========================================================\n",
      "Epoch 045/128 - Mean training loss 0.085674; Mean training F1 0.937568; Mean validation loss 0.062399; Mean validation F1 0.935405; Learning rate 0.000728;\n",
      "===========================================================\n",
      "Epoch 046/128 - Mean training loss 0.085556; Mean training F1 0.937736; Mean validation loss 0.088563; Mean validation F1 0.936248; Learning rate 0.000717;\n",
      "===========================================================\n",
      "Epoch 047/128 - Mean training loss 0.085579; Mean training F1 0.937470; Mean validation loss 0.070902; Mean validation F1 0.935583; Learning rate 0.000706;\n",
      "===========================================================\n",
      "Epoch 048/128 - Mean training loss 0.085003; Mean training F1 0.937918; Mean validation loss 0.095264; Mean validation F1 0.937492; Learning rate 0.000695;\n",
      "===========================================================\n",
      "Epoch 049/128 - Mean training loss 0.084741; Mean training F1 0.937887; Mean validation loss 0.078799; Mean validation F1 0.936541; Learning rate 0.000683;\n",
      "===========================================================\n",
      "Epoch 050/128 - Mean training loss 0.084551; Mean training F1 0.938028; Mean validation loss 0.074012; Mean validation F1 0.936976; Learning rate 0.000672;\n",
      "===========================================================\n",
      "Epoch 051/128 - Mean training loss 0.084788; Mean training F1 0.937725; Mean validation loss 0.049457; Mean validation F1 0.937621; Learning rate 0.000661;\n",
      "===========================================================\n",
      "Epoch 052/128 - Mean training loss 0.084291; Mean training F1 0.938154; Mean validation loss 0.097025; Mean validation F1 0.937233; Learning rate 0.000649;\n",
      "===========================================================\n",
      "Epoch 053/128 - Mean training loss 0.084323; Mean training F1 0.937996; Mean validation loss 0.098507; Mean validation F1 0.935349; Learning rate 0.000637;\n",
      "===========================================================\n",
      "Epoch 054/128 - Mean training loss 0.084649; Mean training F1 0.938049; Mean validation loss 0.072711; Mean validation F1 0.937514; Learning rate 0.000626;\n",
      "===========================================================\n",
      "Epoch 055/128 - Mean training loss 0.084251; Mean training F1 0.938300; Mean validation loss 0.093277; Mean validation F1 0.936841; Learning rate 0.000614;\n",
      "===========================================================\n",
      "Epoch 056/128 - Mean training loss 0.084238; Mean training F1 0.938098; Mean validation loss 0.061042; Mean validation F1 0.936433; Learning rate 0.000602;\n",
      "===========================================================\n",
      "Epoch 057/128 - Mean training loss 0.084591; Mean training F1 0.937980; Mean validation loss 0.074831; Mean validation F1 0.937716; Learning rate 0.000590;\n",
      "===========================================================\n",
      "Epoch 058/128 - Mean training loss 0.083933; Mean training F1 0.938382; Mean validation loss 0.128268; Mean validation F1 0.937611; Learning rate 0.000578;\n",
      "===========================================================\n",
      "Epoch 059/128 - Mean training loss 0.083561; Mean training F1 0.938469; Mean validation loss 0.086266; Mean validation F1 0.931716; Learning rate 0.000566;\n",
      "===========================================================\n",
      "Epoch 060/128 - Mean training loss 0.083790; Mean training F1 0.938303; Mean validation loss 0.080172; Mean validation F1 0.934402; Learning rate 0.000554;\n",
      "===========================================================\n",
      "Epoch 061/128 - Mean training loss 0.083687; Mean training F1 0.938381; Mean validation loss 0.090960; Mean validation F1 0.937303; Learning rate 0.000542;\n",
      "===========================================================\n",
      "Epoch 062/128 - Mean training loss 0.084041; Mean training F1 0.938286; Mean validation loss 0.063932; Mean validation F1 0.937667; Learning rate 0.000530;\n",
      "===========================================================\n",
      "Epoch 063/128 - Mean training loss 0.084755; Mean training F1 0.938115; Mean validation loss 0.077203; Mean validation F1 0.919868; Learning rate 0.000517;\n",
      "===========================================================\n",
      "Epoch 064/128 - Mean training loss 0.084562; Mean training F1 0.938098; Mean validation loss 0.110722; Mean validation F1 0.934649; Learning rate 0.000505;\n",
      "===========================================================\n",
      "Epoch 065/128 - Mean training loss 0.083305; Mean training F1 0.938575; Mean validation loss 0.050447; Mean validation F1 0.938216; Learning rate 0.000493;\n",
      "===========================================================\n",
      "Epoch 066/128 - Mean training loss 0.083070; Mean training F1 0.938723; Mean validation loss 0.088293; Mean validation F1 0.935945; Learning rate 0.000481;\n",
      "===========================================================\n",
      "Epoch 067/128 - Mean training loss 0.083073; Mean training F1 0.938701; Mean validation loss 0.111353; Mean validation F1 0.936209; Learning rate 0.000469;\n",
      "===========================================================\n",
      "Epoch 068/128 - Mean training loss 0.082917; Mean training F1 0.938738; Mean validation loss 0.096077; Mean validation F1 0.938194; Learning rate 0.000457;\n",
      "===========================================================\n",
      "Epoch 069/128 - Mean training loss 0.083196; Mean training F1 0.938735; Mean validation loss 0.066515; Mean validation F1 0.937517; Learning rate 0.000445;\n",
      "===========================================================\n",
      "Epoch 070/128 - Mean training loss 0.082985; Mean training F1 0.938686; Mean validation loss 0.071607; Mean validation F1 0.937967; Learning rate 0.000433;\n",
      "===========================================================\n",
      "Epoch 071/128 - Mean training loss 0.083079; Mean training F1 0.938746; Mean validation loss 0.065501; Mean validation F1 0.938063; Learning rate 0.000421;\n",
      "===========================================================\n",
      "Epoch 072/128 - Mean training loss 0.082759; Mean training F1 0.938850; Mean validation loss 0.115366; Mean validation F1 0.937891; Learning rate 0.000409;\n",
      "===========================================================\n",
      "Epoch 073/128 - Mean training loss 0.082689; Mean training F1 0.938945; Mean validation loss 0.085196; Mean validation F1 0.937368; Learning rate 0.000397;\n",
      "===========================================================\n",
      "Epoch 074/128 - Mean training loss 0.083153; Mean training F1 0.938603; Mean validation loss 0.063078; Mean validation F1 0.937410; Learning rate 0.000385;\n",
      "===========================================================\n",
      "Epoch 075/128 - Mean training loss 0.082501; Mean training F1 0.939047; Mean validation loss 0.091337; Mean validation F1 0.937390; Learning rate 0.000373;\n",
      "===========================================================\n",
      "Epoch 076/128 - Mean training loss 0.083111; Mean training F1 0.938717; Mean validation loss 0.116192; Mean validation F1 0.937694; Learning rate 0.000362;\n",
      "===========================================================\n",
      "Epoch 077/128 - Mean training loss 0.082986; Mean training F1 0.938684; Mean validation loss 0.128623; Mean validation F1 0.936741; Learning rate 0.000350;\n",
      "===========================================================\n",
      "Epoch 078/128 - Mean training loss 0.082221; Mean training F1 0.939127; Mean validation loss 0.089918; Mean validation F1 0.938055; Learning rate 0.000339;\n",
      "===========================================================\n",
      "Epoch 079/128 - Mean training loss 0.082500; Mean training F1 0.938937; Mean validation loss 0.095858; Mean validation F1 0.938123; Learning rate 0.000327;\n",
      "===========================================================\n",
      "Epoch 080/128 - Mean training loss 0.082324; Mean training F1 0.939123; Mean validation loss 0.093575; Mean validation F1 0.937956; Learning rate 0.000316;\n",
      "===========================================================\n",
      "Epoch 081/128 - Mean training loss 0.082132; Mean training F1 0.939176; Mean validation loss 0.114035; Mean validation F1 0.937895; Learning rate 0.000305;\n",
      "===========================================================\n",
      "Epoch 082/128 - Mean training loss 0.082101; Mean training F1 0.939166; Mean validation loss 0.076559; Mean validation F1 0.937469; Learning rate 0.000294;\n",
      "===========================================================\n",
      "Epoch 083/128 - Mean training loss 0.082094; Mean training F1 0.939209; Mean validation loss 0.084262; Mean validation F1 0.937346; Learning rate 0.000283;\n",
      "===========================================================\n",
      "Epoch 084/128 - Mean training loss 0.082091; Mean training F1 0.939209; Mean validation loss 0.071758; Mean validation F1 0.937852; Learning rate 0.000272;\n",
      "===========================================================\n",
      "Epoch 085/128 - Mean training loss 0.081915; Mean training F1 0.939279; Mean validation loss 0.131780; Mean validation F1 0.937397; Learning rate 0.000261;\n",
      "===========================================================\n",
      "Epoch 086/128 - Mean training loss 0.081839; Mean training F1 0.939357; Mean validation loss 0.049181; Mean validation F1 0.937434; Learning rate 0.000251;\n",
      "===========================================================\n",
      "Epoch 087/128 - Mean training loss 0.081741; Mean training F1 0.939369; Mean validation loss 0.114885; Mean validation F1 0.937871; Learning rate 0.000240;\n",
      "===========================================================\n",
      "Epoch 088/128 - Mean training loss 0.081634; Mean training F1 0.939402; Mean validation loss 0.069987; Mean validation F1 0.937466; Learning rate 0.000230;\n",
      "===========================================================\n",
      "Epoch 089/128 - Mean training loss 0.081837; Mean training F1 0.939437; Mean validation loss 0.075373; Mean validation F1 0.937852; Learning rate 0.000220;\n",
      "===========================================================\n",
      "Epoch 090/128 - Mean training loss 0.081566; Mean training F1 0.939383; Mean validation loss 0.081617; Mean validation F1 0.937892; Learning rate 0.000210;\n",
      "===========================================================\n",
      "Epoch 091/128 - Mean training loss 0.081560; Mean training F1 0.939345; Mean validation loss 0.049602; Mean validation F1 0.937605; Learning rate 0.000201;\n",
      "===========================================================\n",
      "Epoch 092/128 - Mean training loss 0.081504; Mean training F1 0.939372; Mean validation loss 0.118655; Mean validation F1 0.938005; Learning rate 0.000191;\n",
      "===========================================================\n",
      "Epoch 093/128 - Mean training loss 0.081483; Mean training F1 0.939480; Mean validation loss 0.083128; Mean validation F1 0.937848; Learning rate 0.000182;\n",
      "===========================================================\n",
      "Epoch 094/128 - Mean training loss 0.083152; Mean training F1 0.938703; Mean validation loss 0.087367; Mean validation F1 0.937583; Learning rate 0.000173;\n",
      "===========================================================\n",
      "Epoch 095/128 - Mean training loss 0.081388; Mean training F1 0.939488; Mean validation loss 0.065898; Mean validation F1 0.938090; Learning rate 0.000164;\n",
      "===========================================================\n",
      "Epoch 096/128 - Mean training loss 0.081301; Mean training F1 0.939709; Mean validation loss 0.079324; Mean validation F1 0.938189; Learning rate 0.000155;\n",
      "===========================================================\n",
      "Epoch 097/128 - Mean training loss 0.081242; Mean training F1 0.939668; Mean validation loss 0.076853; Mean validation F1 0.938147; Learning rate 0.000147;\n",
      "===========================================================\n",
      "Epoch 098/128 - Mean training loss 0.081164; Mean training F1 0.939674; Mean validation loss 0.091606; Mean validation F1 0.937978; Learning rate 0.000139;\n",
      "===========================================================\n",
      "Epoch 099/128 - Mean training loss 0.081235; Mean training F1 0.939675; Mean validation loss 0.097966; Mean validation F1 0.937877; Learning rate 0.000130;\n",
      "===========================================================\n",
      "Epoch 100/128 - Mean training loss 0.081111; Mean training F1 0.939678; Mean validation loss 0.054214; Mean validation F1 0.938035; Learning rate 0.000123;\n",
      "===========================================================\n",
      "Epoch 101/128 - Mean training loss 0.081126; Mean training F1 0.939674; Mean validation loss 0.057750; Mean validation F1 0.937859; Learning rate 0.000115;\n",
      "===========================================================\n",
      "Epoch 102/128 - Mean training loss 0.081027; Mean training F1 0.939669; Mean validation loss 0.081932; Mean validation F1 0.937971; Learning rate 0.000108;\n",
      "===========================================================\n",
      "Epoch 103/128 - Mean training loss 0.081010; Mean training F1 0.939784; Mean validation loss 0.082992; Mean validation F1 0.937985; Learning rate 0.000101;\n",
      "===========================================================\n",
      "Epoch 104/128 - Mean training loss 0.080956; Mean training F1 0.939794; Mean validation loss 0.089459; Mean validation F1 0.937985; Learning rate 0.000094;\n",
      "===========================================================\n",
      "Epoch 105/128 - Mean training loss 0.081146; Mean training F1 0.939764; Mean validation loss 0.081344; Mean validation F1 0.937852; Learning rate 0.000087;\n",
      "===========================================================\n",
      "Epoch 106/128 - Mean training loss 0.080928; Mean training F1 0.939836; Mean validation loss 0.112390; Mean validation F1 0.938161; Learning rate 0.000081;\n",
      "===========================================================\n",
      "Epoch 107/128 - Mean training loss 0.080902; Mean training F1 0.939916; Mean validation loss 0.052185; Mean validation F1 0.938082; Learning rate 0.000075;\n",
      "===========================================================\n",
      "Epoch 108/128 - Mean training loss 0.080924; Mean training F1 0.939787; Mean validation loss 0.042447; Mean validation F1 0.938082; Learning rate 0.000069;\n",
      "===========================================================\n",
      "Epoch 109/128 - Mean training loss 0.080857; Mean training F1 0.939768; Mean validation loss 0.095907; Mean validation F1 0.938202; Learning rate 0.000063;\n",
      "===========================================================\n",
      "Epoch 110/128 - Mean training loss 0.080832; Mean training F1 0.939761; Mean validation loss 0.100330; Mean validation F1 0.938121; Learning rate 0.000058;\n",
      "===========================================================\n",
      "Epoch 111/128 - Mean training loss 0.080810; Mean training F1 0.939839; Mean validation loss 0.087099; Mean validation F1 0.938123; Learning rate 0.000053;\n",
      "===========================================================\n",
      "Epoch 112/128 - Mean training loss 0.080748; Mean training F1 0.939842; Mean validation loss 0.092007; Mean validation F1 0.938229; Learning rate 0.000048;\n",
      "===========================================================\n",
      "Epoch 113/128 - Mean training loss 0.080724; Mean training F1 0.939938; Mean validation loss 0.087568; Mean validation F1 0.938015; Learning rate 0.000043;\n",
      "===========================================================\n",
      "Epoch 114/128 - Mean training loss 0.080731; Mean training F1 0.939932; Mean validation loss 0.079349; Mean validation F1 0.938192; Learning rate 0.000039;\n",
      "===========================================================\n",
      "Epoch 115/128 - Mean training loss 0.080738; Mean training F1 0.939909; Mean validation loss 0.078457; Mean validation F1 0.938043; Learning rate 0.000035;\n",
      "===========================================================\n",
      "Epoch 116/128 - Mean training loss 0.080685; Mean training F1 0.939866; Mean validation loss 0.079243; Mean validation F1 0.938202; Learning rate 0.000032;\n",
      "===========================================================\n",
      "Epoch 117/128 - Mean training loss 0.080670; Mean training F1 0.939916; Mean validation loss 0.070477; Mean validation F1 0.938126; Learning rate 0.000028;\n",
      "===========================================================\n",
      "Epoch 118/128 - Mean training loss 0.080618; Mean training F1 0.939968; Mean validation loss 0.097240; Mean validation F1 0.938314; Learning rate 0.000025;\n",
      "===========================================================\n",
      "Epoch 119/128 - Mean training loss 0.080627; Mean training F1 0.939996; Mean validation loss 0.086037; Mean validation F1 0.938077; Learning rate 0.000022;\n",
      "===========================================================\n",
      "Epoch 120/128 - Mean training loss 0.080641; Mean training F1 0.939942; Mean validation loss 0.085704; Mean validation F1 0.938297; Learning rate 0.000020;\n",
      "===========================================================\n",
      "Epoch 121/128 - Mean training loss 0.080579; Mean training F1 0.940019; Mean validation loss 0.084496; Mean validation F1 0.938184; Learning rate 0.000018;\n",
      "===========================================================\n",
      "Epoch 122/128 - Mean training loss 0.080611; Mean training F1 0.940123; Mean validation loss 0.080589; Mean validation F1 0.938164; Learning rate 0.000016;\n",
      "===========================================================\n",
      "Epoch 123/128 - Mean training loss 0.080558; Mean training F1 0.940042; Mean validation loss 0.057941; Mean validation F1 0.938185; Learning rate 0.000014;\n",
      "===========================================================\n",
      "Epoch 124/128 - Mean training loss 0.080643; Mean training F1 0.940097; Mean validation loss 0.083538; Mean validation F1 0.938163; Learning rate 0.000013;\n",
      "===========================================================\n",
      "Epoch 125/128 - Mean training loss 0.080560; Mean training F1 0.939989; Mean validation loss 0.071918; Mean validation F1 0.938175; Learning rate 0.000012;\n",
      "===========================================================\n",
      "Epoch 126/128 - Mean training loss 0.080621; Mean training F1 0.940014; Mean validation loss 0.108610; Mean validation F1 0.938230; Learning rate 0.000011;\n",
      "===========================================================\n",
      "Epoch 127/128 - Mean training loss 0.080624; Mean training F1 0.940019; Mean validation loss 0.077312; Mean validation F1 0.938174; Learning rate 0.000010;\n",
      "===========================================================\n",
      "Epoch 128/128 - Mean training loss 0.080533; Mean training F1 0.940053; Mean validation loss 0.087472; Mean validation F1 0.938157; Learning rate 0.000010;\n",
      "################################################################\n",
      "Training/validation for fold 2/5;\n",
      "===========================================================\n",
      "Epoch 001/128 - Mean training loss 0.483452; Mean training F1 0.742301; Mean validation loss 0.230383; Mean validation F1 0.883428; Learning rate 0.001000;\n",
      "===========================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6b25442efaa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mtraining_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloader_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloader_vld\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mfold_number\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfld\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./saved_models/wavenet_model_backtobasic_s500w500_fold{:03d}_checkpoint.pth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     )\n",
      "\u001b[0;32m<ipython-input-10-64974504c8e5>\u001b[0m in \u001b[0;36mfold_train_validate\u001b[0;34m(model, optimizer, criterion, scheduler, training_loader, validation_loader, fold_number, save_path)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mtrn_batch_prd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_batch_dat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mtrn_batch_prd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrn_batch_prd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_batch_prd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mtrn_batch_lbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrn_batch_lbl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/kaggle/ion_switching/code/NNs.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwave_block3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwave_block4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for fld, (ndcs_trn, ndcs_vld) in enumerate(skf.split(series_trn, skf_grp)):\n",
    "    print('################################################################')\n",
    "    print('Training/validation for fold {:d}/{:d};'.format(fld+1, N_FOLDS))\n",
    "    \n",
    "    # setup fold data\n",
    "    dat_trn, lbl_trn = series_trn[ndcs_trn], series_lbl[ndcs_trn]\n",
    "    dat_vld, lbl_vld = series_trn[ndcs_vld], series_lbl[ndcs_vld]\n",
    "    \n",
    "    waveset_trn = Waveset(dat_trn, lbl_trn)\n",
    "    waveset_vld = Waveset(dat_vld, lbl_vld)\n",
    "\n",
    "    loader_trn = DataLoader(waveset_trn, BATCHSIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    loader_vld = DataLoader(waveset_vld, BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    \n",
    "    # setup fold model\n",
    "    mdl = Wave_Classifier(series_trn.shape[-1]).to(DEVICE)\n",
    "    critrn = nn.CrossEntropyLoss()\n",
    "    optimzr = torch.optim.AdamW(mdl.parameters(), lr=LR)\n",
    "    schdlr = torch.optim.lr_scheduler.CosineAnnealingLR(optimzr, T_max=EPOCHS, eta_min=LR/100)\n",
    "    \n",
    "    # run\n",
    "    fold_train_validate(\n",
    "        model=mdl, optimizer=optimzr, criterion=critrn, scheduler=schdlr, \n",
    "        training_loader=loader_trn, validation_loader=loader_vld, \n",
    "        fold_number=fld,\n",
    "        save_path='./saved_models/wavenet_model_backtobasic_s500w500_fold{:03d}_checkpoint.pth',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv', dtype={'time': str, 'open_channels': 'Int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- fold 0 --------\n",
      "model validation loss: 0.077; validation f1: 0.939;\n",
      "-------- fold 1 --------\n",
      "model validation loss: 0.144; validation f1: 0.938;\n",
      "-------- fold 2 --------\n",
      "model validation loss: 0.093; validation f1: 0.937;\n",
      "-------- fold 3 --------\n",
      "model validation loss: 0.096; validation f1: 0.939;\n",
      "-------- fold 4 --------\n",
      "model validation loss: 0.058; validation f1: 0.939;\n"
     ]
    }
   ],
   "source": [
    "submission_pred = np.zeros(shape=(submission.shape[0], 11))\n",
    "\n",
    "waveset_tst = Waveset(series_tst)\n",
    "loader_tst = DataLoader(waveset_tst, BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "for fld in range(5):\n",
    "    print('-------- fold {:d} --------'.format(fld))\n",
    "    fld_weight = torch.load('./saved_models/wavenet_model_backtobasic_s500w500_fold{:03d}_checkpoint.pth'.format(fld))\n",
    "    print('model validation loss: {:.3f}; validation f1: {:.3f};'.format(fld_weight['loss'], fld_weight['f1']))\n",
    "#     mdl = Wave_Classifier(series_tst.shape[-1]).to(DEVICE)\n",
    "#     mdl.load_state_dict(fld_weight['model'])\n",
    "#     with torch.no_grad():\n",
    "#         tst_fold_prd = []\n",
    "#         for tst_batch_dat in loader_tst:\n",
    "#             tst_batch_prd = mdl(tst_batch_dat.to(DEVICE))\n",
    "#             tst_batch_prd = tst_batch_prd.view(-1, tst_batch_prd.size(-1)).detach().cpu().numpy()\n",
    "#             tst_fold_prd.append(tst_batch_prd)\n",
    "            \n",
    "#         submission_pred += np.concatenate(tst_fold_prd, 0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "submission['open_channels'] = submission_pred.argmax(1)\n",
    "submission.to_csv(\"../submissions/sub3_waveRNN_basicwithnew2_cvbyentropy_meanstdnorm_w500.csv\", index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "for ndcs_trn, ndcs_vld in skf.split(series_trn, skf_grp):\n",
    "    dat_trn, lbl_trn = series_trn[ndcs_trn], series_lbl[ndcs_trn]\n",
    "    dat_vld, lbl_vld = series_trn[ndcs_vld], series_lbl[ndcs_vld]\n",
    "    break"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "mdl = Wave_Classifier(49).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(mdl.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=LR/100)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "waveset_trn = Waveset(dat_trn, lbl_trn)\n",
    "waveset_vld = Waveset(dat_vld, lbl_vld)\n",
    "\n",
    "loader_trn = DataLoader(waveset_trn, BATCHSIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "loader_vld = DataLoader(waveset_vld, BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "trn_losses = [np.nan]\n",
    "vld_losses = [np.nan]\n",
    "vld_f1s = [np.nan]\n",
    "\n",
    "for epc in range(EPOCHS):\n",
    "    print('===========================================================')\n",
    "    \n",
    "    epoch_trn_losses = []\n",
    "    epoch_trn_lbls = []\n",
    "    epoch_trn_prds = []\n",
    "    epoch_vld_losses = []\n",
    "    epoch_vld_lbls = []\n",
    "    epoch_vld_prds = []\n",
    "    \n",
    "    # ------ training ------\n",
    "    mdl.train()\n",
    "    for i, (trn_batch_dat, trn_batch_lbl) in enumerate(loader_trn):\n",
    "        trn_batch_dat, trn_batch_lbl = trn_batch_dat.to(DEVICE), trn_batch_lbl.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        trn_batch_prd = mdl(trn_batch_dat)\n",
    "        trn_batch_prd = trn_batch_prd.view(-1, trn_batch_prd.size(-1))\n",
    "        trn_batch_lbl = trn_batch_lbl.view(-1)\n",
    "        loss = criterion(trn_batch_prd, trn_batch_lbl)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_trn_losses.append(loss.item())\n",
    "        epoch_trn_lbls.append(trn_batch_lbl.detach().cpu().numpy())\n",
    "        epoch_trn_prds.append(trn_batch_prd.detach().cpu().numpy())\n",
    "        \n",
    "        print(\n",
    "            'Epoch {:03d}/{:03d} - Training batch {:04d}/{:04d}: Training loss {:.6f};'.format(\n",
    "                epc + 1, EPOCHS, i + 1, len(loader_trn), epoch_trn_losses[-1],\n",
    "            ), \n",
    "            end='\\r'\n",
    "        )\n",
    "    \n",
    "    # ------ validation ------\n",
    "    mdl.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (vld_batch_dat, vld_batch_lbl) in enumerate(loader_vld):\n",
    "            vld_batch_dat, vld_batch_lbl = vld_batch_dat.to(DEVICE), vld_batch_lbl.to(DEVICE)\n",
    "            \n",
    "            vld_batch_prd = mdl(vld_batch_dat)\n",
    "            vld_batch_prd = vld_batch_prd.view(-1, vld_batch_prd.size(-1))\n",
    "            vld_batch_lbl = vld_batch_lbl.view(-1)\n",
    "            loss = criterion(trn_batch_prd, trn_batch_lbl)\n",
    "            \n",
    "            epoch_vld_losses.append(loss.item())\n",
    "            epoch_vld_lbls.append(vld_batch_lbl.detach().cpu().numpy())\n",
    "            epoch_vld_prds.append(vld_batch_prd.detach().cpu().numpy())\n",
    "            \n",
    "            print(\n",
    "                'Epoch {:03d}/{:03d} - Validation batch {:04d}/{:04d}: Validation loss {:.6f};'.format(\n",
    "                    epc + 1, EPOCHS, i + 1, len(loader_vld), epoch_vld_losses[-1],\n",
    "                ), \n",
    "                end='\\r'\n",
    "            )\n",
    "    \n",
    "    # ------ epoch end ------\n",
    "    f1_trn = f1_score(\n",
    "        np.concatenate(epoch_trn_lbls, axis=0), \n",
    "        np.concatenate(epoch_trn_prds, axis=0).argmax(1),\n",
    "        labels=list(range(11)), \n",
    "        average='macro'\n",
    "    )\n",
    "    f1_vld = f1_score(\n",
    "        np.concatenate(epoch_vld_lbls, axis=0), \n",
    "        np.concatenate(epoch_vld_prds, axis=0).argmax(1),\n",
    "        labels=list(range(11)), \n",
    "        average='macro'\n",
    "    )\n",
    "    \n",
    "    \n",
    "    print(\n",
    "        'Epoch {:03d}/{:03d} - Mean training loss {:.6f}; Mean training F1 {:.6f}; Mean validation loss {:.6f}; Mean validation F1 {:.6f}; Learning rate {:.6f};'.format(\n",
    "            epc + 1, EPOCHS, np.mean(epoch_trn_losses), f1_trn, np.mean(epoch_vld_losses), f1_vld, scheduler.get_lr()[0],\n",
    "        )\n",
    "    )\n",
    "    \n",
    "#     if f1_vld > np.max(vld_f1s):\n",
    "#         torch.save(\n",
    "#             {\n",
    "#                 'epoch': epc + 1,\n",
    "#                 'model': mdl.state_dict(),\n",
    "#                 'optimizer': optimizer.state_dict(),\n",
    "#                 'f1': f1_vld,\n",
    "#                 'loss': np.mean(epoch_vld_losses),\n",
    "#             }, \n",
    "#             './checkpoints/wavenet_model_fold{:03d}_checkpoint.pth'.format(fld)\n",
    "#         )\n",
    "    \n",
    "#     vld_f1s.append(f1_vld)\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "for index, (train_index, val_index, _) in enumerate(new_splits[0:], start=0):\n",
    "    print(\"Fold : {}\".format(index))\n",
    "    train_dataset = IronDataset(train[train_index], train_tr[train_index], seq_len=GROUP_BATCH_SIZE, flip=flip, noise_level=noise)\n",
    "    train_dataloader = DataLoader(train_dataset, NNBATCHSIZE, shuffle=True, num_workers=8, pin_memory=True)\n",
    "\n",
    "    valid_dataset = IronDataset(train[val_index], train_tr[val_index], seq_len=GROUP_BATCH_SIZE, flip=False)\n",
    "    valid_dataloader = DataLoader(valid_dataset, NNBATCHSIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    it = 0\n",
    "    model = Classifier()\n",
    "    model = model.cuda()\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=40, is_maximize=True,\n",
    "                                   checkpoint_path=os.path.join(outdir, \"gru_clean_checkpoint_fold_{}_iter_{}.pt\".format(index,\n",
    "                                                                                                             it)))\n",
    "\n",
    "    weight = None#cal_weights()\n",
    "    criterion = nn.CrossEntropyLoss(weight=weight)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "\n",
    "    schedular = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, factor=0.2)\n",
    "    avg_train_losses, avg_valid_losses = [], []\n",
    "\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        print('**********************************')\n",
    "        print(\"Folder : {} Epoch : {}\".format(index, epoch))\n",
    "        print(\"Curr learning_rate: {:0.9f}\".format(optimizer.param_groups[0]['lr']))\n",
    "        train_losses, valid_losses = [], []\n",
    "        tr_loss_cls_item, val_loss_cls_item = [], []\n",
    "\n",
    "        model.train()  # prep model for training\n",
    "        train_preds, train_true = torch.Tensor([]).cuda(), torch.LongTensor([]).cuda()#.to(device)\n",
    "\n",
    "        for x, y in tqdm(train_dataloader):\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(x)\n",
    "\n",
    "            predictions_ = predictions.view(-1, predictions.shape[-1])\n",
    "            y_ = y.view(-1)\n",
    "\n",
    "            loss = criterion(predictions_, y_)\n",
    "\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            #schedular.step()\n",
    "            # record training lossa\n",
    "            train_losses.append(loss.item())\n",
    "            train_true = torch.cat([train_true, y_], 0)\n",
    "            train_preds = torch.cat([train_preds, predictions_], 0)\n",
    "\n",
    "        model.eval()  # prep model for evaluation\n",
    "        val_preds, val_true = torch.Tensor([]).cuda(), torch.LongTensor([]).cuda()\n",
    "        print('EVALUATION')\n",
    "        with torch.no_grad():\n",
    "            for x, y in tqdm(valid_dataloader):\n",
    "                x = x.cuda()#.to(device)\n",
    "                y = y.cuda()#..to(device)\n",
    "\n",
    "                predictions = model(x)\n",
    "                predictions_ = predictions.view(-1, predictions.shape[-1])\n",
    "                y_ = y.view(-1)\n",
    "\n",
    "                loss = criterion(predictions_, y_)\n",
    "\n",
    "                valid_losses.append(loss.item())\n",
    "\n",
    "\n",
    "                val_true = torch.cat([val_true, y_], 0)\n",
    "                val_preds = torch.cat([val_preds, predictions_], 0)\n",
    "\n",
    "        # calculate average loss over an epoch\n",
    "        train_loss = np.average(train_losses)\n",
    "        valid_loss = np.average(valid_losses)\n",
    "        avg_train_losses.append(train_loss)\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "        print(\"train_loss: {:0.6f}, valid_loss: {:0.6f}\".format(train_loss, valid_loss))\n",
    "\n",
    "        train_score = f1_score(train_true.cpu().detach().numpy(), train_preds.cpu().detach().numpy().argmax(1),\n",
    "                               labels=list(range(11)), average='macro')\n",
    "\n",
    "        val_score = f1_score(val_true.cpu().detach().numpy(), val_preds.cpu().detach().numpy().argmax(1),\n",
    "                             labels=list(range(11)), average='macro')\n",
    "\n",
    "        schedular.step(val_score)\n",
    "        print(\"train_f1: {:0.6f}, valid_f1: {:0.6f}\".format(train_score, val_score))\n",
    "        res = early_stopping(val_score, model)\n",
    "        #print('fres:', res)\n",
    "        if  res == 2:\n",
    "            print(\"Early Stopping\")\n",
    "            print('folder %d global best val max f1 model score %f' % (index, early_stopping.best_score))\n",
    "            break\n",
    "        elif res == 1:\n",
    "            print('save folder %d global val max f1 model score %f' % (index, val_score))\n",
    "    print('Folder {} finally best global max f1 score is {}'.format(index, early_stopping.best_score))\n",
    "    oof_score.append(round(early_stopping.best_score, 6))\n",
    "    \n",
    "    model.eval()\n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(test_dataloader):\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "            predictions = model(x)\n",
    "            predictions_ = predictions.view(-1, predictions.shape[-1]) # shape [128, 4000, 11]\n",
    "            #print(predictions.shape, F.softmax(predictions_, dim=1).cpu().numpy().shape)\n",
    "            pred_list.append(F.softmax(predictions_, dim=1).cpu().numpy()) # shape (512000, 11)\n",
    "            #a = input()\n",
    "        test_preds = np.vstack(pred_list) # shape [2000000, 11]\n",
    "        test_preds_all += test_preds\n",
    "print('all folder score is:%s'%str(oof_score))\n",
    "print('OOF mean score is: %f'% (sum(oof_score)/len(oof_score)))\n",
    "print('Generate submission.............')\n",
    "submission_csv_path = '/kaggle/input/liverpool-ion-switching/sample_submission.csv'\n",
    "ss = pd.read_csv(submission_csv_path, dtype={'time': str})\n",
    "test_preds_all = test_preds_all / np.sum(test_preds_all, axis=1)[:, None]\n",
    "test_pred_frame = pd.DataFrame({'time': ss['time'].astype(str),\n",
    "                                'open_channels': np.argmax(test_preds_all, axis=1)})\n",
    "test_pred_frame.to_csv(\"./gru_preds.csv\", index=False)\n",
    "print('over')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "wavenet with more bascis, and bn, s500w500backtobasic"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-------- fold 0 --------\n",
    "model validation loss: 0.077; validation f1: 0.939;\n",
    "-------- fold 1 --------\n",
    "model validation loss: 0.144; validation f1: 0.938;\n",
    "-------- fold 2 --------\n",
    "model validation loss: 0.093; validation f1: 0.937;\n",
    "-------- fold 3 --------\n",
    "model validation loss: 0.096; validation f1: 0.939;\n",
    "-------- fold 4 --------\n",
    "model validation loss: 0.058; validation f1: 0.939;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "################################################################\n",
    "Training/validation for fold 1/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.443187; Mean training F1 0.775501; Mean validation loss 0.157432; Mean validation F1 0.908407; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.176621; Mean training F1 0.896537; Mean validation loss 0.088333; Mean validation F1 0.926757; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.145589; Mean training F1 0.912245; Mean validation loss 0.128243; Mean validation F1 0.925197; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.119830; Mean training F1 0.921972; Mean validation loss 0.175598; Mean validation F1 0.932371; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.116352; Mean training F1 0.922449; Mean validation loss 0.110527; Mean validation F1 0.930187; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.109843; Mean training F1 0.925998; Mean validation loss 0.080138; Mean validation F1 0.926181; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.106074; Mean training F1 0.927512; Mean validation loss 0.110072; Mean validation F1 0.930918; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.102570; Mean training F1 0.929566; Mean validation loss 0.096324; Mean validation F1 0.925954; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.100761; Mean training F1 0.929757; Mean validation loss 0.079212; Mean validation F1 0.932744; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.096325; Mean training F1 0.930647; Mean validation loss 0.045482; Mean validation F1 0.932350; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.104327; Mean training F1 0.928266; Mean validation loss 0.123147; Mean validation F1 0.932823; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.094120; Mean training F1 0.931690; Mean validation loss 0.108961; Mean validation F1 0.936187; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.098285; Mean training F1 0.931148; Mean validation loss 0.080484; Mean validation F1 0.935286; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.093696; Mean training F1 0.932221; Mean validation loss 0.094194; Mean validation F1 0.937227; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.094361; Mean training F1 0.932145; Mean validation loss 0.101115; Mean validation F1 0.928084; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.096180; Mean training F1 0.931303; Mean validation loss 0.080297; Mean validation F1 0.938000; Learning rate 0.000963;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.089570; Mean training F1 0.934084; Mean validation loss 0.107117; Mean validation F1 0.938238; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.089128; Mean training F1 0.934200; Mean validation loss 0.074790; Mean validation F1 0.935869; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.096952; Mean training F1 0.931185; Mean validation loss 0.265953; Mean validation F1 0.910870; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.095654; Mean training F1 0.931420; Mean validation loss 0.092755; Mean validation F1 0.937337; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.093414; Mean training F1 0.932564; Mean validation loss 0.102765; Mean validation F1 0.935545; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.091176; Mean training F1 0.933743; Mean validation loss 0.089588; Mean validation F1 0.936979; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.096146; Mean training F1 0.931584; Mean validation loss 0.104889; Mean validation F1 0.938106; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.094436; Mean training F1 0.931362; Mean validation loss 0.080686; Mean validation F1 0.934132; Learning rate 0.000917;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.087172; Mean training F1 0.935218; Mean validation loss 0.117009; Mean validation F1 0.937807; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.087822; Mean training F1 0.934859; Mean validation loss 0.074843; Mean validation F1 0.936333; Learning rate 0.000903;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.087880; Mean training F1 0.934804; Mean validation loss 0.128360; Mean validation F1 0.936934; Learning rate 0.000896;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.086236; Mean training F1 0.935718; Mean validation loss 0.052390; Mean validation F1 0.933594; Learning rate 0.000888;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.093719; Mean training F1 0.932482; Mean validation loss 0.089964; Mean validation F1 0.937943; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.093437; Mean training F1 0.932798; Mean validation loss 0.105313; Mean validation F1 0.932557; Learning rate 0.000872;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.088955; Mean training F1 0.934647; Mean validation loss 0.062508; Mean validation F1 0.936532; Learning rate 0.000864;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.086264; Mean training F1 0.935532; Mean validation loss 0.142852; Mean validation F1 0.937379; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.085214; Mean training F1 0.936128; Mean validation loss 0.048007; Mean validation F1 0.938114; Learning rate 0.000847;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.085970; Mean training F1 0.935914; Mean validation loss 0.115630; Mean validation F1 0.938914; Learning rate 0.000838;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.084883; Mean training F1 0.936286; Mean validation loss 0.053729; Mean validation F1 0.938023; Learning rate 0.000829;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.093804; Mean training F1 0.932538; Mean validation loss 0.095039; Mean validation F1 0.937301; Learning rate 0.000819;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.086438; Mean training F1 0.935419; Mean validation loss 0.025748; Mean validation F1 0.937369; Learning rate 0.000810;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.084853; Mean training F1 0.936075; Mean validation loss 0.088159; Mean validation F1 0.938498; Learning rate 0.000800;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.084481; Mean training F1 0.936487; Mean validation loss 0.065098; Mean validation F1 0.938696; Learning rate 0.000790;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.084021; Mean training F1 0.936886; Mean validation loss 0.070570; Mean validation F1 0.938056; Learning rate 0.000780;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.085691; Mean training F1 0.936013; Mean validation loss 0.076688; Mean validation F1 0.937779; Learning rate 0.000770;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.084099; Mean training F1 0.936383; Mean validation loss 0.099667; Mean validation F1 0.937909; Learning rate 0.000760;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.083828; Mean training F1 0.936439; Mean validation loss 0.082241; Mean validation F1 0.937733; Learning rate 0.000749;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.084167; Mean training F1 0.936542; Mean validation loss 0.092290; Mean validation F1 0.938984; Learning rate 0.000739;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.086675; Mean training F1 0.935389; Mean validation loss 0.078931; Mean validation F1 0.935908; Learning rate 0.000728;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.084512; Mean training F1 0.936590; Mean validation loss 0.059533; Mean validation F1 0.938593; Learning rate 0.000717;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.083500; Mean training F1 0.936823; Mean validation loss 0.049707; Mean validation F1 0.937006; Learning rate 0.000706;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.082994; Mean training F1 0.937036; Mean validation loss 0.057967; Mean validation F1 0.937137; Learning rate 0.000695;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.083007; Mean training F1 0.937058; Mean validation loss 0.142055; Mean validation F1 0.938920; Learning rate 0.000683;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.083031; Mean training F1 0.937359; Mean validation loss 0.074951; Mean validation F1 0.939111; Learning rate 0.000672;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.083578; Mean training F1 0.936680; Mean validation loss 0.066640; Mean validation F1 0.938734; Learning rate 0.000661;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.083202; Mean training F1 0.937133; Mean validation loss 0.066178; Mean validation F1 0.938709; Learning rate 0.000649;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.082168; Mean training F1 0.937646; Mean validation loss 0.044251; Mean validation F1 0.938395; Learning rate 0.000637;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.082189; Mean training F1 0.937635; Mean validation loss 0.079593; Mean validation F1 0.938419; Learning rate 0.000626;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.082483; Mean training F1 0.937416; Mean validation loss 0.040463; Mean validation F1 0.939037; Learning rate 0.000614;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.082137; Mean training F1 0.937403; Mean validation loss 0.065385; Mean validation F1 0.937558; Learning rate 0.000602;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.083884; Mean training F1 0.936995; Mean validation loss 0.113912; Mean validation F1 0.938901; Learning rate 0.000590;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.081785; Mean training F1 0.937778; Mean validation loss 0.073147; Mean validation F1 0.938647; Learning rate 0.000578;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.081888; Mean training F1 0.937774; Mean validation loss 0.063827; Mean validation F1 0.938256; Learning rate 0.000566;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.081808; Mean training F1 0.937848; Mean validation loss 0.043247; Mean validation F1 0.937451; Learning rate 0.000554;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.082309; Mean training F1 0.937379; Mean validation loss 0.089141; Mean validation F1 0.938389; Learning rate 0.000542;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.083068; Mean training F1 0.936993; Mean validation loss 0.076980; Mean validation F1 0.935120; Learning rate 0.000530;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.081323; Mean training F1 0.938010; Mean validation loss 0.089773; Mean validation F1 0.938616; Learning rate 0.000517;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.081262; Mean training F1 0.938020; Mean validation loss 0.065708; Mean validation F1 0.938516; Learning rate 0.000505;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.080772; Mean training F1 0.938279; Mean validation loss 0.080238; Mean validation F1 0.939248; Learning rate 0.000493;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.080969; Mean training F1 0.938222; Mean validation loss 0.091071; Mean validation F1 0.938155; Learning rate 0.000481;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.080837; Mean training F1 0.938221; Mean validation loss 0.046904; Mean validation F1 0.938615; Learning rate 0.000469;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.080680; Mean training F1 0.938081; Mean validation loss 0.054450; Mean validation F1 0.938663; Learning rate 0.000457;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.081436; Mean training F1 0.937942; Mean validation loss 0.049667; Mean validation F1 0.938919; Learning rate 0.000445;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.080784; Mean training F1 0.938364; Mean validation loss 0.111702; Mean validation F1 0.939021; Learning rate 0.000433;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.080248; Mean training F1 0.938710; Mean validation loss 0.058845; Mean validation F1 0.937774; Learning rate 0.000421;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.080516; Mean training F1 0.938458; Mean validation loss 0.101314; Mean validation F1 0.938300; Learning rate 0.000409;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.080246; Mean training F1 0.938519; Mean validation loss 0.103175; Mean validation F1 0.938096; Learning rate 0.000397;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.080166; Mean training F1 0.938718; Mean validation loss 0.057096; Mean validation F1 0.938571; Learning rate 0.000385;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.079874; Mean training F1 0.938830; Mean validation loss 0.087818; Mean validation F1 0.939075; Learning rate 0.000373;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.081246; Mean training F1 0.938080; Mean validation loss 0.080737; Mean validation F1 0.938598; Learning rate 0.000362;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.079990; Mean training F1 0.938830; Mean validation loss 0.064972; Mean validation F1 0.938701; Learning rate 0.000350;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.079530; Mean training F1 0.939011; Mean validation loss 0.042769; Mean validation F1 0.939146; Learning rate 0.000339;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.080001; Mean training F1 0.938712; Mean validation loss 0.062372; Mean validation F1 0.938966; Learning rate 0.000327;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.079521; Mean training F1 0.938888; Mean validation loss 0.104537; Mean validation F1 0.939101; Learning rate 0.000316;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.079449; Mean training F1 0.938956; Mean validation loss 0.096801; Mean validation F1 0.938206; Learning rate 0.000305;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.079440; Mean training F1 0.938946; Mean validation loss 0.049279; Mean validation F1 0.939090; Learning rate 0.000294;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.079069; Mean training F1 0.939249; Mean validation loss 0.076237; Mean validation F1 0.938756; Learning rate 0.000283;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.079009; Mean training F1 0.939309; Mean validation loss 0.054741; Mean validation F1 0.938823; Learning rate 0.000272;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.078971; Mean training F1 0.939428; Mean validation loss 0.057343; Mean validation F1 0.938946; Learning rate 0.000261;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.078959; Mean training F1 0.939153; Mean validation loss 0.081136; Mean validation F1 0.939054; Learning rate 0.000251;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.078927; Mean training F1 0.939320; Mean validation loss 0.061322; Mean validation F1 0.938832; Learning rate 0.000240;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.078781; Mean training F1 0.939479; Mean validation loss 0.080915; Mean validation F1 0.939049; Learning rate 0.000230;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.078964; Mean training F1 0.939258; Mean validation loss 0.137896; Mean validation F1 0.938943; Learning rate 0.000220;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.078648; Mean training F1 0.939338; Mean validation loss 0.090349; Mean validation F1 0.939111; Learning rate 0.000210;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.078551; Mean training F1 0.939431; Mean validation loss 0.071391; Mean validation F1 0.939128; Learning rate 0.000201;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.078519; Mean training F1 0.939603; Mean validation loss 0.085378; Mean validation F1 0.938936; Learning rate 0.000191;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.079386; Mean training F1 0.939268; Mean validation loss 0.048690; Mean validation F1 0.939103; Learning rate 0.000182;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.078150; Mean training F1 0.939664; Mean validation loss 0.047088; Mean validation F1 0.938544; Learning rate 0.000173;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.078092; Mean training F1 0.939754; Mean validation loss 0.076841; Mean validation F1 0.939375; Learning rate 0.000164;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.078092; Mean training F1 0.939694; Mean validation loss 0.094143; Mean validation F1 0.938775; Learning rate 0.000155;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.077955; Mean training F1 0.939642; Mean validation loss 0.077629; Mean validation F1 0.938688; Learning rate 0.000147;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.078088; Mean training F1 0.939734; Mean validation loss 0.136580; Mean validation F1 0.938788; Learning rate 0.000139;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.077997; Mean training F1 0.939799; Mean validation loss 0.057868; Mean validation F1 0.938755; Learning rate 0.000130;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.077896; Mean training F1 0.939869; Mean validation loss 0.077994; Mean validation F1 0.939226; Learning rate 0.000123;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.077782; Mean training F1 0.939892; Mean validation loss 0.038034; Mean validation F1 0.938821; Learning rate 0.000115;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.077772; Mean training F1 0.940020; Mean validation loss 0.084816; Mean validation F1 0.938797; Learning rate 0.000108;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.077735; Mean training F1 0.940075; Mean validation loss 0.076753; Mean validation F1 0.939044; Learning rate 0.000101;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.077612; Mean training F1 0.940036; Mean validation loss 0.070886; Mean validation F1 0.938970; Learning rate 0.000094;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.077669; Mean training F1 0.940011; Mean validation loss 0.065378; Mean validation F1 0.938683; Learning rate 0.000087;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.077698; Mean training F1 0.939909; Mean validation loss 0.063156; Mean validation F1 0.938871; Learning rate 0.000081;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.077472; Mean training F1 0.940129; Mean validation loss 0.057795; Mean validation F1 0.938900; Learning rate 0.000075;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.077413; Mean training F1 0.940187; Mean validation loss 0.120668; Mean validation F1 0.938988; Learning rate 0.000069;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.077442; Mean training F1 0.940176; Mean validation loss 0.087056; Mean validation F1 0.938842; Learning rate 0.000063;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.077353; Mean training F1 0.940175; Mean validation loss 0.074239; Mean validation F1 0.939282; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.077347; Mean training F1 0.940125; Mean validation loss 0.064154; Mean validation F1 0.939267; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.077213; Mean training F1 0.940238; Mean validation loss 0.121250; Mean validation F1 0.938955; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.077190; Mean training F1 0.940224; Mean validation loss 0.112880; Mean validation F1 0.939008; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.077249; Mean training F1 0.940249; Mean validation loss 0.051612; Mean validation F1 0.939016; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.077184; Mean training F1 0.940245; Mean validation loss 0.022722; Mean validation F1 0.939160; Learning rate 0.000035;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.077150; Mean training F1 0.940295; Mean validation loss 0.087831; Mean validation F1 0.938579; Learning rate 0.000032;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.077069; Mean training F1 0.940344; Mean validation loss 0.059964; Mean validation F1 0.938948; Learning rate 0.000028;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.077088; Mean training F1 0.940380; Mean validation loss 0.052682; Mean validation F1 0.938996; Learning rate 0.000025;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.077115; Mean training F1 0.940256; Mean validation loss 0.032385; Mean validation F1 0.938925; Learning rate 0.000022;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.077117; Mean training F1 0.940330; Mean validation loss 0.054641; Mean validation F1 0.938907; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.077010; Mean training F1 0.940414; Mean validation loss 0.070136; Mean validation F1 0.939176; Learning rate 0.000018;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.076988; Mean training F1 0.940328; Mean validation loss 0.065344; Mean validation F1 0.939072; Learning rate 0.000016;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.076988; Mean training F1 0.940328; Mean validation loss 0.084555; Mean validation F1 0.939097; Learning rate 0.000014;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.076920; Mean training F1 0.940315; Mean validation loss 0.068948; Mean validation F1 0.938850; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.077030; Mean training F1 0.940371; Mean validation loss 0.053763; Mean validation F1 0.939077; Learning rate 0.000012;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.077001; Mean training F1 0.940244; Mean validation loss 0.047373; Mean validation F1 0.939035; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.077034; Mean training F1 0.940297; Mean validation loss 0.143241; Mean validation F1 0.938926; Learning rate 0.000010;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.076903; Mean training F1 0.940439; Mean validation loss 0.109915; Mean validation F1 0.938911; Learning rate 0.000010;\n",
    "################################################################\n",
    "Training/validation for fold 2/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.439218; Mean training F1 0.779303; Mean validation loss 0.117782; Mean validation F1 0.888377; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.168520; Mean training F1 0.898462; Mean validation loss 0.235101; Mean validation F1 0.864354; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.129950; Mean training F1 0.914768; Mean validation loss 0.138343; Mean validation F1 0.913866; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.114563; Mean training F1 0.922971; Mean validation loss 0.129731; Mean validation F1 0.931632; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.108373; Mean training F1 0.925413; Mean validation loss 0.140853; Mean validation F1 0.921430; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.107097; Mean training F1 0.924500; Mean validation loss 0.211265; Mean validation F1 0.699071; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.101314; Mean training F1 0.928192; Mean validation loss 0.065023; Mean validation F1 0.925037; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.105392; Mean training F1 0.926673; Mean validation loss 0.065217; Mean validation F1 0.927218; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.113279; Mean training F1 0.923459; Mean validation loss 0.091556; Mean validation F1 0.932614; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.092815; Mean training F1 0.932879; Mean validation loss 0.124688; Mean validation F1 0.934408; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.091764; Mean training F1 0.932764; Mean validation loss 0.079333; Mean validation F1 0.933382; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.097593; Mean training F1 0.930001; Mean validation loss 0.153821; Mean validation F1 0.929503; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.090756; Mean training F1 0.933002; Mean validation loss 0.092503; Mean validation F1 0.931989; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.092232; Mean training F1 0.932854; Mean validation loss 0.156970; Mean validation F1 0.934795; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.089124; Mean training F1 0.933869; Mean validation loss 0.098101; Mean validation F1 0.932371; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.088956; Mean training F1 0.934158; Mean validation loss 0.101097; Mean validation F1 0.934224; Learning rate 0.000963;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.090559; Mean training F1 0.932674; Mean validation loss 0.058507; Mean validation F1 0.935451; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.090869; Mean training F1 0.932932; Mean validation loss 0.088572; Mean validation F1 0.931588; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.087396; Mean training F1 0.934974; Mean validation loss 0.098368; Mean validation F1 0.934735; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.086651; Mean training F1 0.935018; Mean validation loss 0.050316; Mean validation F1 0.933986; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.086465; Mean training F1 0.935424; Mean validation loss 0.070391; Mean validation F1 0.933643; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.085881; Mean training F1 0.935567; Mean validation loss 0.079629; Mean validation F1 0.934895; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.095633; Mean training F1 0.931314; Mean validation loss 0.130776; Mean validation F1 0.929550; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.085963; Mean training F1 0.935129; Mean validation loss 0.068517; Mean validation F1 0.934463; Learning rate 0.000917;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.085105; Mean training F1 0.936060; Mean validation loss 0.055026; Mean validation F1 0.936090; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.084969; Mean training F1 0.935875; Mean validation loss 0.106490; Mean validation F1 0.934987; Learning rate 0.000903;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.083659; Mean training F1 0.936773; Mean validation loss 0.125335; Mean validation F1 0.935056; Learning rate 0.000896;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.084662; Mean training F1 0.936338; Mean validation loss 0.116060; Mean validation F1 0.936516; Learning rate 0.000888;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.084635; Mean training F1 0.936133; Mean validation loss 0.066475; Mean validation F1 0.932973; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.084248; Mean training F1 0.936387; Mean validation loss 0.105039; Mean validation F1 0.935726; Learning rate 0.000872;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.085918; Mean training F1 0.936061; Mean validation loss 0.133328; Mean validation F1 0.915395; Learning rate 0.000864;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.087441; Mean training F1 0.935282; Mean validation loss 0.118980; Mean validation F1 0.935493; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.082868; Mean training F1 0.936986; Mean validation loss 0.064180; Mean validation F1 0.935944; Learning rate 0.000847;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.082490; Mean training F1 0.937208; Mean validation loss 0.062314; Mean validation F1 0.936961; Learning rate 0.000838;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.082389; Mean training F1 0.937276; Mean validation loss 0.062271; Mean validation F1 0.935792; Learning rate 0.000829;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.082226; Mean training F1 0.937386; Mean validation loss 0.060344; Mean validation F1 0.935702; Learning rate 0.000819;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.082155; Mean training F1 0.937079; Mean validation loss 0.087056; Mean validation F1 0.935280; Learning rate 0.000810;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.082526; Mean training F1 0.937047; Mean validation loss 0.093800; Mean validation F1 0.936993; Learning rate 0.000800;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.081944; Mean training F1 0.937299; Mean validation loss 0.097757; Mean validation F1 0.933733; Learning rate 0.000790;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.087075; Mean training F1 0.934933; Mean validation loss 0.065405; Mean validation F1 0.734435; Learning rate 0.000780;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.082483; Mean training F1 0.937535; Mean validation loss 0.056177; Mean validation F1 0.936784; Learning rate 0.000770;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.081097; Mean training F1 0.937990; Mean validation loss 0.099109; Mean validation F1 0.936558; Learning rate 0.000760;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.086148; Mean training F1 0.936473; Mean validation loss 0.055921; Mean validation F1 0.935026; Learning rate 0.000749;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.081803; Mean training F1 0.937808; Mean validation loss 0.087435; Mean validation F1 0.936786; Learning rate 0.000739;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.081065; Mean training F1 0.937943; Mean validation loss 0.098193; Mean validation F1 0.936616; Learning rate 0.000728;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.081235; Mean training F1 0.937869; Mean validation loss 0.077397; Mean validation F1 0.937329; Learning rate 0.000717;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.082635; Mean training F1 0.937214; Mean validation loss 0.558269; Mean validation F1 0.912569; Learning rate 0.000706;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.083426; Mean training F1 0.936766; Mean validation loss 0.075089; Mean validation F1 0.936824; Learning rate 0.000695;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.080943; Mean training F1 0.938019; Mean validation loss 0.051920; Mean validation F1 0.935590; Learning rate 0.000683;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.080993; Mean training F1 0.937936; Mean validation loss 0.068640; Mean validation F1 0.936784; Learning rate 0.000672;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.080637; Mean training F1 0.938001; Mean validation loss 0.123051; Mean validation F1 0.936684; Learning rate 0.000661;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.080740; Mean training F1 0.937977; Mean validation loss 0.041115; Mean validation F1 0.935898; Learning rate 0.000649;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.080540; Mean training F1 0.938241; Mean validation loss 0.030083; Mean validation F1 0.935669; Learning rate 0.000637;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.080416; Mean training F1 0.938344; Mean validation loss 0.071040; Mean validation F1 0.936199; Learning rate 0.000626;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.080177; Mean training F1 0.938358; Mean validation loss 0.132243; Mean validation F1 0.935987; Learning rate 0.000614;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.080251; Mean training F1 0.938179; Mean validation loss 0.052241; Mean validation F1 0.936887; Learning rate 0.000602;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.080876; Mean training F1 0.937889; Mean validation loss 0.045886; Mean validation F1 0.935841; Learning rate 0.000590;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.080140; Mean training F1 0.938498; Mean validation loss 0.112389; Mean validation F1 0.937179; Learning rate 0.000578;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.079478; Mean training F1 0.938915; Mean validation loss 0.046029; Mean validation F1 0.937053; Learning rate 0.000566;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.079872; Mean training F1 0.938750; Mean validation loss 0.057383; Mean validation F1 0.937316; Learning rate 0.000554;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.080032; Mean training F1 0.938577; Mean validation loss 0.143775; Mean validation F1 0.937553; Learning rate 0.000542;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.079587; Mean training F1 0.938728; Mean validation loss 0.085845; Mean validation F1 0.937278; Learning rate 0.000530;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.079224; Mean training F1 0.939019; Mean validation loss 0.044504; Mean validation F1 0.936110; Learning rate 0.000517;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.079326; Mean training F1 0.938813; Mean validation loss 0.066973; Mean validation F1 0.937174; Learning rate 0.000505;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.079113; Mean training F1 0.939088; Mean validation loss 0.066780; Mean validation F1 0.936842; Learning rate 0.000493;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.079416; Mean training F1 0.938910; Mean validation loss 0.095310; Mean validation F1 0.936127; Learning rate 0.000481;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.079157; Mean training F1 0.938893; Mean validation loss 0.116883; Mean validation F1 0.937180; Learning rate 0.000469;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.078857; Mean training F1 0.939131; Mean validation loss 0.128797; Mean validation F1 0.937119; Learning rate 0.000457;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.078660; Mean training F1 0.939250; Mean validation loss 0.141361; Mean validation F1 0.936995; Learning rate 0.000445;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.078558; Mean training F1 0.939228; Mean validation loss 0.080346; Mean validation F1 0.937127; Learning rate 0.000433;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.078691; Mean training F1 0.939445; Mean validation loss 0.067409; Mean validation F1 0.937087; Learning rate 0.000421;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.078822; Mean training F1 0.939313; Mean validation loss 0.069609; Mean validation F1 0.936648; Learning rate 0.000409;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.078223; Mean training F1 0.939732; Mean validation loss 0.066104; Mean validation F1 0.935710; Learning rate 0.000397;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.078296; Mean training F1 0.939539; Mean validation loss 0.034025; Mean validation F1 0.936527; Learning rate 0.000385;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.078196; Mean training F1 0.939590; Mean validation loss 0.130717; Mean validation F1 0.936723; Learning rate 0.000373;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.077958; Mean training F1 0.939669; Mean validation loss 0.128057; Mean validation F1 0.936769; Learning rate 0.000362;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.077869; Mean training F1 0.939569; Mean validation loss 0.042717; Mean validation F1 0.936826; Learning rate 0.000350;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.078501; Mean training F1 0.939487; Mean validation loss 0.058402; Mean validation F1 0.936362; Learning rate 0.000339;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.077695; Mean training F1 0.939784; Mean validation loss 0.047448; Mean validation F1 0.936648; Learning rate 0.000327;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.077640; Mean training F1 0.940024; Mean validation loss 0.070670; Mean validation F1 0.936836; Learning rate 0.000316;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.077645; Mean training F1 0.939766; Mean validation loss 0.078512; Mean validation F1 0.937171; Learning rate 0.000305;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.077329; Mean training F1 0.940112; Mean validation loss 0.076557; Mean validation F1 0.937150; Learning rate 0.000294;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.077360; Mean training F1 0.940015; Mean validation loss 0.122173; Mean validation F1 0.936502; Learning rate 0.000283;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.077288; Mean training F1 0.940037; Mean validation loss 0.060746; Mean validation F1 0.936904; Learning rate 0.000272;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.077136; Mean training F1 0.940178; Mean validation loss 0.033380; Mean validation F1 0.936503; Learning rate 0.000261;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.077101; Mean training F1 0.940156; Mean validation loss 0.078106; Mean validation F1 0.937160; Learning rate 0.000251;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.077027; Mean training F1 0.940256; Mean validation loss 0.091879; Mean validation F1 0.937223; Learning rate 0.000240;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.077031; Mean training F1 0.940452; Mean validation loss 0.123591; Mean validation F1 0.936925; Learning rate 0.000230;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.076958; Mean training F1 0.940357; Mean validation loss 0.134133; Mean validation F1 0.936978; Learning rate 0.000220;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.076843; Mean training F1 0.940345; Mean validation loss 0.054209; Mean validation F1 0.937255; Learning rate 0.000210;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.076824; Mean training F1 0.940362; Mean validation loss 0.061992; Mean validation F1 0.936868; Learning rate 0.000201;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.076547; Mean training F1 0.940673; Mean validation loss 0.092589; Mean validation F1 0.937026; Learning rate 0.000191;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.076467; Mean training F1 0.940654; Mean validation loss 0.101685; Mean validation F1 0.936922; Learning rate 0.000182;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.076429; Mean training F1 0.940678; Mean validation loss 0.054841; Mean validation F1 0.937093; Learning rate 0.000173;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.076397; Mean training F1 0.940748; Mean validation loss 0.134197; Mean validation F1 0.936570; Learning rate 0.000164;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.076304; Mean training F1 0.940718; Mean validation loss 0.073654; Mean validation F1 0.936755; Learning rate 0.000155;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.076187; Mean training F1 0.940878; Mean validation loss 0.049379; Mean validation F1 0.936754; Learning rate 0.000147;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.076110; Mean training F1 0.940852; Mean validation loss 0.054621; Mean validation F1 0.936953; Learning rate 0.000139;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.076100; Mean training F1 0.940914; Mean validation loss 0.086100; Mean validation F1 0.937099; Learning rate 0.000130;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.076082; Mean training F1 0.940837; Mean validation loss 0.040802; Mean validation F1 0.936523; Learning rate 0.000123;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.075989; Mean training F1 0.940940; Mean validation loss 0.058035; Mean validation F1 0.936725; Learning rate 0.000115;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.075867; Mean training F1 0.941081; Mean validation loss 0.080956; Mean validation F1 0.936931; Learning rate 0.000108;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.075900; Mean training F1 0.941069; Mean validation loss 0.056987; Mean validation F1 0.936933; Learning rate 0.000101;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.075768; Mean training F1 0.941067; Mean validation loss 0.086377; Mean validation F1 0.937071; Learning rate 0.000094;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.075765; Mean training F1 0.941156; Mean validation loss 0.067010; Mean validation F1 0.936313; Learning rate 0.000087;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.075779; Mean training F1 0.941065; Mean validation loss 0.053118; Mean validation F1 0.936793; Learning rate 0.000081;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.075644; Mean training F1 0.941059; Mean validation loss 0.071710; Mean validation F1 0.936786; Learning rate 0.000075;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.075605; Mean training F1 0.941122; Mean validation loss 0.065579; Mean validation F1 0.936958; Learning rate 0.000069;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.075524; Mean training F1 0.941282; Mean validation loss 0.036832; Mean validation F1 0.937004; Learning rate 0.000063;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.075671; Mean training F1 0.941197; Mean validation loss 0.082922; Mean validation F1 0.937026; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.075509; Mean training F1 0.941371; Mean validation loss 0.040662; Mean validation F1 0.937049; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.075408; Mean training F1 0.941329; Mean validation loss 0.110608; Mean validation F1 0.937108; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.075382; Mean training F1 0.941339; Mean validation loss 0.081190; Mean validation F1 0.936995; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.075374; Mean training F1 0.941320; Mean validation loss 0.053880; Mean validation F1 0.936742; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.075321; Mean training F1 0.941469; Mean validation loss 0.051068; Mean validation F1 0.936742; Learning rate 0.000035;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.075349; Mean training F1 0.941540; Mean validation loss 0.067313; Mean validation F1 0.936740; Learning rate 0.000032;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.075259; Mean training F1 0.941460; Mean validation loss 0.059101; Mean validation F1 0.936836; Learning rate 0.000028;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.075299; Mean training F1 0.941433; Mean validation loss 0.056207; Mean validation F1 0.936807; Learning rate 0.000025;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.075174; Mean training F1 0.941508; Mean validation loss 0.102081; Mean validation F1 0.936713; Learning rate 0.000022;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.075226; Mean training F1 0.941535; Mean validation loss 0.055532; Mean validation F1 0.936877; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.075132; Mean training F1 0.941675; Mean validation loss 0.075399; Mean validation F1 0.936854; Learning rate 0.000018;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.075155; Mean training F1 0.941457; Mean validation loss 0.068266; Mean validation F1 0.936792; Learning rate 0.000016;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.075196; Mean training F1 0.941530; Mean validation loss 0.074717; Mean validation F1 0.936766; Learning rate 0.000014;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.075080; Mean training F1 0.941693; Mean validation loss 0.048892; Mean validation F1 0.936794; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.075140; Mean training F1 0.941516; Mean validation loss 0.092972; Mean validation F1 0.936776; Learning rate 0.000012;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.075073; Mean training F1 0.941611; Mean validation loss 0.057750; Mean validation F1 0.936817; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.075119; Mean training F1 0.941628; Mean validation loss 0.049685; Mean validation F1 0.936670; Learning rate 0.000010;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.075072; Mean training F1 0.941574; Mean validation loss 0.111078; Mean validation F1 0.936807; Learning rate 0.000010;\n",
    "################################################################\n",
    "Training/validation for fold 3/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.501613; Mean training F1 0.741260; Mean validation loss 0.292396; Mean validation F1 0.774201; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.184478; Mean training F1 0.895970; Mean validation loss 0.085378; Mean validation F1 0.918056; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.142096; Mean training F1 0.913401; Mean validation loss 0.161028; Mean validation F1 0.922468; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.125623; Mean training F1 0.919561; Mean validation loss 0.312490; Mean validation F1 0.900792; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.118277; Mean training F1 0.922703; Mean validation loss 0.112091; Mean validation F1 0.930750; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.108399; Mean training F1 0.927055; Mean validation loss 0.070481; Mean validation F1 0.929828; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.108093; Mean training F1 0.927293; Mean validation loss 0.081431; Mean validation F1 0.929968; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.105446; Mean training F1 0.928155; Mean validation loss 0.166003; Mean validation F1 0.928891; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.104509; Mean training F1 0.927981; Mean validation loss 0.166021; Mean validation F1 0.926280; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.104048; Mean training F1 0.927934; Mean validation loss 0.208578; Mean validation F1 0.932156; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.094994; Mean training F1 0.931941; Mean validation loss 0.088685; Mean validation F1 0.929697; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.094341; Mean training F1 0.931909; Mean validation loss 0.073326; Mean validation F1 0.925190; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.095720; Mean training F1 0.931517; Mean validation loss 0.070204; Mean validation F1 0.932279; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.091516; Mean training F1 0.933252; Mean validation loss 0.061973; Mean validation F1 0.934484; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.089211; Mean training F1 0.934509; Mean validation loss 0.085723; Mean validation F1 0.935528; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.089417; Mean training F1 0.934379; Mean validation loss 0.047472; Mean validation F1 0.935497; Learning rate 0.000963;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.096545; Mean training F1 0.930386; Mean validation loss 0.137715; Mean validation F1 0.737810; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.091706; Mean training F1 0.933232; Mean validation loss 0.145635; Mean validation F1 0.935204; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.088115; Mean training F1 0.934952; Mean validation loss 0.067093; Mean validation F1 0.936457; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.086492; Mean training F1 0.935451; Mean validation loss 0.095836; Mean validation F1 0.934723; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.088253; Mean training F1 0.934890; Mean validation loss 0.080654; Mean validation F1 0.933636; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.087017; Mean training F1 0.935323; Mean validation loss 0.071681; Mean validation F1 0.932558; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.093726; Mean training F1 0.932156; Mean validation loss 0.050491; Mean validation F1 0.936199; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.085696; Mean training F1 0.936242; Mean validation loss 0.040566; Mean validation F1 0.934431; Learning rate 0.000917;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.085644; Mean training F1 0.936029; Mean validation loss 0.137719; Mean validation F1 0.931184; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.084903; Mean training F1 0.936272; Mean validation loss 0.041063; Mean validation F1 0.935236; Learning rate 0.000903;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.085276; Mean training F1 0.936176; Mean validation loss 0.146341; Mean validation F1 0.936301; Learning rate 0.000896;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.084677; Mean training F1 0.936447; Mean validation loss 0.061227; Mean validation F1 0.936536; Learning rate 0.000888;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.084721; Mean training F1 0.936309; Mean validation loss 0.100169; Mean validation F1 0.936237; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.085318; Mean training F1 0.936284; Mean validation loss 0.067382; Mean validation F1 0.935108; Learning rate 0.000872;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.084099; Mean training F1 0.936591; Mean validation loss 0.080471; Mean validation F1 0.936998; Learning rate 0.000864;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.084183; Mean training F1 0.936803; Mean validation loss 0.105537; Mean validation F1 0.935937; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.083786; Mean training F1 0.936838; Mean validation loss 0.123184; Mean validation F1 0.936025; Learning rate 0.000847;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.083668; Mean training F1 0.937120; Mean validation loss 0.079675; Mean validation F1 0.934480; Learning rate 0.000838;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.083813; Mean training F1 0.936925; Mean validation loss 0.070251; Mean validation F1 0.934849; Learning rate 0.000829;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.092684; Mean training F1 0.932627; Mean validation loss 0.106581; Mean validation F1 0.935911; Learning rate 0.000819;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.083081; Mean training F1 0.937332; Mean validation loss 0.103252; Mean validation F1 0.936921; Learning rate 0.000810;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.082663; Mean training F1 0.937520; Mean validation loss 0.102239; Mean validation F1 0.937109; Learning rate 0.000800;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.087572; Mean training F1 0.935066; Mean validation loss 0.062659; Mean validation F1 0.936147; Learning rate 0.000790;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.082591; Mean training F1 0.937722; Mean validation loss 0.099900; Mean validation F1 0.936983; Learning rate 0.000780;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.082513; Mean training F1 0.937546; Mean validation loss 0.054228; Mean validation F1 0.936452; Learning rate 0.000770;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.084517; Mean training F1 0.936888; Mean validation loss 0.103085; Mean validation F1 0.936712; Learning rate 0.000760;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.082440; Mean training F1 0.937786; Mean validation loss 0.084487; Mean validation F1 0.937049; Learning rate 0.000749;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.082247; Mean training F1 0.937582; Mean validation loss 0.107918; Mean validation F1 0.935490; Learning rate 0.000739;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.082069; Mean training F1 0.937492; Mean validation loss 0.098432; Mean validation F1 0.936348; Learning rate 0.000728;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.081815; Mean training F1 0.938058; Mean validation loss 0.094541; Mean validation F1 0.936585; Learning rate 0.000717;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.081798; Mean training F1 0.938103; Mean validation loss 0.101207; Mean validation F1 0.936332; Learning rate 0.000706;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.081993; Mean training F1 0.937937; Mean validation loss 0.087441; Mean validation F1 0.936058; Learning rate 0.000695;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.082087; Mean training F1 0.937826; Mean validation loss 0.061545; Mean validation F1 0.936437; Learning rate 0.000683;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.081549; Mean training F1 0.937981; Mean validation loss 0.086064; Mean validation F1 0.936244; Learning rate 0.000672;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.081758; Mean training F1 0.938040; Mean validation loss 0.120044; Mean validation F1 0.936177; Learning rate 0.000661;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.081456; Mean training F1 0.938131; Mean validation loss 0.056361; Mean validation F1 0.935698; Learning rate 0.000649;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.082371; Mean training F1 0.937847; Mean validation loss 0.048077; Mean validation F1 0.936978; Learning rate 0.000637;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.080891; Mean training F1 0.938505; Mean validation loss 0.057093; Mean validation F1 0.936608; Learning rate 0.000626;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.081371; Mean training F1 0.938375; Mean validation loss 0.111259; Mean validation F1 0.936677; Learning rate 0.000614;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.080839; Mean training F1 0.938523; Mean validation loss 0.079146; Mean validation F1 0.936966; Learning rate 0.000602;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.080568; Mean training F1 0.938478; Mean validation loss 0.087124; Mean validation F1 0.936964; Learning rate 0.000590;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.081700; Mean training F1 0.938141; Mean validation loss 0.083865; Mean validation F1 0.937283; Learning rate 0.000578;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.080290; Mean training F1 0.938698; Mean validation loss 0.073029; Mean validation F1 0.936682; Learning rate 0.000566;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.080149; Mean training F1 0.938825; Mean validation loss 0.092643; Mean validation F1 0.936934; Learning rate 0.000554;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.080417; Mean training F1 0.938814; Mean validation loss 0.092672; Mean validation F1 0.937467; Learning rate 0.000542;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.080113; Mean training F1 0.939092; Mean validation loss 0.083875; Mean validation F1 0.937386; Learning rate 0.000530;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.079869; Mean training F1 0.939032; Mean validation loss 0.043123; Mean validation F1 0.936694; Learning rate 0.000517;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.079982; Mean training F1 0.938960; Mean validation loss 0.045761; Mean validation F1 0.936331; Learning rate 0.000505;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.079691; Mean training F1 0.939078; Mean validation loss 0.093009; Mean validation F1 0.937252; Learning rate 0.000493;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.079697; Mean training F1 0.939152; Mean validation loss 0.069253; Mean validation F1 0.936572; Learning rate 0.000481;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.079586; Mean training F1 0.939185; Mean validation loss 0.078160; Mean validation F1 0.936439; Learning rate 0.000469;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.079485; Mean training F1 0.939198; Mean validation loss 0.112354; Mean validation F1 0.936658; Learning rate 0.000457;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.079202; Mean training F1 0.939378; Mean validation loss 0.035574; Mean validation F1 0.937030; Learning rate 0.000445;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.079037; Mean training F1 0.939437; Mean validation loss 0.155787; Mean validation F1 0.936612; Learning rate 0.000433;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.081014; Mean training F1 0.938737; Mean validation loss 0.084306; Mean validation F1 0.936936; Learning rate 0.000421;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.079367; Mean training F1 0.939434; Mean validation loss 0.024177; Mean validation F1 0.936299; Learning rate 0.000409;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.078856; Mean training F1 0.939588; Mean validation loss 0.106792; Mean validation F1 0.937041; Learning rate 0.000397;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.078666; Mean training F1 0.939718; Mean validation loss 0.146129; Mean validation F1 0.936830; Learning rate 0.000385;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.078574; Mean training F1 0.939832; Mean validation loss 0.057633; Mean validation F1 0.936308; Learning rate 0.000373;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.078459; Mean training F1 0.939697; Mean validation loss 0.065887; Mean validation F1 0.936977; Learning rate 0.000362;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.078586; Mean training F1 0.939697; Mean validation loss 0.078267; Mean validation F1 0.937149; Learning rate 0.000350;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.078423; Mean training F1 0.939752; Mean validation loss 0.079085; Mean validation F1 0.937312; Learning rate 0.000339;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.078236; Mean training F1 0.939940; Mean validation loss 0.083962; Mean validation F1 0.936559; Learning rate 0.000327;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.078177; Mean training F1 0.939951; Mean validation loss 0.074790; Mean validation F1 0.936938; Learning rate 0.000316;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.078484; Mean training F1 0.939914; Mean validation loss 0.072764; Mean validation F1 0.937017; Learning rate 0.000305;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.077930; Mean training F1 0.940084; Mean validation loss 0.066941; Mean validation F1 0.936571; Learning rate 0.000294;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.077922; Mean training F1 0.939937; Mean validation loss 0.097208; Mean validation F1 0.937130; Learning rate 0.000283;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.077810; Mean training F1 0.940115; Mean validation loss 0.070969; Mean validation F1 0.937081; Learning rate 0.000272;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.077679; Mean training F1 0.940156; Mean validation loss 0.055883; Mean validation F1 0.936626; Learning rate 0.000261;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.077533; Mean training F1 0.940276; Mean validation loss 0.094050; Mean validation F1 0.937173; Learning rate 0.000251;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.077463; Mean training F1 0.940359; Mean validation loss 0.054063; Mean validation F1 0.936969; Learning rate 0.000240;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.077318; Mean training F1 0.940360; Mean validation loss 0.084677; Mean validation F1 0.936763; Learning rate 0.000230;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.077410; Mean training F1 0.940149; Mean validation loss 0.110376; Mean validation F1 0.936891; Learning rate 0.000220;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.077166; Mean training F1 0.940473; Mean validation loss 0.084006; Mean validation F1 0.936187; Learning rate 0.000210;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.077039; Mean training F1 0.940487; Mean validation loss 0.065349; Mean validation F1 0.936430; Learning rate 0.000201;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.076990; Mean training F1 0.940534; Mean validation loss 0.023892; Mean validation F1 0.937152; Learning rate 0.000191;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.076917; Mean training F1 0.940514; Mean validation loss 0.096708; Mean validation F1 0.937183; Learning rate 0.000182;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.076799; Mean training F1 0.940625; Mean validation loss 0.086659; Mean validation F1 0.936193; Learning rate 0.000173;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.076709; Mean training F1 0.940729; Mean validation loss 0.080111; Mean validation F1 0.937164; Learning rate 0.000164;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.076710; Mean training F1 0.940662; Mean validation loss 0.106131; Mean validation F1 0.936935; Learning rate 0.000155;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.076556; Mean training F1 0.940693; Mean validation loss 0.094147; Mean validation F1 0.937033; Learning rate 0.000147;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.076427; Mean training F1 0.940793; Mean validation loss 0.058220; Mean validation F1 0.936969; Learning rate 0.000139;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.076425; Mean training F1 0.940796; Mean validation loss 0.071266; Mean validation F1 0.936866; Learning rate 0.000130;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.076324; Mean training F1 0.940849; Mean validation loss 0.064395; Mean validation F1 0.937004; Learning rate 0.000123;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.076231; Mean training F1 0.940865; Mean validation loss 0.064649; Mean validation F1 0.936976; Learning rate 0.000115;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.076175; Mean training F1 0.941031; Mean validation loss 0.072953; Mean validation F1 0.937069; Learning rate 0.000108;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.076123; Mean training F1 0.941013; Mean validation loss 0.096077; Mean validation F1 0.937145; Learning rate 0.000101;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.076228; Mean training F1 0.940977; Mean validation loss 0.072366; Mean validation F1 0.936985; Learning rate 0.000094;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.076046; Mean training F1 0.941140; Mean validation loss 0.069380; Mean validation F1 0.937048; Learning rate 0.000087;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.075916; Mean training F1 0.941081; Mean validation loss 0.053596; Mean validation F1 0.936839; Learning rate 0.000081;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.075861; Mean training F1 0.941248; Mean validation loss 0.057792; Mean validation F1 0.937051; Learning rate 0.000075;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.075817; Mean training F1 0.941178; Mean validation loss 0.092708; Mean validation F1 0.936967; Learning rate 0.000069;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.075772; Mean training F1 0.941266; Mean validation loss 0.083793; Mean validation F1 0.937042; Learning rate 0.000063;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.075685; Mean training F1 0.941266; Mean validation loss 0.108263; Mean validation F1 0.937077; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.075774; Mean training F1 0.941133; Mean validation loss 0.116625; Mean validation F1 0.936953; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.075642; Mean training F1 0.941363; Mean validation loss 0.097587; Mean validation F1 0.936829; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.075560; Mean training F1 0.941285; Mean validation loss 0.033412; Mean validation F1 0.937108; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.075620; Mean training F1 0.941333; Mean validation loss 0.079018; Mean validation F1 0.937060; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.075608; Mean training F1 0.941314; Mean validation loss 0.101988; Mean validation F1 0.936872; Learning rate 0.000035;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.075515; Mean training F1 0.941265; Mean validation loss 0.067411; Mean validation F1 0.937065; Learning rate 0.000032;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.075478; Mean training F1 0.941290; Mean validation loss 0.061067; Mean validation F1 0.936948; Learning rate 0.000028;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.075410; Mean training F1 0.941408; Mean validation loss 0.091816; Mean validation F1 0.936969; Learning rate 0.000025;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.075492; Mean training F1 0.941360; Mean validation loss 0.090552; Mean validation F1 0.937126; Learning rate 0.000022;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.075412; Mean training F1 0.941312; Mean validation loss 0.064768; Mean validation F1 0.937124; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.075379; Mean training F1 0.941421; Mean validation loss 0.045134; Mean validation F1 0.937019; Learning rate 0.000018;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.075372; Mean training F1 0.941392; Mean validation loss 0.068001; Mean validation F1 0.937038; Learning rate 0.000016;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.075473; Mean training F1 0.941365; Mean validation loss 0.079533; Mean validation F1 0.936886; Learning rate 0.000014;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.075342; Mean training F1 0.941464; Mean validation loss 0.054718; Mean validation F1 0.937042; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.075332; Mean training F1 0.941494; Mean validation loss 0.098109; Mean validation F1 0.937019; Learning rate 0.000012;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.075322; Mean training F1 0.941352; Mean validation loss 0.091232; Mean validation F1 0.936912; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.075289; Mean training F1 0.941438; Mean validation loss 0.053537; Mean validation F1 0.936922; Learning rate 0.000010;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.075289; Mean training F1 0.941430; Mean validation loss 0.100052; Mean validation F1 0.936976; Learning rate 0.000010;\n",
    "################################################################\n",
    "Training/validation for fold 4/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.505087; Mean training F1 0.738266; Mean validation loss 0.187218; Mean validation F1 0.923073; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.183054; Mean training F1 0.891457; Mean validation loss 0.113343; Mean validation F1 0.911481; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.133019; Mean training F1 0.913758; Mean validation loss 0.161645; Mean validation F1 0.914971; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.118211; Mean training F1 0.920746; Mean validation loss 0.205895; Mean validation F1 0.920456; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.111757; Mean training F1 0.924459; Mean validation loss 0.053097; Mean validation F1 0.930711; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.104877; Mean training F1 0.926923; Mean validation loss 0.135984; Mean validation F1 0.932374; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.100008; Mean training F1 0.929374; Mean validation loss 0.039304; Mean validation F1 0.922801; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.102156; Mean training F1 0.928893; Mean validation loss 0.094704; Mean validation F1 0.910939; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.098611; Mean training F1 0.930055; Mean validation loss 0.104729; Mean validation F1 0.932026; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.095402; Mean training F1 0.931748; Mean validation loss 0.072624; Mean validation F1 0.926202; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.107291; Mean training F1 0.926000; Mean validation loss 0.064404; Mean validation F1 0.933383; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.093508; Mean training F1 0.932279; Mean validation loss 0.098135; Mean validation F1 0.936140; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.091886; Mean training F1 0.933428; Mean validation loss 0.071622; Mean validation F1 0.932272; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.091285; Mean training F1 0.933294; Mean validation loss 0.107904; Mean validation F1 0.934851; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.090269; Mean training F1 0.933975; Mean validation loss 0.148172; Mean validation F1 0.936758; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.090020; Mean training F1 0.934287; Mean validation loss 0.182436; Mean validation F1 0.932210; Learning rate 0.000963;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.097447; Mean training F1 0.930466; Mean validation loss 0.115333; Mean validation F1 0.934598; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.088533; Mean training F1 0.935192; Mean validation loss 0.065801; Mean validation F1 0.935340; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.089473; Mean training F1 0.934321; Mean validation loss 0.068052; Mean validation F1 0.935728; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.088757; Mean training F1 0.934697; Mean validation loss 0.107782; Mean validation F1 0.937028; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.088339; Mean training F1 0.934551; Mean validation loss 0.105177; Mean validation F1 0.936554; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.087390; Mean training F1 0.934981; Mean validation loss 0.108812; Mean validation F1 0.863770; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.087279; Mean training F1 0.935309; Mean validation loss 0.088341; Mean validation F1 0.929535; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.088186; Mean training F1 0.934330; Mean validation loss 0.095277; Mean validation F1 0.934207; Learning rate 0.000917;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.087532; Mean training F1 0.935263; Mean validation loss 0.113961; Mean validation F1 0.936418; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.094788; Mean training F1 0.931718; Mean validation loss 0.068103; Mean validation F1 0.936969; Learning rate 0.000903;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.087804; Mean training F1 0.935277; Mean validation loss 0.093504; Mean validation F1 0.936674; Learning rate 0.000896;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.085472; Mean training F1 0.936425; Mean validation loss 0.116250; Mean validation F1 0.937391; Learning rate 0.000888;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.085449; Mean training F1 0.936334; Mean validation loss 0.074549; Mean validation F1 0.937521; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.086023; Mean training F1 0.935871; Mean validation loss 0.133147; Mean validation F1 0.938130; Learning rate 0.000872;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.088291; Mean training F1 0.935600; Mean validation loss 0.103234; Mean validation F1 0.934974; Learning rate 0.000864;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.085473; Mean training F1 0.936094; Mean validation loss 0.088424; Mean validation F1 0.936146; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.084598; Mean training F1 0.936498; Mean validation loss 0.125097; Mean validation F1 0.937685; Learning rate 0.000847;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.084414; Mean training F1 0.936700; Mean validation loss 0.079229; Mean validation F1 0.934645; Learning rate 0.000838;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.084915; Mean training F1 0.936514; Mean validation loss 0.085764; Mean validation F1 0.937493; Learning rate 0.000829;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.087415; Mean training F1 0.935269; Mean validation loss 0.164785; Mean validation F1 0.865476; Learning rate 0.000819;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.090009; Mean training F1 0.934656; Mean validation loss 0.105277; Mean validation F1 0.936316; Learning rate 0.000810;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.083945; Mean training F1 0.937305; Mean validation loss 0.108998; Mean validation F1 0.937683; Learning rate 0.000800;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.083493; Mean training F1 0.937236; Mean validation loss 0.127815; Mean validation F1 0.934238; Learning rate 0.000790;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.085450; Mean training F1 0.936703; Mean validation loss 0.049453; Mean validation F1 0.938055; Learning rate 0.000780;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.083413; Mean training F1 0.937154; Mean validation loss 0.091008; Mean validation F1 0.937845; Learning rate 0.000770;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.083071; Mean training F1 0.937420; Mean validation loss 0.123939; Mean validation F1 0.936439; Learning rate 0.000760;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.083051; Mean training F1 0.937216; Mean validation loss 0.065559; Mean validation F1 0.938151; Learning rate 0.000749;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.083496; Mean training F1 0.937199; Mean validation loss 0.069698; Mean validation F1 0.938050; Learning rate 0.000739;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.086633; Mean training F1 0.935835; Mean validation loss 0.039490; Mean validation F1 0.938269; Learning rate 0.000728;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.082885; Mean training F1 0.937517; Mean validation loss 0.098492; Mean validation F1 0.938243; Learning rate 0.000717;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.082537; Mean training F1 0.937736; Mean validation loss 0.090866; Mean validation F1 0.938067; Learning rate 0.000706;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.082414; Mean training F1 0.937533; Mean validation loss 0.054409; Mean validation F1 0.937575; Learning rate 0.000695;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.082380; Mean training F1 0.937555; Mean validation loss 0.075619; Mean validation F1 0.938141; Learning rate 0.000683;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.082357; Mean training F1 0.937811; Mean validation loss 0.049406; Mean validation F1 0.938009; Learning rate 0.000672;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.082248; Mean training F1 0.937875; Mean validation loss 0.100152; Mean validation F1 0.933596; Learning rate 0.000661;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.081953; Mean training F1 0.937930; Mean validation loss 0.096111; Mean validation F1 0.938574; Learning rate 0.000649;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.082334; Mean training F1 0.937636; Mean validation loss 0.083655; Mean validation F1 0.937442; Learning rate 0.000637;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.081699; Mean training F1 0.938143; Mean validation loss 0.107141; Mean validation F1 0.938376; Learning rate 0.000626;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.081795; Mean training F1 0.937923; Mean validation loss 0.101518; Mean validation F1 0.937490; Learning rate 0.000614;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.082382; Mean training F1 0.937764; Mean validation loss 0.111485; Mean validation F1 0.935405; Learning rate 0.000602;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.081430; Mean training F1 0.938318; Mean validation loss 0.080663; Mean validation F1 0.938159; Learning rate 0.000590;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.081617; Mean training F1 0.937956; Mean validation loss 0.101949; Mean validation F1 0.938391; Learning rate 0.000578;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.081336; Mean training F1 0.938506; Mean validation loss 0.047258; Mean validation F1 0.938378; Learning rate 0.000566;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.080989; Mean training F1 0.938270; Mean validation loss 0.086325; Mean validation F1 0.936700; Learning rate 0.000554;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.080853; Mean training F1 0.938505; Mean validation loss 0.093561; Mean validation F1 0.938194; Learning rate 0.000542;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.080869; Mean training F1 0.938554; Mean validation loss 0.064323; Mean validation F1 0.938231; Learning rate 0.000530;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.080843; Mean training F1 0.938428; Mean validation loss 0.049864; Mean validation F1 0.938195; Learning rate 0.000517;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.080593; Mean training F1 0.938763; Mean validation loss 0.096624; Mean validation F1 0.937438; Learning rate 0.000505;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.080698; Mean training F1 0.938606; Mean validation loss 0.055456; Mean validation F1 0.938444; Learning rate 0.000493;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.080708; Mean training F1 0.938830; Mean validation loss 0.062678; Mean validation F1 0.937463; Learning rate 0.000481;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.080378; Mean training F1 0.938763; Mean validation loss 0.115302; Mean validation F1 0.938541; Learning rate 0.000469;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.080114; Mean training F1 0.938935; Mean validation loss 0.086621; Mean validation F1 0.937860; Learning rate 0.000457;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.079892; Mean training F1 0.939192; Mean validation loss 0.093973; Mean validation F1 0.938162; Learning rate 0.000445;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.079776; Mean training F1 0.939054; Mean validation loss 0.062468; Mean validation F1 0.938497; Learning rate 0.000433;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.079936; Mean training F1 0.939197; Mean validation loss 0.048384; Mean validation F1 0.936894; Learning rate 0.000421;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.079684; Mean training F1 0.939286; Mean validation loss 0.109022; Mean validation F1 0.938287; Learning rate 0.000409;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.079432; Mean training F1 0.939458; Mean validation loss 0.148432; Mean validation F1 0.937858; Learning rate 0.000397;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.079340; Mean training F1 0.939437; Mean validation loss 0.098987; Mean validation F1 0.938183; Learning rate 0.000385;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.079225; Mean training F1 0.939378; Mean validation loss 0.088567; Mean validation F1 0.938525; Learning rate 0.000373;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.079290; Mean training F1 0.939436; Mean validation loss 0.123080; Mean validation F1 0.936834; Learning rate 0.000362;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.078968; Mean training F1 0.939639; Mean validation loss 0.065748; Mean validation F1 0.938042; Learning rate 0.000350;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.079093; Mean training F1 0.939625; Mean validation loss 0.190227; Mean validation F1 0.938271; Learning rate 0.000339;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.078827; Mean training F1 0.939661; Mean validation loss 0.020952; Mean validation F1 0.938174; Learning rate 0.000327;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.078866; Mean training F1 0.939706; Mean validation loss 0.073377; Mean validation F1 0.937951; Learning rate 0.000316;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.078570; Mean training F1 0.939896; Mean validation loss 0.085343; Mean validation F1 0.937919; Learning rate 0.000305;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.078669; Mean training F1 0.939774; Mean validation loss 0.104547; Mean validation F1 0.938016; Learning rate 0.000294;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.078624; Mean training F1 0.939793; Mean validation loss 0.071704; Mean validation F1 0.937567; Learning rate 0.000283;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.078370; Mean training F1 0.939877; Mean validation loss 0.057201; Mean validation F1 0.938184; Learning rate 0.000272;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.078144; Mean training F1 0.940133; Mean validation loss 0.136455; Mean validation F1 0.938346; Learning rate 0.000261;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.078106; Mean training F1 0.940043; Mean validation loss 0.037702; Mean validation F1 0.938408; Learning rate 0.000251;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.077982; Mean training F1 0.940181; Mean validation loss 0.044131; Mean validation F1 0.938468; Learning rate 0.000240;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.077908; Mean training F1 0.940057; Mean validation loss 0.116510; Mean validation F1 0.938099; Learning rate 0.000230;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.077837; Mean training F1 0.940157; Mean validation loss 0.036196; Mean validation F1 0.937639; Learning rate 0.000220;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.077712; Mean training F1 0.940316; Mean validation loss 0.103101; Mean validation F1 0.938551; Learning rate 0.000210;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.077719; Mean training F1 0.940320; Mean validation loss 0.124320; Mean validation F1 0.937409; Learning rate 0.000201;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.077453; Mean training F1 0.940400; Mean validation loss 0.059250; Mean validation F1 0.938086; Learning rate 0.000191;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.077774; Mean training F1 0.940307; Mean validation loss 0.047863; Mean validation F1 0.937703; Learning rate 0.000182;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.077329; Mean training F1 0.940580; Mean validation loss 0.055206; Mean validation F1 0.937538; Learning rate 0.000173;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.077323; Mean training F1 0.940488; Mean validation loss 0.100585; Mean validation F1 0.937836; Learning rate 0.000164;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.077183; Mean training F1 0.940547; Mean validation loss 0.130022; Mean validation F1 0.937162; Learning rate 0.000155;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.077151; Mean training F1 0.940657; Mean validation loss 0.098403; Mean validation F1 0.937193; Learning rate 0.000147;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.077059; Mean training F1 0.940647; Mean validation loss 0.107562; Mean validation F1 0.937815; Learning rate 0.000139;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.077045; Mean training F1 0.940675; Mean validation loss 0.112453; Mean validation F1 0.937765; Learning rate 0.000130;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.076997; Mean training F1 0.940646; Mean validation loss 0.070257; Mean validation F1 0.938416; Learning rate 0.000123;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.076764; Mean training F1 0.940902; Mean validation loss 0.081110; Mean validation F1 0.938367; Learning rate 0.000115;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.076747; Mean training F1 0.940851; Mean validation loss 0.096714; Mean validation F1 0.937959; Learning rate 0.000108;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.076728; Mean training F1 0.940845; Mean validation loss 0.090369; Mean validation F1 0.937896; Learning rate 0.000101;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.076555; Mean training F1 0.940796; Mean validation loss 0.061397; Mean validation F1 0.937889; Learning rate 0.000094;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.076569; Mean training F1 0.940948; Mean validation loss 0.059677; Mean validation F1 0.937813; Learning rate 0.000087;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.076532; Mean training F1 0.940895; Mean validation loss 0.064124; Mean validation F1 0.938036; Learning rate 0.000081;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.076490; Mean training F1 0.940926; Mean validation loss 0.083479; Mean validation F1 0.937742; Learning rate 0.000075;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.076541; Mean training F1 0.940959; Mean validation loss 0.100030; Mean validation F1 0.937828; Learning rate 0.000069;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.076370; Mean training F1 0.940977; Mean validation loss 0.027904; Mean validation F1 0.937913; Learning rate 0.000063;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.076328; Mean training F1 0.941030; Mean validation loss 0.040982; Mean validation F1 0.938021; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.076270; Mean training F1 0.940999; Mean validation loss 0.087406; Mean validation F1 0.937741; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.076265; Mean training F1 0.941163; Mean validation loss 0.054270; Mean validation F1 0.937927; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.076268; Mean training F1 0.941147; Mean validation loss 0.117918; Mean validation F1 0.937873; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.076161; Mean training F1 0.941103; Mean validation loss 0.078271; Mean validation F1 0.937726; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.076187; Mean training F1 0.941111; Mean validation loss 0.058515; Mean validation F1 0.937727; Learning rate 0.000035;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.076133; Mean training F1 0.941097; Mean validation loss 0.054291; Mean validation F1 0.937695; Learning rate 0.000032;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.076078; Mean training F1 0.941272; Mean validation loss 0.082243; Mean validation F1 0.938002; Learning rate 0.000028;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.076110; Mean training F1 0.941276; Mean validation loss 0.084149; Mean validation F1 0.937892; Learning rate 0.000025;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.076022; Mean training F1 0.941219; Mean validation loss 0.084696; Mean validation F1 0.937962; Learning rate 0.000022;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.076032; Mean training F1 0.941285; Mean validation loss 0.105033; Mean validation F1 0.937728; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.076033; Mean training F1 0.941193; Mean validation loss 0.066947; Mean validation F1 0.938150; Learning rate 0.000018;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.076026; Mean training F1 0.941214; Mean validation loss 0.058317; Mean validation F1 0.937872; Learning rate 0.000016;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.076650; Mean training F1 0.941131; Mean validation loss 0.055297; Mean validation F1 0.938044; Learning rate 0.000014;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.075948; Mean training F1 0.941332; Mean validation loss 0.057194; Mean validation F1 0.937965; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.075908; Mean training F1 0.941364; Mean validation loss 0.054238; Mean validation F1 0.938102; Learning rate 0.000012;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.075940; Mean training F1 0.941335; Mean validation loss 0.053596; Mean validation F1 0.937955; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.075927; Mean training F1 0.941325; Mean validation loss 0.068226; Mean validation F1 0.938030; Learning rate 0.000010;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.075985; Mean training F1 0.941227; Mean validation loss 0.125380; Mean validation F1 0.937841; Learning rate 0.000010;\n",
    "################################################################\n",
    "Training/validation for fold 5/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.465174; Mean training F1 0.759113; Mean validation loss 0.119207; Mean validation F1 0.818576; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.174194; Mean training F1 0.897559; Mean validation loss 0.098778; Mean validation F1 0.845345; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.124856; Mean training F1 0.919980; Mean validation loss 0.078301; Mean validation F1 0.915727; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.119071; Mean training F1 0.922309; Mean validation loss 0.096053; Mean validation F1 0.933274; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.104796; Mean training F1 0.928640; Mean validation loss 0.156160; Mean validation F1 0.819681; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.106218; Mean training F1 0.926531; Mean validation loss 0.081551; Mean validation F1 0.910431; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.109074; Mean training F1 0.926330; Mean validation loss 0.063607; Mean validation F1 0.934874; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.097871; Mean training F1 0.931163; Mean validation loss 0.129593; Mean validation F1 0.935295; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.100274; Mean training F1 0.930026; Mean validation loss 0.090411; Mean validation F1 0.932188; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.096780; Mean training F1 0.931454; Mean validation loss 0.072218; Mean validation F1 0.639308; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.106054; Mean training F1 0.925599; Mean validation loss 0.128482; Mean validation F1 0.932251; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.092470; Mean training F1 0.933739; Mean validation loss 0.097532; Mean validation F1 0.934192; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.091482; Mean training F1 0.933879; Mean validation loss 0.078992; Mean validation F1 0.933831; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.101265; Mean training F1 0.929788; Mean validation loss 0.064638; Mean validation F1 0.934076; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.091143; Mean training F1 0.933905; Mean validation loss 0.062563; Mean validation F1 0.936697; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.089533; Mean training F1 0.934739; Mean validation loss 0.109596; Mean validation F1 0.936757; Learning rate 0.000963;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.089441; Mean training F1 0.934916; Mean validation loss 0.059367; Mean validation F1 0.934967; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.089959; Mean training F1 0.934408; Mean validation loss 0.087061; Mean validation F1 0.933345; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.095857; Mean training F1 0.931446; Mean validation loss 0.139038; Mean validation F1 0.936094; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.088930; Mean training F1 0.935006; Mean validation loss 0.043698; Mean validation F1 0.937046; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.087845; Mean training F1 0.935277; Mean validation loss 0.083528; Mean validation F1 0.935546; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.087568; Mean training F1 0.935753; Mean validation loss 0.066606; Mean validation F1 0.937821; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.086931; Mean training F1 0.935532; Mean validation loss 0.126708; Mean validation F1 0.936827; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.087227; Mean training F1 0.935798; Mean validation loss 0.103126; Mean validation F1 0.937992; Learning rate 0.000917;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.086718; Mean training F1 0.935862; Mean validation loss 0.045705; Mean validation F1 0.936176; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.086815; Mean training F1 0.935703; Mean validation loss 0.095437; Mean validation F1 0.938041; Learning rate 0.000903;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.091842; Mean training F1 0.934020; Mean validation loss 0.058563; Mean validation F1 0.936087; Learning rate 0.000896;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.086048; Mean training F1 0.936395; Mean validation loss 0.057198; Mean validation F1 0.937861; Learning rate 0.000888;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.085359; Mean training F1 0.936361; Mean validation loss 0.130964; Mean validation F1 0.938237; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.084793; Mean training F1 0.936820; Mean validation loss 0.068536; Mean validation F1 0.937735; Learning rate 0.000872;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.085008; Mean training F1 0.936618; Mean validation loss 0.099423; Mean validation F1 0.937392; Learning rate 0.000864;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.085146; Mean training F1 0.936678; Mean validation loss 0.065731; Mean validation F1 0.937930; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.093842; Mean training F1 0.932463; Mean validation loss 0.074871; Mean validation F1 0.938197; Learning rate 0.000847;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.084568; Mean training F1 0.936797; Mean validation loss 0.079851; Mean validation F1 0.938288; Learning rate 0.000838;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.084153; Mean training F1 0.937114; Mean validation loss 0.038682; Mean validation F1 0.938199; Learning rate 0.000829;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.083877; Mean training F1 0.937344; Mean validation loss 0.064209; Mean validation F1 0.938105; Learning rate 0.000819;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.083824; Mean training F1 0.937282; Mean validation loss 0.068261; Mean validation F1 0.937038; Learning rate 0.000810;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.083893; Mean training F1 0.937082; Mean validation loss 0.110776; Mean validation F1 0.936973; Learning rate 0.000800;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.086879; Mean training F1 0.935943; Mean validation loss 0.158098; Mean validation F1 0.879621; Learning rate 0.000790;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.087468; Mean training F1 0.935810; Mean validation loss 0.049994; Mean validation F1 0.937937; Learning rate 0.000780;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.083386; Mean training F1 0.937616; Mean validation loss 0.107838; Mean validation F1 0.938132; Learning rate 0.000770;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.083283; Mean training F1 0.937700; Mean validation loss 0.143455; Mean validation F1 0.937741; Learning rate 0.000760;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.083072; Mean training F1 0.937564; Mean validation loss 0.167139; Mean validation F1 0.938082; Learning rate 0.000749;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.083071; Mean training F1 0.937602; Mean validation loss 0.138613; Mean validation F1 0.938051; Learning rate 0.000739;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.082971; Mean training F1 0.937777; Mean validation loss 0.102588; Mean validation F1 0.937117; Learning rate 0.000728;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.082617; Mean training F1 0.937794; Mean validation loss 0.043992; Mean validation F1 0.938201; Learning rate 0.000717;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.082726; Mean training F1 0.937946; Mean validation loss 0.058045; Mean validation F1 0.937534; Learning rate 0.000706;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.082813; Mean training F1 0.937690; Mean validation loss 0.084389; Mean validation F1 0.937346; Learning rate 0.000695;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.082693; Mean training F1 0.937978; Mean validation loss 0.062775; Mean validation F1 0.937597; Learning rate 0.000683;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.082281; Mean training F1 0.938092; Mean validation loss 0.119588; Mean validation F1 0.938334; Learning rate 0.000672;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.082001; Mean training F1 0.938129; Mean validation loss 0.098578; Mean validation F1 0.938095; Learning rate 0.000661;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.082135; Mean training F1 0.938101; Mean validation loss 0.095549; Mean validation F1 0.938363; Learning rate 0.000649;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.081797; Mean training F1 0.938509; Mean validation loss 0.092894; Mean validation F1 0.936751; Learning rate 0.000637;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.081709; Mean training F1 0.938332; Mean validation loss 0.093266; Mean validation F1 0.937596; Learning rate 0.000626;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.081708; Mean training F1 0.938080; Mean validation loss 0.131593; Mean validation F1 0.938314; Learning rate 0.000614;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.081300; Mean training F1 0.938492; Mean validation loss 0.057751; Mean validation F1 0.938365; Learning rate 0.000602;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.081271; Mean training F1 0.938600; Mean validation loss 0.076438; Mean validation F1 0.938407; Learning rate 0.000590;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.087213; Mean training F1 0.937097; Mean validation loss 0.077789; Mean validation F1 0.938262; Learning rate 0.000578;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.081795; Mean training F1 0.938423; Mean validation loss 0.083370; Mean validation F1 0.938495; Learning rate 0.000566;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.080914; Mean training F1 0.938752; Mean validation loss 0.128679; Mean validation F1 0.938343; Learning rate 0.000554;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.080680; Mean training F1 0.938953; Mean validation loss 0.111821; Mean validation F1 0.938311; Learning rate 0.000542;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.080601; Mean training F1 0.938726; Mean validation loss 0.048975; Mean validation F1 0.938291; Learning rate 0.000530;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.080595; Mean training F1 0.938771; Mean validation loss 0.063066; Mean validation F1 0.936124; Learning rate 0.000517;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.080428; Mean training F1 0.938990; Mean validation loss 0.105937; Mean validation F1 0.938358; Learning rate 0.000505;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.080412; Mean training F1 0.938977; Mean validation loss 0.058953; Mean validation F1 0.935667; Learning rate 0.000493;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.080280; Mean training F1 0.938943; Mean validation loss 0.044214; Mean validation F1 0.938054; Learning rate 0.000481;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.080110; Mean training F1 0.939193; Mean validation loss 0.064921; Mean validation F1 0.937600; Learning rate 0.000469;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.080118; Mean training F1 0.939025; Mean validation loss 0.092505; Mean validation F1 0.938068; Learning rate 0.000457;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.080129; Mean training F1 0.939117; Mean validation loss 0.060373; Mean validation F1 0.937998; Learning rate 0.000445;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.079866; Mean training F1 0.939189; Mean validation loss 0.065542; Mean validation F1 0.938365; Learning rate 0.000433;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.079608; Mean training F1 0.939420; Mean validation loss 0.059687; Mean validation F1 0.938112; Learning rate 0.000421;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.079582; Mean training F1 0.939403; Mean validation loss 0.095965; Mean validation F1 0.938162; Learning rate 0.000409;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.079534; Mean training F1 0.939428; Mean validation loss 0.110120; Mean validation F1 0.938414; Learning rate 0.000397;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.079398; Mean training F1 0.939389; Mean validation loss 0.081960; Mean validation F1 0.938288; Learning rate 0.000385;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.079224; Mean training F1 0.939589; Mean validation loss 0.057722; Mean validation F1 0.938645; Learning rate 0.000373;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.079024; Mean training F1 0.939866; Mean validation loss 0.139334; Mean validation F1 0.938451; Learning rate 0.000362;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.078936; Mean training F1 0.939778; Mean validation loss 0.067812; Mean validation F1 0.937952; Learning rate 0.000350;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.078739; Mean training F1 0.939973; Mean validation loss 0.084260; Mean validation F1 0.938584; Learning rate 0.000339;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.078757; Mean training F1 0.939811; Mean validation loss 0.060509; Mean validation F1 0.937713; Learning rate 0.000327;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.078580; Mean training F1 0.939931; Mean validation loss 0.077209; Mean validation F1 0.938245; Learning rate 0.000316;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.078504; Mean training F1 0.940119; Mean validation loss 0.040577; Mean validation F1 0.937359; Learning rate 0.000305;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.078528; Mean training F1 0.939902; Mean validation loss 0.107090; Mean validation F1 0.938222; Learning rate 0.000294;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.078139; Mean training F1 0.940274; Mean validation loss 0.040766; Mean validation F1 0.938365; Learning rate 0.000283;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.078216; Mean training F1 0.940047; Mean validation loss 0.099303; Mean validation F1 0.938327; Learning rate 0.000272;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.078153; Mean training F1 0.940111; Mean validation loss 0.084877; Mean validation F1 0.938450; Learning rate 0.000261;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.077883; Mean training F1 0.940294; Mean validation loss 0.090271; Mean validation F1 0.938047; Learning rate 0.000251;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.077821; Mean training F1 0.940329; Mean validation loss 0.053801; Mean validation F1 0.938568; Learning rate 0.000240;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.077686; Mean training F1 0.940325; Mean validation loss 0.127261; Mean validation F1 0.936667; Learning rate 0.000230;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.077610; Mean training F1 0.940471; Mean validation loss 0.078100; Mean validation F1 0.937657; Learning rate 0.000220;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.077554; Mean training F1 0.940407; Mean validation loss 0.101109; Mean validation F1 0.938111; Learning rate 0.000210;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.077363; Mean training F1 0.940506; Mean validation loss 0.075224; Mean validation F1 0.938468; Learning rate 0.000201;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.077242; Mean training F1 0.940740; Mean validation loss 0.049799; Mean validation F1 0.938334; Learning rate 0.000191;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.077351; Mean training F1 0.940621; Mean validation loss 0.090311; Mean validation F1 0.937633; Learning rate 0.000182;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.077135; Mean training F1 0.940830; Mean validation loss 0.100632; Mean validation F1 0.938347; Learning rate 0.000173;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.077173; Mean training F1 0.940812; Mean validation loss 0.094411; Mean validation F1 0.938072; Learning rate 0.000164;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.076962; Mean training F1 0.940809; Mean validation loss 0.064926; Mean validation F1 0.937932; Learning rate 0.000155;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.076945; Mean training F1 0.940870; Mean validation loss 0.086796; Mean validation F1 0.938066; Learning rate 0.000147;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.076912; Mean training F1 0.940929; Mean validation loss 0.053946; Mean validation F1 0.938284; Learning rate 0.000139;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.076729; Mean training F1 0.940891; Mean validation loss 0.113551; Mean validation F1 0.938188; Learning rate 0.000130;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.076686; Mean training F1 0.940925; Mean validation loss 0.067659; Mean validation F1 0.938202; Learning rate 0.000123;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.076571; Mean training F1 0.941041; Mean validation loss 0.115558; Mean validation F1 0.937906; Learning rate 0.000115;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.076516; Mean training F1 0.941063; Mean validation loss 0.069559; Mean validation F1 0.938358; Learning rate 0.000108;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.076420; Mean training F1 0.941096; Mean validation loss 0.082894; Mean validation F1 0.938200; Learning rate 0.000101;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.076407; Mean training F1 0.941112; Mean validation loss 0.042629; Mean validation F1 0.938225; Learning rate 0.000094;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.076310; Mean training F1 0.941111; Mean validation loss 0.078271; Mean validation F1 0.938186; Learning rate 0.000087;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.076244; Mean training F1 0.941205; Mean validation loss 0.077176; Mean validation F1 0.938207; Learning rate 0.000081;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.076141; Mean training F1 0.941133; Mean validation loss 0.084106; Mean validation F1 0.938311; Learning rate 0.000075;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.076112; Mean training F1 0.941350; Mean validation loss 0.041621; Mean validation F1 0.938381; Learning rate 0.000069;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.076056; Mean training F1 0.941235; Mean validation loss 0.067341; Mean validation F1 0.937902; Learning rate 0.000063;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.076031; Mean training F1 0.941343; Mean validation loss 0.088629; Mean validation F1 0.938307; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.075965; Mean training F1 0.941367; Mean validation loss 0.105245; Mean validation F1 0.938082; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.075939; Mean training F1 0.941405; Mean validation loss 0.055674; Mean validation F1 0.938196; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.075866; Mean training F1 0.941359; Mean validation loss 0.099849; Mean validation F1 0.938316; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.075920; Mean training F1 0.941346; Mean validation loss 0.071038; Mean validation F1 0.938366; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.075855; Mean training F1 0.941494; Mean validation loss 0.052188; Mean validation F1 0.938375; Learning rate 0.000035;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.075810; Mean training F1 0.941488; Mean validation loss 0.069235; Mean validation F1 0.938340; Learning rate 0.000032;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.075791; Mean training F1 0.941538; Mean validation loss 0.050742; Mean validation F1 0.938156; Learning rate 0.000028;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.075705; Mean training F1 0.941386; Mean validation loss 0.088334; Mean validation F1 0.937899; Learning rate 0.000025;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.075625; Mean training F1 0.941461; Mean validation loss 0.064193; Mean validation F1 0.938081; Learning rate 0.000022;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.075680; Mean training F1 0.941497; Mean validation loss 0.031785; Mean validation F1 0.938278; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.075699; Mean training F1 0.941568; Mean validation loss 0.063777; Mean validation F1 0.938216; Learning rate 0.000018;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.075669; Mean training F1 0.941517; Mean validation loss 0.059783; Mean validation F1 0.938311; Learning rate 0.000016;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.075643; Mean training F1 0.941583; Mean validation loss 0.056659; Mean validation F1 0.938336; Learning rate 0.000014;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.075567; Mean training F1 0.941562; Mean validation loss 0.083648; Mean validation F1 0.938086; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.075658; Mean training F1 0.941527; Mean validation loss 0.120417; Mean validation F1 0.938072; Learning rate 0.000012;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.075585; Mean training F1 0.941494; Mean validation loss 0.078514; Mean validation F1 0.938325; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.075626; Mean training F1 0.941514; Mean validation loss 0.036821; Mean validation F1 0.938198; Learning rate 0.000010;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.075523; Mean training F1 0.941556; Mean validation loss 0.064924; Mean validation F1 0.938246; Learning rate 0.000010;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "wavenet with more channels, cbr and bn, s1000w1000featnew3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-------- fold 0 --------\n",
    "model validation loss: 0.088; validation f1: 0.940;\n",
    "-------- fold 1 --------\n",
    "model validation loss: 0.085; validation f1: 0.938;\n",
    "-------- fold 2 --------\n",
    "model validation loss: 0.074; validation f1: 0.938;\n",
    "-------- fold 3 --------\n",
    "model validation loss: 0.068; validation f1: 0.939;\n",
    "-------- fold 4 --------\n",
    "model validation loss: 0.071; validation f1: 0.939;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "################################################################\n",
    "Training/validation for fold 1/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.578216; Mean training F1 0.704480; Mean validation loss 0.240019; Mean validation F1 0.851220; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.234991; Mean training F1 0.872873; Mean validation loss 0.255417; Mean validation F1 0.856555; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.184402; Mean training F1 0.890276; Mean validation loss 0.104672; Mean validation F1 0.901627; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.151214; Mean training F1 0.906437; Mean validation loss 0.140660; Mean validation F1 0.919292; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.152075; Mean training F1 0.906231; Mean validation loss 0.094731; Mean validation F1 0.922355; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.132767; Mean training F1 0.915997; Mean validation loss 0.128800; Mean validation F1 0.925563; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.134786; Mean training F1 0.915775; Mean validation loss 0.158576; Mean validation F1 0.912683; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.127033; Mean training F1 0.918112; Mean validation loss 0.293566; Mean validation F1 0.911930; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.113157; Mean training F1 0.924418; Mean validation loss 0.100873; Mean validation F1 0.922876; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.100865; Mean training F1 0.930361; Mean validation loss 0.112750; Mean validation F1 0.934553; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.101891; Mean training F1 0.928560; Mean validation loss 0.129119; Mean validation F1 0.931267; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.096768; Mean training F1 0.931401; Mean validation loss 0.160964; Mean validation F1 0.699831; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.094785; Mean training F1 0.931973; Mean validation loss 0.080692; Mean validation F1 0.935452; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.094006; Mean training F1 0.931844; Mean validation loss 0.112149; Mean validation F1 0.932876; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.095421; Mean training F1 0.931845; Mean validation loss 0.173304; Mean validation F1 0.719044; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.098381; Mean training F1 0.930922; Mean validation loss 0.093812; Mean validation F1 0.498280; Learning rate 0.000963;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.095214; Mean training F1 0.931734; Mean validation loss 0.114467; Mean validation F1 0.935342; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.092259; Mean training F1 0.932826; Mean validation loss 0.130102; Mean validation F1 0.933582; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.091008; Mean training F1 0.933160; Mean validation loss 0.105601; Mean validation F1 0.935793; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.090398; Mean training F1 0.933761; Mean validation loss 0.099269; Mean validation F1 0.936690; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.090332; Mean training F1 0.933937; Mean validation loss 0.085838; Mean validation F1 0.936341; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.090518; Mean training F1 0.934241; Mean validation loss 0.178949; Mean validation F1 0.933954; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.091555; Mean training F1 0.933249; Mean validation loss 0.083710; Mean validation F1 0.936152; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.088313; Mean training F1 0.934799; Mean validation loss 0.082177; Mean validation F1 0.933168; Learning rate 0.000917;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.088663; Mean training F1 0.934432; Mean validation loss 0.096510; Mean validation F1 0.935217; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.086957; Mean training F1 0.935589; Mean validation loss 0.086551; Mean validation F1 0.936664; Learning rate 0.000903;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.087107; Mean training F1 0.934812; Mean validation loss 0.089080; Mean validation F1 0.935511; Learning rate 0.000896;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.087985; Mean training F1 0.934458; Mean validation loss 0.079321; Mean validation F1 0.936460; Learning rate 0.000888;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.089043; Mean training F1 0.934504; Mean validation loss 0.073169; Mean validation F1 0.934744; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.086537; Mean training F1 0.935554; Mean validation loss 0.065050; Mean validation F1 0.937763; Learning rate 0.000872;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.089190; Mean training F1 0.934112; Mean validation loss 0.092721; Mean validation F1 0.935421; Learning rate 0.000864;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.087755; Mean training F1 0.934363; Mean validation loss 0.089368; Mean validation F1 0.934571; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.089236; Mean training F1 0.932841; Mean validation loss 0.109082; Mean validation F1 0.929280; Learning rate 0.000847;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.088012; Mean training F1 0.934582; Mean validation loss 0.129891; Mean validation F1 0.924415; Learning rate 0.000838;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.085217; Mean training F1 0.936056; Mean validation loss 0.091857; Mean validation F1 0.935171; Learning rate 0.000829;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.085729; Mean training F1 0.935844; Mean validation loss 0.108688; Mean validation F1 0.938427; Learning rate 0.000819;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.084567; Mean training F1 0.936104; Mean validation loss 0.093665; Mean validation F1 0.935605; Learning rate 0.000810;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.086103; Mean training F1 0.935688; Mean validation loss 0.097048; Mean validation F1 0.933738; Learning rate 0.000800;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.085724; Mean training F1 0.935723; Mean validation loss 0.085612; Mean validation F1 0.936415; Learning rate 0.000790;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.086724; Mean training F1 0.934956; Mean validation loss 0.085284; Mean validation F1 0.936182; Learning rate 0.000780;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.084555; Mean training F1 0.936484; Mean validation loss 0.109048; Mean validation F1 0.937962; Learning rate 0.000770;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.085680; Mean training F1 0.935748; Mean validation loss 0.086504; Mean validation F1 0.936319; Learning rate 0.000760;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.083959; Mean training F1 0.936497; Mean validation loss 0.098168; Mean validation F1 0.937177; Learning rate 0.000749;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.084797; Mean training F1 0.935979; Mean validation loss 0.114745; Mean validation F1 0.935676; Learning rate 0.000739;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.085294; Mean training F1 0.935420; Mean validation loss 0.070910; Mean validation F1 0.936196; Learning rate 0.000728;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.084117; Mean training F1 0.936591; Mean validation loss 0.060378; Mean validation F1 0.936273; Learning rate 0.000717;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.083782; Mean training F1 0.936863; Mean validation loss 0.108816; Mean validation F1 0.936482; Learning rate 0.000706;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.083762; Mean training F1 0.936498; Mean validation loss 0.080662; Mean validation F1 0.937526; Learning rate 0.000695;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.083429; Mean training F1 0.936574; Mean validation loss 0.067481; Mean validation F1 0.938178; Learning rate 0.000683;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.082683; Mean training F1 0.937380; Mean validation loss 0.087831; Mean validation F1 0.937597; Learning rate 0.000672;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.082349; Mean training F1 0.937429; Mean validation loss 0.069900; Mean validation F1 0.938665; Learning rate 0.000661;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.083329; Mean training F1 0.937255; Mean validation loss 0.134042; Mean validation F1 0.937484; Learning rate 0.000649;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.083203; Mean training F1 0.936708; Mean validation loss 0.064267; Mean validation F1 0.936133; Learning rate 0.000637;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.083346; Mean training F1 0.936832; Mean validation loss 0.109002; Mean validation F1 0.937162; Learning rate 0.000626;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.083712; Mean training F1 0.936796; Mean validation loss 0.107521; Mean validation F1 0.934849; Learning rate 0.000614;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.083820; Mean training F1 0.936087; Mean validation loss 0.105101; Mean validation F1 0.936314; Learning rate 0.000602;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.083418; Mean training F1 0.936843; Mean validation loss 0.091102; Mean validation F1 0.936572; Learning rate 0.000590;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.081819; Mean training F1 0.937747; Mean validation loss 0.073577; Mean validation F1 0.935828; Learning rate 0.000578;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.082509; Mean training F1 0.937177; Mean validation loss 0.074508; Mean validation F1 0.938166; Learning rate 0.000566;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.082298; Mean training F1 0.937651; Mean validation loss 0.071554; Mean validation F1 0.938140; Learning rate 0.000554;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.083106; Mean training F1 0.937343; Mean validation loss 0.112826; Mean validation F1 0.936586; Learning rate 0.000542;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.082572; Mean training F1 0.937499; Mean validation loss 0.087499; Mean validation F1 0.932468; Learning rate 0.000530;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.081990; Mean training F1 0.937959; Mean validation loss 0.096139; Mean validation F1 0.936918; Learning rate 0.000517;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.081695; Mean training F1 0.937911; Mean validation loss 0.086850; Mean validation F1 0.938441; Learning rate 0.000505;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.081459; Mean training F1 0.937899; Mean validation loss 0.061183; Mean validation F1 0.938347; Learning rate 0.000493;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.081378; Mean training F1 0.937992; Mean validation loss 0.083322; Mean validation F1 0.937869; Learning rate 0.000481;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.081933; Mean training F1 0.937841; Mean validation loss 0.100880; Mean validation F1 0.935361; Learning rate 0.000469;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.081909; Mean training F1 0.937722; Mean validation loss 0.083106; Mean validation F1 0.938070; Learning rate 0.000457;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.081410; Mean training F1 0.938220; Mean validation loss 0.112885; Mean validation F1 0.938710; Learning rate 0.000445;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.080708; Mean training F1 0.938520; Mean validation loss 0.088448; Mean validation F1 0.937044; Learning rate 0.000433;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.081456; Mean training F1 0.938048; Mean validation loss 0.106207; Mean validation F1 0.938425; Learning rate 0.000421;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.081129; Mean training F1 0.938427; Mean validation loss 0.087548; Mean validation F1 0.938316; Learning rate 0.000409;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.081302; Mean training F1 0.938115; Mean validation loss 0.087601; Mean validation F1 0.936468; Learning rate 0.000397;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.081209; Mean training F1 0.938153; Mean validation loss 0.076475; Mean validation F1 0.938471; Learning rate 0.000385;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.080550; Mean training F1 0.938639; Mean validation loss 0.092915; Mean validation F1 0.938378; Learning rate 0.000373;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.080717; Mean training F1 0.938525; Mean validation loss 0.059543; Mean validation F1 0.938786; Learning rate 0.000362;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.080747; Mean training F1 0.938592; Mean validation loss 0.107826; Mean validation F1 0.938883; Learning rate 0.000350;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.080491; Mean training F1 0.938731; Mean validation loss 0.092136; Mean validation F1 0.938750; Learning rate 0.000339;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.080276; Mean training F1 0.938647; Mean validation loss 0.073116; Mean validation F1 0.936186; Learning rate 0.000327;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.080382; Mean training F1 0.938752; Mean validation loss 0.102038; Mean validation F1 0.938350; Learning rate 0.000316;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.079916; Mean training F1 0.938892; Mean validation loss 0.076581; Mean validation F1 0.938639; Learning rate 0.000305;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.080097; Mean training F1 0.939023; Mean validation loss 0.083162; Mean validation F1 0.938630; Learning rate 0.000294;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.080070; Mean training F1 0.938860; Mean validation loss 0.068719; Mean validation F1 0.936107; Learning rate 0.000283;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.079621; Mean training F1 0.938957; Mean validation loss 0.053067; Mean validation F1 0.937250; Learning rate 0.000272;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.080194; Mean training F1 0.938832; Mean validation loss 0.071208; Mean validation F1 0.936240; Learning rate 0.000261;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.080602; Mean training F1 0.938443; Mean validation loss 0.098632; Mean validation F1 0.938665; Learning rate 0.000251;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.080026; Mean training F1 0.938794; Mean validation loss 0.094378; Mean validation F1 0.938907; Learning rate 0.000240;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.079914; Mean training F1 0.939171; Mean validation loss 0.106424; Mean validation F1 0.938549; Learning rate 0.000230;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.080289; Mean training F1 0.938719; Mean validation loss 0.076357; Mean validation F1 0.938715; Learning rate 0.000220;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.079856; Mean training F1 0.939090; Mean validation loss 0.055692; Mean validation F1 0.938075; Learning rate 0.000210;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.079105; Mean training F1 0.939397; Mean validation loss 0.048459; Mean validation F1 0.938915; Learning rate 0.000201;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.079406; Mean training F1 0.939220; Mean validation loss 0.076169; Mean validation F1 0.938696; Learning rate 0.000191;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.079527; Mean training F1 0.939260; Mean validation loss 0.091826; Mean validation F1 0.938959; Learning rate 0.000182;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.079367; Mean training F1 0.939427; Mean validation loss 0.100731; Mean validation F1 0.938717; Learning rate 0.000173;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.079101; Mean training F1 0.939431; Mean validation loss 0.077141; Mean validation F1 0.939047; Learning rate 0.000164;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.078938; Mean training F1 0.939446; Mean validation loss 0.050359; Mean validation F1 0.938658; Learning rate 0.000155;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.078847; Mean training F1 0.939442; Mean validation loss 0.057574; Mean validation F1 0.938972; Learning rate 0.000147;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.079462; Mean training F1 0.939266; Mean validation loss 0.078598; Mean validation F1 0.938449; Learning rate 0.000139;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.079173; Mean training F1 0.939527; Mean validation loss 0.091337; Mean validation F1 0.938637; Learning rate 0.000130;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.079100; Mean training F1 0.939466; Mean validation loss 0.076150; Mean validation F1 0.938297; Learning rate 0.000123;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.078991; Mean training F1 0.939645; Mean validation loss 0.084661; Mean validation F1 0.938947; Learning rate 0.000115;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.078866; Mean training F1 0.939600; Mean validation loss 0.079166; Mean validation F1 0.938552; Learning rate 0.000108;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.082619; Mean training F1 0.937900; Mean validation loss 0.091917; Mean validation F1 0.937928; Learning rate 0.000101;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.080164; Mean training F1 0.938982; Mean validation loss 0.094293; Mean validation F1 0.938255; Learning rate 0.000094;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.079055; Mean training F1 0.939625; Mean validation loss 0.094389; Mean validation F1 0.938286; Learning rate 0.000087;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.078644; Mean training F1 0.939735; Mean validation loss 0.062049; Mean validation F1 0.938449; Learning rate 0.000081;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.078562; Mean training F1 0.939720; Mean validation loss 0.061831; Mean validation F1 0.938955; Learning rate 0.000075;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.078945; Mean training F1 0.939616; Mean validation loss 0.103210; Mean validation F1 0.938918; Learning rate 0.000069;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.078895; Mean training F1 0.939607; Mean validation loss 0.091741; Mean validation F1 0.938841; Learning rate 0.000063;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.078906; Mean training F1 0.939621; Mean validation loss 0.094389; Mean validation F1 0.939077; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.078640; Mean training F1 0.939792; Mean validation loss 0.080491; Mean validation F1 0.938870; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.078760; Mean training F1 0.939644; Mean validation loss 0.087226; Mean validation F1 0.938462; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.078435; Mean training F1 0.939913; Mean validation loss 0.082715; Mean validation F1 0.939063; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.078430; Mean training F1 0.939814; Mean validation loss 0.066476; Mean validation F1 0.938782; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.078405; Mean training F1 0.939830; Mean validation loss 0.060106; Mean validation F1 0.938396; Learning rate 0.000035;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.078361; Mean training F1 0.939836; Mean validation loss 0.065973; Mean validation F1 0.938778; Learning rate 0.000032;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.078527; Mean training F1 0.939866; Mean validation loss 0.096666; Mean validation F1 0.939092; Learning rate 0.000028;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.078566; Mean training F1 0.939856; Mean validation loss 0.095826; Mean validation F1 0.938849; Learning rate 0.000025;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.078278; Mean training F1 0.939902; Mean validation loss 0.072793; Mean validation F1 0.938851; Learning rate 0.000022;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.078375; Mean training F1 0.939859; Mean validation loss 0.084032; Mean validation F1 0.938971; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.078458; Mean training F1 0.939837; Mean validation loss 0.075287; Mean validation F1 0.938942; Learning rate 0.000018;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.078429; Mean training F1 0.939964; Mean validation loss 0.099862; Mean validation F1 0.938906; Learning rate 0.000016;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.078049; Mean training F1 0.939889; Mean validation loss 0.050896; Mean validation F1 0.938750; Learning rate 0.000014;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.078410; Mean training F1 0.940029; Mean validation loss 0.080387; Mean validation F1 0.939101; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.078402; Mean training F1 0.939954; Mean validation loss 0.085556; Mean validation F1 0.938959; Learning rate 0.000012;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.078100; Mean training F1 0.939878; Mean validation loss 0.055335; Mean validation F1 0.938792; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.078255; Mean training F1 0.940007; Mean validation loss 0.083109; Mean validation F1 0.938977; Learning rate 0.000010;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.078448; Mean training F1 0.939901; Mean validation loss 0.097059; Mean validation F1 0.938732; Learning rate 0.000010;\n",
    "################################################################\n",
    "Training/validation for fold 2/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.556618; Mean training F1 0.712192; Mean validation loss 0.280484; Mean validation F1 0.875126; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.242499; Mean training F1 0.873512; Mean validation loss 0.333428; Mean validation F1 0.870924; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.169649; Mean training F1 0.900001; Mean validation loss 0.322927; Mean validation F1 0.888312; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.145633; Mean training F1 0.911299; Mean validation loss 0.212506; Mean validation F1 0.907126; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.166166; Mean training F1 0.902797; Mean validation loss 0.138510; Mean validation F1 0.919622; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.137472; Mean training F1 0.913558; Mean validation loss 0.228054; Mean validation F1 0.925048; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.122516; Mean training F1 0.920831; Mean validation loss 0.106445; Mean validation F1 0.920459; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.121078; Mean training F1 0.920575; Mean validation loss 0.132656; Mean validation F1 0.929285; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.114925; Mean training F1 0.923148; Mean validation loss 0.106268; Mean validation F1 0.931295; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.123001; Mean training F1 0.920803; Mean validation loss 0.159349; Mean validation F1 0.925968; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.108691; Mean training F1 0.926976; Mean validation loss 0.164585; Mean validation F1 0.922373; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.104849; Mean training F1 0.927989; Mean validation loss 0.102663; Mean validation F1 0.854636; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.103760; Mean training F1 0.927746; Mean validation loss 0.295533; Mean validation F1 0.924551; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.105118; Mean training F1 0.928306; Mean validation loss 0.086157; Mean validation F1 0.929481; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.094576; Mean training F1 0.932432; Mean validation loss 0.105669; Mean validation F1 0.911451; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.094842; Mean training F1 0.932392; Mean validation loss 0.128677; Mean validation F1 0.869753; Learning rate 0.000963;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.101552; Mean training F1 0.926370; Mean validation loss 0.063974; Mean validation F1 0.934250; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.093108; Mean training F1 0.932010; Mean validation loss 0.091013; Mean validation F1 0.894908; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.090371; Mean training F1 0.933065; Mean validation loss 0.102711; Mean validation F1 0.930888; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.089793; Mean training F1 0.932554; Mean validation loss 0.103416; Mean validation F1 0.922686; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.089395; Mean training F1 0.933578; Mean validation loss 0.081407; Mean validation F1 0.935466; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.088582; Mean training F1 0.934341; Mean validation loss 0.075257; Mean validation F1 0.933448; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.089160; Mean training F1 0.934678; Mean validation loss 0.096955; Mean validation F1 0.931990; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.088277; Mean training F1 0.934493; Mean validation loss 0.077749; Mean validation F1 0.932044; Learning rate 0.000917;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.086720; Mean training F1 0.935186; Mean validation loss 0.085033; Mean validation F1 0.935586; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.088272; Mean training F1 0.933790; Mean validation loss 0.129926; Mean validation F1 0.925469; Learning rate 0.000903;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.087624; Mean training F1 0.934700; Mean validation loss 0.105229; Mean validation F1 0.934778; Learning rate 0.000896;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.085942; Mean training F1 0.935210; Mean validation loss 0.069032; Mean validation F1 0.934605; Learning rate 0.000888;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.086385; Mean training F1 0.935767; Mean validation loss 0.112312; Mean validation F1 0.935664; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.086274; Mean training F1 0.935798; Mean validation loss 0.116873; Mean validation F1 0.932964; Learning rate 0.000872;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.084671; Mean training F1 0.936121; Mean validation loss 0.069451; Mean validation F1 0.934330; Learning rate 0.000864;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.085759; Mean training F1 0.935305; Mean validation loss 0.073396; Mean validation F1 0.931879; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.083557; Mean training F1 0.936652; Mean validation loss 0.067908; Mean validation F1 0.935612; Learning rate 0.000847;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.083931; Mean training F1 0.936548; Mean validation loss 0.073644; Mean validation F1 0.936521; Learning rate 0.000838;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.084598; Mean training F1 0.936684; Mean validation loss 0.071947; Mean validation F1 0.936160; Learning rate 0.000829;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.083849; Mean training F1 0.936312; Mean validation loss 0.072424; Mean validation F1 0.933930; Learning rate 0.000819;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.083787; Mean training F1 0.936428; Mean validation loss 0.091935; Mean validation F1 0.935078; Learning rate 0.000810;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.085849; Mean training F1 0.935146; Mean validation loss 0.104054; Mean validation F1 0.935314; Learning rate 0.000800;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.085244; Mean training F1 0.935899; Mean validation loss 0.085542; Mean validation F1 0.936109; Learning rate 0.000790;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.084656; Mean training F1 0.935350; Mean validation loss 0.119329; Mean validation F1 0.936780; Learning rate 0.000780;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.082723; Mean training F1 0.937436; Mean validation loss 0.085126; Mean validation F1 0.936305; Learning rate 0.000770;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.084149; Mean training F1 0.936354; Mean validation loss 0.082370; Mean validation F1 0.935175; Learning rate 0.000760;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.084754; Mean training F1 0.935452; Mean validation loss 0.077620; Mean validation F1 0.937162; Learning rate 0.000749;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.083163; Mean training F1 0.936967; Mean validation loss 0.103819; Mean validation F1 0.935000; Learning rate 0.000739;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.083801; Mean training F1 0.935887; Mean validation loss 0.048597; Mean validation F1 0.933367; Learning rate 0.000728;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.082757; Mean training F1 0.936938; Mean validation loss 0.087337; Mean validation F1 0.931198; Learning rate 0.000717;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.082765; Mean training F1 0.936824; Mean validation loss 0.058174; Mean validation F1 0.935004; Learning rate 0.000706;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.082246; Mean training F1 0.936872; Mean validation loss 0.032995; Mean validation F1 0.936042; Learning rate 0.000695;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.082771; Mean training F1 0.936950; Mean validation loss 0.116906; Mean validation F1 0.936438; Learning rate 0.000683;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.082901; Mean training F1 0.936676; Mean validation loss 0.090766; Mean validation F1 0.937304; Learning rate 0.000672;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.082815; Mean training F1 0.936586; Mean validation loss 0.082138; Mean validation F1 0.936273; Learning rate 0.000661;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.083067; Mean training F1 0.936760; Mean validation loss 0.067883; Mean validation F1 0.936932; Learning rate 0.000649;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.081215; Mean training F1 0.938015; Mean validation loss 0.052527; Mean validation F1 0.934120; Learning rate 0.000637;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.082236; Mean training F1 0.937225; Mean validation loss 0.122832; Mean validation F1 0.936721; Learning rate 0.000626;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.082719; Mean training F1 0.936287; Mean validation loss 0.065823; Mean validation F1 0.936162; Learning rate 0.000614;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.081935; Mean training F1 0.937569; Mean validation loss 0.094823; Mean validation F1 0.937384; Learning rate 0.000602;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.081646; Mean training F1 0.937826; Mean validation loss 0.115618; Mean validation F1 0.935814; Learning rate 0.000590;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.086677; Mean training F1 0.935531; Mean validation loss 0.105852; Mean validation F1 0.936811; Learning rate 0.000578;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.082954; Mean training F1 0.936332; Mean validation loss 0.081985; Mean validation F1 0.932271; Learning rate 0.000566;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.082440; Mean training F1 0.936924; Mean validation loss 0.089737; Mean validation F1 0.937379; Learning rate 0.000554;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.080791; Mean training F1 0.937925; Mean validation loss 0.072349; Mean validation F1 0.936827; Learning rate 0.000542;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.080886; Mean training F1 0.938084; Mean validation loss 0.086156; Mean validation F1 0.936560; Learning rate 0.000530;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.080822; Mean training F1 0.938276; Mean validation loss 0.087866; Mean validation F1 0.936588; Learning rate 0.000517;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.080821; Mean training F1 0.938033; Mean validation loss 0.101701; Mean validation F1 0.937035; Learning rate 0.000505;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.084498; Mean training F1 0.937615; Mean validation loss 0.289224; Mean validation F1 0.879199; Learning rate 0.000493;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.165384; Mean training F1 0.900932; Mean validation loss 0.066707; Mean validation F1 0.885849; Learning rate 0.000481;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.091036; Mean training F1 0.934114; Mean validation loss 0.093720; Mean validation F1 0.935589; Learning rate 0.000469;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.085346; Mean training F1 0.936374; Mean validation loss 0.059842; Mean validation F1 0.936164; Learning rate 0.000457;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.084418; Mean training F1 0.936720; Mean validation loss 0.092668; Mean validation F1 0.936960; Learning rate 0.000445;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.082723; Mean training F1 0.937745; Mean validation loss 0.118665; Mean validation F1 0.936861; Learning rate 0.000433;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.081650; Mean training F1 0.937895; Mean validation loss 0.054888; Mean validation F1 0.937393; Learning rate 0.000421;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.081489; Mean training F1 0.938200; Mean validation loss 0.052162; Mean validation F1 0.936558; Learning rate 0.000409;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.081879; Mean training F1 0.937735; Mean validation loss 0.083841; Mean validation F1 0.937266; Learning rate 0.000397;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.081410; Mean training F1 0.938212; Mean validation loss 0.087108; Mean validation F1 0.937589; Learning rate 0.000385;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.080665; Mean training F1 0.938573; Mean validation loss 0.069677; Mean validation F1 0.937056; Learning rate 0.000373;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.080472; Mean training F1 0.938506; Mean validation loss 0.055745; Mean validation F1 0.937623; Learning rate 0.000362;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.080766; Mean training F1 0.938591; Mean validation loss 0.100394; Mean validation F1 0.937180; Learning rate 0.000350;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.080381; Mean training F1 0.938684; Mean validation loss 0.065861; Mean validation F1 0.937142; Learning rate 0.000339;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.080812; Mean training F1 0.938626; Mean validation loss 0.113303; Mean validation F1 0.937245; Learning rate 0.000327;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.080024; Mean training F1 0.938829; Mean validation loss 0.059987; Mean validation F1 0.936684; Learning rate 0.000316;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.081308; Mean training F1 0.938359; Mean validation loss 0.137978; Mean validation F1 0.936270; Learning rate 0.000305;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.085368; Mean training F1 0.935640; Mean validation loss 0.079596; Mean validation F1 0.937229; Learning rate 0.000294;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.080810; Mean training F1 0.938519; Mean validation loss 0.103244; Mean validation F1 0.937514; Learning rate 0.000283;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.080078; Mean training F1 0.938945; Mean validation loss 0.074681; Mean validation F1 0.937640; Learning rate 0.000272;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.080411; Mean training F1 0.938590; Mean validation loss 0.110736; Mean validation F1 0.937546; Learning rate 0.000261;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.080256; Mean training F1 0.938708; Mean validation loss 0.086865; Mean validation F1 0.937571; Learning rate 0.000251;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.080276; Mean training F1 0.938538; Mean validation loss 0.071609; Mean validation F1 0.937737; Learning rate 0.000240;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.080683; Mean training F1 0.938748; Mean validation loss 0.145520; Mean validation F1 0.937569; Learning rate 0.000230;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.079809; Mean training F1 0.938531; Mean validation loss 0.051216; Mean validation F1 0.937693; Learning rate 0.000220;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.080036; Mean training F1 0.938912; Mean validation loss 0.088538; Mean validation F1 0.937314; Learning rate 0.000210;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.079976; Mean training F1 0.939114; Mean validation loss 0.114768; Mean validation F1 0.937644; Learning rate 0.000201;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.080221; Mean training F1 0.938604; Mean validation loss 0.105772; Mean validation F1 0.938018; Learning rate 0.000191;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.079746; Mean training F1 0.938831; Mean validation loss 0.072997; Mean validation F1 0.937912; Learning rate 0.000182;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.079394; Mean training F1 0.939129; Mean validation loss 0.058813; Mean validation F1 0.937483; Learning rate 0.000173;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.080090; Mean training F1 0.939032; Mean validation loss 0.141563; Mean validation F1 0.936865; Learning rate 0.000164;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.079951; Mean training F1 0.938768; Mean validation loss 0.097656; Mean validation F1 0.937746; Learning rate 0.000155;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.079441; Mean training F1 0.939297; Mean validation loss 0.090712; Mean validation F1 0.938009; Learning rate 0.000147;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.079586; Mean training F1 0.939100; Mean validation loss 0.120980; Mean validation F1 0.937975; Learning rate 0.000139;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.079438; Mean training F1 0.939109; Mean validation loss 0.107294; Mean validation F1 0.937867; Learning rate 0.000130;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.079378; Mean training F1 0.939257; Mean validation loss 0.106301; Mean validation F1 0.937931; Learning rate 0.000123;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.079143; Mean training F1 0.939275; Mean validation loss 0.082868; Mean validation F1 0.937506; Learning rate 0.000115;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.079183; Mean training F1 0.939085; Mean validation loss 0.070491; Mean validation F1 0.937595; Learning rate 0.000108;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.079362; Mean training F1 0.939140; Mean validation loss 0.089724; Mean validation F1 0.937673; Learning rate 0.000101;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.079099; Mean training F1 0.939310; Mean validation loss 0.088502; Mean validation F1 0.937950; Learning rate 0.000094;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.078885; Mean training F1 0.939350; Mean validation loss 0.059890; Mean validation F1 0.938067; Learning rate 0.000087;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.078986; Mean training F1 0.939235; Mean validation loss 0.071328; Mean validation F1 0.937870; Learning rate 0.000081;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.078895; Mean training F1 0.939260; Mean validation loss 0.057023; Mean validation F1 0.937812; Learning rate 0.000075;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.078989; Mean training F1 0.939425; Mean validation loss 0.086146; Mean validation F1 0.937735; Learning rate 0.000069;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.079207; Mean training F1 0.939258; Mean validation loss 0.085534; Mean validation F1 0.937792; Learning rate 0.000063;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.078880; Mean training F1 0.939426; Mean validation loss 0.082338; Mean validation F1 0.937864; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.079642; Mean training F1 0.939340; Mean validation loss 0.144527; Mean validation F1 0.937985; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.079052; Mean training F1 0.939569; Mean validation loss 0.100105; Mean validation F1 0.937772; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.079202; Mean training F1 0.939469; Mean validation loss 0.119374; Mean validation F1 0.937860; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.079028; Mean training F1 0.939255; Mean validation loss 0.079225; Mean validation F1 0.937960; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.079021; Mean training F1 0.939576; Mean validation loss 0.105114; Mean validation F1 0.937961; Learning rate 0.000035;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.078641; Mean training F1 0.939397; Mean validation loss 0.046655; Mean validation F1 0.937734; Learning rate 0.000032;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.078682; Mean training F1 0.939455; Mean validation loss 0.062161; Mean validation F1 0.938143; Learning rate 0.000028;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.078598; Mean training F1 0.939429; Mean validation loss 0.064154; Mean validation F1 0.937812; Learning rate 0.000025;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.078931; Mean training F1 0.939644; Mean validation loss 0.107788; Mean validation F1 0.938061; Learning rate 0.000022;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.078882; Mean training F1 0.939459; Mean validation loss 0.097172; Mean validation F1 0.937899; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.078577; Mean training F1 0.939593; Mean validation loss 0.061328; Mean validation F1 0.937934; Learning rate 0.000018;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.078628; Mean training F1 0.939539; Mean validation loss 0.070997; Mean validation F1 0.937949; Learning rate 0.000016;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.078404; Mean training F1 0.939671; Mean validation loss 0.048135; Mean validation F1 0.937742; Learning rate 0.000014;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.078689; Mean training F1 0.939600; Mean validation loss 0.087958; Mean validation F1 0.937804; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.078743; Mean training F1 0.939483; Mean validation loss 0.088843; Mean validation F1 0.937928; Learning rate 0.000012;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.078755; Mean training F1 0.939532; Mean validation loss 0.087093; Mean validation F1 0.937923; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.078883; Mean training F1 0.939569; Mean validation loss 0.111066; Mean validation F1 0.937698; Learning rate 0.000010;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.078711; Mean training F1 0.939552; Mean validation loss 0.079163; Mean validation F1 0.938036; Learning rate 0.000010;\n",
    "################################################################\n",
    "Training/validation for fold 3/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.594109; Mean training F1 0.694603; Mean validation loss 0.240811; Mean validation F1 0.867047; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.217220; Mean training F1 0.884987; Mean validation loss 0.161032; Mean validation F1 0.880499; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.149041; Mean training F1 0.910371; Mean validation loss 0.138557; Mean validation F1 0.888599; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.127602; Mean training F1 0.918172; Mean validation loss 0.092522; Mean validation F1 0.902772; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.120598; Mean training F1 0.921499; Mean validation loss 0.153800; Mean validation F1 0.928468; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.108250; Mean training F1 0.927021; Mean validation loss 0.131010; Mean validation F1 0.930876; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.114208; Mean training F1 0.927185; Mean validation loss 0.580231; Mean validation F1 0.842942; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.182190; Mean training F1 0.898614; Mean validation loss 0.172231; Mean validation F1 0.921875; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.118848; Mean training F1 0.921351; Mean validation loss 0.133188; Mean validation F1 0.930251; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.105584; Mean training F1 0.927870; Mean validation loss 0.109883; Mean validation F1 0.927310; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.104129; Mean training F1 0.929412; Mean validation loss 0.144181; Mean validation F1 0.926953; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.100673; Mean training F1 0.930178; Mean validation loss 0.127758; Mean validation F1 0.915814; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.100770; Mean training F1 0.928253; Mean validation loss 0.172239; Mean validation F1 0.926355; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.097220; Mean training F1 0.931070; Mean validation loss 0.089571; Mean validation F1 0.927673; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.097278; Mean training F1 0.930946; Mean validation loss 0.117682; Mean validation F1 0.931623; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.105373; Mean training F1 0.928297; Mean validation loss 0.186881; Mean validation F1 0.570527; Learning rate 0.000963;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.096880; Mean training F1 0.931868; Mean validation loss 0.090579; Mean validation F1 0.933271; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.095007; Mean training F1 0.932325; Mean validation loss 0.080700; Mean validation F1 0.934986; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.091697; Mean training F1 0.933171; Mean validation loss 0.098937; Mean validation F1 0.934151; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.092403; Mean training F1 0.933247; Mean validation loss 0.078582; Mean validation F1 0.932587; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.091606; Mean training F1 0.933093; Mean validation loss 0.080174; Mean validation F1 0.931386; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.090437; Mean training F1 0.933344; Mean validation loss 0.070597; Mean validation F1 0.934917; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.090926; Mean training F1 0.934070; Mean validation loss 0.075212; Mean validation F1 0.933198; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.089138; Mean training F1 0.934939; Mean validation loss 0.098434; Mean validation F1 0.931639; Learning rate 0.000917;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.087687; Mean training F1 0.934820; Mean validation loss 0.087804; Mean validation F1 0.935843; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.086959; Mean training F1 0.935112; Mean validation loss 0.063895; Mean validation F1 0.926756; Learning rate 0.000903;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.090168; Mean training F1 0.932654; Mean validation loss 0.082376; Mean validation F1 0.934200; Learning rate 0.000896;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.087653; Mean training F1 0.934962; Mean validation loss 0.076071; Mean validation F1 0.933931; Learning rate 0.000888;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.086884; Mean training F1 0.935912; Mean validation loss 0.105146; Mean validation F1 0.935229; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.088840; Mean training F1 0.934085; Mean validation loss 0.126625; Mean validation F1 0.935398; Learning rate 0.000872;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.086839; Mean training F1 0.935422; Mean validation loss 0.081549; Mean validation F1 0.933785; Learning rate 0.000864;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.086461; Mean training F1 0.936322; Mean validation loss 0.133653; Mean validation F1 0.935230; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.086447; Mean training F1 0.935094; Mean validation loss 0.083697; Mean validation F1 0.929650; Learning rate 0.000847;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.086466; Mean training F1 0.935097; Mean validation loss 0.115133; Mean validation F1 0.935843; Learning rate 0.000838;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.085380; Mean training F1 0.935904; Mean validation loss 0.073079; Mean validation F1 0.936333; Learning rate 0.000829;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.084082; Mean training F1 0.937240; Mean validation loss 0.098385; Mean validation F1 0.936036; Learning rate 0.000819;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.084832; Mean training F1 0.936332; Mean validation loss 0.090814; Mean validation F1 0.932547; Learning rate 0.000810;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.085296; Mean training F1 0.936392; Mean validation loss 0.066111; Mean validation F1 0.936059; Learning rate 0.000800;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.084449; Mean training F1 0.936233; Mean validation loss 0.071691; Mean validation F1 0.935811; Learning rate 0.000790;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.083877; Mean training F1 0.936688; Mean validation loss 0.091479; Mean validation F1 0.936095; Learning rate 0.000780;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.083867; Mean training F1 0.936913; Mean validation loss 0.073032; Mean validation F1 0.935817; Learning rate 0.000770;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.083878; Mean training F1 0.936780; Mean validation loss 0.068504; Mean validation F1 0.935844; Learning rate 0.000760;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.083697; Mean training F1 0.937064; Mean validation loss 0.104118; Mean validation F1 0.936384; Learning rate 0.000749;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.083528; Mean training F1 0.937031; Mean validation loss 0.084208; Mean validation F1 0.937118; Learning rate 0.000739;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.099864; Mean training F1 0.930506; Mean validation loss 0.101082; Mean validation F1 0.924210; Learning rate 0.000728;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.092169; Mean training F1 0.933398; Mean validation loss 0.103868; Mean validation F1 0.933306; Learning rate 0.000717;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.085714; Mean training F1 0.935683; Mean validation loss 0.087722; Mean validation F1 0.936337; Learning rate 0.000706;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.084337; Mean training F1 0.936327; Mean validation loss 0.059685; Mean validation F1 0.935376; Learning rate 0.000695;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.083839; Mean training F1 0.937089; Mean validation loss 0.086160; Mean validation F1 0.934837; Learning rate 0.000683;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.084445; Mean training F1 0.936352; Mean validation loss 0.076291; Mean validation F1 0.936158; Learning rate 0.000672;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.110463; Mean training F1 0.923220; Mean validation loss 0.116162; Mean validation F1 0.506116; Learning rate 0.000661;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.094625; Mean training F1 0.932032; Mean validation loss 0.095157; Mean validation F1 0.934866; Learning rate 0.000649;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.086787; Mean training F1 0.935337; Mean validation loss 0.093982; Mean validation F1 0.936314; Learning rate 0.000637;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.084139; Mean training F1 0.936654; Mean validation loss 0.055122; Mean validation F1 0.936509; Learning rate 0.000626;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.084288; Mean training F1 0.936625; Mean validation loss 0.103489; Mean validation F1 0.936464; Learning rate 0.000614;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.083501; Mean training F1 0.936696; Mean validation loss 0.056857; Mean validation F1 0.936364; Learning rate 0.000602;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.083073; Mean training F1 0.937231; Mean validation loss 0.104809; Mean validation F1 0.937127; Learning rate 0.000590;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.082357; Mean training F1 0.937470; Mean validation loss 0.078553; Mean validation F1 0.935911; Learning rate 0.000578;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.082714; Mean training F1 0.937258; Mean validation loss 0.071245; Mean validation F1 0.934024; Learning rate 0.000566;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.082387; Mean training F1 0.937900; Mean validation loss 0.106912; Mean validation F1 0.936172; Learning rate 0.000554;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.082402; Mean training F1 0.937579; Mean validation loss 0.077506; Mean validation F1 0.936462; Learning rate 0.000542;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.081432; Mean training F1 0.937942; Mean validation loss 0.047385; Mean validation F1 0.937041; Learning rate 0.000530;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.081950; Mean training F1 0.938202; Mean validation loss 0.078942; Mean validation F1 0.934965; Learning rate 0.000517;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.082139; Mean training F1 0.938002; Mean validation loss 0.095528; Mean validation F1 0.937467; Learning rate 0.000505;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.082538; Mean training F1 0.937419; Mean validation loss 0.060658; Mean validation F1 0.936633; Learning rate 0.000493;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.081797; Mean training F1 0.938076; Mean validation loss 0.090413; Mean validation F1 0.936733; Learning rate 0.000481;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.081298; Mean training F1 0.938160; Mean validation loss 0.061319; Mean validation F1 0.936965; Learning rate 0.000469;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.081420; Mean training F1 0.938101; Mean validation loss 0.082083; Mean validation F1 0.936996; Learning rate 0.000457;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.081212; Mean training F1 0.938310; Mean validation loss 0.060083; Mean validation F1 0.936928; Learning rate 0.000445;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.080906; Mean training F1 0.938480; Mean validation loss 0.053874; Mean validation F1 0.937063; Learning rate 0.000433;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.081248; Mean training F1 0.938290; Mean validation loss 0.062659; Mean validation F1 0.936727; Learning rate 0.000421;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.081242; Mean training F1 0.938339; Mean validation loss 0.080717; Mean validation F1 0.936417; Learning rate 0.000409;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.080618; Mean training F1 0.938675; Mean validation loss 0.092996; Mean validation F1 0.937256; Learning rate 0.000397;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.080561; Mean training F1 0.938719; Mean validation loss 0.080128; Mean validation F1 0.937232; Learning rate 0.000385;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.080263; Mean training F1 0.938695; Mean validation loss 0.049587; Mean validation F1 0.936471; Learning rate 0.000373;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.080979; Mean training F1 0.938441; Mean validation loss 0.063815; Mean validation F1 0.937122; Learning rate 0.000362;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.081138; Mean training F1 0.938482; Mean validation loss 0.089871; Mean validation F1 0.937213; Learning rate 0.000350;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.080403; Mean training F1 0.938785; Mean validation loss 0.081688; Mean validation F1 0.936857; Learning rate 0.000339;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.081307; Mean training F1 0.938619; Mean validation loss 0.164627; Mean validation F1 0.935143; Learning rate 0.000327;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.081109; Mean training F1 0.938058; Mean validation loss 0.078582; Mean validation F1 0.936825; Learning rate 0.000316;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.080303; Mean training F1 0.938786; Mean validation loss 0.063329; Mean validation F1 0.937154; Learning rate 0.000305;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.080080; Mean training F1 0.938763; Mean validation loss 0.071907; Mean validation F1 0.937326; Learning rate 0.000294;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.080005; Mean training F1 0.938868; Mean validation loss 0.086815; Mean validation F1 0.936335; Learning rate 0.000283;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.080209; Mean training F1 0.938784; Mean validation loss 0.054808; Mean validation F1 0.936818; Learning rate 0.000272;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.080110; Mean training F1 0.939007; Mean validation loss 0.089151; Mean validation F1 0.936921; Learning rate 0.000261;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.079823; Mean training F1 0.939046; Mean validation loss 0.073936; Mean validation F1 0.937088; Learning rate 0.000251;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.080381; Mean training F1 0.939031; Mean validation loss 0.122156; Mean validation F1 0.937022; Learning rate 0.000240;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.080293; Mean training F1 0.938885; Mean validation loss 0.074166; Mean validation F1 0.936723; Learning rate 0.000230;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.079660; Mean training F1 0.939245; Mean validation loss 0.073734; Mean validation F1 0.937480; Learning rate 0.000220;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.079788; Mean training F1 0.939119; Mean validation loss 0.076787; Mean validation F1 0.937282; Learning rate 0.000210;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.079534; Mean training F1 0.939176; Mean validation loss 0.066475; Mean validation F1 0.937571; Learning rate 0.000201;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.080037; Mean training F1 0.938959; Mean validation loss 0.125104; Mean validation F1 0.936792; Learning rate 0.000191;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.079498; Mean training F1 0.939163; Mean validation loss 0.083243; Mean validation F1 0.937276; Learning rate 0.000182;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.079287; Mean training F1 0.939203; Mean validation loss 0.063437; Mean validation F1 0.937522; Learning rate 0.000173;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.079338; Mean training F1 0.939358; Mean validation loss 0.083191; Mean validation F1 0.937625; Learning rate 0.000164;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.079599; Mean training F1 0.939186; Mean validation loss 0.066240; Mean validation F1 0.937214; Learning rate 0.000155;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.079540; Mean training F1 0.939347; Mean validation loss 0.085121; Mean validation F1 0.937334; Learning rate 0.000147;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.079403; Mean training F1 0.939546; Mean validation loss 0.093454; Mean validation F1 0.937319; Learning rate 0.000139;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.079036; Mean training F1 0.939374; Mean validation loss 0.062401; Mean validation F1 0.937396; Learning rate 0.000130;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.078950; Mean training F1 0.939597; Mean validation loss 0.063866; Mean validation F1 0.937012; Learning rate 0.000123;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.079342; Mean training F1 0.939444; Mean validation loss 0.111403; Mean validation F1 0.937121; Learning rate 0.000115;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.079108; Mean training F1 0.939386; Mean validation loss 0.080038; Mean validation F1 0.937180; Learning rate 0.000108;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.079238; Mean training F1 0.939521; Mean validation loss 0.114208; Mean validation F1 0.937289; Learning rate 0.000101;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.079090; Mean training F1 0.939531; Mean validation loss 0.083436; Mean validation F1 0.937369; Learning rate 0.000094;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.078989; Mean training F1 0.939590; Mean validation loss 0.093799; Mean validation F1 0.937132; Learning rate 0.000087;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.078676; Mean training F1 0.939803; Mean validation loss 0.075290; Mean validation F1 0.937683; Learning rate 0.000081;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.078753; Mean training F1 0.939655; Mean validation loss 0.078017; Mean validation F1 0.937439; Learning rate 0.000075;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.078490; Mean training F1 0.939703; Mean validation loss 0.047864; Mean validation F1 0.937468; Learning rate 0.000069;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.078928; Mean training F1 0.939662; Mean validation loss 0.084939; Mean validation F1 0.937173; Learning rate 0.000063;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.078735; Mean training F1 0.939776; Mean validation loss 0.079543; Mean validation F1 0.937272; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.078557; Mean training F1 0.939722; Mean validation loss 0.063589; Mean validation F1 0.937073; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.078734; Mean training F1 0.939709; Mean validation loss 0.091532; Mean validation F1 0.937250; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.078553; Mean training F1 0.939734; Mean validation loss 0.073983; Mean validation F1 0.937369; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.078456; Mean training F1 0.939948; Mean validation loss 0.067234; Mean validation F1 0.937733; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.078677; Mean training F1 0.939892; Mean validation loss 0.094314; Mean validation F1 0.937399; Learning rate 0.000035;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.078500; Mean training F1 0.939882; Mean validation loss 0.070085; Mean validation F1 0.937358; Learning rate 0.000032;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.078513; Mean training F1 0.939918; Mean validation loss 0.081400; Mean validation F1 0.937479; Learning rate 0.000028;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.078458; Mean training F1 0.939917; Mean validation loss 0.085374; Mean validation F1 0.937457; Learning rate 0.000025;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.078641; Mean training F1 0.939715; Mean validation loss 0.093661; Mean validation F1 0.937570; Learning rate 0.000022;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.078293; Mean training F1 0.939827; Mean validation loss 0.048481; Mean validation F1 0.937511; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.078291; Mean training F1 0.939831; Mean validation loss 0.070019; Mean validation F1 0.937585; Learning rate 0.000018;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.078645; Mean training F1 0.939817; Mean validation loss 0.086814; Mean validation F1 0.937340; Learning rate 0.000016;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.078448; Mean training F1 0.939929; Mean validation loss 0.070104; Mean validation F1 0.937500; Learning rate 0.000014;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.078384; Mean training F1 0.939889; Mean validation loss 0.072803; Mean validation F1 0.937362; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.078558; Mean training F1 0.939885; Mean validation loss 0.095241; Mean validation F1 0.937390; Learning rate 0.000012;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.078324; Mean training F1 0.939976; Mean validation loss 0.075451; Mean validation F1 0.937376; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.078705; Mean training F1 0.939911; Mean validation loss 0.106606; Mean validation F1 0.937316; Learning rate 0.000010;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.078368; Mean training F1 0.939827; Mean validation loss 0.080304; Mean validation F1 0.937456; Learning rate 0.000010;\n",
    "################################################################\n",
    "Training/validation for fold 4/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.591017; Mean training F1 0.700309; Mean validation loss 0.361485; Mean validation F1 0.828858; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.242066; Mean training F1 0.868732; Mean validation loss 0.200327; Mean validation F1 0.885264; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.166147; Mean training F1 0.899043; Mean validation loss 0.191121; Mean validation F1 0.928203; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.157937; Mean training F1 0.895780; Mean validation loss 0.101935; Mean validation F1 0.918857; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.134020; Mean training F1 0.915542; Mean validation loss 0.100171; Mean validation F1 0.867889; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.132163; Mean training F1 0.913970; Mean validation loss 0.164109; Mean validation F1 0.911833; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.137577; Mean training F1 0.912637; Mean validation loss 0.142487; Mean validation F1 0.928810; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.121258; Mean training F1 0.920932; Mean validation loss 0.134753; Mean validation F1 0.923840; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.119587; Mean training F1 0.921708; Mean validation loss 0.089929; Mean validation F1 0.930667; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.113709; Mean training F1 0.924940; Mean validation loss 0.079608; Mean validation F1 0.926882; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.108760; Mean training F1 0.926166; Mean validation loss 0.082378; Mean validation F1 0.933084; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.104408; Mean training F1 0.929389; Mean validation loss 0.114820; Mean validation F1 0.930843; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.108679; Mean training F1 0.926905; Mean validation loss 0.121303; Mean validation F1 0.896340; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.113873; Mean training F1 0.923058; Mean validation loss 0.112730; Mean validation F1 0.927951; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.099848; Mean training F1 0.931202; Mean validation loss 0.072704; Mean validation F1 0.929873; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.102455; Mean training F1 0.928975; Mean validation loss 0.095606; Mean validation F1 0.931953; Learning rate 0.000963;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.108959; Mean training F1 0.924485; Mean validation loss 0.069817; Mean validation F1 0.929987; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.100872; Mean training F1 0.930239; Mean validation loss 0.076911; Mean validation F1 0.935146; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.100928; Mean training F1 0.930253; Mean validation loss 0.139574; Mean validation F1 0.929419; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.098753; Mean training F1 0.930798; Mean validation loss 0.066936; Mean validation F1 0.907912; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.105353; Mean training F1 0.926552; Mean validation loss 0.111599; Mean validation F1 0.710830; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.094311; Mean training F1 0.932354; Mean validation loss 0.092410; Mean validation F1 0.936546; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.097037; Mean training F1 0.931493; Mean validation loss 0.088834; Mean validation F1 0.933045; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.091199; Mean training F1 0.933671; Mean validation loss 0.058768; Mean validation F1 0.932729; Learning rate 0.000917;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.090434; Mean training F1 0.934031; Mean validation loss 0.143746; Mean validation F1 0.935684; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.090702; Mean training F1 0.933361; Mean validation loss 0.069856; Mean validation F1 0.931048; Learning rate 0.000903;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.091117; Mean training F1 0.933365; Mean validation loss 0.076075; Mean validation F1 0.936827; Learning rate 0.000896;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.088862; Mean training F1 0.934019; Mean validation loss 0.085579; Mean validation F1 0.936610; Learning rate 0.000888;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.088418; Mean training F1 0.934402; Mean validation loss 0.117530; Mean validation F1 0.935118; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.086771; Mean training F1 0.935842; Mean validation loss 0.089296; Mean validation F1 0.937236; Learning rate 0.000872;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.088756; Mean training F1 0.934938; Mean validation loss 0.097730; Mean validation F1 0.937403; Learning rate 0.000864;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.088122; Mean training F1 0.933984; Mean validation loss 0.085154; Mean validation F1 0.936396; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.088925; Mean training F1 0.934092; Mean validation loss 0.120237; Mean validation F1 0.936504; Learning rate 0.000847;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.088693; Mean training F1 0.933355; Mean validation loss 0.087783; Mean validation F1 0.932260; Learning rate 0.000838;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.086923; Mean training F1 0.935753; Mean validation loss 0.069214; Mean validation F1 0.935188; Learning rate 0.000829;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.086804; Mean training F1 0.935920; Mean validation loss 0.116365; Mean validation F1 0.910717; Learning rate 0.000819;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.087637; Mean training F1 0.935183; Mean validation loss 0.104439; Mean validation F1 0.936992; Learning rate 0.000810;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.085429; Mean training F1 0.936277; Mean validation loss 0.092451; Mean validation F1 0.937859; Learning rate 0.000800;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.085609; Mean training F1 0.935804; Mean validation loss 0.109865; Mean validation F1 0.935760; Learning rate 0.000790;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.085653; Mean training F1 0.935295; Mean validation loss 0.073019; Mean validation F1 0.937359; Learning rate 0.000780;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.084909; Mean training F1 0.936786; Mean validation loss 0.104952; Mean validation F1 0.938478; Learning rate 0.000770;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.086048; Mean training F1 0.935585; Mean validation loss 0.085160; Mean validation F1 0.934066; Learning rate 0.000760;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.084483; Mean training F1 0.936491; Mean validation loss 0.081538; Mean validation F1 0.938106; Learning rate 0.000749;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.084631; Mean training F1 0.936970; Mean validation loss 0.081419; Mean validation F1 0.936907; Learning rate 0.000739;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.084682; Mean training F1 0.936203; Mean validation loss 0.075965; Mean validation F1 0.936369; Learning rate 0.000728;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.087417; Mean training F1 0.933833; Mean validation loss 0.086372; Mean validation F1 0.938173; Learning rate 0.000717;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.089426; Mean training F1 0.934839; Mean validation loss 0.101340; Mean validation F1 0.936774; Learning rate 0.000706;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.084237; Mean training F1 0.936746; Mean validation loss 0.103204; Mean validation F1 0.938871; Learning rate 0.000695;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.083413; Mean training F1 0.937015; Mean validation loss 0.071512; Mean validation F1 0.936353; Learning rate 0.000683;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.083559; Mean training F1 0.937464; Mean validation loss 0.086000; Mean validation F1 0.938415; Learning rate 0.000672;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.083698; Mean training F1 0.937399; Mean validation loss 0.080692; Mean validation F1 0.936779; Learning rate 0.000661;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.083898; Mean training F1 0.936917; Mean validation loss 0.103610; Mean validation F1 0.935238; Learning rate 0.000649;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.083424; Mean training F1 0.936970; Mean validation loss 0.082177; Mean validation F1 0.938045; Learning rate 0.000637;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.083239; Mean training F1 0.937062; Mean validation loss 0.068478; Mean validation F1 0.937977; Learning rate 0.000626;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.083752; Mean training F1 0.936935; Mean validation loss 0.091111; Mean validation F1 0.938345; Learning rate 0.000614;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.083040; Mean training F1 0.937325; Mean validation loss 0.079921; Mean validation F1 0.937024; Learning rate 0.000602;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.082301; Mean training F1 0.937966; Mean validation loss 0.094682; Mean validation F1 0.938735; Learning rate 0.000590;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.083136; Mean training F1 0.937376; Mean validation loss 0.097589; Mean validation F1 0.936809; Learning rate 0.000578;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.086392; Mean training F1 0.935717; Mean validation loss 0.088609; Mean validation F1 0.915325; Learning rate 0.000566;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.083595; Mean training F1 0.937068; Mean validation loss 0.071050; Mean validation F1 0.937287; Learning rate 0.000554;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.083044; Mean training F1 0.937207; Mean validation loss 0.086207; Mean validation F1 0.935593; Learning rate 0.000542;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.082984; Mean training F1 0.937502; Mean validation loss 0.070666; Mean validation F1 0.938308; Learning rate 0.000530;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.082568; Mean training F1 0.937656; Mean validation loss 0.055841; Mean validation F1 0.938055; Learning rate 0.000517;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.082428; Mean training F1 0.937883; Mean validation loss 0.083830; Mean validation F1 0.938245; Learning rate 0.000505;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.082077; Mean training F1 0.938063; Mean validation loss 0.096218; Mean validation F1 0.938615; Learning rate 0.000493;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.081619; Mean training F1 0.938108; Mean validation loss 0.076916; Mean validation F1 0.938131; Learning rate 0.000481;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.081853; Mean training F1 0.938317; Mean validation loss 0.110562; Mean validation F1 0.937171; Learning rate 0.000469;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.082379; Mean training F1 0.938098; Mean validation loss 0.089060; Mean validation F1 0.938553; Learning rate 0.000457;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.082147; Mean training F1 0.938228; Mean validation loss 0.127422; Mean validation F1 0.938730; Learning rate 0.000445;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.081234; Mean training F1 0.938457; Mean validation loss 0.078795; Mean validation F1 0.938896; Learning rate 0.000433;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.082300; Mean training F1 0.937875; Mean validation loss 0.114725; Mean validation F1 0.938297; Learning rate 0.000421;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.081410; Mean training F1 0.938388; Mean validation loss 0.071763; Mean validation F1 0.939008; Learning rate 0.000409;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.081452; Mean training F1 0.938119; Mean validation loss 0.098875; Mean validation F1 0.938633; Learning rate 0.000397;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.081606; Mean training F1 0.938530; Mean validation loss 0.094485; Mean validation F1 0.938565; Learning rate 0.000385;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.081156; Mean training F1 0.938280; Mean validation loss 0.082802; Mean validation F1 0.938435; Learning rate 0.000373;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.080752; Mean training F1 0.938692; Mean validation loss 0.057382; Mean validation F1 0.938719; Learning rate 0.000362;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.080877; Mean training F1 0.938846; Mean validation loss 0.086465; Mean validation F1 0.938908; Learning rate 0.000350;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.081073; Mean training F1 0.938510; Mean validation loss 0.092088; Mean validation F1 0.938305; Learning rate 0.000339;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.080623; Mean training F1 0.938889; Mean validation loss 0.086927; Mean validation F1 0.938564; Learning rate 0.000327;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.080886; Mean training F1 0.938758; Mean validation loss 0.083855; Mean validation F1 0.938524; Learning rate 0.000316;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.080978; Mean training F1 0.938594; Mean validation loss 0.087582; Mean validation F1 0.938957; Learning rate 0.000305;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.080756; Mean training F1 0.938753; Mean validation loss 0.078440; Mean validation F1 0.938934; Learning rate 0.000294;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.080485; Mean training F1 0.938819; Mean validation loss 0.090254; Mean validation F1 0.937767; Learning rate 0.000283;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.080711; Mean training F1 0.938869; Mean validation loss 0.125535; Mean validation F1 0.939106; Learning rate 0.000272;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.080370; Mean training F1 0.939065; Mean validation loss 0.072672; Mean validation F1 0.938748; Learning rate 0.000261;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.080806; Mean training F1 0.938572; Mean validation loss 0.106052; Mean validation F1 0.938869; Learning rate 0.000251;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.080238; Mean training F1 0.938876; Mean validation loss 0.053694; Mean validation F1 0.938567; Learning rate 0.000240;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.080399; Mean training F1 0.938748; Mean validation loss 0.082051; Mean validation F1 0.938488; Learning rate 0.000230;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.079848; Mean training F1 0.939103; Mean validation loss 0.062114; Mean validation F1 0.939115; Learning rate 0.000220;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.079910; Mean training F1 0.939007; Mean validation loss 0.040172; Mean validation F1 0.938240; Learning rate 0.000210;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.079939; Mean training F1 0.939196; Mean validation loss 0.074792; Mean validation F1 0.938922; Learning rate 0.000201;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.079921; Mean training F1 0.939250; Mean validation loss 0.100751; Mean validation F1 0.939052; Learning rate 0.000191;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.079814; Mean training F1 0.939249; Mean validation loss 0.093978; Mean validation F1 0.939096; Learning rate 0.000182;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.079871; Mean training F1 0.939105; Mean validation loss 0.084277; Mean validation F1 0.938126; Learning rate 0.000173;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.081043; Mean training F1 0.938896; Mean validation loss 0.091581; Mean validation F1 0.934105; Learning rate 0.000164;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.080119; Mean training F1 0.939147; Mean validation loss 0.081206; Mean validation F1 0.938975; Learning rate 0.000155;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.079767; Mean training F1 0.939293; Mean validation loss 0.081498; Mean validation F1 0.939176; Learning rate 0.000147;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.079691; Mean training F1 0.939245; Mean validation loss 0.069898; Mean validation F1 0.939020; Learning rate 0.000139;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.079539; Mean training F1 0.939478; Mean validation loss 0.085920; Mean validation F1 0.939199; Learning rate 0.000130;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.079473; Mean training F1 0.939406; Mean validation loss 0.061283; Mean validation F1 0.938862; Learning rate 0.000123;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.079717; Mean training F1 0.939448; Mean validation loss 0.099864; Mean validation F1 0.939245; Learning rate 0.000115;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.079611; Mean training F1 0.939346; Mean validation loss 0.070873; Mean validation F1 0.939222; Learning rate 0.000108;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.079312; Mean training F1 0.939705; Mean validation loss 0.091213; Mean validation F1 0.939203; Learning rate 0.000101;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.079363; Mean training F1 0.939591; Mean validation loss 0.090581; Mean validation F1 0.939180; Learning rate 0.000094;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.079253; Mean training F1 0.939638; Mean validation loss 0.081922; Mean validation F1 0.939252; Learning rate 0.000087;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.079281; Mean training F1 0.939748; Mean validation loss 0.092412; Mean validation F1 0.938939; Learning rate 0.000081;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.079230; Mean training F1 0.939490; Mean validation loss 0.079748; Mean validation F1 0.939160; Learning rate 0.000075;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.078992; Mean training F1 0.939641; Mean validation loss 0.056010; Mean validation F1 0.939133; Learning rate 0.000069;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.078864; Mean training F1 0.939667; Mean validation loss 0.063355; Mean validation F1 0.939194; Learning rate 0.000063;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.079040; Mean training F1 0.939747; Mean validation loss 0.083041; Mean validation F1 0.938926; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.079006; Mean training F1 0.939606; Mean validation loss 0.077330; Mean validation F1 0.939239; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.079026; Mean training F1 0.939873; Mean validation loss 0.087546; Mean validation F1 0.939173; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.079025; Mean training F1 0.939656; Mean validation loss 0.082202; Mean validation F1 0.939209; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.079181; Mean training F1 0.939796; Mean validation loss 0.112732; Mean validation F1 0.939261; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.078917; Mean training F1 0.939676; Mean validation loss 0.073395; Mean validation F1 0.939292; Learning rate 0.000035;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.078653; Mean training F1 0.939895; Mean validation loss 0.070633; Mean validation F1 0.939257; Learning rate 0.000032;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.079024; Mean training F1 0.939763; Mean validation loss 0.084328; Mean validation F1 0.939155; Learning rate 0.000028;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.078717; Mean training F1 0.939873; Mean validation loss 0.059424; Mean validation F1 0.939312; Learning rate 0.000025;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.078849; Mean training F1 0.939979; Mean validation loss 0.084743; Mean validation F1 0.939231; Learning rate 0.000022;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.078781; Mean training F1 0.939864; Mean validation loss 0.088366; Mean validation F1 0.939131; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.078736; Mean training F1 0.939855; Mean validation loss 0.080122; Mean validation F1 0.939234; Learning rate 0.000018;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.078885; Mean training F1 0.939841; Mean validation loss 0.090226; Mean validation F1 0.939195; Learning rate 0.000016;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.078664; Mean training F1 0.940014; Mean validation loss 0.067118; Mean validation F1 0.939203; Learning rate 0.000014;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.079020; Mean training F1 0.939736; Mean validation loss 0.094824; Mean validation F1 0.939129; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.078580; Mean training F1 0.939846; Mean validation loss 0.048519; Mean validation F1 0.939194; Learning rate 0.000012;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.078716; Mean training F1 0.939949; Mean validation loss 0.082842; Mean validation F1 0.939350; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.079004; Mean training F1 0.939876; Mean validation loss 0.111674; Mean validation F1 0.939125; Learning rate 0.000010;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.078826; Mean training F1 0.939896; Mean validation loss 0.092048; Mean validation F1 0.939188; Learning rate 0.000010;\n",
    "################################################################\n",
    "Training/validation for fold 5/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.598566; Mean training F1 0.692001; Mean validation loss 0.544039; Mean validation F1 0.799312; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.259639; Mean training F1 0.863670; Mean validation loss 0.287853; Mean validation F1 0.881187; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.179995; Mean training F1 0.896705; Mean validation loss 0.197234; Mean validation F1 0.915540; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.148941; Mean training F1 0.906130; Mean validation loss 0.160538; Mean validation F1 0.916061; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.170589; Mean training F1 0.896520; Mean validation loss 0.173512; Mean validation F1 0.916481; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.128307; Mean training F1 0.919797; Mean validation loss 0.131435; Mean validation F1 0.923474; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.143163; Mean training F1 0.907454; Mean validation loss 0.115658; Mean validation F1 0.924049; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.126916; Mean training F1 0.918865; Mean validation loss 0.166925; Mean validation F1 0.931351; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.118577; Mean training F1 0.921175; Mean validation loss 0.117148; Mean validation F1 0.910543; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.114764; Mean training F1 0.920781; Mean validation loss 0.130134; Mean validation F1 0.932813; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.102242; Mean training F1 0.929425; Mean validation loss 0.117237; Mean validation F1 0.933303; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.101419; Mean training F1 0.930637; Mean validation loss 0.131056; Mean validation F1 0.934117; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.100562; Mean training F1 0.930958; Mean validation loss 0.106190; Mean validation F1 0.934253; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.101959; Mean training F1 0.928185; Mean validation loss 0.087222; Mean validation F1 0.928767; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.098541; Mean training F1 0.930693; Mean validation loss 0.123368; Mean validation F1 0.925610; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.097646; Mean training F1 0.929706; Mean validation loss 0.117989; Mean validation F1 0.934940; Learning rate 0.000963;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.096010; Mean training F1 0.931287; Mean validation loss 0.081371; Mean validation F1 0.932104; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.094640; Mean training F1 0.932638; Mean validation loss 0.122206; Mean validation F1 0.936332; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.091880; Mean training F1 0.933367; Mean validation loss 0.070928; Mean validation F1 0.936137; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.093771; Mean training F1 0.932070; Mean validation loss 0.123597; Mean validation F1 0.924840; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.090598; Mean training F1 0.934341; Mean validation loss 0.074546; Mean validation F1 0.840645; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.091561; Mean training F1 0.934206; Mean validation loss 0.091830; Mean validation F1 0.933872; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.093955; Mean training F1 0.931828; Mean validation loss 0.085150; Mean validation F1 0.925755; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.092123; Mean training F1 0.933016; Mean validation loss 0.094195; Mean validation F1 0.904701; Learning rate 0.000917;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.090336; Mean training F1 0.934276; Mean validation loss 0.091883; Mean validation F1 0.936690; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.093205; Mean training F1 0.933854; Mean validation loss 0.168340; Mean validation F1 0.934940; Learning rate 0.000903;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.091604; Mean training F1 0.933214; Mean validation loss 0.147204; Mean validation F1 0.934278; Learning rate 0.000896;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.090569; Mean training F1 0.933507; Mean validation loss 0.098757; Mean validation F1 0.935645; Learning rate 0.000888;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.090518; Mean training F1 0.934571; Mean validation loss 0.126650; Mean validation F1 0.932730; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.088107; Mean training F1 0.935098; Mean validation loss 0.054836; Mean validation F1 0.934488; Learning rate 0.000872;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.087969; Mean training F1 0.935076; Mean validation loss 0.057518; Mean validation F1 0.936766; Learning rate 0.000864;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.091466; Mean training F1 0.932847; Mean validation loss 0.067156; Mean validation F1 0.937044; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.087657; Mean training F1 0.935599; Mean validation loss 0.112521; Mean validation F1 0.937099; Learning rate 0.000847;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.087312; Mean training F1 0.935782; Mean validation loss 0.125928; Mean validation F1 0.937467; Learning rate 0.000838;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.088126; Mean training F1 0.935446; Mean validation loss 0.062324; Mean validation F1 0.936876; Learning rate 0.000829;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.086838; Mean training F1 0.935587; Mean validation loss 0.057142; Mean validation F1 0.937180; Learning rate 0.000819;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.086868; Mean training F1 0.935777; Mean validation loss 0.101769; Mean validation F1 0.936627; Learning rate 0.000810;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.086196; Mean training F1 0.936567; Mean validation loss 0.069771; Mean validation F1 0.937687; Learning rate 0.000800;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.085419; Mean training F1 0.936558; Mean validation loss 0.127600; Mean validation F1 0.937370; Learning rate 0.000790;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.086077; Mean training F1 0.935471; Mean validation loss 0.088008; Mean validation F1 0.935446; Learning rate 0.000780;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.085850; Mean training F1 0.936328; Mean validation loss 0.052014; Mean validation F1 0.937744; Learning rate 0.000770;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.085359; Mean training F1 0.936271; Mean validation loss 0.063876; Mean validation F1 0.937094; Learning rate 0.000760;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.085793; Mean training F1 0.936203; Mean validation loss 0.104644; Mean validation F1 0.935367; Learning rate 0.000749;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.084790; Mean training F1 0.936619; Mean validation loss 0.069643; Mean validation F1 0.934186; Learning rate 0.000739;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.084922; Mean training F1 0.936570; Mean validation loss 0.075422; Mean validation F1 0.936543; Learning rate 0.000728;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.085055; Mean training F1 0.936626; Mean validation loss 0.082994; Mean validation F1 0.935692; Learning rate 0.000717;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.086869; Mean training F1 0.935781; Mean validation loss 0.094360; Mean validation F1 0.937249; Learning rate 0.000706;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.084235; Mean training F1 0.937240; Mean validation loss 0.074544; Mean validation F1 0.936605; Learning rate 0.000695;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.085265; Mean training F1 0.936899; Mean validation loss 0.072320; Mean validation F1 0.936388; Learning rate 0.000683;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.084788; Mean training F1 0.937128; Mean validation loss 0.093798; Mean validation F1 0.937972; Learning rate 0.000672;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.085436; Mean training F1 0.936549; Mean validation loss 0.074904; Mean validation F1 0.937200; Learning rate 0.000661;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.084552; Mean training F1 0.936492; Mean validation loss 0.073715; Mean validation F1 0.937172; Learning rate 0.000649;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.084156; Mean training F1 0.937229; Mean validation loss 0.093355; Mean validation F1 0.936063; Learning rate 0.000637;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.084193; Mean training F1 0.936973; Mean validation loss 0.079817; Mean validation F1 0.936609; Learning rate 0.000626;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.084390; Mean training F1 0.936589; Mean validation loss 0.077078; Mean validation F1 0.936918; Learning rate 0.000614;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.083468; Mean training F1 0.937511; Mean validation loss 0.071642; Mean validation F1 0.933878; Learning rate 0.000602;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.085407; Mean training F1 0.936433; Mean validation loss 0.074480; Mean validation F1 0.938038; Learning rate 0.000590;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.082955; Mean training F1 0.937815; Mean validation loss 0.077403; Mean validation F1 0.937660; Learning rate 0.000578;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.082769; Mean training F1 0.937551; Mean validation loss 0.075529; Mean validation F1 0.937796; Learning rate 0.000566;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.083155; Mean training F1 0.937299; Mean validation loss 0.055992; Mean validation F1 0.937176; Learning rate 0.000554;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.083484; Mean training F1 0.937455; Mean validation loss 0.067719; Mean validation F1 0.937419; Learning rate 0.000542;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.083543; Mean training F1 0.937529; Mean validation loss 0.123090; Mean validation F1 0.935610; Learning rate 0.000530;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.083728; Mean training F1 0.937417; Mean validation loss 0.072132; Mean validation F1 0.937425; Learning rate 0.000517;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.082441; Mean training F1 0.937708; Mean validation loss 0.047243; Mean validation F1 0.935983; Learning rate 0.000505;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.082240; Mean training F1 0.937865; Mean validation loss 0.080789; Mean validation F1 0.938209; Learning rate 0.000493;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.082074; Mean training F1 0.937965; Mean validation loss 0.048649; Mean validation F1 0.938424; Learning rate 0.000481;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.082346; Mean training F1 0.937991; Mean validation loss 0.079632; Mean validation F1 0.936848; Learning rate 0.000469;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.082281; Mean training F1 0.937596; Mean validation loss 0.067292; Mean validation F1 0.938323; Learning rate 0.000457;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.081697; Mean training F1 0.938378; Mean validation loss 0.068208; Mean validation F1 0.938428; Learning rate 0.000445;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.082170; Mean training F1 0.938022; Mean validation loss 0.105168; Mean validation F1 0.938369; Learning rate 0.000433;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.081574; Mean training F1 0.938419; Mean validation loss 0.081678; Mean validation F1 0.937426; Learning rate 0.000421;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.081568; Mean training F1 0.938599; Mean validation loss 0.087967; Mean validation F1 0.938363; Learning rate 0.000409;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.082433; Mean training F1 0.938068; Mean validation loss 0.086482; Mean validation F1 0.935182; Learning rate 0.000397;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.082022; Mean training F1 0.937884; Mean validation loss 0.072317; Mean validation F1 0.938045; Learning rate 0.000385;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.082467; Mean training F1 0.938067; Mean validation loss 0.124771; Mean validation F1 0.938312; Learning rate 0.000373;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.081695; Mean training F1 0.938310; Mean validation loss 0.087694; Mean validation F1 0.938216; Learning rate 0.000362;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.081832; Mean training F1 0.938430; Mean validation loss 0.100464; Mean validation F1 0.937513; Learning rate 0.000350;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.080512; Mean training F1 0.938848; Mean validation loss 0.041957; Mean validation F1 0.938194; Learning rate 0.000339;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.080719; Mean training F1 0.938739; Mean validation loss 0.067314; Mean validation F1 0.938100; Learning rate 0.000327;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.080696; Mean training F1 0.938884; Mean validation loss 0.077059; Mean validation F1 0.938212; Learning rate 0.000316;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.080852; Mean training F1 0.938703; Mean validation loss 0.061325; Mean validation F1 0.937740; Learning rate 0.000305;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.081948; Mean training F1 0.938349; Mean validation loss 0.121056; Mean validation F1 0.935793; Learning rate 0.000294;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.082847; Mean training F1 0.938059; Mean validation loss 0.083603; Mean validation F1 0.938386; Learning rate 0.000283;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.081261; Mean training F1 0.938636; Mean validation loss 0.102620; Mean validation F1 0.938073; Learning rate 0.000272;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.080872; Mean training F1 0.938895; Mean validation loss 0.076315; Mean validation F1 0.937662; Learning rate 0.000261;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.080597; Mean training F1 0.938976; Mean validation loss 0.075680; Mean validation F1 0.938457; Learning rate 0.000251;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.081225; Mean training F1 0.938914; Mean validation loss 0.136991; Mean validation F1 0.937841; Learning rate 0.000240;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.080726; Mean training F1 0.939029; Mean validation loss 0.058186; Mean validation F1 0.938447; Learning rate 0.000230;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.080153; Mean training F1 0.939119; Mean validation loss 0.056868; Mean validation F1 0.938465; Learning rate 0.000220;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.081131; Mean training F1 0.938930; Mean validation loss 0.134288; Mean validation F1 0.938252; Learning rate 0.000210;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.080407; Mean training F1 0.938791; Mean validation loss 0.076138; Mean validation F1 0.937518; Learning rate 0.000201;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.080360; Mean training F1 0.939269; Mean validation loss 0.069510; Mean validation F1 0.938197; Learning rate 0.000191;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.080355; Mean training F1 0.939304; Mean validation loss 0.083684; Mean validation F1 0.938360; Learning rate 0.000182;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.079954; Mean training F1 0.939475; Mean validation loss 0.080207; Mean validation F1 0.938603; Learning rate 0.000173;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.079651; Mean training F1 0.939440; Mean validation loss 0.055753; Mean validation F1 0.938347; Learning rate 0.000164;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.079950; Mean training F1 0.939355; Mean validation loss 0.070456; Mean validation F1 0.938127; Learning rate 0.000155;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.079792; Mean training F1 0.939493; Mean validation loss 0.065315; Mean validation F1 0.938242; Learning rate 0.000147;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.080825; Mean training F1 0.939084; Mean validation loss 0.103368; Mean validation F1 0.938611; Learning rate 0.000139;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.080361; Mean training F1 0.939428; Mean validation loss 0.086615; Mean validation F1 0.937938; Learning rate 0.000130;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.080837; Mean training F1 0.939065; Mean validation loss 0.089617; Mean validation F1 0.938196; Learning rate 0.000123;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.079897; Mean training F1 0.939263; Mean validation loss 0.065818; Mean validation F1 0.938590; Learning rate 0.000115;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.079471; Mean training F1 0.939745; Mean validation loss 0.057446; Mean validation F1 0.938584; Learning rate 0.000108;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.079502; Mean training F1 0.939577; Mean validation loss 0.058359; Mean validation F1 0.938583; Learning rate 0.000101;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.079516; Mean training F1 0.939663; Mean validation loss 0.060018; Mean validation F1 0.938716; Learning rate 0.000094;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.079715; Mean training F1 0.939543; Mean validation loss 0.068335; Mean validation F1 0.938706; Learning rate 0.000087;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.079598; Mean training F1 0.939597; Mean validation loss 0.071385; Mean validation F1 0.938753; Learning rate 0.000081;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.079280; Mean training F1 0.939714; Mean validation loss 0.052758; Mean validation F1 0.938522; Learning rate 0.000075;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.079336; Mean training F1 0.939635; Mean validation loss 0.072464; Mean validation F1 0.938770; Learning rate 0.000069;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.079338; Mean training F1 0.939741; Mean validation loss 0.069600; Mean validation F1 0.938631; Learning rate 0.000063;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.079294; Mean training F1 0.939771; Mean validation loss 0.073620; Mean validation F1 0.938613; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.079463; Mean training F1 0.939671; Mean validation loss 0.080509; Mean validation F1 0.938405; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.079570; Mean training F1 0.939808; Mean validation loss 0.108287; Mean validation F1 0.938866; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.079135; Mean training F1 0.939742; Mean validation loss 0.064557; Mean validation F1 0.938712; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.079240; Mean training F1 0.939678; Mean validation loss 0.074723; Mean validation F1 0.938686; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.079311; Mean training F1 0.939940; Mean validation loss 0.093131; Mean validation F1 0.938754; Learning rate 0.000035;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.079520; Mean training F1 0.939846; Mean validation loss 0.103241; Mean validation F1 0.938523; Learning rate 0.000032;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.079077; Mean training F1 0.939732; Mean validation loss 0.068071; Mean validation F1 0.938684; Learning rate 0.000028;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.079400; Mean training F1 0.939980; Mean validation loss 0.118815; Mean validation F1 0.938518; Learning rate 0.000025;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.078917; Mean training F1 0.939894; Mean validation loss 0.058965; Mean validation F1 0.938699; Learning rate 0.000022;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.079098; Mean training F1 0.940045; Mean validation loss 0.094610; Mean validation F1 0.938627; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.079254; Mean training F1 0.939952; Mean validation loss 0.101742; Mean validation F1 0.938878; Learning rate 0.000018;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.079038; Mean training F1 0.939920; Mean validation loss 0.076410; Mean validation F1 0.938632; Learning rate 0.000016;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.079052; Mean training F1 0.939964; Mean validation loss 0.089192; Mean validation F1 0.938883; Learning rate 0.000014;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.079030; Mean training F1 0.939878; Mean validation loss 0.073888; Mean validation F1 0.938789; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.078981; Mean training F1 0.939963; Mean validation loss 0.072714; Mean validation F1 0.938739; Learning rate 0.000012;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.079088; Mean training F1 0.939971; Mean validation loss 0.086007; Mean validation F1 0.938771; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.078985; Mean training F1 0.939957; Mean validation loss 0.075147; Mean validation F1 0.938710; Learning rate 0.000010;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.078931; Mean training F1 0.939975; Mean validation loss 0.075098; Mean validation F1 0.938760; Learning rate 0.000010;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "wavenet baseline, s500w500featnew2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-------- fold 0 --------\n",
    "model validation loss: 0.088; validation f1: 0.940;\n",
    "-------- fold 1 --------\n",
    "model validation loss: 0.085; validation f1: 0.938;\n",
    "-------- fold 2 --------\n",
    "model validation loss: 0.074; validation f1: 0.938;\n",
    "-------- fold 3 --------\n",
    "model validation loss: 0.068; validation f1: 0.939;\n",
    "-------- fold 4 --------\n",
    "model validation loss: 0.071; validation f1: 0.939;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "################################################################\n",
    "Training/validation for fold 1/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.609986; Mean training F1 0.688344; Mean validation loss 0.186328; Mean validation F1 0.894271; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.183804; Mean training F1 0.897156; Mean validation loss 0.155514; Mean validation F1 0.904298; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.146173; Mean training F1 0.910604; Mean validation loss 0.133364; Mean validation F1 0.907671; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.135504; Mean training F1 0.914611; Mean validation loss 0.174445; Mean validation F1 0.912226; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.102614; Mean training F1 0.929741; Mean validation loss 0.102168; Mean validation F1 0.935460; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.095742; Mean training F1 0.932535; Mean validation loss 0.110102; Mean validation F1 0.932849; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.091134; Mean training F1 0.934473; Mean validation loss 0.100862; Mean validation F1 0.935862; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.088142; Mean training F1 0.935519; Mean validation loss 0.070060; Mean validation F1 0.937846; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.087263; Mean training F1 0.936227; Mean validation loss 0.089154; Mean validation F1 0.936347; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.086960; Mean training F1 0.936159; Mean validation loss 0.086690; Mean validation F1 0.936358; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.086046; Mean training F1 0.936536; Mean validation loss 0.067791; Mean validation F1 0.937196; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.085589; Mean training F1 0.936670; Mean validation loss 0.065854; Mean validation F1 0.937220; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.085084; Mean training F1 0.936753; Mean validation loss 0.089981; Mean validation F1 0.938096; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.085207; Mean training F1 0.936546; Mean validation loss 0.093893; Mean validation F1 0.937956; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.085180; Mean training F1 0.936446; Mean validation loss 0.083447; Mean validation F1 0.938261; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.084773; Mean training F1 0.936935; Mean validation loss 0.064824; Mean validation F1 0.936824; Learning rate 0.000962;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.085134; Mean training F1 0.936764; Mean validation loss 0.076395; Mean validation F1 0.938502; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.084127; Mean training F1 0.937107; Mean validation loss 0.086532; Mean validation F1 0.937792; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.084190; Mean training F1 0.936812; Mean validation loss 0.094309; Mean validation F1 0.937338; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.084029; Mean training F1 0.937267; Mean validation loss 0.051669; Mean validation F1 0.935241; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.084289; Mean training F1 0.936586; Mean validation loss 0.082420; Mean validation F1 0.938760; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.083599; Mean training F1 0.937227; Mean validation loss 0.093724; Mean validation F1 0.938416; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.097526; Mean training F1 0.927271; Mean validation loss 0.098853; Mean validation F1 0.937324; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.084447; Mean training F1 0.937016; Mean validation loss 0.074117; Mean validation F1 0.938005; Learning rate 0.000916;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.083258; Mean training F1 0.937635; Mean validation loss 0.078494; Mean validation F1 0.937020; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.083000; Mean training F1 0.937528; Mean validation loss 0.078244; Mean validation F1 0.938574; Learning rate 0.000902;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.083365; Mean training F1 0.937346; Mean validation loss 0.073348; Mean validation F1 0.937955; Learning rate 0.000895;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.083093; Mean training F1 0.937539; Mean validation loss 0.073812; Mean validation F1 0.938200; Learning rate 0.000887;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.082839; Mean training F1 0.937671; Mean validation loss 0.069598; Mean validation F1 0.938027; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.082281; Mean training F1 0.937843; Mean validation loss 0.072134; Mean validation F1 0.938636; Learning rate 0.000871;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.082738; Mean training F1 0.937761; Mean validation loss 0.078943; Mean validation F1 0.938419; Learning rate 0.000863;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.082445; Mean training F1 0.937662; Mean validation loss 0.105386; Mean validation F1 0.938822; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.090444; Mean training F1 0.933741; Mean validation loss 0.108590; Mean validation F1 0.915385; Learning rate 0.000846;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.087999; Mean training F1 0.934739; Mean validation loss 0.088219; Mean validation F1 0.936966; Learning rate 0.000837;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.084429; Mean training F1 0.937414; Mean validation loss 0.076882; Mean validation F1 0.938016; Learning rate 0.000828;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.083278; Mean training F1 0.937367; Mean validation loss 0.103240; Mean validation F1 0.938238; Learning rate 0.000818;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.082556; Mean training F1 0.937697; Mean validation loss 0.083735; Mean validation F1 0.938739; Learning rate 0.000809;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.082379; Mean training F1 0.937844; Mean validation loss 0.075505; Mean validation F1 0.938198; Learning rate 0.000799;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.081938; Mean training F1 0.938106; Mean validation loss 0.103809; Mean validation F1 0.938489; Learning rate 0.000789;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.082338; Mean training F1 0.937820; Mean validation loss 0.092112; Mean validation F1 0.938483; Learning rate 0.000779;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.082031; Mean training F1 0.938039; Mean validation loss 0.082745; Mean validation F1 0.938115; Learning rate 0.000769;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.081619; Mean training F1 0.938153; Mean validation loss 0.078691; Mean validation F1 0.938756; Learning rate 0.000759;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.081639; Mean training F1 0.938230; Mean validation loss 0.068331; Mean validation F1 0.937892; Learning rate 0.000748;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.081650; Mean training F1 0.938080; Mean validation loss 0.075737; Mean validation F1 0.938246; Learning rate 0.000737;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.081395; Mean training F1 0.938235; Mean validation loss 0.067350; Mean validation F1 0.938779; Learning rate 0.000726;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.081553; Mean training F1 0.938095; Mean validation loss 0.091368; Mean validation F1 0.938457; Learning rate 0.000716;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.081034; Mean training F1 0.938555; Mean validation loss 0.091011; Mean validation F1 0.939186; Learning rate 0.000704;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.081389; Mean training F1 0.938101; Mean validation loss 0.085028; Mean validation F1 0.938932; Learning rate 0.000693;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.081170; Mean training F1 0.938342; Mean validation loss 0.074260; Mean validation F1 0.938738; Learning rate 0.000682;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.081043; Mean training F1 0.938227; Mean validation loss 0.080907; Mean validation F1 0.937311; Learning rate 0.000670;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.080942; Mean training F1 0.938355; Mean validation loss 0.062744; Mean validation F1 0.937570; Learning rate 0.000659;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.080819; Mean training F1 0.938401; Mean validation loss 0.095707; Mean validation F1 0.939192; Learning rate 0.000647;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.080707; Mean training F1 0.938445; Mean validation loss 0.083418; Mean validation F1 0.939028; Learning rate 0.000635;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.080567; Mean training F1 0.938473; Mean validation loss 0.080787; Mean validation F1 0.937844; Learning rate 0.000624;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.080537; Mean training F1 0.938473; Mean validation loss 0.085204; Mean validation F1 0.938744; Learning rate 0.000612;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.080454; Mean training F1 0.938653; Mean validation loss 0.090267; Mean validation F1 0.938422; Learning rate 0.000600;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.080282; Mean training F1 0.938689; Mean validation loss 0.077698; Mean validation F1 0.939085; Learning rate 0.000588;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.083379; Mean training F1 0.937620; Mean validation loss 0.086908; Mean validation F1 0.935754; Learning rate 0.000576;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.085017; Mean training F1 0.936860; Mean validation loss 0.066001; Mean validation F1 0.939293; Learning rate 0.000564;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.081185; Mean training F1 0.938373; Mean validation loss 0.081697; Mean validation F1 0.939050; Learning rate 0.000552;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.080260; Mean training F1 0.938558; Mean validation loss 0.053181; Mean validation F1 0.937884; Learning rate 0.000539;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.079824; Mean training F1 0.938912; Mean validation loss 0.061711; Mean validation F1 0.939375; Learning rate 0.000527;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.079879; Mean training F1 0.938858; Mean validation loss 0.081321; Mean validation F1 0.939246; Learning rate 0.000515;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.079641; Mean training F1 0.939032; Mean validation loss 0.090524; Mean validation F1 0.938481; Learning rate 0.000503;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.079677; Mean training F1 0.938942; Mean validation loss 0.083447; Mean validation F1 0.939447; Learning rate 0.000491;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.079858; Mean training F1 0.939035; Mean validation loss 0.055315; Mean validation F1 0.939198; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.079451; Mean training F1 0.939187; Mean validation loss 0.086004; Mean validation F1 0.938151; Learning rate 0.000466;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.079335; Mean training F1 0.939039; Mean validation loss 0.092196; Mean validation F1 0.939274; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.079417; Mean training F1 0.939212; Mean validation loss 0.085013; Mean validation F1 0.939282; Learning rate 0.000442;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.079496; Mean training F1 0.939039; Mean validation loss 0.096211; Mean validation F1 0.938620; Learning rate 0.000430;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.079303; Mean training F1 0.939005; Mean validation loss 0.104886; Mean validation F1 0.939571; Learning rate 0.000418;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.079021; Mean training F1 0.939335; Mean validation loss 0.085304; Mean validation F1 0.939266; Learning rate 0.000406;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.079099; Mean training F1 0.939322; Mean validation loss 0.083264; Mean validation F1 0.938959; Learning rate 0.000394;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.079069; Mean training F1 0.939506; Mean validation loss 0.077668; Mean validation F1 0.939404; Learning rate 0.000382;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.078845; Mean training F1 0.939516; Mean validation loss 0.076809; Mean validation F1 0.939488; Learning rate 0.000370;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.078722; Mean training F1 0.939495; Mean validation loss 0.079914; Mean validation F1 0.939367; Learning rate 0.000358;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.078663; Mean training F1 0.939643; Mean validation loss 0.061766; Mean validation F1 0.939223; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.078646; Mean training F1 0.939573; Mean validation loss 0.109871; Mean validation F1 0.939363; Learning rate 0.000335;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.078512; Mean training F1 0.939570; Mean validation loss 0.094717; Mean validation F1 0.939303; Learning rate 0.000324;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.078461; Mean training F1 0.939724; Mean validation loss 0.078740; Mean validation F1 0.939168; Learning rate 0.000312;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.078501; Mean training F1 0.939729; Mean validation loss 0.049834; Mean validation F1 0.939310; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.078326; Mean training F1 0.939759; Mean validation loss 0.101183; Mean validation F1 0.939204; Learning rate 0.000290;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.078180; Mean training F1 0.939795; Mean validation loss 0.077297; Mean validation F1 0.938959; Learning rate 0.000279;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.078065; Mean training F1 0.939827; Mean validation loss 0.096880; Mean validation F1 0.939536; Learning rate 0.000268;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.078047; Mean training F1 0.939812; Mean validation loss 0.105954; Mean validation F1 0.938921; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.077963; Mean training F1 0.940045; Mean validation loss 0.084349; Mean validation F1 0.938864; Learning rate 0.000247;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.077851; Mean training F1 0.939922; Mean validation loss 0.094090; Mean validation F1 0.939324; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.077735; Mean training F1 0.940018; Mean validation loss 0.089524; Mean validation F1 0.939318; Learning rate 0.000226;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.077770; Mean training F1 0.940006; Mean validation loss 0.093493; Mean validation F1 0.939221; Learning rate 0.000216;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.077635; Mean training F1 0.940127; Mean validation loss 0.082335; Mean validation F1 0.939040; Learning rate 0.000206;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.077621; Mean training F1 0.940045; Mean validation loss 0.058920; Mean validation F1 0.939694; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.077587; Mean training F1 0.940180; Mean validation loss 0.068396; Mean validation F1 0.939302; Learning rate 0.000187;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.077440; Mean training F1 0.940271; Mean validation loss 0.088144; Mean validation F1 0.939496; Learning rate 0.000178;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.077332; Mean training F1 0.940354; Mean validation loss 0.078471; Mean validation F1 0.939343; Learning rate 0.000169;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.077406; Mean training F1 0.940304; Mean validation loss 0.078553; Mean validation F1 0.939282; Learning rate 0.000160;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.077326; Mean training F1 0.940289; Mean validation loss 0.090614; Mean validation F1 0.939469; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.077260; Mean training F1 0.940266; Mean validation loss 0.072416; Mean validation F1 0.939199; Learning rate 0.000142;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.077124; Mean training F1 0.940365; Mean validation loss 0.089607; Mean validation F1 0.939643; Learning rate 0.000134;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.077105; Mean training F1 0.940416; Mean validation loss 0.090504; Mean validation F1 0.939148; Learning rate 0.000126;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.077082; Mean training F1 0.940451; Mean validation loss 0.063530; Mean validation F1 0.939360; Learning rate 0.000118;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.076978; Mean training F1 0.940489; Mean validation loss 0.081354; Mean validation F1 0.939328; Learning rate 0.000111;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.076975; Mean training F1 0.940517; Mean validation loss 0.088389; Mean validation F1 0.939751; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.076902; Mean training F1 0.940602; Mean validation loss 0.056200; Mean validation F1 0.939751; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.076893; Mean training F1 0.940490; Mean validation loss 0.066999; Mean validation F1 0.939585; Learning rate 0.000089;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.076790; Mean training F1 0.940649; Mean validation loss 0.068105; Mean validation F1 0.939430; Learning rate 0.000082;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.076763; Mean training F1 0.940690; Mean validation loss 0.075049; Mean validation F1 0.939533; Learning rate 0.000076;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.076725; Mean training F1 0.940592; Mean validation loss 0.075058; Mean validation F1 0.939296; Learning rate 0.000070;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.076690; Mean training F1 0.940686; Mean validation loss 0.072790; Mean validation F1 0.939428; Learning rate 0.000064;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.076671; Mean training F1 0.940659; Mean validation loss 0.077146; Mean validation F1 0.939602; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.076618; Mean training F1 0.940743; Mean validation loss 0.084434; Mean validation F1 0.939454; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.076594; Mean training F1 0.940694; Mean validation loss 0.058771; Mean validation F1 0.939636; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.076544; Mean training F1 0.940751; Mean validation loss 0.097915; Mean validation F1 0.939613; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.076530; Mean training F1 0.940741; Mean validation loss 0.050422; Mean validation F1 0.939530; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.076502; Mean training F1 0.940862; Mean validation loss 0.082512; Mean validation F1 0.939400; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.076499; Mean training F1 0.940748; Mean validation loss 0.090205; Mean validation F1 0.939458; Learning rate 0.000030;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.076458; Mean training F1 0.940851; Mean validation loss 0.071931; Mean validation F1 0.939353; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.076424; Mean training F1 0.940807; Mean validation loss 0.087962; Mean validation F1 0.939443; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.076404; Mean training F1 0.940858; Mean validation loss 0.072388; Mean validation F1 0.939461; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.076379; Mean training F1 0.940889; Mean validation loss 0.080568; Mean validation F1 0.939449; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.076359; Mean training F1 0.940886; Mean validation loss 0.081753; Mean validation F1 0.939498; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.076349; Mean training F1 0.940879; Mean validation loss 0.077133; Mean validation F1 0.939484; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.076338; Mean training F1 0.940922; Mean validation loss 0.069280; Mean validation F1 0.939608; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.076320; Mean training F1 0.940907; Mean validation loss 0.069561; Mean validation F1 0.939505; Learning rate 0.000009;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.076310; Mean training F1 0.940963; Mean validation loss 0.068244; Mean validation F1 0.939506; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.076309; Mean training F1 0.940894; Mean validation loss 0.061573; Mean validation F1 0.939550; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.076295; Mean training F1 0.940933; Mean validation loss 0.070360; Mean validation F1 0.939482; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.076294; Mean training F1 0.940941; Mean validation loss 0.086130; Mean validation F1 0.939495; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.076289; Mean training F1 0.940948; Mean validation loss 0.063875; Mean validation F1 0.939496; Learning rate 0.000005;\n",
    "################################################################\n",
    "Training/validation for fold 2/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.619248; Mean training F1 0.660636; Mean validation loss 0.219761; Mean validation F1 0.868954; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.181179; Mean training F1 0.898279; Mean validation loss 0.158279; Mean validation F1 0.904641; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.146811; Mean training F1 0.911092; Mean validation loss 0.094220; Mean validation F1 0.914140; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.106296; Mean training F1 0.928075; Mean validation loss 0.111277; Mean validation F1 0.929799; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.091524; Mean training F1 0.933966; Mean validation loss 0.113810; Mean validation F1 0.932251; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.104366; Mean training F1 0.926726; Mean validation loss 0.099660; Mean validation F1 0.889713; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.093144; Mean training F1 0.931953; Mean validation loss 0.104672; Mean validation F1 0.934230; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.086660; Mean training F1 0.936265; Mean validation loss 0.090704; Mean validation F1 0.934144; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.086129; Mean training F1 0.936255; Mean validation loss 0.098221; Mean validation F1 0.934688; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.085527; Mean training F1 0.936512; Mean validation loss 0.062606; Mean validation F1 0.932786; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.084961; Mean training F1 0.936660; Mean validation loss 0.093483; Mean validation F1 0.935108; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.084511; Mean training F1 0.936766; Mean validation loss 0.069870; Mean validation F1 0.932078; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.085164; Mean training F1 0.936406; Mean validation loss 0.063171; Mean validation F1 0.934656; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.085782; Mean training F1 0.935754; Mean validation loss 0.081876; Mean validation F1 0.935025; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.083688; Mean training F1 0.937221; Mean validation loss 0.087105; Mean validation F1 0.935823; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.083710; Mean training F1 0.937100; Mean validation loss 0.078598; Mean validation F1 0.935866; Learning rate 0.000962;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.083197; Mean training F1 0.937479; Mean validation loss 0.079550; Mean validation F1 0.935682; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.083431; Mean training F1 0.937355; Mean validation loss 0.087355; Mean validation F1 0.935353; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.083097; Mean training F1 0.937188; Mean validation loss 0.109312; Mean validation F1 0.936017; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.082706; Mean training F1 0.937522; Mean validation loss 0.077994; Mean validation F1 0.935247; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.082742; Mean training F1 0.937316; Mean validation loss 0.073086; Mean validation F1 0.935983; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.092787; Mean training F1 0.932562; Mean validation loss 0.077561; Mean validation F1 0.928977; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.089670; Mean training F1 0.934340; Mean validation loss 0.100702; Mean validation F1 0.934874; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.083784; Mean training F1 0.936862; Mean validation loss 0.105560; Mean validation F1 0.936204; Learning rate 0.000916;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.082755; Mean training F1 0.937608; Mean validation loss 0.089956; Mean validation F1 0.936207; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.082237; Mean training F1 0.937571; Mean validation loss 0.069686; Mean validation F1 0.935589; Learning rate 0.000902;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.082586; Mean training F1 0.937361; Mean validation loss 0.092501; Mean validation F1 0.936465; Learning rate 0.000895;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.082054; Mean training F1 0.937677; Mean validation loss 0.089524; Mean validation F1 0.935511; Learning rate 0.000887;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.081735; Mean training F1 0.937772; Mean validation loss 0.085021; Mean validation F1 0.936735; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.081114; Mean training F1 0.938229; Mean validation loss 0.081768; Mean validation F1 0.936666; Learning rate 0.000871;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.081263; Mean training F1 0.938107; Mean validation loss 0.070569; Mean validation F1 0.936230; Learning rate 0.000863;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.081266; Mean training F1 0.937928; Mean validation loss 0.056160; Mean validation F1 0.936666; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.081330; Mean training F1 0.937900; Mean validation loss 0.093850; Mean validation F1 0.936523; Learning rate 0.000846;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.080710; Mean training F1 0.938205; Mean validation loss 0.075474; Mean validation F1 0.936825; Learning rate 0.000837;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.081182; Mean training F1 0.937940; Mean validation loss 0.084893; Mean validation F1 0.937044; Learning rate 0.000828;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.081004; Mean training F1 0.937925; Mean validation loss 0.072937; Mean validation F1 0.936817; Learning rate 0.000818;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.080892; Mean training F1 0.938219; Mean validation loss 0.087056; Mean validation F1 0.935130; Learning rate 0.000809;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.083536; Mean training F1 0.936438; Mean validation loss 0.065520; Mean validation F1 0.937126; Learning rate 0.000799;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.081186; Mean training F1 0.937991; Mean validation loss 0.081434; Mean validation F1 0.936605; Learning rate 0.000789;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.080795; Mean training F1 0.938196; Mean validation loss 0.068524; Mean validation F1 0.936735; Learning rate 0.000779;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.080410; Mean training F1 0.938406; Mean validation loss 0.095077; Mean validation F1 0.936914; Learning rate 0.000769;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.080285; Mean training F1 0.938390; Mean validation loss 0.090620; Mean validation F1 0.936060; Learning rate 0.000759;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.080663; Mean training F1 0.938304; Mean validation loss 0.091864; Mean validation F1 0.936623; Learning rate 0.000748;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.080417; Mean training F1 0.938108; Mean validation loss 0.073223; Mean validation F1 0.936758; Learning rate 0.000737;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.080075; Mean training F1 0.938428; Mean validation loss 0.067339; Mean validation F1 0.935942; Learning rate 0.000726;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.080219; Mean training F1 0.938361; Mean validation loss 0.081524; Mean validation F1 0.937152; Learning rate 0.000716;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.080026; Mean training F1 0.938504; Mean validation loss 0.078982; Mean validation F1 0.936622; Learning rate 0.000704;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.079632; Mean training F1 0.938707; Mean validation loss 0.079080; Mean validation F1 0.936275; Learning rate 0.000693;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.079563; Mean training F1 0.938742; Mean validation loss 0.092592; Mean validation F1 0.937097; Learning rate 0.000682;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.079822; Mean training F1 0.938507; Mean validation loss 0.055635; Mean validation F1 0.937033; Learning rate 0.000670;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.079377; Mean training F1 0.938868; Mean validation loss 0.098830; Mean validation F1 0.936912; Learning rate 0.000659;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.079655; Mean training F1 0.938831; Mean validation loss 0.100636; Mean validation F1 0.937192; Learning rate 0.000647;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.079222; Mean training F1 0.938827; Mean validation loss 0.087903; Mean validation F1 0.937186; Learning rate 0.000635;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.079110; Mean training F1 0.938852; Mean validation loss 0.069934; Mean validation F1 0.936318; Learning rate 0.000624;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.079232; Mean training F1 0.938860; Mean validation loss 0.095895; Mean validation F1 0.936973; Learning rate 0.000612;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.079140; Mean training F1 0.938853; Mean validation loss 0.099527; Mean validation F1 0.937348; Learning rate 0.000600;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.079060; Mean training F1 0.938709; Mean validation loss 0.095655; Mean validation F1 0.937340; Learning rate 0.000588;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.078837; Mean training F1 0.938957; Mean validation loss 0.078064; Mean validation F1 0.937206; Learning rate 0.000576;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.078713; Mean training F1 0.939028; Mean validation loss 0.068852; Mean validation F1 0.936801; Learning rate 0.000564;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.078665; Mean training F1 0.939239; Mean validation loss 0.060177; Mean validation F1 0.937036; Learning rate 0.000552;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.078746; Mean training F1 0.939024; Mean validation loss 0.076555; Mean validation F1 0.936558; Learning rate 0.000539;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.078392; Mean training F1 0.939305; Mean validation loss 0.070271; Mean validation F1 0.937151; Learning rate 0.000527;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.078389; Mean training F1 0.939153; Mean validation loss 0.081709; Mean validation F1 0.937715; Learning rate 0.000515;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.078617; Mean training F1 0.939229; Mean validation loss 0.067235; Mean validation F1 0.937679; Learning rate 0.000503;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.078672; Mean training F1 0.939032; Mean validation loss 0.061085; Mean validation F1 0.936900; Learning rate 0.000491;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.078502; Mean training F1 0.939106; Mean validation loss 0.093690; Mean validation F1 0.937095; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.078175; Mean training F1 0.939491; Mean validation loss 0.085877; Mean validation F1 0.937669; Learning rate 0.000466;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.078081; Mean training F1 0.939350; Mean validation loss 0.066047; Mean validation F1 0.937506; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.078000; Mean training F1 0.939428; Mean validation loss 0.067618; Mean validation F1 0.937058; Learning rate 0.000442;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.077869; Mean training F1 0.939498; Mean validation loss 0.091071; Mean validation F1 0.937573; Learning rate 0.000430;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.077761; Mean training F1 0.939700; Mean validation loss 0.063816; Mean validation F1 0.936686; Learning rate 0.000418;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.077822; Mean training F1 0.939586; Mean validation loss 0.086172; Mean validation F1 0.937444; Learning rate 0.000406;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.077768; Mean training F1 0.939750; Mean validation loss 0.080573; Mean validation F1 0.937463; Learning rate 0.000394;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.077549; Mean training F1 0.939672; Mean validation loss 0.082140; Mean validation F1 0.937865; Learning rate 0.000382;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.077451; Mean training F1 0.939729; Mean validation loss 0.050917; Mean validation F1 0.937528; Learning rate 0.000370;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.077394; Mean training F1 0.939792; Mean validation loss 0.072259; Mean validation F1 0.937172; Learning rate 0.000358;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.077452; Mean training F1 0.939771; Mean validation loss 0.075201; Mean validation F1 0.937182; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.077240; Mean training F1 0.939808; Mean validation loss 0.069577; Mean validation F1 0.937584; Learning rate 0.000335;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.077246; Mean training F1 0.939989; Mean validation loss 0.095477; Mean validation F1 0.936898; Learning rate 0.000324;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.077266; Mean training F1 0.939745; Mean validation loss 0.065870; Mean validation F1 0.937139; Learning rate 0.000312;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.077040; Mean training F1 0.939983; Mean validation loss 0.069943; Mean validation F1 0.937410; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.076989; Mean training F1 0.940024; Mean validation loss 0.085424; Mean validation F1 0.937187; Learning rate 0.000290;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.076960; Mean training F1 0.940140; Mean validation loss 0.096602; Mean validation F1 0.937747; Learning rate 0.000279;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.076879; Mean training F1 0.940024; Mean validation loss 0.086982; Mean validation F1 0.937415; Learning rate 0.000268;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.076892; Mean training F1 0.940049; Mean validation loss 0.081185; Mean validation F1 0.937397; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.076698; Mean training F1 0.939988; Mean validation loss 0.092170; Mean validation F1 0.937100; Learning rate 0.000247;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.076684; Mean training F1 0.940217; Mean validation loss 0.074134; Mean validation F1 0.937282; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.076566; Mean training F1 0.940178; Mean validation loss 0.061936; Mean validation F1 0.937507; Learning rate 0.000226;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.076524; Mean training F1 0.940215; Mean validation loss 0.076947; Mean validation F1 0.937506; Learning rate 0.000216;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.076451; Mean training F1 0.940339; Mean validation loss 0.081258; Mean validation F1 0.937648; Learning rate 0.000206;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.076383; Mean training F1 0.940310; Mean validation loss 0.071659; Mean validation F1 0.937646; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.076293; Mean training F1 0.940411; Mean validation loss 0.080814; Mean validation F1 0.937555; Learning rate 0.000187;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.076296; Mean training F1 0.940374; Mean validation loss 0.064374; Mean validation F1 0.937301; Learning rate 0.000178;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.076185; Mean training F1 0.940484; Mean validation loss 0.085317; Mean validation F1 0.937739; Learning rate 0.000169;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.076157; Mean training F1 0.940495; Mean validation loss 0.069047; Mean validation F1 0.937714; Learning rate 0.000160;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.076112; Mean training F1 0.940502; Mean validation loss 0.088182; Mean validation F1 0.937729; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.076061; Mean training F1 0.940567; Mean validation loss 0.081715; Mean validation F1 0.937826; Learning rate 0.000142;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.075943; Mean training F1 0.940684; Mean validation loss 0.064588; Mean validation F1 0.937598; Learning rate 0.000134;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.075945; Mean training F1 0.940662; Mean validation loss 0.083833; Mean validation F1 0.937426; Learning rate 0.000126;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.075851; Mean training F1 0.940705; Mean validation loss 0.089516; Mean validation F1 0.937696; Learning rate 0.000118;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.075775; Mean training F1 0.940742; Mean validation loss 0.078849; Mean validation F1 0.937574; Learning rate 0.000111;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.075728; Mean training F1 0.940794; Mean validation loss 0.079097; Mean validation F1 0.937850; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.075756; Mean training F1 0.940709; Mean validation loss 0.079966; Mean validation F1 0.937773; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.075683; Mean training F1 0.940767; Mean validation loss 0.098637; Mean validation F1 0.937702; Learning rate 0.000089;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.075638; Mean training F1 0.940850; Mean validation loss 0.077397; Mean validation F1 0.937525; Learning rate 0.000082;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.075621; Mean training F1 0.940812; Mean validation loss 0.085283; Mean validation F1 0.937948; Learning rate 0.000076;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.075546; Mean training F1 0.940833; Mean validation loss 0.082266; Mean validation F1 0.937761; Learning rate 0.000070;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.075529; Mean training F1 0.940948; Mean validation loss 0.098335; Mean validation F1 0.937884; Learning rate 0.000064;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.075470; Mean training F1 0.940914; Mean validation loss 0.080647; Mean validation F1 0.937688; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.075452; Mean training F1 0.940970; Mean validation loss 0.070857; Mean validation F1 0.937759; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.075438; Mean training F1 0.940897; Mean validation loss 0.063873; Mean validation F1 0.937630; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.075392; Mean training F1 0.940966; Mean validation loss 0.075935; Mean validation F1 0.937817; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.075350; Mean training F1 0.940983; Mean validation loss 0.085003; Mean validation F1 0.937758; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.075315; Mean training F1 0.940998; Mean validation loss 0.079379; Mean validation F1 0.937839; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.075306; Mean training F1 0.941052; Mean validation loss 0.061421; Mean validation F1 0.937866; Learning rate 0.000030;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.075272; Mean training F1 0.941033; Mean validation loss 0.078783; Mean validation F1 0.937843; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.075270; Mean training F1 0.940990; Mean validation loss 0.061420; Mean validation F1 0.937825; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.075230; Mean training F1 0.941035; Mean validation loss 0.079094; Mean validation F1 0.937749; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.075230; Mean training F1 0.941033; Mean validation loss 0.079665; Mean validation F1 0.937784; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.075208; Mean training F1 0.941098; Mean validation loss 0.069584; Mean validation F1 0.937780; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.075200; Mean training F1 0.941107; Mean validation loss 0.081389; Mean validation F1 0.937786; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.075188; Mean training F1 0.941075; Mean validation loss 0.072850; Mean validation F1 0.937710; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.075171; Mean training F1 0.941055; Mean validation loss 0.066153; Mean validation F1 0.937842; Learning rate 0.000009;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.075157; Mean training F1 0.941096; Mean validation loss 0.049971; Mean validation F1 0.937795; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.075151; Mean training F1 0.941093; Mean validation loss 0.087952; Mean validation F1 0.937769; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.075142; Mean training F1 0.941088; Mean validation loss 0.073250; Mean validation F1 0.937838; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.075135; Mean training F1 0.941106; Mean validation loss 0.075718; Mean validation F1 0.937771; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.075131; Mean training F1 0.941124; Mean validation loss 0.085370; Mean validation F1 0.937733; Learning rate 0.000005;\n",
    "################################################################\n",
    "Training/validation for fold 3/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.625913; Mean training F1 0.663597; Mean validation loss 0.310893; Mean validation F1 0.857451; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.191329; Mean training F1 0.891634; Mean validation loss 0.143737; Mean validation F1 0.903470; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.131539; Mean training F1 0.915022; Mean validation loss 0.095012; Mean validation F1 0.929298; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.096925; Mean training F1 0.933485; Mean validation loss 0.114239; Mean validation F1 0.933038; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.092004; Mean training F1 0.934957; Mean validation loss 0.095330; Mean validation F1 0.931302; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.093838; Mean training F1 0.933674; Mean validation loss 0.100529; Mean validation F1 0.934668; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.089106; Mean training F1 0.936004; Mean validation loss 0.085770; Mean validation F1 0.935240; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.088206; Mean training F1 0.936311; Mean validation loss 0.086565; Mean validation F1 0.934714; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.087880; Mean training F1 0.936056; Mean validation loss 0.123590; Mean validation F1 0.934738; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.086640; Mean training F1 0.936913; Mean validation loss 0.070959; Mean validation F1 0.934530; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.087193; Mean training F1 0.936339; Mean validation loss 0.085145; Mean validation F1 0.934177; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.097901; Mean training F1 0.931647; Mean validation loss 0.082898; Mean validation F1 0.929305; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.088852; Mean training F1 0.935543; Mean validation loss 0.073876; Mean validation F1 0.935292; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.085845; Mean training F1 0.936789; Mean validation loss 0.068817; Mean validation F1 0.935884; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.085528; Mean training F1 0.936811; Mean validation loss 0.084580; Mean validation F1 0.935941; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.084891; Mean training F1 0.937015; Mean validation loss 0.084957; Mean validation F1 0.935357; Learning rate 0.000962;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.084375; Mean training F1 0.937109; Mean validation loss 0.071172; Mean validation F1 0.935748; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.084352; Mean training F1 0.937153; Mean validation loss 0.068788; Mean validation F1 0.935037; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.083688; Mean training F1 0.937545; Mean validation loss 0.087258; Mean validation F1 0.935805; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.084150; Mean training F1 0.937283; Mean validation loss 0.082189; Mean validation F1 0.935119; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.083817; Mean training F1 0.937615; Mean validation loss 0.092471; Mean validation F1 0.935541; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.083978; Mean training F1 0.937183; Mean validation loss 0.077676; Mean validation F1 0.936386; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.083590; Mean training F1 0.937373; Mean validation loss 0.067001; Mean validation F1 0.936833; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.083516; Mean training F1 0.937410; Mean validation loss 0.052965; Mean validation F1 0.934448; Learning rate 0.000916;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.083421; Mean training F1 0.937591; Mean validation loss 0.096438; Mean validation F1 0.935727; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.083225; Mean training F1 0.937709; Mean validation loss 0.095718; Mean validation F1 0.936081; Learning rate 0.000902;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.083813; Mean training F1 0.937419; Mean validation loss 0.073209; Mean validation F1 0.931618; Learning rate 0.000895;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.083766; Mean training F1 0.937399; Mean validation loss 0.092545; Mean validation F1 0.936816; Learning rate 0.000887;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.083222; Mean training F1 0.937517; Mean validation loss 0.051828; Mean validation F1 0.934553; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.083042; Mean training F1 0.937772; Mean validation loss 0.098264; Mean validation F1 0.934674; Learning rate 0.000871;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.082660; Mean training F1 0.937964; Mean validation loss 0.057466; Mean validation F1 0.935758; Learning rate 0.000863;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.090333; Mean training F1 0.934760; Mean validation loss 0.094277; Mean validation F1 0.934816; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.083017; Mean training F1 0.937920; Mean validation loss 0.075887; Mean validation F1 0.936603; Learning rate 0.000846;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.082642; Mean training F1 0.937990; Mean validation loss 0.061412; Mean validation F1 0.936348; Learning rate 0.000837;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.082298; Mean training F1 0.938182; Mean validation loss 0.095196; Mean validation F1 0.936893; Learning rate 0.000828;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.082173; Mean training F1 0.938156; Mean validation loss 0.091352; Mean validation F1 0.937243; Learning rate 0.000818;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.082081; Mean training F1 0.938065; Mean validation loss 0.086306; Mean validation F1 0.933442; Learning rate 0.000809;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.082340; Mean training F1 0.937870; Mean validation loss 0.099002; Mean validation F1 0.936897; Learning rate 0.000799;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.081972; Mean training F1 0.938233; Mean validation loss 0.075502; Mean validation F1 0.936883; Learning rate 0.000789;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.083726; Mean training F1 0.937202; Mean validation loss 0.126728; Mean validation F1 0.912540; Learning rate 0.000779;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.086984; Mean training F1 0.935231; Mean validation loss 0.074837; Mean validation F1 0.936379; Learning rate 0.000769;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.081872; Mean training F1 0.938384; Mean validation loss 0.081202; Mean validation F1 0.937003; Learning rate 0.000759;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.081667; Mean training F1 0.938592; Mean validation loss 0.091120; Mean validation F1 0.937092; Learning rate 0.000748;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.081561; Mean training F1 0.938643; Mean validation loss 0.075997; Mean validation F1 0.937163; Learning rate 0.000737;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.081306; Mean training F1 0.938702; Mean validation loss 0.087782; Mean validation F1 0.936681; Learning rate 0.000726;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.081646; Mean training F1 0.938531; Mean validation loss 0.058654; Mean validation F1 0.937250; Learning rate 0.000716;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.081389; Mean training F1 0.938588; Mean validation loss 0.078869; Mean validation F1 0.937457; Learning rate 0.000704;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.081206; Mean training F1 0.938693; Mean validation loss 0.105285; Mean validation F1 0.937172; Learning rate 0.000693;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.081184; Mean training F1 0.938654; Mean validation loss 0.082127; Mean validation F1 0.937343; Learning rate 0.000682;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.081058; Mean training F1 0.938678; Mean validation loss 0.070345; Mean validation F1 0.936986; Learning rate 0.000670;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.090025; Mean training F1 0.934104; Mean validation loss 0.075421; Mean validation F1 0.936462; Learning rate 0.000659;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.081277; Mean training F1 0.938912; Mean validation loss 0.088267; Mean validation F1 0.936716; Learning rate 0.000647;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.081109; Mean training F1 0.938791; Mean validation loss 0.080021; Mean validation F1 0.937546; Learning rate 0.000635;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.080890; Mean training F1 0.938716; Mean validation loss 0.059504; Mean validation F1 0.937282; Learning rate 0.000624;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.080612; Mean training F1 0.938940; Mean validation loss 0.065938; Mean validation F1 0.937241; Learning rate 0.000612;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.080633; Mean training F1 0.938902; Mean validation loss 0.081969; Mean validation F1 0.936880; Learning rate 0.000600;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.080815; Mean training F1 0.939008; Mean validation loss 0.051084; Mean validation F1 0.937242; Learning rate 0.000588;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.080659; Mean training F1 0.938966; Mean validation loss 0.042155; Mean validation F1 0.936460; Learning rate 0.000576;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.080360; Mean training F1 0.939072; Mean validation loss 0.080043; Mean validation F1 0.937069; Learning rate 0.000564;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.080159; Mean training F1 0.939076; Mean validation loss 0.085735; Mean validation F1 0.937701; Learning rate 0.000552;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.082789; Mean training F1 0.938377; Mean validation loss 0.095663; Mean validation F1 0.934634; Learning rate 0.000539;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.083446; Mean training F1 0.937710; Mean validation loss 0.070369; Mean validation F1 0.937336; Learning rate 0.000527;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.080310; Mean training F1 0.939169; Mean validation loss 0.102096; Mean validation F1 0.937149; Learning rate 0.000515;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.080078; Mean training F1 0.939282; Mean validation loss 0.046907; Mean validation F1 0.937423; Learning rate 0.000503;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.079890; Mean training F1 0.939270; Mean validation loss 0.048313; Mean validation F1 0.937110; Learning rate 0.000491;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.079796; Mean training F1 0.939522; Mean validation loss 0.105892; Mean validation F1 0.937148; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.079720; Mean training F1 0.939504; Mean validation loss 0.046449; Mean validation F1 0.937803; Learning rate 0.000466;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.079864; Mean training F1 0.939268; Mean validation loss 0.056046; Mean validation F1 0.937244; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.079629; Mean training F1 0.939363; Mean validation loss 0.066223; Mean validation F1 0.937472; Learning rate 0.000442;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.079592; Mean training F1 0.939330; Mean validation loss 0.091837; Mean validation F1 0.937464; Learning rate 0.000430;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.079507; Mean training F1 0.939613; Mean validation loss 0.074642; Mean validation F1 0.937137; Learning rate 0.000418;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.079303; Mean training F1 0.939710; Mean validation loss 0.105497; Mean validation F1 0.937638; Learning rate 0.000406;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.079217; Mean training F1 0.939629; Mean validation loss 0.056956; Mean validation F1 0.937279; Learning rate 0.000394;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.079339; Mean training F1 0.939567; Mean validation loss 0.107201; Mean validation F1 0.937270; Learning rate 0.000382;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.079135; Mean training F1 0.939591; Mean validation loss 0.064926; Mean validation F1 0.937593; Learning rate 0.000370;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.078973; Mean training F1 0.939763; Mean validation loss 0.088047; Mean validation F1 0.937277; Learning rate 0.000358;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.078885; Mean training F1 0.939744; Mean validation loss 0.072943; Mean validation F1 0.936963; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.078984; Mean training F1 0.939661; Mean validation loss 0.064525; Mean validation F1 0.937677; Learning rate 0.000335;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.078781; Mean training F1 0.940014; Mean validation loss 0.086253; Mean validation F1 0.937582; Learning rate 0.000324;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.078761; Mean training F1 0.939927; Mean validation loss 0.077976; Mean validation F1 0.937443; Learning rate 0.000312;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.078701; Mean training F1 0.939932; Mean validation loss 0.062319; Mean validation F1 0.937461; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.078516; Mean training F1 0.940005; Mean validation loss 0.079566; Mean validation F1 0.937513; Learning rate 0.000290;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.078431; Mean training F1 0.940095; Mean validation loss 0.081293; Mean validation F1 0.937278; Learning rate 0.000279;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.078509; Mean training F1 0.940099; Mean validation loss 0.078677; Mean validation F1 0.937262; Learning rate 0.000268;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.078382; Mean training F1 0.940140; Mean validation loss 0.079527; Mean validation F1 0.937492; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.078281; Mean training F1 0.940158; Mean validation loss 0.106910; Mean validation F1 0.937649; Learning rate 0.000247;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.078075; Mean training F1 0.940351; Mean validation loss 0.075798; Mean validation F1 0.937610; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.078160; Mean training F1 0.940128; Mean validation loss 0.071025; Mean validation F1 0.937605; Learning rate 0.000226;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.077929; Mean training F1 0.940313; Mean validation loss 0.085161; Mean validation F1 0.937730; Learning rate 0.000216;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.078007; Mean training F1 0.940252; Mean validation loss 0.078063; Mean validation F1 0.937781; Learning rate 0.000206;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.077815; Mean training F1 0.940405; Mean validation loss 0.075300; Mean validation F1 0.937258; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.077813; Mean training F1 0.940368; Mean validation loss 0.080271; Mean validation F1 0.937751; Learning rate 0.000187;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.077770; Mean training F1 0.940373; Mean validation loss 0.082801; Mean validation F1 0.937682; Learning rate 0.000178;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.077671; Mean training F1 0.940510; Mean validation loss 0.095120; Mean validation F1 0.937618; Learning rate 0.000169;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.077666; Mean training F1 0.940513; Mean validation loss 0.053569; Mean validation F1 0.937965; Learning rate 0.000160;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.077526; Mean training F1 0.940605; Mean validation loss 0.084064; Mean validation F1 0.937580; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.077501; Mean training F1 0.940606; Mean validation loss 0.085573; Mean validation F1 0.937662; Learning rate 0.000142;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.077429; Mean training F1 0.940543; Mean validation loss 0.086941; Mean validation F1 0.937648; Learning rate 0.000134;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.077314; Mean training F1 0.940657; Mean validation loss 0.067282; Mean validation F1 0.937704; Learning rate 0.000126;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.077315; Mean training F1 0.940676; Mean validation loss 0.074737; Mean validation F1 0.937421; Learning rate 0.000118;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.077253; Mean training F1 0.940692; Mean validation loss 0.085489; Mean validation F1 0.937852; Learning rate 0.000111;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.077203; Mean training F1 0.940807; Mean validation loss 0.112455; Mean validation F1 0.937758; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.077148; Mean training F1 0.940792; Mean validation loss 0.090695; Mean validation F1 0.937769; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.077124; Mean training F1 0.940838; Mean validation loss 0.094590; Mean validation F1 0.937815; Learning rate 0.000089;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.077089; Mean training F1 0.940791; Mean validation loss 0.077696; Mean validation F1 0.937865; Learning rate 0.000082;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.076997; Mean training F1 0.940827; Mean validation loss 0.081991; Mean validation F1 0.937776; Learning rate 0.000076;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.076982; Mean training F1 0.940844; Mean validation loss 0.076412; Mean validation F1 0.937913; Learning rate 0.000070;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.076951; Mean training F1 0.940838; Mean validation loss 0.078151; Mean validation F1 0.937470; Learning rate 0.000064;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.076906; Mean training F1 0.940913; Mean validation loss 0.106888; Mean validation F1 0.937877; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.076880; Mean training F1 0.940920; Mean validation loss 0.088056; Mean validation F1 0.937982; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.076814; Mean training F1 0.941004; Mean validation loss 0.068413; Mean validation F1 0.937823; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.076799; Mean training F1 0.940970; Mean validation loss 0.062990; Mean validation F1 0.937690; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.076755; Mean training F1 0.941022; Mean validation loss 0.083597; Mean validation F1 0.937696; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.076736; Mean training F1 0.941011; Mean validation loss 0.074195; Mean validation F1 0.938154; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.076702; Mean training F1 0.941028; Mean validation loss 0.073525; Mean validation F1 0.937913; Learning rate 0.000030;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.076687; Mean training F1 0.941021; Mean validation loss 0.069366; Mean validation F1 0.937845; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.076655; Mean training F1 0.941025; Mean validation loss 0.058549; Mean validation F1 0.937873; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.076635; Mean training F1 0.941032; Mean validation loss 0.062846; Mean validation F1 0.937938; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.076624; Mean training F1 0.941127; Mean validation loss 0.100495; Mean validation F1 0.937858; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.076596; Mean training F1 0.941106; Mean validation loss 0.052867; Mean validation F1 0.938004; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.076579; Mean training F1 0.941093; Mean validation loss 0.060481; Mean validation F1 0.937885; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.076570; Mean training F1 0.941107; Mean validation loss 0.062367; Mean validation F1 0.937897; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.076554; Mean training F1 0.941117; Mean validation loss 0.069399; Mean validation F1 0.937992; Learning rate 0.000009;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.076547; Mean training F1 0.941161; Mean validation loss 0.063184; Mean validation F1 0.937951; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.076536; Mean training F1 0.941093; Mean validation loss 0.057113; Mean validation F1 0.937949; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.076530; Mean training F1 0.941159; Mean validation loss 0.074208; Mean validation F1 0.937846; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.076525; Mean training F1 0.941117; Mean validation loss 0.075531; Mean validation F1 0.937902; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.076523; Mean training F1 0.941115; Mean validation loss 0.082415; Mean validation F1 0.937902; Learning rate 0.000005;\n",
    "################################################################\n",
    "Training/validation for fold 4/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.592100; Mean training F1 0.682003; Mean validation loss 0.213096; Mean validation F1 0.864718; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.180516; Mean training F1 0.898362; Mean validation loss 0.129497; Mean validation F1 0.903487; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.152013; Mean training F1 0.906321; Mean validation loss 0.133376; Mean validation F1 0.899298; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.139366; Mean training F1 0.913330; Mean validation loss 0.111602; Mean validation F1 0.917763; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.106776; Mean training F1 0.928640; Mean validation loss 0.102782; Mean validation F1 0.933345; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.093088; Mean training F1 0.934365; Mean validation loss 0.122620; Mean validation F1 0.935603; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.091951; Mean training F1 0.934910; Mean validation loss 0.101816; Mean validation F1 0.936928; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.100728; Mean training F1 0.929632; Mean validation loss 0.073052; Mean validation F1 0.934330; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.090623; Mean training F1 0.934953; Mean validation loss 0.099901; Mean validation F1 0.934606; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.088830; Mean training F1 0.935662; Mean validation loss 0.075826; Mean validation F1 0.935779; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.087797; Mean training F1 0.936181; Mean validation loss 0.067758; Mean validation F1 0.937489; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.086832; Mean training F1 0.936623; Mean validation loss 0.108605; Mean validation F1 0.933526; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.086411; Mean training F1 0.936730; Mean validation loss 0.101691; Mean validation F1 0.937092; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.088507; Mean training F1 0.935541; Mean validation loss 0.078149; Mean validation F1 0.937221; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.086199; Mean training F1 0.936629; Mean validation loss 0.110264; Mean validation F1 0.935451; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.085710; Mean training F1 0.936815; Mean validation loss 0.090939; Mean validation F1 0.937472; Learning rate 0.000962;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.085429; Mean training F1 0.936700; Mean validation loss 0.075548; Mean validation F1 0.936970; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.085140; Mean training F1 0.936900; Mean validation loss 0.089519; Mean validation F1 0.937949; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.085386; Mean training F1 0.936916; Mean validation loss 0.085329; Mean validation F1 0.937950; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.084672; Mean training F1 0.937252; Mean validation loss 0.070319; Mean validation F1 0.936907; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.084567; Mean training F1 0.937148; Mean validation loss 0.089159; Mean validation F1 0.935793; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.084704; Mean training F1 0.937249; Mean validation loss 0.077736; Mean validation F1 0.937346; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.084838; Mean training F1 0.936757; Mean validation loss 0.072419; Mean validation F1 0.934979; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.084540; Mean training F1 0.937329; Mean validation loss 0.091075; Mean validation F1 0.938062; Learning rate 0.000916;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.084242; Mean training F1 0.937340; Mean validation loss 0.084347; Mean validation F1 0.935339; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.130837; Mean training F1 0.919143; Mean validation loss 0.099093; Mean validation F1 0.936007; Learning rate 0.000902;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.088200; Mean training F1 0.936343; Mean validation loss 0.132348; Mean validation F1 0.937514; Learning rate 0.000895;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.086754; Mean training F1 0.936836; Mean validation loss 0.074491; Mean validation F1 0.937445; Learning rate 0.000887;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.085410; Mean training F1 0.937301; Mean validation loss 0.074043; Mean validation F1 0.937559; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.084937; Mean training F1 0.937395; Mean validation loss 0.080140; Mean validation F1 0.937502; Learning rate 0.000871;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.084612; Mean training F1 0.937429; Mean validation loss 0.083920; Mean validation F1 0.937778; Learning rate 0.000863;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.084109; Mean training F1 0.937708; Mean validation loss 0.055463; Mean validation F1 0.937319; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.084360; Mean training F1 0.937256; Mean validation loss 0.086421; Mean validation F1 0.937185; Learning rate 0.000846;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.083737; Mean training F1 0.937440; Mean validation loss 0.065221; Mean validation F1 0.936987; Learning rate 0.000837;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.083535; Mean training F1 0.937917; Mean validation loss 0.078416; Mean validation F1 0.937901; Learning rate 0.000828;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.083593; Mean training F1 0.937664; Mean validation loss 0.067315; Mean validation F1 0.936980; Learning rate 0.000818;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.083495; Mean training F1 0.937840; Mean validation loss 0.064945; Mean validation F1 0.937146; Learning rate 0.000809;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.083259; Mean training F1 0.937894; Mean validation loss 0.095780; Mean validation F1 0.938353; Learning rate 0.000799;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.083247; Mean training F1 0.937817; Mean validation loss 0.082408; Mean validation F1 0.937785; Learning rate 0.000789;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.083381; Mean training F1 0.937803; Mean validation loss 0.076929; Mean validation F1 0.937734; Learning rate 0.000779;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.083371; Mean training F1 0.937649; Mean validation loss 0.069923; Mean validation F1 0.937852; Learning rate 0.000769;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.083041; Mean training F1 0.937969; Mean validation loss 0.086496; Mean validation F1 0.938345; Learning rate 0.000759;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.083064; Mean training F1 0.938096; Mean validation loss 0.055873; Mean validation F1 0.937805; Learning rate 0.000748;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.083141; Mean training F1 0.937775; Mean validation loss 0.073911; Mean validation F1 0.937989; Learning rate 0.000737;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.083014; Mean training F1 0.937772; Mean validation loss 0.077872; Mean validation F1 0.938117; Learning rate 0.000726;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.082839; Mean training F1 0.938085; Mean validation loss 0.075003; Mean validation F1 0.937938; Learning rate 0.000716;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.082936; Mean training F1 0.937900; Mean validation loss 0.074749; Mean validation F1 0.937727; Learning rate 0.000704;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.082764; Mean training F1 0.938135; Mean validation loss 0.078177; Mean validation F1 0.938405; Learning rate 0.000693;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.082511; Mean training F1 0.938234; Mean validation loss 0.084504; Mean validation F1 0.938353; Learning rate 0.000682;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.082410; Mean training F1 0.938211; Mean validation loss 0.095439; Mean validation F1 0.938337; Learning rate 0.000670;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.082435; Mean training F1 0.938245; Mean validation loss 0.081115; Mean validation F1 0.938196; Learning rate 0.000659;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.082469; Mean training F1 0.938069; Mean validation loss 0.105115; Mean validation F1 0.938300; Learning rate 0.000647;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.082160; Mean training F1 0.938406; Mean validation loss 0.084406; Mean validation F1 0.936963; Learning rate 0.000635;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.082406; Mean training F1 0.937746; Mean validation loss 0.089606; Mean validation F1 0.938214; Learning rate 0.000624;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.082429; Mean training F1 0.938258; Mean validation loss 0.087446; Mean validation F1 0.938616; Learning rate 0.000612;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.082399; Mean training F1 0.938085; Mean validation loss 0.078057; Mean validation F1 0.938477; Learning rate 0.000600;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.081877; Mean training F1 0.938413; Mean validation loss 0.069410; Mean validation F1 0.938423; Learning rate 0.000588;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.081690; Mean training F1 0.938323; Mean validation loss 0.074129; Mean validation F1 0.937967; Learning rate 0.000576;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.081911; Mean training F1 0.938384; Mean validation loss 0.100836; Mean validation F1 0.938071; Learning rate 0.000564;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.082061; Mean training F1 0.938362; Mean validation loss 0.113544; Mean validation F1 0.938066; Learning rate 0.000552;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.081801; Mean training F1 0.938511; Mean validation loss 0.082595; Mean validation F1 0.938321; Learning rate 0.000539;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.083416; Mean training F1 0.937711; Mean validation loss 0.101926; Mean validation F1 0.938063; Learning rate 0.000527;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.081653; Mean training F1 0.938543; Mean validation loss 0.080575; Mean validation F1 0.938237; Learning rate 0.000515;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.081657; Mean training F1 0.938475; Mean validation loss 0.087309; Mean validation F1 0.937915; Learning rate 0.000503;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.082605; Mean training F1 0.938183; Mean validation loss 0.067848; Mean validation F1 0.936737; Learning rate 0.000491;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.081803; Mean training F1 0.938401; Mean validation loss 0.079606; Mean validation F1 0.938653; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.081264; Mean training F1 0.938725; Mean validation loss 0.082016; Mean validation F1 0.938361; Learning rate 0.000466;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.081329; Mean training F1 0.938813; Mean validation loss 0.053495; Mean validation F1 0.938251; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.081238; Mean training F1 0.938918; Mean validation loss 0.056553; Mean validation F1 0.938024; Learning rate 0.000442;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.080899; Mean training F1 0.938912; Mean validation loss 0.061519; Mean validation F1 0.937892; Learning rate 0.000430;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.080882; Mean training F1 0.938850; Mean validation loss 0.075922; Mean validation F1 0.937507; Learning rate 0.000418;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.080881; Mean training F1 0.938941; Mean validation loss 0.093630; Mean validation F1 0.938441; Learning rate 0.000406;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.080652; Mean training F1 0.939070; Mean validation loss 0.049209; Mean validation F1 0.938399; Learning rate 0.000394;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.080673; Mean training F1 0.938906; Mean validation loss 0.073249; Mean validation F1 0.938323; Learning rate 0.000382;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.080677; Mean training F1 0.938973; Mean validation loss 0.070850; Mean validation F1 0.938242; Learning rate 0.000370;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.080406; Mean training F1 0.939108; Mean validation loss 0.077176; Mean validation F1 0.938446; Learning rate 0.000358;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.080218; Mean training F1 0.939305; Mean validation loss 0.095602; Mean validation F1 0.938545; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.080398; Mean training F1 0.939118; Mean validation loss 0.089998; Mean validation F1 0.937719; Learning rate 0.000335;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.080166; Mean training F1 0.939254; Mean validation loss 0.069392; Mean validation F1 0.938032; Learning rate 0.000324;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.080093; Mean training F1 0.939298; Mean validation loss 0.076252; Mean validation F1 0.938735; Learning rate 0.000312;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.080086; Mean training F1 0.939387; Mean validation loss 0.074919; Mean validation F1 0.938583; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.078734; Mean training F1 0.939979; Mean validation loss 0.057261; Mean validation F1 0.938479; Learning rate 0.000111;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.078660; Mean training F1 0.939917; Mean validation loss 0.080929; Mean validation F1 0.938707; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.078617; Mean training F1 0.939995; Mean validation loss 0.073176; Mean validation F1 0.938722; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.078582; Mean training F1 0.940030; Mean validation loss 0.096687; Mean validation F1 0.938947; Learning rate 0.000089;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.078507; Mean training F1 0.940065; Mean validation loss 0.063425; Mean validation F1 0.938568; Learning rate 0.000082;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.078484; Mean training F1 0.940187; Mean validation loss 0.088458; Mean validation F1 0.938838; Learning rate 0.000076;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.078456; Mean training F1 0.940090; Mean validation loss 0.068926; Mean validation F1 0.938825; Learning rate 0.000070;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.078418; Mean training F1 0.940132; Mean validation loss 0.056485; Mean validation F1 0.938871; Learning rate 0.000064;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.078384; Mean training F1 0.940119; Mean validation loss 0.089751; Mean validation F1 0.938833; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.078343; Mean training F1 0.940264; Mean validation loss 0.067976; Mean validation F1 0.938747; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.078293; Mean training F1 0.940157; Mean validation loss 0.061505; Mean validation F1 0.938612; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.078263; Mean training F1 0.940263; Mean validation loss 0.078018; Mean validation F1 0.938759; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.078250; Mean training F1 0.940192; Mean validation loss 0.078680; Mean validation F1 0.938705; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.078217; Mean training F1 0.940205; Mean validation loss 0.079117; Mean validation F1 0.938845; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.078198; Mean training F1 0.940231; Mean validation loss 0.072833; Mean validation F1 0.938838; Learning rate 0.000030;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.078156; Mean training F1 0.940251; Mean validation loss 0.050637; Mean validation F1 0.938827; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.078138; Mean training F1 0.940272; Mean validation loss 0.065862; Mean validation F1 0.938822; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.078133; Mean training F1 0.940244; Mean validation loss 0.090971; Mean validation F1 0.938809; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.078107; Mean training F1 0.940284; Mean validation loss 0.091027; Mean validation F1 0.938898; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.078102; Mean training F1 0.940237; Mean validation loss 0.063663; Mean validation F1 0.938844; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.078091; Mean training F1 0.940301; Mean validation loss 0.079069; Mean validation F1 0.938919; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.078070; Mean training F1 0.940314; Mean validation loss 0.076589; Mean validation F1 0.938780; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.088880; Mean training F1 0.936477; Mean validation loss 0.093567; Mean validation F1 0.937493; Learning rate 0.000962;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.088213; Mean training F1 0.936773; Mean validation loss 0.101563; Mean validation F1 0.937515; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.087873; Mean training F1 0.936787; Mean validation loss 0.073331; Mean validation F1 0.936772; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.087872; Mean training F1 0.936738; Mean validation loss 0.078268; Mean validation F1 0.938036; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.087306; Mean training F1 0.936965; Mean validation loss 0.083821; Mean validation F1 0.937099; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.088575; Mean training F1 0.936212; Mean validation loss 0.096667; Mean validation F1 0.937429; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.087213; Mean training F1 0.936917; Mean validation loss 0.111808; Mean validation F1 0.937485; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.086876; Mean training F1 0.937039; Mean validation loss 0.129000; Mean validation F1 0.938037; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.086617; Mean training F1 0.936966; Mean validation loss 0.092045; Mean validation F1 0.938032; Learning rate 0.000916;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.086241; Mean training F1 0.936944; Mean validation loss 0.095287; Mean validation F1 0.938051; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.086324; Mean training F1 0.936936; Mean validation loss 0.059445; Mean validation F1 0.937570; Learning rate 0.000902;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.086370; Mean training F1 0.936901; Mean validation loss 0.097269; Mean validation F1 0.937307; Learning rate 0.000895;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.099359; Mean training F1 0.929734; Mean validation loss 0.117022; Mean validation F1 0.919582; Learning rate 0.000887;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.092736; Mean training F1 0.934287; Mean validation loss 0.065859; Mean validation F1 0.935109; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.088401; Mean training F1 0.936500; Mean validation loss 0.101192; Mean validation F1 0.937740; Learning rate 0.000871;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.086251; Mean training F1 0.937279; Mean validation loss 0.070026; Mean validation F1 0.938399; Learning rate 0.000863;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.085760; Mean training F1 0.937248; Mean validation loss 0.119437; Mean validation F1 0.938271; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.085722; Mean training F1 0.937192; Mean validation loss 0.081135; Mean validation F1 0.937423; Learning rate 0.000846;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.085353; Mean training F1 0.937422; Mean validation loss 0.059952; Mean validation F1 0.936080; Learning rate 0.000837;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.080959; Mean training F1 0.938927; Mean validation loss 0.099246; Mean validation F1 0.939116; Learning rate 0.000406;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.080891; Mean training F1 0.939087; Mean validation loss 0.086461; Mean validation F1 0.938843; Learning rate 0.000394;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.081239; Mean training F1 0.938874; Mean validation loss 0.092963; Mean validation F1 0.938146; Learning rate 0.000382;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.080880; Mean training F1 0.939052; Mean validation loss 0.099486; Mean validation F1 0.939157; Learning rate 0.000370;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.080597; Mean training F1 0.939171; Mean validation loss 0.094684; Mean validation F1 0.938926; Learning rate 0.000358;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.080548; Mean training F1 0.939098; Mean validation loss 0.069637; Mean validation F1 0.939007; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.080545; Mean training F1 0.939066; Mean validation loss 0.074394; Mean validation F1 0.938900; Learning rate 0.000335;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.080540; Mean training F1 0.939203; Mean validation loss 0.109007; Mean validation F1 0.939001; Learning rate 0.000324;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.080378; Mean training F1 0.939269; Mean validation loss 0.081789; Mean validation F1 0.939273; Learning rate 0.000312;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.080137; Mean training F1 0.939350; Mean validation loss 0.079607; Mean validation F1 0.938658; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.080217; Mean training F1 0.939287; Mean validation loss 0.089399; Mean validation F1 0.938972; Learning rate 0.000290;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.080205; Mean training F1 0.939341; Mean validation loss 0.066147; Mean validation F1 0.939068; Learning rate 0.000279;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.080078; Mean training F1 0.939366; Mean validation loss 0.077559; Mean validation F1 0.938737; Learning rate 0.000268;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.079938; Mean training F1 0.939400; Mean validation loss 0.089914; Mean validation F1 0.939027; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.080044; Mean training F1 0.939312; Mean validation loss 0.087611; Mean validation F1 0.939118; Learning rate 0.000247;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.079869; Mean training F1 0.939423; Mean validation loss 0.101063; Mean validation F1 0.939048; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.079910; Mean training F1 0.939458; Mean validation loss 0.063181; Mean validation F1 0.939184; Learning rate 0.000226;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.079688; Mean training F1 0.939592; Mean validation loss 0.081576; Mean validation F1 0.939198; Learning rate 0.000216;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.079727; Mean training F1 0.939560; Mean validation loss 0.085914; Mean validation F1 0.939028; Learning rate 0.000206;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.078402; Mean training F1 0.940166; Mean validation loss 0.051454; Mean validation F1 0.939368; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.078401; Mean training F1 0.940185; Mean validation loss 0.064974; Mean validation F1 0.939351; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.078386; Mean training F1 0.940198; Mean validation loss 0.070023; Mean validation F1 0.939337; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.078382; Mean training F1 0.940167; Mean validation loss 0.073370; Mean validation F1 0.939359; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.078382; Mean training F1 0.940150; Mean validation loss 0.084015; Mean validation F1 0.939275; Learning rate 0.000005;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-------- fold 0 --------\n",
    "model validation loss: 0.062; validation f1: 0.940;\n",
    "-------- fold 1 --------\n",
    "model validation loss: 0.083; validation f1: 0.938;\n",
    "-------- fold 2 --------\n",
    "model validation loss: 0.047; validation f1: 0.937;\n",
    "-------- fold 3 --------\n",
    "model validation loss: 0.087; validation f1: 0.939;\n",
    "-------- fold 4 --------\n",
    "model validation loss: 0.086; validation f1: 0.939;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "################################################################\n",
    "Training/validation for fold 1/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.831691; Mean training F1 0.535447; Mean validation loss 0.550472; Mean validation F1 0.718114; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.312835; Mean training F1 0.824668; Mean validation loss 0.216069; Mean validation F1 0.900422; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.130562; Mean training F1 0.917581; Mean validation loss 0.116826; Mean validation F1 0.931875; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.113237; Mean training F1 0.921949; Mean validation loss 0.091665; Mean validation F1 0.933153; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.093309; Mean training F1 0.933347; Mean validation loss 0.123785; Mean validation F1 0.934461; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.118039; Mean training F1 0.915961; Mean validation loss 0.100093; Mean validation F1 0.934269; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.091335; Mean training F1 0.933967; Mean validation loss 0.091710; Mean validation F1 0.935207; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.090022; Mean training F1 0.934624; Mean validation loss 0.086560; Mean validation F1 0.933112; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.089928; Mean training F1 0.934678; Mean validation loss 0.098240; Mean validation F1 0.936688; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.089409; Mean training F1 0.934939; Mean validation loss 0.099206; Mean validation F1 0.935685; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.089276; Mean training F1 0.935173; Mean validation loss 0.094494; Mean validation F1 0.936025; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.088166; Mean training F1 0.935434; Mean validation loss 0.050602; Mean validation F1 0.936016; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.087659; Mean training F1 0.935912; Mean validation loss 0.095010; Mean validation F1 0.936713; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.088555; Mean training F1 0.935220; Mean validation loss 0.087549; Mean validation F1 0.936164; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.088028; Mean training F1 0.935584; Mean validation loss 0.076670; Mean validation F1 0.937448; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.087489; Mean training F1 0.936034; Mean validation loss 0.101991; Mean validation F1 0.937516; Learning rate 0.000962;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.086389; Mean training F1 0.936341; Mean validation loss 0.100565; Mean validation F1 0.934513; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.087059; Mean training F1 0.935812; Mean validation loss 0.081648; Mean validation F1 0.936914; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.086869; Mean training F1 0.935880; Mean validation loss 0.110857; Mean validation F1 0.935844; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.086422; Mean training F1 0.936268; Mean validation loss 0.070783; Mean validation F1 0.937421; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.086091; Mean training F1 0.936150; Mean validation loss 0.078613; Mean validation F1 0.936115; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.088285; Mean training F1 0.935050; Mean validation loss 0.074148; Mean validation F1 0.936685; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.085650; Mean training F1 0.936396; Mean validation loss 0.079849; Mean validation F1 0.937216; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.086123; Mean training F1 0.935930; Mean validation loss 0.087263; Mean validation F1 0.936721; Learning rate 0.000916;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.085800; Mean training F1 0.936299; Mean validation loss 0.090738; Mean validation F1 0.933418; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.085900; Mean training F1 0.936360; Mean validation loss 0.093053; Mean validation F1 0.936814; Learning rate 0.000902;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.197207; Mean training F1 0.898825; Mean validation loss 0.085272; Mean validation F1 0.931924; Learning rate 0.000895;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.093438; Mean training F1 0.934266; Mean validation loss 0.057703; Mean validation F1 0.934457; Learning rate 0.000887;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.089742; Mean training F1 0.935445; Mean validation loss 0.114135; Mean validation F1 0.936821; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.088000; Mean training F1 0.936147; Mean validation loss 0.085165; Mean validation F1 0.936073; Learning rate 0.000871;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.087802; Mean training F1 0.936238; Mean validation loss 0.084987; Mean validation F1 0.937096; Learning rate 0.000863;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.086848; Mean training F1 0.936436; Mean validation loss 0.111408; Mean validation F1 0.937013; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.087963; Mean training F1 0.936120; Mean validation loss 0.134650; Mean validation F1 0.936042; Learning rate 0.000846;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.088847; Mean training F1 0.935519; Mean validation loss 0.075510; Mean validation F1 0.937709; Learning rate 0.000837;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.086101; Mean training F1 0.936723; Mean validation loss 0.079615; Mean validation F1 0.937887; Learning rate 0.000828;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.085749; Mean training F1 0.936843; Mean validation loss 0.112208; Mean validation F1 0.937651; Learning rate 0.000818;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.085588; Mean training F1 0.936705; Mean validation loss 0.069106; Mean validation F1 0.938055; Learning rate 0.000809;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.085130; Mean training F1 0.936988; Mean validation loss 0.066794; Mean validation F1 0.937755; Learning rate 0.000799;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.085072; Mean training F1 0.937025; Mean validation loss 0.080109; Mean validation F1 0.938070; Learning rate 0.000789;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.085034; Mean training F1 0.936969; Mean validation loss 0.094780; Mean validation F1 0.937675; Learning rate 0.000779;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.084502; Mean training F1 0.937204; Mean validation loss 0.072063; Mean validation F1 0.938166; Learning rate 0.000769;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.084944; Mean training F1 0.937003; Mean validation loss 0.076169; Mean validation F1 0.936881; Learning rate 0.000759;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.084704; Mean training F1 0.937005; Mean validation loss 0.085094; Mean validation F1 0.937575; Learning rate 0.000748;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.084216; Mean training F1 0.937174; Mean validation loss 0.096327; Mean validation F1 0.938355; Learning rate 0.000737;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.084633; Mean training F1 0.937045; Mean validation loss 0.089086; Mean validation F1 0.936719; Learning rate 0.000726;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.083848; Mean training F1 0.937617; Mean validation loss 0.081450; Mean validation F1 0.937919; Learning rate 0.000716;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.083854; Mean training F1 0.937269; Mean validation loss 0.073952; Mean validation F1 0.938673; Learning rate 0.000704;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.084000; Mean training F1 0.937129; Mean validation loss 0.079148; Mean validation F1 0.937303; Learning rate 0.000693;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.083863; Mean training F1 0.937425; Mean validation loss 0.077982; Mean validation F1 0.937934; Learning rate 0.000682;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.084153; Mean training F1 0.937090; Mean validation loss 0.094083; Mean validation F1 0.937796; Learning rate 0.000670;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.083671; Mean training F1 0.937222; Mean validation loss 0.098382; Mean validation F1 0.938463; Learning rate 0.000659;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.083548; Mean training F1 0.937511; Mean validation loss 0.068574; Mean validation F1 0.938264; Learning rate 0.000647;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.083160; Mean training F1 0.937597; Mean validation loss 0.075014; Mean validation F1 0.937999; Learning rate 0.000635;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.083211; Mean training F1 0.937743; Mean validation loss 0.104914; Mean validation F1 0.938390; Learning rate 0.000624;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.083158; Mean training F1 0.937581; Mean validation loss 0.064185; Mean validation F1 0.938344; Learning rate 0.000612;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.082981; Mean training F1 0.937614; Mean validation loss 0.083333; Mean validation F1 0.938030; Learning rate 0.000600;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.107043; Mean training F1 0.923158; Mean validation loss 0.087166; Mean validation F1 0.935346; Learning rate 0.000588;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.086973; Mean training F1 0.936028; Mean validation loss 0.099897; Mean validation F1 0.935283; Learning rate 0.000576;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.084851; Mean training F1 0.936970; Mean validation loss 0.063895; Mean validation F1 0.938311; Learning rate 0.000564;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.084008; Mean training F1 0.937481; Mean validation loss 0.100571; Mean validation F1 0.937068; Learning rate 0.000552;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.083728; Mean training F1 0.937421; Mean validation loss 0.100800; Mean validation F1 0.938696; Learning rate 0.000539;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.083263; Mean training F1 0.937787; Mean validation loss 0.094611; Mean validation F1 0.938597; Learning rate 0.000527;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.083673; Mean training F1 0.937506; Mean validation loss 0.075639; Mean validation F1 0.938646; Learning rate 0.000515;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.082833; Mean training F1 0.937810; Mean validation loss 0.069119; Mean validation F1 0.938433; Learning rate 0.000503;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.082852; Mean training F1 0.937868; Mean validation loss 0.069293; Mean validation F1 0.938295; Learning rate 0.000491;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.082829; Mean training F1 0.937835; Mean validation loss 0.080081; Mean validation F1 0.938226; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.082668; Mean training F1 0.937851; Mean validation loss 0.054044; Mean validation F1 0.938246; Learning rate 0.000466;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.082621; Mean training F1 0.937824; Mean validation loss 0.076269; Mean validation F1 0.938471; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.082334; Mean training F1 0.938208; Mean validation loss 0.071068; Mean validation F1 0.938788; Learning rate 0.000442;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.082153; Mean training F1 0.938179; Mean validation loss 0.095918; Mean validation F1 0.938624; Learning rate 0.000430;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.082240; Mean training F1 0.937893; Mean validation loss 0.066531; Mean validation F1 0.938745; Learning rate 0.000418;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.082410; Mean training F1 0.938017; Mean validation loss 0.074590; Mean validation F1 0.938585; Learning rate 0.000406;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.082031; Mean training F1 0.937996; Mean validation loss 0.096941; Mean validation F1 0.938696; Learning rate 0.000394;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.082078; Mean training F1 0.938088; Mean validation loss 0.095094; Mean validation F1 0.938931; Learning rate 0.000382;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.081945; Mean training F1 0.938248; Mean validation loss 0.104565; Mean validation F1 0.938910; Learning rate 0.000370;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.081960; Mean training F1 0.938185; Mean validation loss 0.062754; Mean validation F1 0.938798; Learning rate 0.000358;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.081819; Mean training F1 0.938240; Mean validation loss 0.073070; Mean validation F1 0.938108; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.081726; Mean training F1 0.938375; Mean validation loss 0.062937; Mean validation F1 0.938960; Learning rate 0.000335;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.081712; Mean training F1 0.938246; Mean validation loss 0.092433; Mean validation F1 0.938775; Learning rate 0.000324;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.081620; Mean training F1 0.938289; Mean validation loss 0.099885; Mean validation F1 0.938632; Learning rate 0.000312;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.081601; Mean training F1 0.938379; Mean validation loss 0.092066; Mean validation F1 0.938809; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.082037; Mean training F1 0.938176; Mean validation loss 0.093149; Mean validation F1 0.938766; Learning rate 0.000290;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.081365; Mean training F1 0.938547; Mean validation loss 0.096497; Mean validation F1 0.938647; Learning rate 0.000279;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.081400; Mean training F1 0.938393; Mean validation loss 0.065159; Mean validation F1 0.938797; Learning rate 0.000268;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.081257; Mean training F1 0.938604; Mean validation loss 0.081906; Mean validation F1 0.938723; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.081316; Mean training F1 0.938657; Mean validation loss 0.089892; Mean validation F1 0.938945; Learning rate 0.000247;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.081225; Mean training F1 0.938502; Mean validation loss 0.084583; Mean validation F1 0.939110; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.081105; Mean training F1 0.938546; Mean validation loss 0.069828; Mean validation F1 0.938919; Learning rate 0.000226;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.081217; Mean training F1 0.938569; Mean validation loss 0.069263; Mean validation F1 0.939127; Learning rate 0.000216;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.081052; Mean training F1 0.938728; Mean validation loss 0.067613; Mean validation F1 0.938652; Learning rate 0.000206;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.080981; Mean training F1 0.938621; Mean validation loss 0.080499; Mean validation F1 0.938946; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.081063; Mean training F1 0.938491; Mean validation loss 0.092203; Mean validation F1 0.937190; Learning rate 0.000187;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.081104; Mean training F1 0.938604; Mean validation loss 0.093186; Mean validation F1 0.938771; Learning rate 0.000178;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.080913; Mean training F1 0.938764; Mean validation loss 0.087378; Mean validation F1 0.938425; Learning rate 0.000169;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.080867; Mean training F1 0.938695; Mean validation loss 0.095881; Mean validation F1 0.938955; Learning rate 0.000160;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.080710; Mean training F1 0.938788; Mean validation loss 0.063345; Mean validation F1 0.938967; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.080652; Mean training F1 0.938750; Mean validation loss 0.096826; Mean validation F1 0.939045; Learning rate 0.000142;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.080633; Mean training F1 0.939001; Mean validation loss 0.074557; Mean validation F1 0.939133; Learning rate 0.000134;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.080554; Mean training F1 0.938842; Mean validation loss 0.071434; Mean validation F1 0.938580; Learning rate 0.000126;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.080549; Mean training F1 0.938868; Mean validation loss 0.068865; Mean validation F1 0.939160; Learning rate 0.000118;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.080498; Mean training F1 0.938860; Mean validation loss 0.060956; Mean validation F1 0.939073; Learning rate 0.000111;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.080395; Mean training F1 0.938971; Mean validation loss 0.069282; Mean validation F1 0.938698; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.080435; Mean training F1 0.938932; Mean validation loss 0.079966; Mean validation F1 0.939064; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.080385; Mean training F1 0.938979; Mean validation loss 0.057599; Mean validation F1 0.938998; Learning rate 0.000089;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.080354; Mean training F1 0.938939; Mean validation loss 0.061900; Mean validation F1 0.939189; Learning rate 0.000082;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.080277; Mean training F1 0.939066; Mean validation loss 0.087188; Mean validation F1 0.939133; Learning rate 0.000076;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.080232; Mean training F1 0.939063; Mean validation loss 0.081271; Mean validation F1 0.939033; Learning rate 0.000070;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.080228; Mean training F1 0.939043; Mean validation loss 0.081007; Mean validation F1 0.939133; Learning rate 0.000064;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.080164; Mean training F1 0.939090; Mean validation loss 0.061566; Mean validation F1 0.939143; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.080166; Mean training F1 0.939138; Mean validation loss 0.085503; Mean validation F1 0.939058; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.080129; Mean training F1 0.939102; Mean validation loss 0.099547; Mean validation F1 0.939216; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.080114; Mean training F1 0.939151; Mean validation loss 0.082156; Mean validation F1 0.939162; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.080089; Mean training F1 0.939166; Mean validation loss 0.096239; Mean validation F1 0.939129; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.080060; Mean training F1 0.939146; Mean validation loss 0.097675; Mean validation F1 0.939036; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.080040; Mean training F1 0.939165; Mean validation loss 0.079122; Mean validation F1 0.939295; Learning rate 0.000030;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.080015; Mean training F1 0.939232; Mean validation loss 0.062310; Mean validation F1 0.939225; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.079974; Mean training F1 0.939213; Mean validation loss 0.090973; Mean validation F1 0.939237; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.079978; Mean training F1 0.939166; Mean validation loss 0.077793; Mean validation F1 0.939111; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.079949; Mean training F1 0.939165; Mean validation loss 0.069454; Mean validation F1 0.939172; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.079924; Mean training F1 0.939247; Mean validation loss 0.090116; Mean validation F1 0.939286; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.079912; Mean training F1 0.939208; Mean validation loss 0.086670; Mean validation F1 0.939208; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.079895; Mean training F1 0.939234; Mean validation loss 0.074169; Mean validation F1 0.939272; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.079888; Mean training F1 0.939241; Mean validation loss 0.082812; Mean validation F1 0.939174; Learning rate 0.000009;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.079881; Mean training F1 0.939260; Mean validation loss 0.064772; Mean validation F1 0.939327; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.079872; Mean training F1 0.939248; Mean validation loss 0.091066; Mean validation F1 0.939310; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.079860; Mean training F1 0.939238; Mean validation loss 0.094940; Mean validation F1 0.939200; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.079855; Mean training F1 0.939274; Mean validation loss 0.073562; Mean validation F1 0.939291; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.079851; Mean training F1 0.939229; Mean validation loss 0.076107; Mean validation F1 0.939233; Learning rate 0.000005;\n",
    "################################################################\n",
    "Training/validation for fold 2/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.808958; Mean training F1 0.535858; Mean validation loss 0.455986; Mean validation F1 0.746767; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.233048; Mean training F1 0.871942; Mean validation loss 0.137898; Mean validation F1 0.918936; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.118455; Mean training F1 0.923090; Mean validation loss 0.101376; Mean validation F1 0.926870; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.095951; Mean training F1 0.932062; Mean validation loss 0.075788; Mean validation F1 0.931962; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.095623; Mean training F1 0.931987; Mean validation loss 0.089496; Mean validation F1 0.929459; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.091864; Mean training F1 0.933146; Mean validation loss 0.120770; Mean validation F1 0.929602; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.094361; Mean training F1 0.931362; Mean validation loss 0.076511; Mean validation F1 0.925431; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.087361; Mean training F1 0.935230; Mean validation loss 0.066516; Mean validation F1 0.934620; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.086789; Mean training F1 0.935305; Mean validation loss 0.094566; Mean validation F1 0.933849; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.085883; Mean training F1 0.936114; Mean validation loss 0.055327; Mean validation F1 0.934341; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.085671; Mean training F1 0.936006; Mean validation loss 0.080762; Mean validation F1 0.935004; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.085350; Mean training F1 0.935908; Mean validation loss 0.106191; Mean validation F1 0.934413; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.094277; Mean training F1 0.930152; Mean validation loss 0.111193; Mean validation F1 0.933905; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.085732; Mean training F1 0.935969; Mean validation loss 0.082762; Mean validation F1 0.934872; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.085050; Mean training F1 0.936092; Mean validation loss 0.072960; Mean validation F1 0.935520; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.083907; Mean training F1 0.936909; Mean validation loss 0.091379; Mean validation F1 0.934414; Learning rate 0.000962;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.084795; Mean training F1 0.936387; Mean validation loss 0.086786; Mean validation F1 0.932300; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.084043; Mean training F1 0.936579; Mean validation loss 0.086520; Mean validation F1 0.934479; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.084712; Mean training F1 0.936507; Mean validation loss 0.079729; Mean validation F1 0.934992; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.083248; Mean training F1 0.937197; Mean validation loss 0.066756; Mean validation F1 0.935825; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.084332; Mean training F1 0.936176; Mean validation loss 0.094469; Mean validation F1 0.934878; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.083466; Mean training F1 0.936881; Mean validation loss 0.098453; Mean validation F1 0.935006; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.083127; Mean training F1 0.936935; Mean validation loss 0.101354; Mean validation F1 0.935968; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.082856; Mean training F1 0.937162; Mean validation loss 0.091308; Mean validation F1 0.935008; Learning rate 0.000916;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.083036; Mean training F1 0.936844; Mean validation loss 0.078994; Mean validation F1 0.935583; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.086139; Mean training F1 0.936154; Mean validation loss 0.083769; Mean validation F1 0.935264; Learning rate 0.000902;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.082511; Mean training F1 0.937271; Mean validation loss 0.055537; Mean validation F1 0.933694; Learning rate 0.000895;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.083792; Mean training F1 0.936126; Mean validation loss 0.075042; Mean validation F1 0.935839; Learning rate 0.000887;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.082857; Mean training F1 0.937038; Mean validation loss 0.113649; Mean validation F1 0.935996; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.082305; Mean training F1 0.937288; Mean validation loss 0.084074; Mean validation F1 0.932410; Learning rate 0.000871;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.082083; Mean training F1 0.937222; Mean validation loss 0.070247; Mean validation F1 0.936025; Learning rate 0.000863;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.082209; Mean training F1 0.937322; Mean validation loss 0.085338; Mean validation F1 0.935264; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.082005; Mean training F1 0.937451; Mean validation loss 0.043725; Mean validation F1 0.936203; Learning rate 0.000846;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.081700; Mean training F1 0.937619; Mean validation loss 0.060642; Mean validation F1 0.935824; Learning rate 0.000837;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.081789; Mean training F1 0.937162; Mean validation loss 0.065307; Mean validation F1 0.933390; Learning rate 0.000828;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.081837; Mean training F1 0.937517; Mean validation loss 0.112540; Mean validation F1 0.935892; Learning rate 0.000818;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.082664; Mean training F1 0.937213; Mean validation loss 0.081189; Mean validation F1 0.935513; Learning rate 0.000809;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.082014; Mean training F1 0.937597; Mean validation loss 0.069292; Mean validation F1 0.935156; Learning rate 0.000799;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.082133; Mean training F1 0.937077; Mean validation loss 0.078986; Mean validation F1 0.936673; Learning rate 0.000789;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.081276; Mean training F1 0.937929; Mean validation loss 0.071995; Mean validation F1 0.936572; Learning rate 0.000779;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.081592; Mean training F1 0.937516; Mean validation loss 0.072756; Mean validation F1 0.934818; Learning rate 0.000769;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.081033; Mean training F1 0.937975; Mean validation loss 0.066072; Mean validation F1 0.936092; Learning rate 0.000759;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.083214; Mean training F1 0.937528; Mean validation loss 0.094104; Mean validation F1 0.931142; Learning rate 0.000748;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.082796; Mean training F1 0.937378; Mean validation loss 0.075408; Mean validation F1 0.935292; Learning rate 0.000737;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.084259; Mean training F1 0.936644; Mean validation loss 0.085587; Mean validation F1 0.936352; Learning rate 0.000726;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.083025; Mean training F1 0.936213; Mean validation loss 0.097438; Mean validation F1 0.936672; Learning rate 0.000716;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.080665; Mean training F1 0.938333; Mean validation loss 0.075408; Mean validation F1 0.936718; Learning rate 0.000704;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.080656; Mean training F1 0.938187; Mean validation loss 0.093235; Mean validation F1 0.936515; Learning rate 0.000693;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.080409; Mean training F1 0.938488; Mean validation loss 0.077447; Mean validation F1 0.937011; Learning rate 0.000682;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.080177; Mean training F1 0.938596; Mean validation loss 0.075493; Mean validation F1 0.936552; Learning rate 0.000670;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.080235; Mean training F1 0.938373; Mean validation loss 0.071550; Mean validation F1 0.935856; Learning rate 0.000659;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.080532; Mean training F1 0.938249; Mean validation loss 0.100240; Mean validation F1 0.934941; Learning rate 0.000647;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.080197; Mean training F1 0.938493; Mean validation loss 0.073456; Mean validation F1 0.937159; Learning rate 0.000635;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.080027; Mean training F1 0.938495; Mean validation loss 0.097354; Mean validation F1 0.936783; Learning rate 0.000624;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.079986; Mean training F1 0.938503; Mean validation loss 0.074499; Mean validation F1 0.936935; Learning rate 0.000612;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.079562; Mean training F1 0.938857; Mean validation loss 0.068383; Mean validation F1 0.937208; Learning rate 0.000600;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.079711; Mean training F1 0.938608; Mean validation loss 0.082463; Mean validation F1 0.936287; Learning rate 0.000588;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.080126; Mean training F1 0.938208; Mean validation loss 0.066284; Mean validation F1 0.935015; Learning rate 0.000576;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.079655; Mean training F1 0.938680; Mean validation loss 0.057878; Mean validation F1 0.936284; Learning rate 0.000564;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.079763; Mean training F1 0.938404; Mean validation loss 0.093004; Mean validation F1 0.935854; Learning rate 0.000552;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.079485; Mean training F1 0.938615; Mean validation loss 0.060788; Mean validation F1 0.936680; Learning rate 0.000539;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.079258; Mean training F1 0.938654; Mean validation loss 0.044658; Mean validation F1 0.935731; Learning rate 0.000527;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.079237; Mean training F1 0.938931; Mean validation loss 0.067012; Mean validation F1 0.937194; Learning rate 0.000515;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.079176; Mean training F1 0.938917; Mean validation loss 0.069886; Mean validation F1 0.936939; Learning rate 0.000503;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.079163; Mean training F1 0.938879; Mean validation loss 0.069306; Mean validation F1 0.937037; Learning rate 0.000491;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.078990; Mean training F1 0.939025; Mean validation loss 0.088042; Mean validation F1 0.936438; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.078816; Mean training F1 0.939187; Mean validation loss 0.083179; Mean validation F1 0.936573; Learning rate 0.000466;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.078963; Mean training F1 0.938842; Mean validation loss 0.094569; Mean validation F1 0.936689; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.079037; Mean training F1 0.938969; Mean validation loss 0.079608; Mean validation F1 0.936618; Learning rate 0.000442;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.078613; Mean training F1 0.939304; Mean validation loss 0.072812; Mean validation F1 0.936819; Learning rate 0.000430;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.078774; Mean training F1 0.939063; Mean validation loss 0.102052; Mean validation F1 0.936716; Learning rate 0.000418;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.078391; Mean training F1 0.939346; Mean validation loss 0.077034; Mean validation F1 0.936965; Learning rate 0.000406;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.078476; Mean training F1 0.939259; Mean validation loss 0.097736; Mean validation F1 0.937035; Learning rate 0.000394;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.078436; Mean training F1 0.939147; Mean validation loss 0.054008; Mean validation F1 0.936326; Learning rate 0.000382;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.078236; Mean training F1 0.939419; Mean validation loss 0.080346; Mean validation F1 0.936869; Learning rate 0.000370;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.078145; Mean training F1 0.939465; Mean validation loss 0.076034; Mean validation F1 0.937040; Learning rate 0.000358;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.078391; Mean training F1 0.939163; Mean validation loss 0.081371; Mean validation F1 0.937119; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.078093; Mean training F1 0.939453; Mean validation loss 0.075345; Mean validation F1 0.936964; Learning rate 0.000335;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.078092; Mean training F1 0.939423; Mean validation loss 0.062066; Mean validation F1 0.937368; Learning rate 0.000324;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.077860; Mean training F1 0.939496; Mean validation loss 0.089534; Mean validation F1 0.937273; Learning rate 0.000312;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.077872; Mean training F1 0.939539; Mean validation loss 0.104957; Mean validation F1 0.936904; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.077703; Mean training F1 0.939641; Mean validation loss 0.081132; Mean validation F1 0.936963; Learning rate 0.000290;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.077623; Mean training F1 0.939732; Mean validation loss 0.081312; Mean validation F1 0.936843; Learning rate 0.000279;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.077594; Mean training F1 0.939630; Mean validation loss 0.082991; Mean validation F1 0.937308; Learning rate 0.000268;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.077537; Mean training F1 0.939695; Mean validation loss 0.059676; Mean validation F1 0.936781; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.077649; Mean training F1 0.939588; Mean validation loss 0.079978; Mean validation F1 0.936254; Learning rate 0.000247;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.077533; Mean training F1 0.939704; Mean validation loss 0.079051; Mean validation F1 0.937130; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.077505; Mean training F1 0.939736; Mean validation loss 0.097458; Mean validation F1 0.937087; Learning rate 0.000226;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.077268; Mean training F1 0.939822; Mean validation loss 0.070509; Mean validation F1 0.936641; Learning rate 0.000216;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.077276; Mean training F1 0.939729; Mean validation loss 0.108791; Mean validation F1 0.936999; Learning rate 0.000206;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.077219; Mean training F1 0.939936; Mean validation loss 0.066473; Mean validation F1 0.937259; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.077067; Mean training F1 0.939992; Mean validation loss 0.082572; Mean validation F1 0.937234; Learning rate 0.000187;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.076962; Mean training F1 0.939964; Mean validation loss 0.065731; Mean validation F1 0.937198; Learning rate 0.000178;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.076975; Mean training F1 0.939955; Mean validation loss 0.076813; Mean validation F1 0.937216; Learning rate 0.000169;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.077057; Mean training F1 0.939959; Mean validation loss 0.062433; Mean validation F1 0.936734; Learning rate 0.000160;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.076902; Mean training F1 0.939989; Mean validation loss 0.084498; Mean validation F1 0.937125; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.076843; Mean training F1 0.940072; Mean validation loss 0.095917; Mean validation F1 0.937029; Learning rate 0.000142;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.076760; Mean training F1 0.940112; Mean validation loss 0.061833; Mean validation F1 0.937349; Learning rate 0.000134;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.076672; Mean training F1 0.940098; Mean validation loss 0.098301; Mean validation F1 0.937281; Learning rate 0.000126;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.076601; Mean training F1 0.940222; Mean validation loss 0.084639; Mean validation F1 0.936991; Learning rate 0.000118;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.076584; Mean training F1 0.940190; Mean validation loss 0.079421; Mean validation F1 0.937051; Learning rate 0.000111;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.076532; Mean training F1 0.940254; Mean validation loss 0.091559; Mean validation F1 0.937172; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.076515; Mean training F1 0.940272; Mean validation loss 0.057251; Mean validation F1 0.937200; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.076441; Mean training F1 0.940311; Mean validation loss 0.044186; Mean validation F1 0.937219; Learning rate 0.000089;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.076417; Mean training F1 0.940285; Mean validation loss 0.080445; Mean validation F1 0.937262; Learning rate 0.000082;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.076380; Mean training F1 0.940270; Mean validation loss 0.057748; Mean validation F1 0.937122; Learning rate 0.000076;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.076342; Mean training F1 0.940349; Mean validation loss 0.102566; Mean validation F1 0.937180; Learning rate 0.000070;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.076353; Mean training F1 0.940284; Mean validation loss 0.075985; Mean validation F1 0.937061; Learning rate 0.000064;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.076237; Mean training F1 0.940412; Mean validation loss 0.062845; Mean validation F1 0.936946; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.076238; Mean training F1 0.940365; Mean validation loss 0.081849; Mean validation F1 0.937276; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.076201; Mean training F1 0.940350; Mean validation loss 0.082733; Mean validation F1 0.937073; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.076142; Mean training F1 0.940419; Mean validation loss 0.065875; Mean validation F1 0.937139; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.076115; Mean training F1 0.940366; Mean validation loss 0.086298; Mean validation F1 0.937233; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.076084; Mean training F1 0.940425; Mean validation loss 0.068148; Mean validation F1 0.937116; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.076085; Mean training F1 0.940492; Mean validation loss 0.090810; Mean validation F1 0.937276; Learning rate 0.000030;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.076042; Mean training F1 0.940501; Mean validation loss 0.056515; Mean validation F1 0.936959; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.076018; Mean training F1 0.940458; Mean validation loss 0.051519; Mean validation F1 0.937357; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.076000; Mean training F1 0.940521; Mean validation loss 0.090554; Mean validation F1 0.937242; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.075984; Mean training F1 0.940483; Mean validation loss 0.096195; Mean validation F1 0.937413; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.075965; Mean training F1 0.940535; Mean validation loss 0.062998; Mean validation F1 0.937160; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.075946; Mean training F1 0.940516; Mean validation loss 0.088751; Mean validation F1 0.937409; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.075935; Mean training F1 0.940454; Mean validation loss 0.082103; Mean validation F1 0.937189; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.075921; Mean training F1 0.940486; Mean validation loss 0.058957; Mean validation F1 0.937221; Learning rate 0.000009;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.075907; Mean training F1 0.940537; Mean validation loss 0.076572; Mean validation F1 0.937138; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.075901; Mean training F1 0.940567; Mean validation loss 0.065382; Mean validation F1 0.937188; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.075892; Mean training F1 0.940562; Mean validation loss 0.062589; Mean validation F1 0.937214; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.075884; Mean training F1 0.940555; Mean validation loss 0.104318; Mean validation F1 0.937228; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.075882; Mean training F1 0.940567; Mean validation loss 0.060241; Mean validation F1 0.937195; Learning rate 0.000005;\n",
    "################################################################\n",
    "Training/validation for fold 3/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.774917; Mean training F1 0.563818; Mean validation loss 0.388473; Mean validation F1 0.762969; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.224798; Mean training F1 0.875541; Mean validation loss 0.147083; Mean validation F1 0.904493; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.142908; Mean training F1 0.910777; Mean validation loss 0.140731; Mean validation F1 0.914542; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.132070; Mean training F1 0.914827; Mean validation loss 0.126615; Mean validation F1 0.913977; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.111368; Mean training F1 0.924140; Mean validation loss 0.093574; Mean validation F1 0.928103; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.092750; Mean training F1 0.932744; Mean validation loss 0.101525; Mean validation F1 0.934675; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.089409; Mean training F1 0.934819; Mean validation loss 0.119711; Mean validation F1 0.933161; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.088402; Mean training F1 0.935462; Mean validation loss 0.088638; Mean validation F1 0.933859; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.088386; Mean training F1 0.935193; Mean validation loss 0.089897; Mean validation F1 0.932613; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.087933; Mean training F1 0.935453; Mean validation loss 0.124374; Mean validation F1 0.933122; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.087826; Mean training F1 0.935460; Mean validation loss 0.073289; Mean validation F1 0.934734; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.088085; Mean training F1 0.934642; Mean validation loss 0.082224; Mean validation F1 0.933652; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.086458; Mean training F1 0.936216; Mean validation loss 0.085180; Mean validation F1 0.935513; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.087700; Mean training F1 0.935519; Mean validation loss 0.107324; Mean validation F1 0.935751; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.085602; Mean training F1 0.936656; Mean validation loss 0.074581; Mean validation F1 0.934756; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.085455; Mean training F1 0.936653; Mean validation loss 0.080415; Mean validation F1 0.936400; Learning rate 0.000962;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.112020; Mean training F1 0.925694; Mean validation loss 0.092137; Mean validation F1 0.934890; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.086680; Mean training F1 0.936081; Mean validation loss 0.058969; Mean validation F1 0.935887; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.085621; Mean training F1 0.936823; Mean validation loss 0.101861; Mean validation F1 0.936049; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.100964; Mean training F1 0.928959; Mean validation loss 0.114717; Mean validation F1 0.923126; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.092117; Mean training F1 0.933346; Mean validation loss 0.091979; Mean validation F1 0.934770; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.085986; Mean training F1 0.936604; Mean validation loss 0.116920; Mean validation F1 0.936018; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.085661; Mean training F1 0.936801; Mean validation loss 0.114171; Mean validation F1 0.936033; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.085276; Mean training F1 0.936787; Mean validation loss 0.079400; Mean validation F1 0.936183; Learning rate 0.000916;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.084672; Mean training F1 0.937267; Mean validation loss 0.084632; Mean validation F1 0.935945; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.084449; Mean training F1 0.937364; Mean validation loss 0.100370; Mean validation F1 0.936732; Learning rate 0.000902;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.084364; Mean training F1 0.937159; Mean validation loss 0.073130; Mean validation F1 0.934931; Learning rate 0.000895;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.084145; Mean training F1 0.937190; Mean validation loss 0.100539; Mean validation F1 0.935831; Learning rate 0.000887;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.084513; Mean training F1 0.936934; Mean validation loss 0.064746; Mean validation F1 0.935084; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.083926; Mean training F1 0.937286; Mean validation loss 0.091144; Mean validation F1 0.936460; Learning rate 0.000871;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.083522; Mean training F1 0.937588; Mean validation loss 0.102763; Mean validation F1 0.936019; Learning rate 0.000863;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.083452; Mean training F1 0.937807; Mean validation loss 0.062283; Mean validation F1 0.934845; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.083602; Mean training F1 0.937455; Mean validation loss 0.074795; Mean validation F1 0.935851; Learning rate 0.000846;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.083581; Mean training F1 0.937365; Mean validation loss 0.088513; Mean validation F1 0.936795; Learning rate 0.000837;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.083377; Mean training F1 0.937619; Mean validation loss 0.085108; Mean validation F1 0.936106; Learning rate 0.000828;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.083523; Mean training F1 0.937444; Mean validation loss 0.080181; Mean validation F1 0.936275; Learning rate 0.000818;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.082593; Mean training F1 0.937877; Mean validation loss 0.066654; Mean validation F1 0.936461; Learning rate 0.000809;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.083105; Mean training F1 0.937673; Mean validation loss 0.084574; Mean validation F1 0.933475; Learning rate 0.000799;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.085258; Mean training F1 0.936438; Mean validation loss 0.074598; Mean validation F1 0.935457; Learning rate 0.000789;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.082993; Mean training F1 0.937780; Mean validation loss 0.082551; Mean validation F1 0.936581; Learning rate 0.000779;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.082600; Mean training F1 0.938005; Mean validation loss 0.061622; Mean validation F1 0.936590; Learning rate 0.000769;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.082550; Mean training F1 0.938039; Mean validation loss 0.098559; Mean validation F1 0.935912; Learning rate 0.000759;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.082917; Mean training F1 0.937413; Mean validation loss 0.072274; Mean validation F1 0.936951; Learning rate 0.000748;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.082338; Mean training F1 0.937828; Mean validation loss 0.083686; Mean validation F1 0.937281; Learning rate 0.000737;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.082063; Mean training F1 0.938304; Mean validation loss 0.074534; Mean validation F1 0.936679; Learning rate 0.000726;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.081962; Mean training F1 0.938014; Mean validation loss 0.065537; Mean validation F1 0.936642; Learning rate 0.000716;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.082390; Mean training F1 0.937862; Mean validation loss 0.058494; Mean validation F1 0.936274; Learning rate 0.000704;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.082225; Mean training F1 0.938047; Mean validation loss 0.077179; Mean validation F1 0.936919; Learning rate 0.000693;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.082866; Mean training F1 0.937876; Mean validation loss 0.082786; Mean validation F1 0.937248; Learning rate 0.000682;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.081840; Mean training F1 0.938189; Mean validation loss 0.075992; Mean validation F1 0.936480; Learning rate 0.000670;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.081892; Mean training F1 0.938206; Mean validation loss 0.077793; Mean validation F1 0.936286; Learning rate 0.000659;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.082101; Mean training F1 0.937970; Mean validation loss 0.102680; Mean validation F1 0.935490; Learning rate 0.000647;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.082299; Mean training F1 0.937658; Mean validation loss 0.077671; Mean validation F1 0.935404; Learning rate 0.000635;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.082022; Mean training F1 0.938171; Mean validation loss 0.096792; Mean validation F1 0.933841; Learning rate 0.000624;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.081272; Mean training F1 0.938484; Mean validation loss 0.064267; Mean validation F1 0.937184; Learning rate 0.000612;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.081214; Mean training F1 0.938576; Mean validation loss 0.076401; Mean validation F1 0.936905; Learning rate 0.000600;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.081387; Mean training F1 0.938556; Mean validation loss 0.082729; Mean validation F1 0.936121; Learning rate 0.000588;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.081271; Mean training F1 0.938751; Mean validation loss 0.060301; Mean validation F1 0.936808; Learning rate 0.000576;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.081020; Mean training F1 0.938675; Mean validation loss 0.093259; Mean validation F1 0.937083; Learning rate 0.000564;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.081086; Mean training F1 0.938499; Mean validation loss 0.078288; Mean validation F1 0.936910; Learning rate 0.000552;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.080900; Mean training F1 0.938789; Mean validation loss 0.059474; Mean validation F1 0.936595; Learning rate 0.000539;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.080627; Mean training F1 0.938833; Mean validation loss 0.080338; Mean validation F1 0.936908; Learning rate 0.000527;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.080840; Mean training F1 0.938774; Mean validation loss 0.093248; Mean validation F1 0.936878; Learning rate 0.000515;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.081099; Mean training F1 0.938566; Mean validation loss 0.070358; Mean validation F1 0.937376; Learning rate 0.000503;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.080437; Mean training F1 0.938882; Mean validation loss 0.093888; Mean validation F1 0.937207; Learning rate 0.000491;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.080742; Mean training F1 0.938927; Mean validation loss 0.121752; Mean validation F1 0.937297; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.080834; Mean training F1 0.938819; Mean validation loss 0.067249; Mean validation F1 0.936950; Learning rate 0.000466;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.080613; Mean training F1 0.938966; Mean validation loss 0.088404; Mean validation F1 0.936321; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.080439; Mean training F1 0.939096; Mean validation loss 0.085756; Mean validation F1 0.937375; Learning rate 0.000442;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.080399; Mean training F1 0.938891; Mean validation loss 0.084507; Mean validation F1 0.937658; Learning rate 0.000430;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.080317; Mean training F1 0.939052; Mean validation loss 0.086397; Mean validation F1 0.937557; Learning rate 0.000418;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.080088; Mean training F1 0.939090; Mean validation loss 0.064404; Mean validation F1 0.937239; Learning rate 0.000406;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.080159; Mean training F1 0.939018; Mean validation loss 0.075505; Mean validation F1 0.937398; Learning rate 0.000394;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.079959; Mean training F1 0.939104; Mean validation loss 0.082111; Mean validation F1 0.936871; Learning rate 0.000382;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.079959; Mean training F1 0.939058; Mean validation loss 0.078447; Mean validation F1 0.937740; Learning rate 0.000370;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.079967; Mean training F1 0.939143; Mean validation loss 0.063496; Mean validation F1 0.936754; Learning rate 0.000358;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.079707; Mean training F1 0.939330; Mean validation loss 0.078289; Mean validation F1 0.937676; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.079666; Mean training F1 0.939257; Mean validation loss 0.081597; Mean validation F1 0.937658; Learning rate 0.000335;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.079696; Mean training F1 0.939341; Mean validation loss 0.071211; Mean validation F1 0.937462; Learning rate 0.000324;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.079665; Mean training F1 0.939327; Mean validation loss 0.072700; Mean validation F1 0.937349; Learning rate 0.000312;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.079816; Mean training F1 0.939162; Mean validation loss 0.060357; Mean validation F1 0.937198; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.079541; Mean training F1 0.939251; Mean validation loss 0.087975; Mean validation F1 0.937624; Learning rate 0.000290;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.079483; Mean training F1 0.939426; Mean validation loss 0.093882; Mean validation F1 0.936870; Learning rate 0.000279;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.079352; Mean training F1 0.939508; Mean validation loss 0.076991; Mean validation F1 0.937461; Learning rate 0.000268;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.079374; Mean training F1 0.939599; Mean validation loss 0.092609; Mean validation F1 0.937425; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.079363; Mean training F1 0.939462; Mean validation loss 0.078106; Mean validation F1 0.937067; Learning rate 0.000247;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.079263; Mean training F1 0.939430; Mean validation loss 0.056974; Mean validation F1 0.937259; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.079330; Mean training F1 0.939527; Mean validation loss 0.091891; Mean validation F1 0.937499; Learning rate 0.000226;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.079106; Mean training F1 0.939621; Mean validation loss 0.090513; Mean validation F1 0.936475; Learning rate 0.000216;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.079052; Mean training F1 0.939710; Mean validation loss 0.088439; Mean validation F1 0.937289; Learning rate 0.000206;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.079091; Mean training F1 0.939651; Mean validation loss 0.070748; Mean validation F1 0.937548; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.078953; Mean training F1 0.939680; Mean validation loss 0.070061; Mean validation F1 0.937722; Learning rate 0.000187;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.078984; Mean training F1 0.939561; Mean validation loss 0.065284; Mean validation F1 0.937504; Learning rate 0.000178;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.078804; Mean training F1 0.939769; Mean validation loss 0.065389; Mean validation F1 0.937341; Learning rate 0.000169;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.078862; Mean training F1 0.939651; Mean validation loss 0.091254; Mean validation F1 0.937510; Learning rate 0.000160;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.078784; Mean training F1 0.939723; Mean validation loss 0.076618; Mean validation F1 0.937468; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.078680; Mean training F1 0.939779; Mean validation loss 0.108645; Mean validation F1 0.937492; Learning rate 0.000142;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.078633; Mean training F1 0.939885; Mean validation loss 0.082910; Mean validation F1 0.937613; Learning rate 0.000134;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.078641; Mean training F1 0.939942; Mean validation loss 0.096210; Mean validation F1 0.937688; Learning rate 0.000126;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.078560; Mean training F1 0.939839; Mean validation loss 0.105973; Mean validation F1 0.937443; Learning rate 0.000118;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.078617; Mean training F1 0.939853; Mean validation loss 0.081214; Mean validation F1 0.937613; Learning rate 0.000111;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.078469; Mean training F1 0.939914; Mean validation loss 0.088551; Mean validation F1 0.937718; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.078470; Mean training F1 0.939977; Mean validation loss 0.067464; Mean validation F1 0.937826; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.078434; Mean training F1 0.939964; Mean validation loss 0.094885; Mean validation F1 0.937750; Learning rate 0.000089;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.078431; Mean training F1 0.940094; Mean validation loss 0.082211; Mean validation F1 0.937467; Learning rate 0.000082;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.078346; Mean training F1 0.940112; Mean validation loss 0.073473; Mean validation F1 0.937676; Learning rate 0.000076;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.078326; Mean training F1 0.940134; Mean validation loss 0.059573; Mean validation F1 0.937589; Learning rate 0.000070;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.078323; Mean training F1 0.940031; Mean validation loss 0.072916; Mean validation F1 0.937640; Learning rate 0.000064;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.078241; Mean training F1 0.940077; Mean validation loss 0.061410; Mean validation F1 0.937643; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.078234; Mean training F1 0.940133; Mean validation loss 0.082364; Mean validation F1 0.937668; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.078228; Mean training F1 0.940184; Mean validation loss 0.066970; Mean validation F1 0.937616; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.078191; Mean training F1 0.940104; Mean validation loss 0.078697; Mean validation F1 0.937674; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.078160; Mean training F1 0.940137; Mean validation loss 0.091072; Mean validation F1 0.937754; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.078117; Mean training F1 0.940192; Mean validation loss 0.068176; Mean validation F1 0.937657; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.078107; Mean training F1 0.940119; Mean validation loss 0.076823; Mean validation F1 0.937442; Learning rate 0.000030;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.078077; Mean training F1 0.940176; Mean validation loss 0.081534; Mean validation F1 0.937759; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.078056; Mean training F1 0.940232; Mean validation loss 0.090948; Mean validation F1 0.937692; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.078057; Mean training F1 0.940127; Mean validation loss 0.097794; Mean validation F1 0.937668; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.078027; Mean training F1 0.940211; Mean validation loss 0.090708; Mean validation F1 0.937709; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.078014; Mean training F1 0.940189; Mean validation loss 0.090203; Mean validation F1 0.937694; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.078000; Mean training F1 0.940256; Mean validation loss 0.089196; Mean validation F1 0.937638; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.077993; Mean training F1 0.940198; Mean validation loss 0.101667; Mean validation F1 0.937808; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.077975; Mean training F1 0.940262; Mean validation loss 0.073258; Mean validation F1 0.937698; Learning rate 0.000009;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.077961; Mean training F1 0.940282; Mean validation loss 0.089670; Mean validation F1 0.937653; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.077958; Mean training F1 0.940295; Mean validation loss 0.072959; Mean validation F1 0.937761; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.077946; Mean training F1 0.940330; Mean validation loss 0.073415; Mean validation F1 0.937711; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.077949; Mean training F1 0.940274; Mean validation loss 0.104079; Mean validation F1 0.937740; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.077944; Mean training F1 0.940274; Mean validation loss 0.066269; Mean validation F1 0.937763; Learning rate 0.000005;\n",
    "################################################################\n",
    "Training/validation for fold 4/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.794365; Mean training F1 0.549660; Mean validation loss 0.374860; Mean validation F1 0.746388; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.278738; Mean training F1 0.847037; Mean validation loss 0.174967; Mean validation F1 0.906854; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.136903; Mean training F1 0.917323; Mean validation loss 0.191032; Mean validation F1 0.926242; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.103414; Mean training F1 0.929358; Mean validation loss 0.083991; Mean validation F1 0.934115; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.094768; Mean training F1 0.933557; Mean validation loss 0.106845; Mean validation F1 0.927452; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.093954; Mean training F1 0.932981; Mean validation loss 0.072950; Mean validation F1 0.934600; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.256257; Mean training F1 0.858485; Mean validation loss 0.161004; Mean validation F1 0.886733; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.118174; Mean training F1 0.923231; Mean validation loss 0.076786; Mean validation F1 0.934378; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.094359; Mean training F1 0.934203; Mean validation loss 0.145153; Mean validation F1 0.935808; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.092207; Mean training F1 0.934939; Mean validation loss 0.100882; Mean validation F1 0.934388; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.091084; Mean training F1 0.935056; Mean validation loss 0.083182; Mean validation F1 0.936184; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.090163; Mean training F1 0.935390; Mean validation loss 0.082003; Mean validation F1 0.936770; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.089217; Mean training F1 0.935846; Mean validation loss 0.100488; Mean validation F1 0.936676; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.088644; Mean training F1 0.935906; Mean validation loss 0.075785; Mean validation F1 0.936733; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.088336; Mean training F1 0.936022; Mean validation loss 0.079299; Mean validation F1 0.936872; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.087776; Mean training F1 0.936231; Mean validation loss 0.078349; Mean validation F1 0.937139; Learning rate 0.000962;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.088329; Mean training F1 0.936175; Mean validation loss 0.089184; Mean validation F1 0.935393; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.087783; Mean training F1 0.935984; Mean validation loss 0.102265; Mean validation F1 0.937126; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.087665; Mean training F1 0.936355; Mean validation loss 0.089167; Mean validation F1 0.936544; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.088380; Mean training F1 0.936147; Mean validation loss 0.086338; Mean validation F1 0.934886; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.087507; Mean training F1 0.936109; Mean validation loss 0.100742; Mean validation F1 0.936987; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.087119; Mean training F1 0.936464; Mean validation loss 0.069714; Mean validation F1 0.937376; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.090512; Mean training F1 0.934816; Mean validation loss 0.103099; Mean validation F1 0.932431; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.089120; Mean training F1 0.935382; Mean validation loss 0.094716; Mean validation F1 0.934535; Learning rate 0.000916;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.087293; Mean training F1 0.936251; Mean validation loss 0.089282; Mean validation F1 0.937287; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.086683; Mean training F1 0.936573; Mean validation loss 0.103270; Mean validation F1 0.937136; Learning rate 0.000902;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.086083; Mean training F1 0.936981; Mean validation loss 0.082036; Mean validation F1 0.937396; Learning rate 0.000895;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.086671; Mean training F1 0.936455; Mean validation loss 0.133724; Mean validation F1 0.937137; Learning rate 0.000887;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.086393; Mean training F1 0.936641; Mean validation loss 0.093681; Mean validation F1 0.937578; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.086077; Mean training F1 0.936954; Mean validation loss 0.118919; Mean validation F1 0.935445; Learning rate 0.000871;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.086105; Mean training F1 0.936753; Mean validation loss 0.089956; Mean validation F1 0.936093; Learning rate 0.000863;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.086156; Mean training F1 0.936572; Mean validation loss 0.071516; Mean validation F1 0.937371; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.085421; Mean training F1 0.936888; Mean validation loss 0.094524; Mean validation F1 0.937767; Learning rate 0.000846;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.085793; Mean training F1 0.937203; Mean validation loss 0.054811; Mean validation F1 0.936983; Learning rate 0.000837;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.085222; Mean training F1 0.937113; Mean validation loss 0.091901; Mean validation F1 0.937768; Learning rate 0.000828;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.085248; Mean training F1 0.936852; Mean validation loss 0.086418; Mean validation F1 0.937429; Learning rate 0.000818;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.085510; Mean training F1 0.936916; Mean validation loss 0.074836; Mean validation F1 0.936219; Learning rate 0.000809;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.085875; Mean training F1 0.936757; Mean validation loss 0.075060; Mean validation F1 0.935864; Learning rate 0.000799;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.085455; Mean training F1 0.936805; Mean validation loss 0.086508; Mean validation F1 0.936872; Learning rate 0.000789;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.086150; Mean training F1 0.936683; Mean validation loss 0.078186; Mean validation F1 0.936462; Learning rate 0.000779;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.088843; Mean training F1 0.935430; Mean validation loss 0.081443; Mean validation F1 0.936969; Learning rate 0.000769;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.084803; Mean training F1 0.937206; Mean validation loss 0.071457; Mean validation F1 0.937626; Learning rate 0.000759;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.084138; Mean training F1 0.937462; Mean validation loss 0.063487; Mean validation F1 0.937010; Learning rate 0.000748;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.084281; Mean training F1 0.937473; Mean validation loss 0.087083; Mean validation F1 0.937696; Learning rate 0.000737;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.084217; Mean training F1 0.937463; Mean validation loss 0.094501; Mean validation F1 0.938263; Learning rate 0.000726;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.084782; Mean training F1 0.937365; Mean validation loss 0.081033; Mean validation F1 0.937785; Learning rate 0.000716;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.084201; Mean training F1 0.937417; Mean validation loss 0.086651; Mean validation F1 0.938073; Learning rate 0.000704;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.083990; Mean training F1 0.937527; Mean validation loss 0.088132; Mean validation F1 0.937953; Learning rate 0.000693;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.083864; Mean training F1 0.937797; Mean validation loss 0.074606; Mean validation F1 0.938029; Learning rate 0.000682;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.083647; Mean training F1 0.937555; Mean validation loss 0.079231; Mean validation F1 0.936441; Learning rate 0.000670;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.083917; Mean training F1 0.937602; Mean validation loss 0.070701; Mean validation F1 0.936850; Learning rate 0.000659;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.083181; Mean training F1 0.937928; Mean validation loss 0.091519; Mean validation F1 0.937937; Learning rate 0.000647;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.083071; Mean training F1 0.938128; Mean validation loss 0.076813; Mean validation F1 0.937960; Learning rate 0.000635;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.083140; Mean training F1 0.938022; Mean validation loss 0.101405; Mean validation F1 0.937635; Learning rate 0.000624;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.083254; Mean training F1 0.937795; Mean validation loss 0.098971; Mean validation F1 0.937632; Learning rate 0.000612;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.083367; Mean training F1 0.937781; Mean validation loss 0.071385; Mean validation F1 0.937751; Learning rate 0.000600;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.083214; Mean training F1 0.937705; Mean validation loss 0.086903; Mean validation F1 0.937086; Learning rate 0.000588;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.083866; Mean training F1 0.937292; Mean validation loss 0.070961; Mean validation F1 0.937368; Learning rate 0.000576;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.082599; Mean training F1 0.938200; Mean validation loss 0.091527; Mean validation F1 0.938285; Learning rate 0.000564;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.082735; Mean training F1 0.938065; Mean validation loss 0.091807; Mean validation F1 0.938137; Learning rate 0.000552;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.118321; Mean training F1 0.921427; Mean validation loss 0.144092; Mean validation F1 0.917301; Learning rate 0.000539;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.089958; Mean training F1 0.934490; Mean validation loss 0.095533; Mean validation F1 0.937170; Learning rate 0.000527;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.085019; Mean training F1 0.937293; Mean validation loss 0.084987; Mean validation F1 0.937122; Learning rate 0.000515;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.084307; Mean training F1 0.937535; Mean validation loss 0.097336; Mean validation F1 0.936656; Learning rate 0.000503;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.084050; Mean training F1 0.937621; Mean validation loss 0.071683; Mean validation F1 0.937846; Learning rate 0.000491;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.083360; Mean training F1 0.937929; Mean validation loss 0.095377; Mean validation F1 0.937337; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.083063; Mean training F1 0.938015; Mean validation loss 0.080454; Mean validation F1 0.937362; Learning rate 0.000466;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.083027; Mean training F1 0.937938; Mean validation loss 0.071231; Mean validation F1 0.938059; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.082864; Mean training F1 0.938153; Mean validation loss 0.086831; Mean validation F1 0.937819; Learning rate 0.000442;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.083238; Mean training F1 0.937951; Mean validation loss 0.079439; Mean validation F1 0.937907; Learning rate 0.000430;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.082955; Mean training F1 0.938035; Mean validation loss 0.097848; Mean validation F1 0.937821; Learning rate 0.000418;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.082483; Mean training F1 0.938473; Mean validation loss 0.061984; Mean validation F1 0.937759; Learning rate 0.000406;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.082427; Mean training F1 0.938200; Mean validation loss 0.106474; Mean validation F1 0.938111; Learning rate 0.000394;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.082332; Mean training F1 0.938340; Mean validation loss 0.076505; Mean validation F1 0.937205; Learning rate 0.000382;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.082371; Mean training F1 0.938340; Mean validation loss 0.073139; Mean validation F1 0.938051; Learning rate 0.000370;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.082216; Mean training F1 0.938392; Mean validation loss 0.087362; Mean validation F1 0.938171; Learning rate 0.000358;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.082196; Mean training F1 0.938442; Mean validation loss 0.111005; Mean validation F1 0.938143; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.082392; Mean training F1 0.938378; Mean validation loss 0.069306; Mean validation F1 0.937249; Learning rate 0.000335;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.082529; Mean training F1 0.938258; Mean validation loss 0.096177; Mean validation F1 0.937911; Learning rate 0.000324;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.082218; Mean training F1 0.938338; Mean validation loss 0.094791; Mean validation F1 0.937994; Learning rate 0.000312;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.081944; Mean training F1 0.938531; Mean validation loss 0.074489; Mean validation F1 0.937973; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.081923; Mean training F1 0.938524; Mean validation loss 0.073571; Mean validation F1 0.937843; Learning rate 0.000290;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.081984; Mean training F1 0.938581; Mean validation loss 0.089063; Mean validation F1 0.937667; Learning rate 0.000279;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.081736; Mean training F1 0.938579; Mean validation loss 0.059787; Mean validation F1 0.938199; Learning rate 0.000268;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.081596; Mean training F1 0.938753; Mean validation loss 0.063342; Mean validation F1 0.936521; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.081683; Mean training F1 0.938478; Mean validation loss 0.083702; Mean validation F1 0.938068; Learning rate 0.000247;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.081606; Mean training F1 0.938561; Mean validation loss 0.095003; Mean validation F1 0.937888; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.081424; Mean training F1 0.938717; Mean validation loss 0.081239; Mean validation F1 0.938097; Learning rate 0.000226;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.081248; Mean training F1 0.938792; Mean validation loss 0.070963; Mean validation F1 0.938085; Learning rate 0.000216;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.081280; Mean training F1 0.938847; Mean validation loss 0.090335; Mean validation F1 0.938238; Learning rate 0.000206;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.081206; Mean training F1 0.938887; Mean validation loss 0.106811; Mean validation F1 0.938371; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.081236; Mean training F1 0.938938; Mean validation loss 0.101200; Mean validation F1 0.938093; Learning rate 0.000187;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.081148; Mean training F1 0.938869; Mean validation loss 0.096981; Mean validation F1 0.938333; Learning rate 0.000178;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.081067; Mean training F1 0.939005; Mean validation loss 0.086261; Mean validation F1 0.938403; Learning rate 0.000169;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.080978; Mean training F1 0.938989; Mean validation loss 0.072045; Mean validation F1 0.938355; Learning rate 0.000160;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.080927; Mean training F1 0.938913; Mean validation loss 0.073274; Mean validation F1 0.938427; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.080856; Mean training F1 0.939080; Mean validation loss 0.091510; Mean validation F1 0.938478; Learning rate 0.000142;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.080807; Mean training F1 0.938968; Mean validation loss 0.061466; Mean validation F1 0.938364; Learning rate 0.000134;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.080774; Mean training F1 0.939173; Mean validation loss 0.104718; Mean validation F1 0.938555; Learning rate 0.000126;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.080784; Mean training F1 0.939063; Mean validation loss 0.052569; Mean validation F1 0.938693; Learning rate 0.000118;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.080747; Mean training F1 0.939154; Mean validation loss 0.066892; Mean validation F1 0.938277; Learning rate 0.000111;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.080668; Mean training F1 0.939225; Mean validation loss 0.063731; Mean validation F1 0.937790; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.080583; Mean training F1 0.939202; Mean validation loss 0.084021; Mean validation F1 0.938468; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.080550; Mean training F1 0.939131; Mean validation loss 0.094927; Mean validation F1 0.938078; Learning rate 0.000089;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.080560; Mean training F1 0.939220; Mean validation loss 0.072872; Mean validation F1 0.938342; Learning rate 0.000082;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.080448; Mean training F1 0.939251; Mean validation loss 0.091769; Mean validation F1 0.938498; Learning rate 0.000076;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.080450; Mean training F1 0.939204; Mean validation loss 0.073625; Mean validation F1 0.938370; Learning rate 0.000070;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.080368; Mean training F1 0.939290; Mean validation loss 0.087469; Mean validation F1 0.938439; Learning rate 0.000064;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.080364; Mean training F1 0.939324; Mean validation loss 0.089798; Mean validation F1 0.938541; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.080315; Mean training F1 0.939310; Mean validation loss 0.071711; Mean validation F1 0.938415; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.080307; Mean training F1 0.939305; Mean validation loss 0.075494; Mean validation F1 0.938660; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.080245; Mean training F1 0.939381; Mean validation loss 0.083576; Mean validation F1 0.938489; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.080217; Mean training F1 0.939339; Mean validation loss 0.081773; Mean validation F1 0.938378; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.080192; Mean training F1 0.939304; Mean validation loss 0.077922; Mean validation F1 0.938502; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.080182; Mean training F1 0.939412; Mean validation loss 0.060507; Mean validation F1 0.938562; Learning rate 0.000030;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.080150; Mean training F1 0.939362; Mean validation loss 0.082808; Mean validation F1 0.938505; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.080120; Mean training F1 0.939365; Mean validation loss 0.095913; Mean validation F1 0.938610; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.080086; Mean training F1 0.939450; Mean validation loss 0.077870; Mean validation F1 0.938638; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.080084; Mean training F1 0.939439; Mean validation loss 0.081381; Mean validation F1 0.938525; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.080062; Mean training F1 0.939452; Mean validation loss 0.083020; Mean validation F1 0.938621; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.080049; Mean training F1 0.939475; Mean validation loss 0.081606; Mean validation F1 0.938494; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.080034; Mean training F1 0.939422; Mean validation loss 0.081954; Mean validation F1 0.938532; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.080027; Mean training F1 0.939462; Mean validation loss 0.055980; Mean validation F1 0.938578; Learning rate 0.000009;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.080007; Mean training F1 0.939489; Mean validation loss 0.093474; Mean validation F1 0.938522; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.080004; Mean training F1 0.939440; Mean validation loss 0.067801; Mean validation F1 0.938548; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.079993; Mean training F1 0.939452; Mean validation loss 0.096867; Mean validation F1 0.938667; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.079987; Mean training F1 0.939493; Mean validation loss 0.083423; Mean validation F1 0.938502; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.079983; Mean training F1 0.939499; Mean validation loss 0.053960; Mean validation F1 0.938545; Learning rate 0.000005;\n",
    "################################################################\n",
    "Training/validation for fold 5/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.800666; Mean training F1 0.539919; Mean validation loss 0.441460; Mean validation F1 0.749961; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.242457; Mean training F1 0.865187; Mean validation loss 0.149004; Mean validation F1 0.898462; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.147619; Mean training F1 0.910663; Mean validation loss 0.156606; Mean validation F1 0.923410; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.107695; Mean training F1 0.926423; Mean validation loss 0.088204; Mean validation F1 0.935058; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.094696; Mean training F1 0.932787; Mean validation loss 0.106490; Mean validation F1 0.935563; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.091910; Mean training F1 0.934070; Mean validation loss 0.098614; Mean validation F1 0.936551; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.090598; Mean training F1 0.934644; Mean validation loss 0.088358; Mean validation F1 0.932910; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.090803; Mean training F1 0.934400; Mean validation loss 0.088421; Mean validation F1 0.936596; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.094796; Mean training F1 0.931325; Mean validation loss 0.085546; Mean validation F1 0.934637; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.094964; Mean training F1 0.932313; Mean validation loss 0.088620; Mean validation F1 0.937390; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.089669; Mean training F1 0.934573; Mean validation loss 0.095362; Mean validation F1 0.936639; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.087534; Mean training F1 0.936169; Mean validation loss 0.111584; Mean validation F1 0.937267; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.087728; Mean training F1 0.935658; Mean validation loss 0.093518; Mean validation F1 0.936335; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.087122; Mean training F1 0.936086; Mean validation loss 0.085042; Mean validation F1 0.937652; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.087718; Mean training F1 0.935709; Mean validation loss 0.087377; Mean validation F1 0.935964; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.087056; Mean training F1 0.936165; Mean validation loss 0.094741; Mean validation F1 0.936846; Learning rate 0.000962;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.087069; Mean training F1 0.935973; Mean validation loss 0.072833; Mean validation F1 0.937260; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.086320; Mean training F1 0.936589; Mean validation loss 0.109609; Mean validation F1 0.937285; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.086239; Mean training F1 0.936449; Mean validation loss 0.087942; Mean validation F1 0.936519; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.085851; Mean training F1 0.936675; Mean validation loss 0.091217; Mean validation F1 0.937763; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.090315; Mean training F1 0.933722; Mean validation loss 0.079394; Mean validation F1 0.936981; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.087466; Mean training F1 0.935580; Mean validation loss 0.087572; Mean validation F1 0.936576; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.088804; Mean training F1 0.935224; Mean validation loss 0.091937; Mean validation F1 0.937709; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.085841; Mean training F1 0.936317; Mean validation loss 0.061457; Mean validation F1 0.937183; Learning rate 0.000916;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.085307; Mean training F1 0.936696; Mean validation loss 0.095391; Mean validation F1 0.937607; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.085041; Mean training F1 0.936983; Mean validation loss 0.080232; Mean validation F1 0.933120; Learning rate 0.000902;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.084898; Mean training F1 0.936734; Mean validation loss 0.089153; Mean validation F1 0.937592; Learning rate 0.000895;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.085313; Mean training F1 0.936869; Mean validation loss 0.090342; Mean validation F1 0.938026; Learning rate 0.000887;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.084781; Mean training F1 0.937134; Mean validation loss 0.080996; Mean validation F1 0.936983; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.084538; Mean training F1 0.937149; Mean validation loss 0.101508; Mean validation F1 0.937988; Learning rate 0.000871;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.091809; Mean training F1 0.933192; Mean validation loss 0.444787; Mean validation F1 0.890981; Learning rate 0.000863;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.100334; Mean training F1 0.926624; Mean validation loss 0.073376; Mean validation F1 0.937410; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.086294; Mean training F1 0.936685; Mean validation loss 0.076455; Mean validation F1 0.937786; Learning rate 0.000846;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.085221; Mean training F1 0.937193; Mean validation loss 0.066927; Mean validation F1 0.937828; Learning rate 0.000837;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.084849; Mean training F1 0.937336; Mean validation loss 0.094990; Mean validation F1 0.937691; Learning rate 0.000828;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.085021; Mean training F1 0.937364; Mean validation loss 0.071554; Mean validation F1 0.938177; Learning rate 0.000818;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.084464; Mean training F1 0.937282; Mean validation loss 0.066701; Mean validation F1 0.938052; Learning rate 0.000809;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.083884; Mean training F1 0.937703; Mean validation loss 0.075169; Mean validation F1 0.937873; Learning rate 0.000799;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.084101; Mean training F1 0.937687; Mean validation loss 0.070433; Mean validation F1 0.937982; Learning rate 0.000789;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.084156; Mean training F1 0.937626; Mean validation loss 0.076235; Mean validation F1 0.938665; Learning rate 0.000779;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.083714; Mean training F1 0.937820; Mean validation loss 0.065782; Mean validation F1 0.937740; Learning rate 0.000769;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.084361; Mean training F1 0.937542; Mean validation loss 0.103308; Mean validation F1 0.937737; Learning rate 0.000759;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.083782; Mean training F1 0.937652; Mean validation loss 0.082070; Mean validation F1 0.938528; Learning rate 0.000748;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.083817; Mean training F1 0.937471; Mean validation loss 0.085558; Mean validation F1 0.938108; Learning rate 0.000737;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.083463; Mean training F1 0.937832; Mean validation loss 0.104887; Mean validation F1 0.938595; Learning rate 0.000726;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.083405; Mean training F1 0.937849; Mean validation loss 0.077405; Mean validation F1 0.937998; Learning rate 0.000716;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.083701; Mean training F1 0.937769; Mean validation loss 0.112718; Mean validation F1 0.938270; Learning rate 0.000704;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.086822; Mean training F1 0.936230; Mean validation loss 0.124869; Mean validation F1 0.901661; Learning rate 0.000693;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.094455; Mean training F1 0.931987; Mean validation loss 0.081558; Mean validation F1 0.937465; Learning rate 0.000682;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.084030; Mean training F1 0.937467; Mean validation loss 0.065565; Mean validation F1 0.938123; Learning rate 0.000670;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.083822; Mean training F1 0.937358; Mean validation loss 0.095763; Mean validation F1 0.938375; Learning rate 0.000659;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.083363; Mean training F1 0.937862; Mean validation loss 0.090735; Mean validation F1 0.937646; Learning rate 0.000647;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.083196; Mean training F1 0.937850; Mean validation loss 0.101004; Mean validation F1 0.938582; Learning rate 0.000635;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.083327; Mean training F1 0.938081; Mean validation loss 0.083360; Mean validation F1 0.937954; Learning rate 0.000624;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.082861; Mean training F1 0.938051; Mean validation loss 0.078285; Mean validation F1 0.938389; Learning rate 0.000612;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.082954; Mean training F1 0.938004; Mean validation loss 0.087234; Mean validation F1 0.938199; Learning rate 0.000600;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.082645; Mean training F1 0.938282; Mean validation loss 0.073972; Mean validation F1 0.938248; Learning rate 0.000588;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.082917; Mean training F1 0.938024; Mean validation loss 0.099296; Mean validation F1 0.938681; Learning rate 0.000576;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.082571; Mean training F1 0.938425; Mean validation loss 0.068395; Mean validation F1 0.938322; Learning rate 0.000564;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.082558; Mean training F1 0.938295; Mean validation loss 0.086438; Mean validation F1 0.936454; Learning rate 0.000552;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.082456; Mean training F1 0.938294; Mean validation loss 0.089247; Mean validation F1 0.938424; Learning rate 0.000539;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.082484; Mean training F1 0.938334; Mean validation loss 0.096332; Mean validation F1 0.938654; Learning rate 0.000527;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.082670; Mean training F1 0.938155; Mean validation loss 0.083970; Mean validation F1 0.938625; Learning rate 0.000515;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.082132; Mean training F1 0.938491; Mean validation loss 0.108557; Mean validation F1 0.938531; Learning rate 0.000503;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.082002; Mean training F1 0.938525; Mean validation loss 0.090393; Mean validation F1 0.937908; Learning rate 0.000491;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.082031; Mean training F1 0.938628; Mean validation loss 0.085440; Mean validation F1 0.938845; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.081990; Mean training F1 0.938601; Mean validation loss 0.083179; Mean validation F1 0.938213; Learning rate 0.000466;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.081699; Mean training F1 0.938600; Mean validation loss 0.084862; Mean validation F1 0.937477; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.081727; Mean training F1 0.938637; Mean validation loss 0.050329; Mean validation F1 0.938785; Learning rate 0.000442;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.081671; Mean training F1 0.938613; Mean validation loss 0.109756; Mean validation F1 0.938583; Learning rate 0.000430;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.081507; Mean training F1 0.938730; Mean validation loss 0.070797; Mean validation F1 0.938522; Learning rate 0.000418;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.082030; Mean training F1 0.938426; Mean validation loss 0.072192; Mean validation F1 0.938361; Learning rate 0.000406;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.081566; Mean training F1 0.938712; Mean validation loss 0.094514; Mean validation F1 0.938619; Learning rate 0.000394;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.081505; Mean training F1 0.938834; Mean validation loss 0.071178; Mean validation F1 0.938367; Learning rate 0.000382;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.081445; Mean training F1 0.938769; Mean validation loss 0.086237; Mean validation F1 0.938506; Learning rate 0.000370;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.081050; Mean training F1 0.939085; Mean validation loss 0.081798; Mean validation F1 0.938680; Learning rate 0.000358;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.081100; Mean training F1 0.938963; Mean validation loss 0.097836; Mean validation F1 0.938572; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.081025; Mean training F1 0.939043; Mean validation loss 0.085028; Mean validation F1 0.938775; Learning rate 0.000335;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.081227; Mean training F1 0.938854; Mean validation loss 0.092018; Mean validation F1 0.938593; Learning rate 0.000324;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.081164; Mean training F1 0.938882; Mean validation loss 0.084605; Mean validation F1 0.938297; Learning rate 0.000312;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.081030; Mean training F1 0.939138; Mean validation loss 0.084941; Mean validation F1 0.938961; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.080751; Mean training F1 0.939075; Mean validation loss 0.080277; Mean validation F1 0.938678; Learning rate 0.000290;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.080858; Mean training F1 0.939106; Mean validation loss 0.054126; Mean validation F1 0.938584; Learning rate 0.000279;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.080594; Mean training F1 0.939203; Mean validation loss 0.080845; Mean validation F1 0.938682; Learning rate 0.000268;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.080648; Mean training F1 0.939233; Mean validation loss 0.066578; Mean validation F1 0.938903; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.080460; Mean training F1 0.939168; Mean validation loss 0.103303; Mean validation F1 0.938728; Learning rate 0.000247;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.080500; Mean training F1 0.939210; Mean validation loss 0.087583; Mean validation F1 0.938774; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.080292; Mean training F1 0.939467; Mean validation loss 0.085557; Mean validation F1 0.938995; Learning rate 0.000226;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.080504; Mean training F1 0.939185; Mean validation loss 0.080491; Mean validation F1 0.938974; Learning rate 0.000216;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.080219; Mean training F1 0.939384; Mean validation loss 0.085220; Mean validation F1 0.938491; Learning rate 0.000206;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.080182; Mean training F1 0.939460; Mean validation loss 0.095097; Mean validation F1 0.938722; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.080174; Mean training F1 0.939425; Mean validation loss 0.078186; Mean validation F1 0.939064; Learning rate 0.000187;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.080018; Mean training F1 0.939569; Mean validation loss 0.078594; Mean validation F1 0.938785; Learning rate 0.000178;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.080058; Mean training F1 0.939463; Mean validation loss 0.095836; Mean validation F1 0.939022; Learning rate 0.000169;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.079965; Mean training F1 0.939506; Mean validation loss 0.071396; Mean validation F1 0.939070; Learning rate 0.000160;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.079912; Mean training F1 0.939562; Mean validation loss 0.084671; Mean validation F1 0.939138; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.079858; Mean training F1 0.939589; Mean validation loss 0.080396; Mean validation F1 0.939175; Learning rate 0.000142;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.079773; Mean training F1 0.939616; Mean validation loss 0.098014; Mean validation F1 0.939077; Learning rate 0.000134;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.079690; Mean training F1 0.939781; Mean validation loss 0.081238; Mean validation F1 0.938944; Learning rate 0.000126;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.079669; Mean training F1 0.939643; Mean validation loss 0.065965; Mean validation F1 0.939069; Learning rate 0.000118;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.079711; Mean training F1 0.939634; Mean validation loss 0.084672; Mean validation F1 0.938753; Learning rate 0.000111;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.079618; Mean training F1 0.939716; Mean validation loss 0.087913; Mean validation F1 0.939142; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.079569; Mean training F1 0.939718; Mean validation loss 0.102747; Mean validation F1 0.939056; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.079532; Mean training F1 0.939765; Mean validation loss 0.084849; Mean validation F1 0.939071; Learning rate 0.000089;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.079470; Mean training F1 0.939753; Mean validation loss 0.073729; Mean validation F1 0.939126; Learning rate 0.000082;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.079455; Mean training F1 0.939771; Mean validation loss 0.069343; Mean validation F1 0.938977; Learning rate 0.000076;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.079372; Mean training F1 0.939901; Mean validation loss 0.070471; Mean validation F1 0.939118; Learning rate 0.000070;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.079362; Mean training F1 0.939878; Mean validation loss 0.083781; Mean validation F1 0.938986; Learning rate 0.000064;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.079276; Mean training F1 0.939930; Mean validation loss 0.069192; Mean validation F1 0.938947; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.079259; Mean training F1 0.939794; Mean validation loss 0.090251; Mean validation F1 0.938943; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.079232; Mean training F1 0.939924; Mean validation loss 0.080913; Mean validation F1 0.938968; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.079191; Mean training F1 0.939980; Mean validation loss 0.075929; Mean validation F1 0.938860; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.079171; Mean training F1 0.939958; Mean validation loss 0.081285; Mean validation F1 0.939020; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.079168; Mean training F1 0.939932; Mean validation loss 0.059534; Mean validation F1 0.939110; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.079114; Mean training F1 0.940005; Mean validation loss 0.085822; Mean validation F1 0.939198; Learning rate 0.000030;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.079082; Mean training F1 0.940022; Mean validation loss 0.073852; Mean validation F1 0.939027; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.079067; Mean training F1 0.940027; Mean validation loss 0.104835; Mean validation F1 0.939053; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.079051; Mean training F1 0.940022; Mean validation loss 0.070871; Mean validation F1 0.939105; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.079028; Mean training F1 0.940034; Mean validation loss 0.090530; Mean validation F1 0.939121; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.079014; Mean training F1 0.940079; Mean validation loss 0.090832; Mean validation F1 0.939069; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.078993; Mean training F1 0.940084; Mean validation loss 0.065637; Mean validation F1 0.939079; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.078987; Mean training F1 0.940072; Mean validation loss 0.064904; Mean validation F1 0.939108; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.078968; Mean training F1 0.940106; Mean validation loss 0.069060; Mean validation F1 0.939159; Learning rate 0.000009;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.078959; Mean training F1 0.940131; Mean validation loss 0.080383; Mean validation F1 0.938984; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.078955; Mean training F1 0.940045; Mean validation loss 0.111712; Mean validation F1 0.939153; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.078942; Mean training F1 0.940079; Mean validation loss 0.075517; Mean validation F1 0.939111; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.078942; Mean training F1 0.940161; Mean validation loss 0.102041; Mean validation F1 0.939145; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.078935; Mean training F1 0.940103; Mean validation loss 0.064622; Mean validation F1 0.939114; Learning rate 0.000005;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-------- fold 0 --------\n",
    "model validation loss: 0.062; validation f1: 0.940;\n",
    "-------- fold 1 --------\n",
    "model validation loss: 0.083; validation f1: 0.938;\n",
    "-------- fold 2 --------\n",
    "model validation loss: 0.047; validation f1: 0.937;\n",
    "-------- fold 3 --------\n",
    "model validation loss: 0.087; validation f1: 0.939;\n",
    "-------- fold 4 --------\n",
    "model validation loss: 0.086; validation f1: 0.939;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "################################################################\n",
    "Training/validation for fold 1/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.790974; Mean training F1 0.552036; Mean validation loss 0.475732; Mean validation F1 0.743318; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.288238; Mean training F1 0.848420; Mean validation loss 0.189631; Mean validation F1 0.863622; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.185838; Mean training F1 0.895089; Mean validation loss 0.203127; Mean validation F1 0.905959; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.160208; Mean training F1 0.905703; Mean validation loss 0.128684; Mean validation F1 0.911402; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.150047; Mean training F1 0.909623; Mean validation loss 0.159521; Mean validation F1 0.916034; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.138423; Mean training F1 0.915225; Mean validation loss 0.137338; Mean validation F1 0.919525; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.131104; Mean training F1 0.917707; Mean validation loss 0.093701; Mean validation F1 0.930165; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.104862; Mean training F1 0.928181; Mean validation loss 0.078590; Mean validation F1 0.934902; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.093353; Mean training F1 0.933771; Mean validation loss 0.099690; Mean validation F1 0.935687; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.090716; Mean training F1 0.935139; Mean validation loss 0.078276; Mean validation F1 0.936098; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.089575; Mean training F1 0.935332; Mean validation loss 0.080951; Mean validation F1 0.936089; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.100413; Mean training F1 0.929191; Mean validation loss 0.090773; Mean validation F1 0.936123; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.088652; Mean training F1 0.935687; Mean validation loss 0.077537; Mean validation F1 0.935122; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.087754; Mean training F1 0.935679; Mean validation loss 0.075803; Mean validation F1 0.937060; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.086570; Mean training F1 0.936136; Mean validation loss 0.076464; Mean validation F1 0.936978; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.086015; Mean training F1 0.936387; Mean validation loss 0.091432; Mean validation F1 0.937769; Learning rate 0.000962;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.085408; Mean training F1 0.936688; Mean validation loss 0.058736; Mean validation F1 0.937249; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.085364; Mean training F1 0.936607; Mean validation loss 0.076303; Mean validation F1 0.936826; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.085108; Mean training F1 0.936848; Mean validation loss 0.125284; Mean validation F1 0.936981; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.085100; Mean training F1 0.936666; Mean validation loss 0.086599; Mean validation F1 0.938042; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.085208; Mean training F1 0.936591; Mean validation loss 0.078129; Mean validation F1 0.937001; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.084473; Mean training F1 0.936908; Mean validation loss 0.073198; Mean validation F1 0.936991; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.084651; Mean training F1 0.936578; Mean validation loss 0.085481; Mean validation F1 0.937909; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.083783; Mean training F1 0.937321; Mean validation loss 0.079518; Mean validation F1 0.937959; Learning rate 0.000916;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.084007; Mean training F1 0.936970; Mean validation loss 0.059468; Mean validation F1 0.937541; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.084285; Mean training F1 0.936827; Mean validation loss 0.092333; Mean validation F1 0.938387; Learning rate 0.000902;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.083713; Mean training F1 0.937261; Mean validation loss 0.089081; Mean validation F1 0.938006; Learning rate 0.000895;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.084313; Mean training F1 0.936738; Mean validation loss 0.073484; Mean validation F1 0.937784; Learning rate 0.000887;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.083577; Mean training F1 0.937382; Mean validation loss 0.081205; Mean validation F1 0.938022; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.084010; Mean training F1 0.936956; Mean validation loss 0.078407; Mean validation F1 0.938485; Learning rate 0.000871;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.083429; Mean training F1 0.937336; Mean validation loss 0.083986; Mean validation F1 0.937751; Learning rate 0.000863;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.083029; Mean training F1 0.937480; Mean validation loss 0.092426; Mean validation F1 0.938633; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.083251; Mean training F1 0.937138; Mean validation loss 0.069679; Mean validation F1 0.938175; Learning rate 0.000846;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.083433; Mean training F1 0.937282; Mean validation loss 0.084280; Mean validation F1 0.938510; Learning rate 0.000837;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.082939; Mean training F1 0.937645; Mean validation loss 0.077357; Mean validation F1 0.938181; Learning rate 0.000828;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.157145; Mean training F1 0.910482; Mean validation loss 0.156865; Mean validation F1 0.930318; Learning rate 0.000818;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.097319; Mean training F1 0.933324; Mean validation loss 0.073108; Mean validation F1 0.935287; Learning rate 0.000809;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.089804; Mean training F1 0.935583; Mean validation loss 0.065689; Mean validation F1 0.936455; Learning rate 0.000799;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.088203; Mean training F1 0.935869; Mean validation loss 0.074468; Mean validation F1 0.936707; Learning rate 0.000789;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.087151; Mean training F1 0.936349; Mean validation loss 0.103059; Mean validation F1 0.937438; Learning rate 0.000779;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.086158; Mean training F1 0.936716; Mean validation loss 0.099343; Mean validation F1 0.937569; Learning rate 0.000769;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.085637; Mean training F1 0.936881; Mean validation loss 0.100475; Mean validation F1 0.936942; Learning rate 0.000759;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.085038; Mean training F1 0.937198; Mean validation loss 0.082491; Mean validation F1 0.937717; Learning rate 0.000748;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.084925; Mean training F1 0.937021; Mean validation loss 0.112559; Mean validation F1 0.937098; Learning rate 0.000737;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.084549; Mean training F1 0.937049; Mean validation loss 0.057043; Mean validation F1 0.937738; Learning rate 0.000726;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.085937; Mean training F1 0.936703; Mean validation loss 0.081464; Mean validation F1 0.936797; Learning rate 0.000716;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.085246; Mean training F1 0.936889; Mean validation loss 0.088227; Mean validation F1 0.938186; Learning rate 0.000704;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.084522; Mean training F1 0.936896; Mean validation loss 0.089530; Mean validation F1 0.937574; Learning rate 0.000693;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.084317; Mean training F1 0.937221; Mean validation loss 0.098584; Mean validation F1 0.938028; Learning rate 0.000682;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.083200; Mean training F1 0.937639; Mean validation loss 0.079703; Mean validation F1 0.937410; Learning rate 0.000670;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.083063; Mean training F1 0.937690; Mean validation loss 0.064053; Mean validation F1 0.938123; Learning rate 0.000659;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.083382; Mean training F1 0.937585; Mean validation loss 0.082444; Mean validation F1 0.937205; Learning rate 0.000647;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.083138; Mean training F1 0.937608; Mean validation loss 0.080089; Mean validation F1 0.938211; Learning rate 0.000635;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.082893; Mean training F1 0.937882; Mean validation loss 0.084773; Mean validation F1 0.938577; Learning rate 0.000624;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.082629; Mean training F1 0.937792; Mean validation loss 0.076399; Mean validation F1 0.938358; Learning rate 0.000612;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.083057; Mean training F1 0.937581; Mean validation loss 0.082890; Mean validation F1 0.937522; Learning rate 0.000600;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.082694; Mean training F1 0.937906; Mean validation loss 0.069345; Mean validation F1 0.937951; Learning rate 0.000588;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.082335; Mean training F1 0.937972; Mean validation loss 0.096385; Mean validation F1 0.938135; Learning rate 0.000576;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.082159; Mean training F1 0.938048; Mean validation loss 0.098945; Mean validation F1 0.938578; Learning rate 0.000564;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.082083; Mean training F1 0.937941; Mean validation loss 0.069061; Mean validation F1 0.938679; Learning rate 0.000552;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.082094; Mean training F1 0.938031; Mean validation loss 0.096147; Mean validation F1 0.938743; Learning rate 0.000539;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.082051; Mean training F1 0.937918; Mean validation loss 0.105581; Mean validation F1 0.938194; Learning rate 0.000527;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.082095; Mean training F1 0.937939; Mean validation loss 0.082312; Mean validation F1 0.938778; Learning rate 0.000515;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.081834; Mean training F1 0.938120; Mean validation loss 0.080957; Mean validation F1 0.938836; Learning rate 0.000503;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.081794; Mean training F1 0.938322; Mean validation loss 0.083741; Mean validation F1 0.938650; Learning rate 0.000491;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.081734; Mean training F1 0.938314; Mean validation loss 0.082666; Mean validation F1 0.938427; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.081507; Mean training F1 0.938189; Mean validation loss 0.065031; Mean validation F1 0.938126; Learning rate 0.000466;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.081652; Mean training F1 0.938307; Mean validation loss 0.071566; Mean validation F1 0.938370; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.081382; Mean training F1 0.938241; Mean validation loss 0.059594; Mean validation F1 0.938709; Learning rate 0.000442;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.081553; Mean training F1 0.938340; Mean validation loss 0.097420; Mean validation F1 0.939147; Learning rate 0.000430;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.081454; Mean training F1 0.938253; Mean validation loss 0.106114; Mean validation F1 0.939039; Learning rate 0.000418;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.081321; Mean training F1 0.938437; Mean validation loss 0.109089; Mean validation F1 0.938828; Learning rate 0.000406;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.081317; Mean training F1 0.938299; Mean validation loss 0.075682; Mean validation F1 0.939002; Learning rate 0.000394;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.081106; Mean training F1 0.938444; Mean validation loss 0.093536; Mean validation F1 0.939145; Learning rate 0.000382;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.080948; Mean training F1 0.938509; Mean validation loss 0.082007; Mean validation F1 0.938609; Learning rate 0.000370;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.081194; Mean training F1 0.938534; Mean validation loss 0.104779; Mean validation F1 0.938461; Learning rate 0.000358;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.080940; Mean training F1 0.938518; Mean validation loss 0.068479; Mean validation F1 0.939211; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.080775; Mean training F1 0.938687; Mean validation loss 0.083460; Mean validation F1 0.938875; Learning rate 0.000335;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.080928; Mean training F1 0.938582; Mean validation loss 0.077479; Mean validation F1 0.939189; Learning rate 0.000324;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.080644; Mean training F1 0.938735; Mean validation loss 0.057270; Mean validation F1 0.936846; Learning rate 0.000312;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.080579; Mean training F1 0.938723; Mean validation loss 0.097347; Mean validation F1 0.939105; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.080519; Mean training F1 0.938820; Mean validation loss 0.093306; Mean validation F1 0.938593; Learning rate 0.000290;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.080359; Mean training F1 0.938853; Mean validation loss 0.077248; Mean validation F1 0.938678; Learning rate 0.000279;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.080317; Mean training F1 0.938861; Mean validation loss 0.070110; Mean validation F1 0.938984; Learning rate 0.000268;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.080353; Mean training F1 0.938814; Mean validation loss 0.063422; Mean validation F1 0.939010; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.080386; Mean training F1 0.938877; Mean validation loss 0.064823; Mean validation F1 0.938450; Learning rate 0.000247;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.080188; Mean training F1 0.938895; Mean validation loss 0.083217; Mean validation F1 0.939064; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.080112; Mean training F1 0.938940; Mean validation loss 0.080490; Mean validation F1 0.939320; Learning rate 0.000226;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.080278; Mean training F1 0.938816; Mean validation loss 0.090686; Mean validation F1 0.938987; Learning rate 0.000216;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.080021; Mean training F1 0.939088; Mean validation loss 0.080402; Mean validation F1 0.939180; Learning rate 0.000206;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.079974; Mean training F1 0.939107; Mean validation loss 0.073504; Mean validation F1 0.938250; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.080008; Mean training F1 0.939065; Mean validation loss 0.063598; Mean validation F1 0.939149; Learning rate 0.000187;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.079875; Mean training F1 0.939178; Mean validation loss 0.099745; Mean validation F1 0.939110; Learning rate 0.000178;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.079807; Mean training F1 0.939081; Mean validation loss 0.065207; Mean validation F1 0.939207; Learning rate 0.000169;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.079863; Mean training F1 0.939147; Mean validation loss 0.056277; Mean validation F1 0.939016; Learning rate 0.000160;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.079629; Mean training F1 0.939248; Mean validation loss 0.108846; Mean validation F1 0.939255; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.079702; Mean training F1 0.939111; Mean validation loss 0.102479; Mean validation F1 0.939428; Learning rate 0.000142;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.079598; Mean training F1 0.939261; Mean validation loss 0.068698; Mean validation F1 0.939217; Learning rate 0.000134;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.079541; Mean training F1 0.939301; Mean validation loss 0.099946; Mean validation F1 0.939364; Learning rate 0.000126;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.079460; Mean training F1 0.939218; Mean validation loss 0.071030; Mean validation F1 0.939168; Learning rate 0.000118;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.079463; Mean training F1 0.939413; Mean validation loss 0.067942; Mean validation F1 0.939441; Learning rate 0.000111;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.079352; Mean training F1 0.939290; Mean validation loss 0.062384; Mean validation F1 0.939165; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.079315; Mean training F1 0.939379; Mean validation loss 0.086170; Mean validation F1 0.939327; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.079314; Mean training F1 0.939399; Mean validation loss 0.085963; Mean validation F1 0.939319; Learning rate 0.000089;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.079287; Mean training F1 0.939375; Mean validation loss 0.056728; Mean validation F1 0.939230; Learning rate 0.000082;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.079198; Mean training F1 0.939433; Mean validation loss 0.075649; Mean validation F1 0.939154; Learning rate 0.000076;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.079188; Mean training F1 0.939403; Mean validation loss 0.067978; Mean validation F1 0.939489; Learning rate 0.000070;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.079176; Mean training F1 0.939371; Mean validation loss 0.048632; Mean validation F1 0.939350; Learning rate 0.000064;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.079083; Mean training F1 0.939559; Mean validation loss 0.076841; Mean validation F1 0.939464; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.079067; Mean training F1 0.939561; Mean validation loss 0.082792; Mean validation F1 0.939384; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.079091; Mean training F1 0.939519; Mean validation loss 0.087891; Mean validation F1 0.939396; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.079014; Mean training F1 0.939611; Mean validation loss 0.073942; Mean validation F1 0.939409; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.078965; Mean training F1 0.939599; Mean validation loss 0.072914; Mean validation F1 0.939441; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.078960; Mean training F1 0.939568; Mean validation loss 0.079766; Mean validation F1 0.939463; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.078956; Mean training F1 0.939512; Mean validation loss 0.092891; Mean validation F1 0.939417; Learning rate 0.000030;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.078906; Mean training F1 0.939642; Mean validation loss 0.087414; Mean validation F1 0.939231; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.078890; Mean training F1 0.939620; Mean validation loss 0.075907; Mean validation F1 0.939422; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.078869; Mean training F1 0.939599; Mean validation loss 0.075618; Mean validation F1 0.939377; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.078844; Mean training F1 0.939611; Mean validation loss 0.062003; Mean validation F1 0.939593; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.078825; Mean training F1 0.939649; Mean validation loss 0.070189; Mean validation F1 0.939463; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.078806; Mean training F1 0.939639; Mean validation loss 0.095015; Mean validation F1 0.939540; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.078798; Mean training F1 0.939684; Mean validation loss 0.083733; Mean validation F1 0.939531; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.078783; Mean training F1 0.939681; Mean validation loss 0.067748; Mean validation F1 0.939514; Learning rate 0.000009;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.078769; Mean training F1 0.939678; Mean validation loss 0.083672; Mean validation F1 0.939461; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.078764; Mean training F1 0.939647; Mean validation loss 0.057210; Mean validation F1 0.939408; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.078755; Mean training F1 0.939696; Mean validation loss 0.091982; Mean validation F1 0.939526; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.078745; Mean training F1 0.939675; Mean validation loss 0.065823; Mean validation F1 0.939503; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.078747; Mean training F1 0.939667; Mean validation loss 0.059298; Mean validation F1 0.939541; Learning rate 0.000005;\n",
    "################################################################\n",
    "Training/validation for fold 2/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.816699; Mean training F1 0.522636; Mean validation loss 0.548428; Mean validation F1 0.722470; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.313954; Mean training F1 0.836813; Mean validation loss 0.273355; Mean validation F1 0.861691; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.172947; Mean training F1 0.901554; Mean validation loss 0.165247; Mean validation F1 0.905252; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.118363; Mean training F1 0.922909; Mean validation loss 0.109570; Mean validation F1 0.921089; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.100041; Mean training F1 0.930480; Mean validation loss 0.131298; Mean validation F1 0.909053; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.097363; Mean training F1 0.931159; Mean validation loss 0.117757; Mean validation F1 0.932417; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.089360; Mean training F1 0.935095; Mean validation loss 0.101646; Mean validation F1 0.932491; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.087891; Mean training F1 0.935595; Mean validation loss 0.105955; Mean validation F1 0.934369; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.086952; Mean training F1 0.935858; Mean validation loss 0.091376; Mean validation F1 0.933746; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.087662; Mean training F1 0.935298; Mean validation loss 0.084969; Mean validation F1 0.932830; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.087123; Mean training F1 0.935193; Mean validation loss 0.054563; Mean validation F1 0.932735; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.085553; Mean training F1 0.936111; Mean validation loss 0.091402; Mean validation F1 0.934996; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.085184; Mean training F1 0.936202; Mean validation loss 0.071097; Mean validation F1 0.932430; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.084693; Mean training F1 0.936606; Mean validation loss 0.068352; Mean validation F1 0.934964; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.084488; Mean training F1 0.936427; Mean validation loss 0.082463; Mean validation F1 0.932315; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.084587; Mean training F1 0.936327; Mean validation loss 0.094124; Mean validation F1 0.935485; Learning rate 0.000962;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.083636; Mean training F1 0.936783; Mean validation loss 0.094555; Mean validation F1 0.934205; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.083538; Mean training F1 0.936782; Mean validation loss 0.076544; Mean validation F1 0.935625; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.083258; Mean training F1 0.936825; Mean validation loss 0.109211; Mean validation F1 0.934692; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.083873; Mean training F1 0.936524; Mean validation loss 0.086154; Mean validation F1 0.936216; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.084065; Mean training F1 0.936254; Mean validation loss 0.096381; Mean validation F1 0.933353; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.084333; Mean training F1 0.936322; Mean validation loss 0.075237; Mean validation F1 0.935136; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.083436; Mean training F1 0.936696; Mean validation loss 0.071657; Mean validation F1 0.935306; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.082577; Mean training F1 0.937340; Mean validation loss 0.074270; Mean validation F1 0.935114; Learning rate 0.000916;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.085108; Mean training F1 0.935439; Mean validation loss 0.082881; Mean validation F1 0.935996; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.082416; Mean training F1 0.937373; Mean validation loss 0.062030; Mean validation F1 0.936305; Learning rate 0.000902;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.082459; Mean training F1 0.937039; Mean validation loss 0.070685; Mean validation F1 0.935005; Learning rate 0.000895;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.082594; Mean training F1 0.936938; Mean validation loss 0.079712; Mean validation F1 0.934609; Learning rate 0.000887;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.082327; Mean training F1 0.937369; Mean validation loss 0.078095; Mean validation F1 0.935621; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.081761; Mean training F1 0.937697; Mean validation loss 0.087772; Mean validation F1 0.936031; Learning rate 0.000871;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.082052; Mean training F1 0.937464; Mean validation loss 0.079899; Mean validation F1 0.934142; Learning rate 0.000863;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.081753; Mean training F1 0.937734; Mean validation loss 0.086633; Mean validation F1 0.936743; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.081397; Mean training F1 0.937823; Mean validation loss 0.087139; Mean validation F1 0.935980; Learning rate 0.000846;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.081472; Mean training F1 0.937835; Mean validation loss 0.059116; Mean validation F1 0.936048; Learning rate 0.000837;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.081781; Mean training F1 0.937558; Mean validation loss 0.095027; Mean validation F1 0.936288; Learning rate 0.000828;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.088503; Mean training F1 0.933569; Mean validation loss 0.101996; Mean validation F1 0.886943; Learning rate 0.000818;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.086898; Mean training F1 0.934224; Mean validation loss 0.088522; Mean validation F1 0.936018; Learning rate 0.000809;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.081888; Mean training F1 0.937244; Mean validation loss 0.086765; Mean validation F1 0.936332; Learning rate 0.000799;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.080882; Mean training F1 0.938188; Mean validation loss 0.069154; Mean validation F1 0.936861; Learning rate 0.000789;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.080851; Mean training F1 0.938002; Mean validation loss 0.061352; Mean validation F1 0.935211; Learning rate 0.000779;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.080746; Mean training F1 0.938071; Mean validation loss 0.111777; Mean validation F1 0.937057; Learning rate 0.000769;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.080480; Mean training F1 0.938202; Mean validation loss 0.082756; Mean validation F1 0.935010; Learning rate 0.000759;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.080641; Mean training F1 0.938211; Mean validation loss 0.080550; Mean validation F1 0.935786; Learning rate 0.000748;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.080532; Mean training F1 0.938304; Mean validation loss 0.084036; Mean validation F1 0.936613; Learning rate 0.000737;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.080543; Mean training F1 0.938167; Mean validation loss 0.083873; Mean validation F1 0.933384; Learning rate 0.000726;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.081346; Mean training F1 0.937784; Mean validation loss 0.083561; Mean validation F1 0.936784; Learning rate 0.000716;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.080284; Mean training F1 0.938262; Mean validation loss 0.075074; Mean validation F1 0.936286; Learning rate 0.000704;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.080270; Mean training F1 0.938532; Mean validation loss 0.101321; Mean validation F1 0.936463; Learning rate 0.000693;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.080219; Mean training F1 0.938369; Mean validation loss 0.087838; Mean validation F1 0.936148; Learning rate 0.000682;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.080089; Mean training F1 0.938477; Mean validation loss 0.098065; Mean validation F1 0.936978; Learning rate 0.000670;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.083716; Mean training F1 0.936449; Mean validation loss 0.081585; Mean validation F1 0.936762; Learning rate 0.000659;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.079902; Mean training F1 0.938496; Mean validation loss 0.104392; Mean validation F1 0.936438; Learning rate 0.000647;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.079832; Mean training F1 0.938633; Mean validation loss 0.055148; Mean validation F1 0.935484; Learning rate 0.000635;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.079913; Mean training F1 0.938625; Mean validation loss 0.064838; Mean validation F1 0.936681; Learning rate 0.000624;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.079734; Mean training F1 0.938403; Mean validation loss 0.108236; Mean validation F1 0.935609; Learning rate 0.000612;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.079812; Mean training F1 0.938636; Mean validation loss 0.091039; Mean validation F1 0.936843; Learning rate 0.000600;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.079400; Mean training F1 0.938682; Mean validation loss 0.086262; Mean validation F1 0.937230; Learning rate 0.000588;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.079542; Mean training F1 0.938693; Mean validation loss 0.075124; Mean validation F1 0.936460; Learning rate 0.000576;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.079557; Mean training F1 0.938680; Mean validation loss 0.110262; Mean validation F1 0.936886; Learning rate 0.000564;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.079331; Mean training F1 0.938934; Mean validation loss 0.086606; Mean validation F1 0.936125; Learning rate 0.000552;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.079267; Mean training F1 0.938838; Mean validation loss 0.098480; Mean validation F1 0.936482; Learning rate 0.000539;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.079060; Mean training F1 0.938954; Mean validation loss 0.087476; Mean validation F1 0.936907; Learning rate 0.000527;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.078907; Mean training F1 0.939084; Mean validation loss 0.087549; Mean validation F1 0.936687; Learning rate 0.000515;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.079069; Mean training F1 0.938843; Mean validation loss 0.073793; Mean validation F1 0.937365; Learning rate 0.000503;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.078821; Mean training F1 0.939182; Mean validation loss 0.100966; Mean validation F1 0.937022; Learning rate 0.000491;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.087228; Mean training F1 0.934685; Mean validation loss 0.133561; Mean validation F1 0.903188; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.088714; Mean training F1 0.935046; Mean validation loss 0.067114; Mean validation F1 0.936228; Learning rate 0.000466;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.079692; Mean training F1 0.938603; Mean validation loss 0.070368; Mean validation F1 0.936626; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.079304; Mean training F1 0.938856; Mean validation loss 0.086354; Mean validation F1 0.936976; Learning rate 0.000442;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.079126; Mean training F1 0.938885; Mean validation loss 0.086638; Mean validation F1 0.936891; Learning rate 0.000430;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.078836; Mean training F1 0.939125; Mean validation loss 0.082370; Mean validation F1 0.937018; Learning rate 0.000418;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.078740; Mean training F1 0.939281; Mean validation loss 0.056443; Mean validation F1 0.936625; Learning rate 0.000406;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.078640; Mean training F1 0.939295; Mean validation loss 0.052578; Mean validation F1 0.937276; Learning rate 0.000394;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.078523; Mean training F1 0.939292; Mean validation loss 0.076680; Mean validation F1 0.937372; Learning rate 0.000382;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.078321; Mean training F1 0.939414; Mean validation loss 0.070952; Mean validation F1 0.936424; Learning rate 0.000370;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.078427; Mean training F1 0.939377; Mean validation loss 0.092705; Mean validation F1 0.937377; Learning rate 0.000358;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.078120; Mean training F1 0.939544; Mean validation loss 0.086867; Mean validation F1 0.937278; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.078252; Mean training F1 0.939541; Mean validation loss 0.097774; Mean validation F1 0.937299; Learning rate 0.000335;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.078157; Mean training F1 0.939505; Mean validation loss 0.077917; Mean validation F1 0.937178; Learning rate 0.000324;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.078194; Mean training F1 0.939352; Mean validation loss 0.064594; Mean validation F1 0.936784; Learning rate 0.000312;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.077966; Mean training F1 0.939504; Mean validation loss 0.077332; Mean validation F1 0.937317; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.077948; Mean training F1 0.939636; Mean validation loss 0.084019; Mean validation F1 0.937195; Learning rate 0.000290;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.077833; Mean training F1 0.939630; Mean validation loss 0.081140; Mean validation F1 0.936453; Learning rate 0.000279;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.077914; Mean training F1 0.939649; Mean validation loss 0.098014; Mean validation F1 0.937141; Learning rate 0.000268;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.077831; Mean training F1 0.939631; Mean validation loss 0.079933; Mean validation F1 0.937445; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.077644; Mean training F1 0.939815; Mean validation loss 0.089439; Mean validation F1 0.937146; Learning rate 0.000247;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.077567; Mean training F1 0.939888; Mean validation loss 0.089933; Mean validation F1 0.936736; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.077652; Mean training F1 0.939771; Mean validation loss 0.080395; Mean validation F1 0.937333; Learning rate 0.000226;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.077525; Mean training F1 0.939813; Mean validation loss 0.071944; Mean validation F1 0.937308; Learning rate 0.000216;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.077490; Mean training F1 0.939825; Mean validation loss 0.082575; Mean validation F1 0.937582; Learning rate 0.000206;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.077398; Mean training F1 0.939991; Mean validation loss 0.092390; Mean validation F1 0.937183; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.077312; Mean training F1 0.940047; Mean validation loss 0.070341; Mean validation F1 0.937241; Learning rate 0.000187;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.077273; Mean training F1 0.939921; Mean validation loss 0.067303; Mean validation F1 0.937209; Learning rate 0.000178;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.077214; Mean training F1 0.939971; Mean validation loss 0.069543; Mean validation F1 0.937153; Learning rate 0.000169;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.077128; Mean training F1 0.940038; Mean validation loss 0.075609; Mean validation F1 0.937277; Learning rate 0.000160;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.077129; Mean training F1 0.940056; Mean validation loss 0.071085; Mean validation F1 0.937340; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.077019; Mean training F1 0.940226; Mean validation loss 0.095770; Mean validation F1 0.937437; Learning rate 0.000142;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.077018; Mean training F1 0.940033; Mean validation loss 0.083960; Mean validation F1 0.937025; Learning rate 0.000134;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.076949; Mean training F1 0.940111; Mean validation loss 0.068056; Mean validation F1 0.937345; Learning rate 0.000126;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.076903; Mean training F1 0.940165; Mean validation loss 0.069190; Mean validation F1 0.937111; Learning rate 0.000118;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.076920; Mean training F1 0.940165; Mean validation loss 0.068251; Mean validation F1 0.936924; Learning rate 0.000111;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.076819; Mean training F1 0.940218; Mean validation loss 0.076342; Mean validation F1 0.937273; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.076744; Mean training F1 0.940299; Mean validation loss 0.086778; Mean validation F1 0.937434; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.076707; Mean training F1 0.940294; Mean validation loss 0.080387; Mean validation F1 0.937370; Learning rate 0.000089;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.076650; Mean training F1 0.940335; Mean validation loss 0.080761; Mean validation F1 0.937454; Learning rate 0.000082;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.076645; Mean training F1 0.940472; Mean validation loss 0.108692; Mean validation F1 0.937250; Learning rate 0.000076;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.076589; Mean training F1 0.940417; Mean validation loss 0.090561; Mean validation F1 0.937490; Learning rate 0.000070;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.076573; Mean training F1 0.940314; Mean validation loss 0.065467; Mean validation F1 0.937509; Learning rate 0.000064;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.076529; Mean training F1 0.940362; Mean validation loss 0.072535; Mean validation F1 0.937234; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.076483; Mean training F1 0.940399; Mean validation loss 0.094492; Mean validation F1 0.937356; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.076463; Mean training F1 0.940402; Mean validation loss 0.052995; Mean validation F1 0.937358; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.076418; Mean training F1 0.940425; Mean validation loss 0.045467; Mean validation F1 0.937317; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.076409; Mean training F1 0.940444; Mean validation loss 0.056657; Mean validation F1 0.937326; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.076374; Mean training F1 0.940495; Mean validation loss 0.078014; Mean validation F1 0.937442; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.076349; Mean training F1 0.940568; Mean validation loss 0.075539; Mean validation F1 0.937445; Learning rate 0.000030;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.076308; Mean training F1 0.940544; Mean validation loss 0.086548; Mean validation F1 0.937307; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.076295; Mean training F1 0.940546; Mean validation loss 0.068831; Mean validation F1 0.937363; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.076284; Mean training F1 0.940539; Mean validation loss 0.086788; Mean validation F1 0.937430; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.076257; Mean training F1 0.940541; Mean validation loss 0.052032; Mean validation F1 0.937422; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.076248; Mean training F1 0.940601; Mean validation loss 0.069814; Mean validation F1 0.937480; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.076239; Mean training F1 0.940628; Mean validation loss 0.059299; Mean validation F1 0.937367; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.076208; Mean training F1 0.940546; Mean validation loss 0.089223; Mean validation F1 0.937384; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.076204; Mean training F1 0.940571; Mean validation loss 0.092383; Mean validation F1 0.937400; Learning rate 0.000009;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.076200; Mean training F1 0.940586; Mean validation loss 0.072738; Mean validation F1 0.937463; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.076181; Mean training F1 0.940577; Mean validation loss 0.077953; Mean validation F1 0.937376; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.076174; Mean training F1 0.940601; Mean validation loss 0.083679; Mean validation F1 0.937367; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.076168; Mean training F1 0.940594; Mean validation loss 0.092730; Mean validation F1 0.937422; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.076168; Mean training F1 0.940612; Mean validation loss 0.061601; Mean validation F1 0.937386; Learning rate 0.000005;\n",
    "################################################################\n",
    "Training/validation for fold 3/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.853486; Mean training F1 0.508937; Mean validation loss 0.429979; Mean validation F1 0.744451; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.277494; Mean training F1 0.854151; Mean validation loss 0.177681; Mean validation F1 0.895721; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.172932; Mean training F1 0.901485; Mean validation loss 0.163806; Mean validation F1 0.910612; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.151798; Mean training F1 0.907880; Mean validation loss 0.152574; Mean validation F1 0.911529; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.137803; Mean training F1 0.914182; Mean validation loss 0.160714; Mean validation F1 0.914325; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.106640; Mean training F1 0.928726; Mean validation loss 0.124444; Mean validation F1 0.932469; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.098221; Mean training F1 0.931526; Mean validation loss 0.081783; Mean validation F1 0.931662; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.090568; Mean training F1 0.934658; Mean validation loss 0.112420; Mean validation F1 0.933288; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.088934; Mean training F1 0.935721; Mean validation loss 0.094742; Mean validation F1 0.934378; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.087702; Mean training F1 0.936147; Mean validation loss 0.076783; Mean validation F1 0.934221; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.087148; Mean training F1 0.936154; Mean validation loss 0.087998; Mean validation F1 0.934350; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.086821; Mean training F1 0.936150; Mean validation loss 0.079834; Mean validation F1 0.935303; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.087037; Mean training F1 0.935881; Mean validation loss 0.079634; Mean validation F1 0.934983; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.085827; Mean training F1 0.936273; Mean validation loss 0.083998; Mean validation F1 0.933917; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.086019; Mean training F1 0.936479; Mean validation loss 0.067222; Mean validation F1 0.933969; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.085265; Mean training F1 0.936887; Mean validation loss 0.113662; Mean validation F1 0.935364; Learning rate 0.000962;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.121305; Mean training F1 0.916430; Mean validation loss 0.099915; Mean validation F1 0.933706; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.089054; Mean training F1 0.935724; Mean validation loss 0.080845; Mean validation F1 0.933508; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.086210; Mean training F1 0.936540; Mean validation loss 0.099196; Mean validation F1 0.935384; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.085490; Mean training F1 0.936847; Mean validation loss 0.067747; Mean validation F1 0.935750; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.084996; Mean training F1 0.937210; Mean validation loss 0.076509; Mean validation F1 0.936176; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.084668; Mean training F1 0.937281; Mean validation loss 0.109225; Mean validation F1 0.935989; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.084649; Mean training F1 0.936963; Mean validation loss 0.076482; Mean validation F1 0.935640; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.084374; Mean training F1 0.937002; Mean validation loss 0.081870; Mean validation F1 0.936150; Learning rate 0.000916;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.084526; Mean training F1 0.936870; Mean validation loss 0.062928; Mean validation F1 0.936512; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.083951; Mean training F1 0.937407; Mean validation loss 0.093781; Mean validation F1 0.935026; Learning rate 0.000902;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.084127; Mean training F1 0.937089; Mean validation loss 0.104977; Mean validation F1 0.936687; Learning rate 0.000895;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.084025; Mean training F1 0.936993; Mean validation loss 0.070548; Mean validation F1 0.935923; Learning rate 0.000887;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.083630; Mean training F1 0.937464; Mean validation loss 0.073134; Mean validation F1 0.934465; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.083730; Mean training F1 0.937311; Mean validation loss 0.064274; Mean validation F1 0.934414; Learning rate 0.000871;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.083286; Mean training F1 0.937321; Mean validation loss 0.104012; Mean validation F1 0.936547; Learning rate 0.000863;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.083258; Mean training F1 0.937695; Mean validation loss 0.082608; Mean validation F1 0.936572; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.083091; Mean training F1 0.937623; Mean validation loss 0.087835; Mean validation F1 0.936216; Learning rate 0.000846;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.083168; Mean training F1 0.937609; Mean validation loss 0.085896; Mean validation F1 0.936133; Learning rate 0.000837;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.082795; Mean training F1 0.937741; Mean validation loss 0.072346; Mean validation F1 0.934266; Learning rate 0.000828;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.082919; Mean training F1 0.937429; Mean validation loss 0.099909; Mean validation F1 0.936926; Learning rate 0.000818;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.082375; Mean training F1 0.937797; Mean validation loss 0.055411; Mean validation F1 0.936199; Learning rate 0.000809;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.082585; Mean training F1 0.937740; Mean validation loss 0.066412; Mean validation F1 0.936784; Learning rate 0.000799;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.083138; Mean training F1 0.937292; Mean validation loss 0.072402; Mean validation F1 0.936412; Learning rate 0.000789;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.082576; Mean training F1 0.937821; Mean validation loss 0.106567; Mean validation F1 0.936444; Learning rate 0.000779;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.082411; Mean training F1 0.937650; Mean validation loss 0.098077; Mean validation F1 0.936277; Learning rate 0.000769;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.082140; Mean training F1 0.937909; Mean validation loss 0.097688; Mean validation F1 0.937002; Learning rate 0.000759;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.082362; Mean training F1 0.937844; Mean validation loss 0.091135; Mean validation F1 0.935844; Learning rate 0.000748;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.082179; Mean training F1 0.937717; Mean validation loss 0.074620; Mean validation F1 0.935843; Learning rate 0.000737;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.081777; Mean training F1 0.938205; Mean validation loss 0.070220; Mean validation F1 0.936685; Learning rate 0.000726;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.081965; Mean training F1 0.937854; Mean validation loss 0.082925; Mean validation F1 0.935881; Learning rate 0.000716;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.082119; Mean training F1 0.937793; Mean validation loss 0.068156; Mean validation F1 0.936676; Learning rate 0.000704;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.081937; Mean training F1 0.938095; Mean validation loss 0.057985; Mean validation F1 0.936743; Learning rate 0.000693;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.081601; Mean training F1 0.938293; Mean validation loss 0.083728; Mean validation F1 0.936894; Learning rate 0.000682;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.081797; Mean training F1 0.938103; Mean validation loss 0.069788; Mean validation F1 0.936622; Learning rate 0.000670;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.081490; Mean training F1 0.938350; Mean validation loss 0.089708; Mean validation F1 0.936632; Learning rate 0.000659;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.081842; Mean training F1 0.937968; Mean validation loss 0.076751; Mean validation F1 0.935978; Learning rate 0.000647;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.085122; Mean training F1 0.936319; Mean validation loss 0.089863; Mean validation F1 0.933913; Learning rate 0.000635;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.100336; Mean training F1 0.924996; Mean validation loss 0.073541; Mean validation F1 0.935546; Learning rate 0.000624;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.082618; Mean training F1 0.937929; Mean validation loss 0.085806; Mean validation F1 0.935287; Learning rate 0.000612;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.081998; Mean training F1 0.938173; Mean validation loss 0.061531; Mean validation F1 0.936313; Learning rate 0.000600;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.081541; Mean training F1 0.938456; Mean validation loss 0.104799; Mean validation F1 0.936467; Learning rate 0.000588;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.081385; Mean training F1 0.938499; Mean validation loss 0.093836; Mean validation F1 0.936632; Learning rate 0.000576;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.081079; Mean training F1 0.938747; Mean validation loss 0.076772; Mean validation F1 0.936671; Learning rate 0.000564;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.081051; Mean training F1 0.938580; Mean validation loss 0.060302; Mean validation F1 0.936715; Learning rate 0.000552;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.080952; Mean training F1 0.938697; Mean validation loss 0.083384; Mean validation F1 0.936258; Learning rate 0.000539;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.080988; Mean training F1 0.938586; Mean validation loss 0.074877; Mean validation F1 0.936628; Learning rate 0.000527;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.080916; Mean training F1 0.938632; Mean validation loss 0.093136; Mean validation F1 0.936858; Learning rate 0.000515;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.080786; Mean training F1 0.938757; Mean validation loss 0.062041; Mean validation F1 0.936985; Learning rate 0.000503;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.080594; Mean training F1 0.938877; Mean validation loss 0.089809; Mean validation F1 0.937033; Learning rate 0.000491;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.080687; Mean training F1 0.938775; Mean validation loss 0.080724; Mean validation F1 0.936847; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.080345; Mean training F1 0.938928; Mean validation loss 0.095159; Mean validation F1 0.937020; Learning rate 0.000466;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.080628; Mean training F1 0.938844; Mean validation loss 0.088270; Mean validation F1 0.937035; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.080619; Mean training F1 0.938743; Mean validation loss 0.076291; Mean validation F1 0.936757; Learning rate 0.000442;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.080389; Mean training F1 0.938846; Mean validation loss 0.109836; Mean validation F1 0.936710; Learning rate 0.000430;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.080433; Mean training F1 0.939010; Mean validation loss 0.068208; Mean validation F1 0.937024; Learning rate 0.000418;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.080209; Mean training F1 0.939024; Mean validation loss 0.055352; Mean validation F1 0.936876; Learning rate 0.000406;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.080243; Mean training F1 0.938922; Mean validation loss 0.069717; Mean validation F1 0.937105; Learning rate 0.000394;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.080146; Mean training F1 0.938964; Mean validation loss 0.070852; Mean validation F1 0.936946; Learning rate 0.000382;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.079930; Mean training F1 0.939094; Mean validation loss 0.086468; Mean validation F1 0.936790; Learning rate 0.000370;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.079961; Mean training F1 0.939056; Mean validation loss 0.070662; Mean validation F1 0.937223; Learning rate 0.000358;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.079947; Mean training F1 0.939070; Mean validation loss 0.086044; Mean validation F1 0.936989; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.079710; Mean training F1 0.939242; Mean validation loss 0.079949; Mean validation F1 0.936409; Learning rate 0.000335;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.079707; Mean training F1 0.939254; Mean validation loss 0.063730; Mean validation F1 0.936503; Learning rate 0.000324;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.079906; Mean training F1 0.938981; Mean validation loss 0.082356; Mean validation F1 0.936973; Learning rate 0.000312;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.079561; Mean training F1 0.939352; Mean validation loss 0.083545; Mean validation F1 0.936395; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.079598; Mean training F1 0.939377; Mean validation loss 0.076264; Mean validation F1 0.937217; Learning rate 0.000290;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.079473; Mean training F1 0.939462; Mean validation loss 0.084385; Mean validation F1 0.937058; Learning rate 0.000279;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.079372; Mean training F1 0.939345; Mean validation loss 0.078539; Mean validation F1 0.936848; Learning rate 0.000268;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.079288; Mean training F1 0.939489; Mean validation loss 0.079369; Mean validation F1 0.937235; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.079280; Mean training F1 0.939475; Mean validation loss 0.083779; Mean validation F1 0.936635; Learning rate 0.000247;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.079312; Mean training F1 0.939359; Mean validation loss 0.089422; Mean validation F1 0.936839; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.079209; Mean training F1 0.939384; Mean validation loss 0.089092; Mean validation F1 0.937273; Learning rate 0.000226;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.079226; Mean training F1 0.939612; Mean validation loss 0.064629; Mean validation F1 0.936933; Learning rate 0.000216;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.079047; Mean training F1 0.939581; Mean validation loss 0.069637; Mean validation F1 0.937056; Learning rate 0.000206;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.079014; Mean training F1 0.939601; Mean validation loss 0.073411; Mean validation F1 0.937068; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.079063; Mean training F1 0.939482; Mean validation loss 0.075100; Mean validation F1 0.936907; Learning rate 0.000187;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.078930; Mean training F1 0.939688; Mean validation loss 0.084176; Mean validation F1 0.937121; Learning rate 0.000178;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.078807; Mean training F1 0.939731; Mean validation loss 0.075683; Mean validation F1 0.937280; Learning rate 0.000169;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.078706; Mean training F1 0.939800; Mean validation loss 0.073439; Mean validation F1 0.936991; Learning rate 0.000160;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.078698; Mean training F1 0.939805; Mean validation loss 0.080449; Mean validation F1 0.937182; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.078699; Mean training F1 0.939781; Mean validation loss 0.072941; Mean validation F1 0.937072; Learning rate 0.000142;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.078644; Mean training F1 0.939783; Mean validation loss 0.082566; Mean validation F1 0.937244; Learning rate 0.000134;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.078547; Mean training F1 0.939820; Mean validation loss 0.079048; Mean validation F1 0.937331; Learning rate 0.000126;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.078500; Mean training F1 0.939984; Mean validation loss 0.079809; Mean validation F1 0.936955; Learning rate 0.000118;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.078509; Mean training F1 0.939949; Mean validation loss 0.083975; Mean validation F1 0.936979; Learning rate 0.000111;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.078400; Mean training F1 0.939970; Mean validation loss 0.061134; Mean validation F1 0.937318; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.078366; Mean training F1 0.939961; Mean validation loss 0.081103; Mean validation F1 0.937069; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.078322; Mean training F1 0.940025; Mean validation loss 0.084950; Mean validation F1 0.937144; Learning rate 0.000089;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.078271; Mean training F1 0.940067; Mean validation loss 0.092509; Mean validation F1 0.937167; Learning rate 0.000082;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.078245; Mean training F1 0.940084; Mean validation loss 0.085046; Mean validation F1 0.937044; Learning rate 0.000076;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.078247; Mean training F1 0.940073; Mean validation loss 0.080147; Mean validation F1 0.937179; Learning rate 0.000070;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.078188; Mean training F1 0.940076; Mean validation loss 0.059166; Mean validation F1 0.937143; Learning rate 0.000064;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.078114; Mean training F1 0.940104; Mean validation loss 0.059688; Mean validation F1 0.937057; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.078112; Mean training F1 0.940151; Mean validation loss 0.057073; Mean validation F1 0.937155; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.078061; Mean training F1 0.940235; Mean validation loss 0.057167; Mean validation F1 0.937131; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.078036; Mean training F1 0.940206; Mean validation loss 0.068563; Mean validation F1 0.937215; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.078018; Mean training F1 0.940186; Mean validation loss 0.102862; Mean validation F1 0.937298; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.077964; Mean training F1 0.940225; Mean validation loss 0.061641; Mean validation F1 0.937295; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.077965; Mean training F1 0.940248; Mean validation loss 0.077663; Mean validation F1 0.937310; Learning rate 0.000030;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.077946; Mean training F1 0.940258; Mean validation loss 0.084036; Mean validation F1 0.937321; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.077902; Mean training F1 0.940321; Mean validation loss 0.094548; Mean validation F1 0.937336; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.077893; Mean training F1 0.940291; Mean validation loss 0.071810; Mean validation F1 0.937361; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.077877; Mean training F1 0.940202; Mean validation loss 0.046743; Mean validation F1 0.937418; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.077855; Mean training F1 0.940247; Mean validation loss 0.072204; Mean validation F1 0.937360; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.077847; Mean training F1 0.940304; Mean validation loss 0.061504; Mean validation F1 0.937313; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.077832; Mean training F1 0.940267; Mean validation loss 0.049497; Mean validation F1 0.937334; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.077810; Mean training F1 0.940291; Mean validation loss 0.076951; Mean validation F1 0.937360; Learning rate 0.000009;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.077802; Mean training F1 0.940319; Mean validation loss 0.078172; Mean validation F1 0.937323; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.077798; Mean training F1 0.940281; Mean validation loss 0.066268; Mean validation F1 0.937281; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.077792; Mean training F1 0.940306; Mean validation loss 0.083730; Mean validation F1 0.937361; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.077783; Mean training F1 0.940285; Mean validation loss 0.072232; Mean validation F1 0.937305; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.077780; Mean training F1 0.940334; Mean validation loss 0.074162; Mean validation F1 0.937254; Learning rate 0.000005;\n",
    "################################################################\n",
    "Training/validation for fold 4/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.802026; Mean training F1 0.548501; Mean validation loss 0.491212; Mean validation F1 0.744351; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.280140; Mean training F1 0.845908; Mean validation loss 0.166573; Mean validation F1 0.906111; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.129945; Mean training F1 0.919616; Mean validation loss 0.100549; Mean validation F1 0.932035; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.102510; Mean training F1 0.930491; Mean validation loss 0.073788; Mean validation F1 0.934083; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.117283; Mean training F1 0.920764; Mean validation loss 0.112350; Mean validation F1 0.933314; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.093384; Mean training F1 0.933895; Mean validation loss 0.069246; Mean validation F1 0.932948; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.091531; Mean training F1 0.934527; Mean validation loss 0.069725; Mean validation F1 0.936606; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.089411; Mean training F1 0.935663; Mean validation loss 0.084204; Mean validation F1 0.935543; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.090880; Mean training F1 0.934180; Mean validation loss 0.088785; Mean validation F1 0.935856; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.111793; Mean training F1 0.922782; Mean validation loss 0.169789; Mean validation F1 0.925595; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.094340; Mean training F1 0.932197; Mean validation loss 0.091765; Mean validation F1 0.935767; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.088740; Mean training F1 0.935586; Mean validation loss 0.095890; Mean validation F1 0.935192; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.089205; Mean training F1 0.935431; Mean validation loss 0.092882; Mean validation F1 0.936841; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.087465; Mean training F1 0.936051; Mean validation loss 0.085986; Mean validation F1 0.936565; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.086904; Mean training F1 0.936225; Mean validation loss 0.076422; Mean validation F1 0.936979; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.087138; Mean training F1 0.936070; Mean validation loss 0.082392; Mean validation F1 0.936501; Learning rate 0.000962;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.086636; Mean training F1 0.936202; Mean validation loss 0.089267; Mean validation F1 0.936932; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.086381; Mean training F1 0.936525; Mean validation loss 0.079108; Mean validation F1 0.936934; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.085966; Mean training F1 0.936463; Mean validation loss 0.106317; Mean validation F1 0.936447; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.085666; Mean training F1 0.936431; Mean validation loss 0.083997; Mean validation F1 0.936707; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.085771; Mean training F1 0.936563; Mean validation loss 0.098066; Mean validation F1 0.937053; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.086265; Mean training F1 0.936547; Mean validation loss 0.105563; Mean validation F1 0.934697; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.085197; Mean training F1 0.936907; Mean validation loss 0.065777; Mean validation F1 0.936201; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.084961; Mean training F1 0.936910; Mean validation loss 0.082767; Mean validation F1 0.936867; Learning rate 0.000916;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.084728; Mean training F1 0.937079; Mean validation loss 0.104253; Mean validation F1 0.937469; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.084814; Mean training F1 0.937029; Mean validation loss 0.110903; Mean validation F1 0.937298; Learning rate 0.000902;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.084660; Mean training F1 0.937088; Mean validation loss 0.089929; Mean validation F1 0.937116; Learning rate 0.000895;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.084752; Mean training F1 0.936932; Mean validation loss 0.084591; Mean validation F1 0.936356; Learning rate 0.000887;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.084552; Mean training F1 0.937069; Mean validation loss 0.070097; Mean validation F1 0.935467; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.084515; Mean training F1 0.937032; Mean validation loss 0.086905; Mean validation F1 0.937588; Learning rate 0.000871;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.083802; Mean training F1 0.937472; Mean validation loss 0.068692; Mean validation F1 0.937211; Learning rate 0.000863;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.084817; Mean training F1 0.936853; Mean validation loss 0.086722; Mean validation F1 0.937444; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.099483; Mean training F1 0.927839; Mean validation loss 0.129734; Mean validation F1 0.936071; Learning rate 0.000846;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.086158; Mean training F1 0.935978; Mean validation loss 0.125114; Mean validation F1 0.936451; Learning rate 0.000837;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.084448; Mean training F1 0.937215; Mean validation loss 0.103632; Mean validation F1 0.937886; Learning rate 0.000828;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.083820; Mean training F1 0.937425; Mean validation loss 0.086292; Mean validation F1 0.936436; Learning rate 0.000818;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.083600; Mean training F1 0.937529; Mean validation loss 0.080513; Mean validation F1 0.935707; Learning rate 0.000809;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.083565; Mean training F1 0.937219; Mean validation loss 0.082588; Mean validation F1 0.937705; Learning rate 0.000799;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.083281; Mean training F1 0.937717; Mean validation loss 0.077011; Mean validation F1 0.937574; Learning rate 0.000789;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.082979; Mean training F1 0.938041; Mean validation loss 0.094252; Mean validation F1 0.937935; Learning rate 0.000779;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.083299; Mean training F1 0.937852; Mean validation loss 0.083048; Mean validation F1 0.938398; Learning rate 0.000769;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.082980; Mean training F1 0.938028; Mean validation loss 0.070394; Mean validation F1 0.937482; Learning rate 0.000759;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.083322; Mean training F1 0.937594; Mean validation loss 0.090868; Mean validation F1 0.937572; Learning rate 0.000748;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.082781; Mean training F1 0.937712; Mean validation loss 0.073669; Mean validation F1 0.937349; Learning rate 0.000737;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.082764; Mean training F1 0.937863; Mean validation loss 0.075307; Mean validation F1 0.937769; Learning rate 0.000726;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.083124; Mean training F1 0.937575; Mean validation loss 0.075560; Mean validation F1 0.937451; Learning rate 0.000716;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.082729; Mean training F1 0.937748; Mean validation loss 0.103758; Mean validation F1 0.938235; Learning rate 0.000704;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.082080; Mean training F1 0.938288; Mean validation loss 0.062978; Mean validation F1 0.937174; Learning rate 0.000693;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.088465; Mean training F1 0.935301; Mean validation loss 0.100288; Mean validation F1 0.936391; Learning rate 0.000682;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.083543; Mean training F1 0.937574; Mean validation loss 0.112643; Mean validation F1 0.937550; Learning rate 0.000670;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.082788; Mean training F1 0.938025; Mean validation loss 0.074334; Mean validation F1 0.937889; Learning rate 0.000659;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.082511; Mean training F1 0.937990; Mean validation loss 0.077570; Mean validation F1 0.936564; Learning rate 0.000647;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.082145; Mean training F1 0.938310; Mean validation loss 0.111925; Mean validation F1 0.936471; Learning rate 0.000635;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.082062; Mean training F1 0.938128; Mean validation loss 0.077990; Mean validation F1 0.937910; Learning rate 0.000624;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.082130; Mean training F1 0.938214; Mean validation loss 0.089999; Mean validation F1 0.938157; Learning rate 0.000612;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.082137; Mean training F1 0.938383; Mean validation loss 0.080872; Mean validation F1 0.937785; Learning rate 0.000600;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.102536; Mean training F1 0.926333; Mean validation loss 0.079871; Mean validation F1 0.936863; Learning rate 0.000588;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.083530; Mean training F1 0.937515; Mean validation loss 0.078837; Mean validation F1 0.937413; Learning rate 0.000576;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.082655; Mean training F1 0.937955; Mean validation loss 0.097500; Mean validation F1 0.938157; Learning rate 0.000564;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.082534; Mean training F1 0.938077; Mean validation loss 0.119916; Mean validation F1 0.937532; Learning rate 0.000552;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.082343; Mean training F1 0.938258; Mean validation loss 0.085138; Mean validation F1 0.938087; Learning rate 0.000539;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.082199; Mean training F1 0.938433; Mean validation loss 0.065350; Mean validation F1 0.937225; Learning rate 0.000527;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.082178; Mean training F1 0.938234; Mean validation loss 0.118189; Mean validation F1 0.938040; Learning rate 0.000515;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.081743; Mean training F1 0.938501; Mean validation loss 0.074871; Mean validation F1 0.938017; Learning rate 0.000503;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.081559; Mean training F1 0.938589; Mean validation loss 0.087292; Mean validation F1 0.937900; Learning rate 0.000491;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.081646; Mean training F1 0.938522; Mean validation loss 0.073166; Mean validation F1 0.938161; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.081231; Mean training F1 0.938730; Mean validation loss 0.084200; Mean validation F1 0.938082; Learning rate 0.000466;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.081292; Mean training F1 0.938717; Mean validation loss 0.069840; Mean validation F1 0.938173; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.081112; Mean training F1 0.938817; Mean validation loss 0.063893; Mean validation F1 0.937770; Learning rate 0.000442;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.081056; Mean training F1 0.938820; Mean validation loss 0.089151; Mean validation F1 0.937692; Learning rate 0.000430;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.081063; Mean training F1 0.938901; Mean validation loss 0.071416; Mean validation F1 0.938122; Learning rate 0.000418;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.081171; Mean training F1 0.938653; Mean validation loss 0.091635; Mean validation F1 0.938005; Learning rate 0.000406;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.080937; Mean training F1 0.938915; Mean validation loss 0.077814; Mean validation F1 0.938482; Learning rate 0.000394;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.080933; Mean training F1 0.938835; Mean validation loss 0.074591; Mean validation F1 0.938406; Learning rate 0.000382;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.080792; Mean training F1 0.938866; Mean validation loss 0.079737; Mean validation F1 0.938044; Learning rate 0.000370;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.080729; Mean training F1 0.939014; Mean validation loss 0.070935; Mean validation F1 0.938359; Learning rate 0.000358;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.080714; Mean training F1 0.938991; Mean validation loss 0.073587; Mean validation F1 0.938270; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.080503; Mean training F1 0.939037; Mean validation loss 0.075901; Mean validation F1 0.937514; Learning rate 0.000335;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.080404; Mean training F1 0.939121; Mean validation loss 0.083358; Mean validation F1 0.937995; Learning rate 0.000324;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.080411; Mean training F1 0.939041; Mean validation loss 0.089756; Mean validation F1 0.938155; Learning rate 0.000312;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.080284; Mean training F1 0.939262; Mean validation loss 0.073638; Mean validation F1 0.938132; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.081477; Mean training F1 0.938547; Mean validation loss 0.086975; Mean validation F1 0.938109; Learning rate 0.000290;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.080304; Mean training F1 0.939215; Mean validation loss 0.091943; Mean validation F1 0.938105; Learning rate 0.000279;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.080170; Mean training F1 0.939265; Mean validation loss 0.064179; Mean validation F1 0.938476; Learning rate 0.000268;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.079972; Mean training F1 0.939347; Mean validation loss 0.071729; Mean validation F1 0.938347; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.080078; Mean training F1 0.939176; Mean validation loss 0.081628; Mean validation F1 0.938219; Learning rate 0.000247;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.079881; Mean training F1 0.939269; Mean validation loss 0.056985; Mean validation F1 0.938072; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.079879; Mean training F1 0.939347; Mean validation loss 0.102576; Mean validation F1 0.938185; Learning rate 0.000226;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.079883; Mean training F1 0.939485; Mean validation loss 0.079340; Mean validation F1 0.938356; Learning rate 0.000216;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.079763; Mean training F1 0.939492; Mean validation loss 0.086463; Mean validation F1 0.937890; Learning rate 0.000206;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.079655; Mean training F1 0.939415; Mean validation loss 0.083374; Mean validation F1 0.938344; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.079629; Mean training F1 0.939463; Mean validation loss 0.090782; Mean validation F1 0.938381; Learning rate 0.000187;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.079531; Mean training F1 0.939628; Mean validation loss 0.089573; Mean validation F1 0.938157; Learning rate 0.000178;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.079466; Mean training F1 0.939524; Mean validation loss 0.063817; Mean validation F1 0.938468; Learning rate 0.000169;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.079287; Mean training F1 0.939698; Mean validation loss 0.071085; Mean validation F1 0.938230; Learning rate 0.000160;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.079383; Mean training F1 0.939557; Mean validation loss 0.085496; Mean validation F1 0.938322; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.079233; Mean training F1 0.939687; Mean validation loss 0.093317; Mean validation F1 0.938386; Learning rate 0.000142;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.079183; Mean training F1 0.939730; Mean validation loss 0.062541; Mean validation F1 0.938233; Learning rate 0.000134;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.079190; Mean training F1 0.939675; Mean validation loss 0.094752; Mean validation F1 0.938292; Learning rate 0.000126;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.079078; Mean training F1 0.939784; Mean validation loss 0.064490; Mean validation F1 0.938468; Learning rate 0.000118;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.079016; Mean training F1 0.939754; Mean validation loss 0.079442; Mean validation F1 0.938397; Learning rate 0.000111;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.078998; Mean training F1 0.939747; Mean validation loss 0.076873; Mean validation F1 0.938457; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.078910; Mean training F1 0.939842; Mean validation loss 0.080132; Mean validation F1 0.938372; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.078904; Mean training F1 0.939818; Mean validation loss 0.084857; Mean validation F1 0.938582; Learning rate 0.000089;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.078815; Mean training F1 0.939836; Mean validation loss 0.103900; Mean validation F1 0.938472; Learning rate 0.000082;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.078818; Mean training F1 0.939910; Mean validation loss 0.096790; Mean validation F1 0.938641; Learning rate 0.000076;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.078707; Mean training F1 0.939964; Mean validation loss 0.087279; Mean validation F1 0.938717; Learning rate 0.000070;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.078741; Mean training F1 0.939886; Mean validation loss 0.141185; Mean validation F1 0.938449; Learning rate 0.000064;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.078685; Mean training F1 0.939919; Mean validation loss 0.072306; Mean validation F1 0.938422; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.078617; Mean training F1 0.940015; Mean validation loss 0.059606; Mean validation F1 0.938502; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.078570; Mean training F1 0.940036; Mean validation loss 0.119194; Mean validation F1 0.938625; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.078562; Mean training F1 0.940017; Mean validation loss 0.071007; Mean validation F1 0.938526; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.078550; Mean training F1 0.939996; Mean validation loss 0.073076; Mean validation F1 0.938596; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.078521; Mean training F1 0.940039; Mean validation loss 0.077984; Mean validation F1 0.938527; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.078517; Mean training F1 0.940032; Mean validation loss 0.069722; Mean validation F1 0.938582; Learning rate 0.000030;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.078462; Mean training F1 0.940094; Mean validation loss 0.084149; Mean validation F1 0.938595; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.078442; Mean training F1 0.940098; Mean validation loss 0.068005; Mean validation F1 0.938536; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.078414; Mean training F1 0.940125; Mean validation loss 0.067818; Mean validation F1 0.938606; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.078385; Mean training F1 0.940139; Mean validation loss 0.078190; Mean validation F1 0.938288; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.078374; Mean training F1 0.940063; Mean validation loss 0.087125; Mean validation F1 0.938603; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.078372; Mean training F1 0.940100; Mean validation loss 0.063495; Mean validation F1 0.938519; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.078344; Mean training F1 0.940135; Mean validation loss 0.079208; Mean validation F1 0.938578; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.078333; Mean training F1 0.940133; Mean validation loss 0.063279; Mean validation F1 0.938580; Learning rate 0.000009;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.078324; Mean training F1 0.940245; Mean validation loss 0.049826; Mean validation F1 0.938480; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.078309; Mean training F1 0.940160; Mean validation loss 0.079079; Mean validation F1 0.938521; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.078306; Mean training F1 0.940121; Mean validation loss 0.108590; Mean validation F1 0.938488; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.078301; Mean training F1 0.940179; Mean validation loss 0.070524; Mean validation F1 0.938561; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.078297; Mean training F1 0.940153; Mean validation loss 0.073527; Mean validation F1 0.938555; Learning rate 0.000005;\n",
    "################################################################\n",
    "Training/validation for fold 5/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.786990; Mean training F1 0.554700; Mean validation loss 0.578322; Mean validation F1 0.732550; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.318651; Mean training F1 0.835867; Mean validation loss 0.204914; Mean validation F1 0.893670; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.179270; Mean training F1 0.896746; Mean validation loss 0.157526; Mean validation F1 0.913848; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.152523; Mean training F1 0.907864; Mean validation loss 0.167753; Mean validation F1 0.915710; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.139154; Mean training F1 0.914453; Mean validation loss 0.155882; Mean validation F1 0.918828; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.124585; Mean training F1 0.920602; Mean validation loss 0.125205; Mean validation F1 0.928800; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.108144; Mean training F1 0.926470; Mean validation loss 0.074418; Mean validation F1 0.934762; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.091497; Mean training F1 0.934769; Mean validation loss 0.098511; Mean validation F1 0.936266; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.089743; Mean training F1 0.935622; Mean validation loss 0.084946; Mean validation F1 0.935852; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.089484; Mean training F1 0.935226; Mean validation loss 0.099652; Mean validation F1 0.933598; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.089698; Mean training F1 0.934768; Mean validation loss 0.095375; Mean validation F1 0.936942; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.088179; Mean training F1 0.935911; Mean validation loss 0.093194; Mean validation F1 0.937207; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.087588; Mean training F1 0.936138; Mean validation loss 0.070207; Mean validation F1 0.936839; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.087747; Mean training F1 0.936195; Mean validation loss 0.059773; Mean validation F1 0.936393; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.087821; Mean training F1 0.935918; Mean validation loss 0.082725; Mean validation F1 0.937732; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.086777; Mean training F1 0.936442; Mean validation loss 0.102071; Mean validation F1 0.937775; Learning rate 0.000962;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.086266; Mean training F1 0.936602; Mean validation loss 0.058407; Mean validation F1 0.938067; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.086852; Mean training F1 0.935922; Mean validation loss 0.080516; Mean validation F1 0.937185; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.086132; Mean training F1 0.936714; Mean validation loss 0.086488; Mean validation F1 0.936751; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.087355; Mean training F1 0.936185; Mean validation loss 0.080126; Mean validation F1 0.937705; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.085849; Mean training F1 0.936729; Mean validation loss 0.086999; Mean validation F1 0.936988; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.085784; Mean training F1 0.936744; Mean validation loss 0.075516; Mean validation F1 0.937574; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.086029; Mean training F1 0.936465; Mean validation loss 0.075333; Mean validation F1 0.937397; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.085229; Mean training F1 0.936985; Mean validation loss 0.077094; Mean validation F1 0.937082; Learning rate 0.000916;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.085628; Mean training F1 0.936808; Mean validation loss 0.075262; Mean validation F1 0.937787; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.084943; Mean training F1 0.937085; Mean validation loss 0.070214; Mean validation F1 0.934705; Learning rate 0.000902;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.085532; Mean training F1 0.936575; Mean validation loss 0.077422; Mean validation F1 0.938215; Learning rate 0.000895;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.084853; Mean training F1 0.937471; Mean validation loss 0.099303; Mean validation F1 0.937085; Learning rate 0.000887;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.085222; Mean training F1 0.936945; Mean validation loss 0.053750; Mean validation F1 0.937656; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.084685; Mean training F1 0.937177; Mean validation loss 0.086721; Mean validation F1 0.938046; Learning rate 0.000871;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.084838; Mean training F1 0.937141; Mean validation loss 0.060141; Mean validation F1 0.937187; Learning rate 0.000863;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.084666; Mean training F1 0.936780; Mean validation loss 0.077894; Mean validation F1 0.936851; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.084729; Mean training F1 0.936911; Mean validation loss 0.095222; Mean validation F1 0.934996; Learning rate 0.000846;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.084098; Mean training F1 0.937126; Mean validation loss 0.063511; Mean validation F1 0.937394; Learning rate 0.000837;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.083971; Mean training F1 0.937408; Mean validation loss 0.069856; Mean validation F1 0.933733; Learning rate 0.000828;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.084576; Mean training F1 0.937298; Mean validation loss 0.082454; Mean validation F1 0.937762; Learning rate 0.000818;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.083433; Mean training F1 0.937455; Mean validation loss 0.071189; Mean validation F1 0.938219; Learning rate 0.000809;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.083620; Mean training F1 0.937367; Mean validation loss 0.065348; Mean validation F1 0.937787; Learning rate 0.000799;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.083123; Mean training F1 0.937808; Mean validation loss 0.091770; Mean validation F1 0.937400; Learning rate 0.000789;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.083396; Mean training F1 0.937718; Mean validation loss 0.086579; Mean validation F1 0.938084; Learning rate 0.000779;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.083075; Mean training F1 0.937792; Mean validation loss 0.079232; Mean validation F1 0.938290; Learning rate 0.000769;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.089978; Mean training F1 0.934482; Mean validation loss 0.085382; Mean validation F1 0.938369; Learning rate 0.000759;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.083491; Mean training F1 0.937647; Mean validation loss 0.056415; Mean validation F1 0.936992; Learning rate 0.000748;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.083397; Mean training F1 0.937496; Mean validation loss 0.086586; Mean validation F1 0.938382; Learning rate 0.000737;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.083010; Mean training F1 0.937792; Mean validation loss 0.113752; Mean validation F1 0.938410; Learning rate 0.000726;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.082942; Mean training F1 0.937666; Mean validation loss 0.060700; Mean validation F1 0.938062; Learning rate 0.000716;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.082535; Mean training F1 0.938014; Mean validation loss 0.081365; Mean validation F1 0.938195; Learning rate 0.000704;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.082184; Mean training F1 0.938263; Mean validation loss 0.078530; Mean validation F1 0.938515; Learning rate 0.000693;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.082207; Mean training F1 0.938176; Mean validation loss 0.083087; Mean validation F1 0.938808; Learning rate 0.000682;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.082113; Mean training F1 0.938180; Mean validation loss 0.082311; Mean validation F1 0.938527; Learning rate 0.000670;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.081960; Mean training F1 0.938401; Mean validation loss 0.074524; Mean validation F1 0.938012; Learning rate 0.000659;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.081792; Mean training F1 0.938468; Mean validation loss 0.089288; Mean validation F1 0.938414; Learning rate 0.000647;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.081894; Mean training F1 0.938236; Mean validation loss 0.069749; Mean validation F1 0.937753; Learning rate 0.000635;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.081798; Mean training F1 0.938591; Mean validation loss 0.073155; Mean validation F1 0.937396; Learning rate 0.000624;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.082318; Mean training F1 0.938210; Mean validation loss 0.081954; Mean validation F1 0.936819; Learning rate 0.000612;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.081881; Mean training F1 0.938368; Mean validation loss 0.065663; Mean validation F1 0.936827; Learning rate 0.000600;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.081634; Mean training F1 0.938324; Mean validation loss 0.052476; Mean validation F1 0.937523; Learning rate 0.000588;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.081672; Mean training F1 0.938491; Mean validation loss 0.080788; Mean validation F1 0.938744; Learning rate 0.000576;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.081258; Mean training F1 0.938641; Mean validation loss 0.127782; Mean validation F1 0.938294; Learning rate 0.000564;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.081831; Mean training F1 0.938318; Mean validation loss 0.091106; Mean validation F1 0.938645; Learning rate 0.000552;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.082206; Mean training F1 0.938295; Mean validation loss 0.091258; Mean validation F1 0.938808; Learning rate 0.000539;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.081072; Mean training F1 0.938830; Mean validation loss 0.074481; Mean validation F1 0.939049; Learning rate 0.000527;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.081175; Mean training F1 0.938593; Mean validation loss 0.109968; Mean validation F1 0.938471; Learning rate 0.000515;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.081021; Mean training F1 0.938744; Mean validation loss 0.087448; Mean validation F1 0.938567; Learning rate 0.000503;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.080948; Mean training F1 0.938730; Mean validation loss 0.059845; Mean validation F1 0.938044; Learning rate 0.000491;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.080787; Mean training F1 0.938944; Mean validation loss 0.083815; Mean validation F1 0.938756; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.080726; Mean training F1 0.938908; Mean validation loss 0.094813; Mean validation F1 0.938794; Learning rate 0.000466;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.080819; Mean training F1 0.938832; Mean validation loss 0.057930; Mean validation F1 0.938962; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.080783; Mean training F1 0.938812; Mean validation loss 0.075743; Mean validation F1 0.938192; Learning rate 0.000442;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.080923; Mean training F1 0.938851; Mean validation loss 0.102607; Mean validation F1 0.937747; Learning rate 0.000430;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.080737; Mean training F1 0.938913; Mean validation loss 0.092871; Mean validation F1 0.938435; Learning rate 0.000418;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.080391; Mean training F1 0.939062; Mean validation loss 0.061140; Mean validation F1 0.938492; Learning rate 0.000406;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.080184; Mean training F1 0.939318; Mean validation loss 0.081951; Mean validation F1 0.938479; Learning rate 0.000394;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.080001; Mean training F1 0.939280; Mean validation loss 0.069261; Mean validation F1 0.938708; Learning rate 0.000382;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.080091; Mean training F1 0.939417; Mean validation loss 0.064174; Mean validation F1 0.938634; Learning rate 0.000370;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.079971; Mean training F1 0.939220; Mean validation loss 0.067905; Mean validation F1 0.937594; Learning rate 0.000358;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.079948; Mean training F1 0.939253; Mean validation loss 0.069033; Mean validation F1 0.938733; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.079876; Mean training F1 0.939280; Mean validation loss 0.072592; Mean validation F1 0.938670; Learning rate 0.000335;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.079787; Mean training F1 0.939406; Mean validation loss 0.098283; Mean validation F1 0.938314; Learning rate 0.000324;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.079730; Mean training F1 0.939388; Mean validation loss 0.086026; Mean validation F1 0.939102; Learning rate 0.000312;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.079613; Mean training F1 0.939353; Mean validation loss 0.087544; Mean validation F1 0.938796; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.079612; Mean training F1 0.939587; Mean validation loss 0.069532; Mean validation F1 0.938840; Learning rate 0.000290;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.079361; Mean training F1 0.939596; Mean validation loss 0.091430; Mean validation F1 0.938614; Learning rate 0.000279;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.079314; Mean training F1 0.939672; Mean validation loss 0.088936; Mean validation F1 0.938846; Learning rate 0.000268;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.079275; Mean training F1 0.939571; Mean validation loss 0.101969; Mean validation F1 0.938673; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.079205; Mean training F1 0.939558; Mean validation loss 0.066855; Mean validation F1 0.938933; Learning rate 0.000247;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.079055; Mean training F1 0.939737; Mean validation loss 0.108587; Mean validation F1 0.938718; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.079157; Mean training F1 0.939638; Mean validation loss 0.060995; Mean validation F1 0.938591; Learning rate 0.000226;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.079038; Mean training F1 0.939750; Mean validation loss 0.098749; Mean validation F1 0.939047; Learning rate 0.000216;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.078988; Mean training F1 0.939785; Mean validation loss 0.096209; Mean validation F1 0.938839; Learning rate 0.000206;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.078977; Mean training F1 0.939610; Mean validation loss 0.088708; Mean validation F1 0.938680; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.078747; Mean training F1 0.939878; Mean validation loss 0.072333; Mean validation F1 0.938721; Learning rate 0.000187;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.078648; Mean training F1 0.940015; Mean validation loss 0.087212; Mean validation F1 0.938942; Learning rate 0.000178;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.078644; Mean training F1 0.940016; Mean validation loss 0.085068; Mean validation F1 0.939028; Learning rate 0.000169;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.078568; Mean training F1 0.940048; Mean validation loss 0.088233; Mean validation F1 0.938833; Learning rate 0.000160;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.078503; Mean training F1 0.940062; Mean validation loss 0.090302; Mean validation F1 0.938936; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.078428; Mean training F1 0.940149; Mean validation loss 0.081373; Mean validation F1 0.938850; Learning rate 0.000142;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.078340; Mean training F1 0.940137; Mean validation loss 0.067592; Mean validation F1 0.938755; Learning rate 0.000134;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.078305; Mean training F1 0.940130; Mean validation loss 0.077309; Mean validation F1 0.938849; Learning rate 0.000126;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.078249; Mean training F1 0.940138; Mean validation loss 0.093907; Mean validation F1 0.938428; Learning rate 0.000118;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.078170; Mean training F1 0.940133; Mean validation loss 0.058795; Mean validation F1 0.938775; Learning rate 0.000111;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.078126; Mean training F1 0.940259; Mean validation loss 0.073894; Mean validation F1 0.938695; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.078076; Mean training F1 0.940306; Mean validation loss 0.078907; Mean validation F1 0.938789; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.078032; Mean training F1 0.940318; Mean validation loss 0.093292; Mean validation F1 0.938834; Learning rate 0.000089;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.077966; Mean training F1 0.940321; Mean validation loss 0.089140; Mean validation F1 0.938842; Learning rate 0.000082;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.077922; Mean training F1 0.940377; Mean validation loss 0.104637; Mean validation F1 0.938749; Learning rate 0.000076;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.077859; Mean training F1 0.940382; Mean validation loss 0.094352; Mean validation F1 0.938762; Learning rate 0.000070;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.077830; Mean training F1 0.940454; Mean validation loss 0.068284; Mean validation F1 0.938672; Learning rate 0.000064;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.077812; Mean training F1 0.940432; Mean validation loss 0.079196; Mean validation F1 0.938962; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.077763; Mean training F1 0.940603; Mean validation loss 0.064695; Mean validation F1 0.938930; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.077716; Mean training F1 0.940502; Mean validation loss 0.068687; Mean validation F1 0.938956; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.077670; Mean training F1 0.940445; Mean validation loss 0.081304; Mean validation F1 0.938951; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.077646; Mean training F1 0.940581; Mean validation loss 0.095735; Mean validation F1 0.938962; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.077609; Mean training F1 0.940590; Mean validation loss 0.043709; Mean validation F1 0.938944; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.077586; Mean training F1 0.940544; Mean validation loss 0.092632; Mean validation F1 0.938992; Learning rate 0.000030;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.077557; Mean training F1 0.940667; Mean validation loss 0.074065; Mean validation F1 0.939085; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.077526; Mean training F1 0.940590; Mean validation loss 0.097651; Mean validation F1 0.938877; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.077519; Mean training F1 0.940553; Mean validation loss 0.071006; Mean validation F1 0.938956; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.077487; Mean training F1 0.940687; Mean validation loss 0.098572; Mean validation F1 0.938942; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.077472; Mean training F1 0.940656; Mean validation loss 0.092661; Mean validation F1 0.938827; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.077462; Mean training F1 0.940615; Mean validation loss 0.087930; Mean validation F1 0.938898; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.077440; Mean training F1 0.940658; Mean validation loss 0.108049; Mean validation F1 0.938977; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.077421; Mean training F1 0.940651; Mean validation loss 0.068430; Mean validation F1 0.938959; Learning rate 0.000009;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.077417; Mean training F1 0.940658; Mean validation loss 0.057854; Mean validation F1 0.938952; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.077402; Mean training F1 0.940684; Mean validation loss 0.063096; Mean validation F1 0.938986; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.077394; Mean training F1 0.940702; Mean validation loss 0.063610; Mean validation F1 0.939032; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.077392; Mean training F1 0.940715; Mean validation loss 0.085186; Mean validation F1 0.939013; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.077384; Mean training F1 0.940705; Mean validation loss 0.080539; Mean validation F1 0.939016; Learning rate 0.000005;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "################################################################\n",
    "Training/validation for fold 1/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.838500; Mean training F1 0.538598; Mean validation loss 0.486150; Mean validation F1 0.665224; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.289376; Mean training F1 0.842213; Mean validation loss 0.194429; Mean validation F1 0.904446; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.125393; Mean training F1 0.920844; Mean validation loss 0.084292; Mean validation F1 0.930551; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.099851; Mean training F1 0.931416; Mean validation loss 0.094166; Mean validation F1 0.932679; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.093579; Mean training F1 0.933371; Mean validation loss 0.088609; Mean validation F1 0.933992; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.091817; Mean training F1 0.933804; Mean validation loss 0.155121; Mean validation F1 0.933476; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.093615; Mean training F1 0.931924; Mean validation loss 0.072296; Mean validation F1 0.932354; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.112363; Mean training F1 0.925215; Mean validation loss 0.064969; Mean validation F1 0.914472; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.092679; Mean training F1 0.932680; Mean validation loss 0.051306; Mean validation F1 0.936473; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.087333; Mean training F1 0.935296; Mean validation loss 0.070151; Mean validation F1 0.935772; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.087845; Mean training F1 0.934504; Mean validation loss 0.070722; Mean validation F1 0.936500; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.086176; Mean training F1 0.936112; Mean validation loss 0.102885; Mean validation F1 0.937133; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.085876; Mean training F1 0.936211; Mean validation loss 0.055908; Mean validation F1 0.936297; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.088892; Mean training F1 0.935077; Mean validation loss 0.075586; Mean validation F1 0.932071; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.085836; Mean training F1 0.935955; Mean validation loss 0.091464; Mean validation F1 0.937006; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.085747; Mean training F1 0.935787; Mean validation loss 0.107201; Mean validation F1 0.936673; Learning rate 0.000962;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.085878; Mean training F1 0.935709; Mean validation loss 0.057131; Mean validation F1 0.936988; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.085145; Mean training F1 0.936307; Mean validation loss 0.069247; Mean validation F1 0.936567; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.085551; Mean training F1 0.935781; Mean validation loss 0.085927; Mean validation F1 0.935659; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.084238; Mean training F1 0.936831; Mean validation loss 0.105815; Mean validation F1 0.937791; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.084258; Mean training F1 0.936918; Mean validation loss 0.096534; Mean validation F1 0.937670; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.084451; Mean training F1 0.936883; Mean validation loss 0.085800; Mean validation F1 0.936652; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.084655; Mean training F1 0.936247; Mean validation loss 0.083521; Mean validation F1 0.930647; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.083564; Mean training F1 0.936976; Mean validation loss 0.059335; Mean validation F1 0.937035; Learning rate 0.000916;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.084043; Mean training F1 0.936982; Mean validation loss 0.094815; Mean validation F1 0.937324; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.084334; Mean training F1 0.936770; Mean validation loss 0.122911; Mean validation F1 0.937635; Learning rate 0.000902;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.083853; Mean training F1 0.936866; Mean validation loss 0.084877; Mean validation F1 0.938045; Learning rate 0.000895;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.083553; Mean training F1 0.937086; Mean validation loss 0.068763; Mean validation F1 0.934071; Learning rate 0.000887;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.083577; Mean training F1 0.937028; Mean validation loss 0.093721; Mean validation F1 0.937563; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.084041; Mean training F1 0.936877; Mean validation loss 0.055392; Mean validation F1 0.937452; Learning rate 0.000871;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.083220; Mean training F1 0.937379; Mean validation loss 0.077404; Mean validation F1 0.937247; Learning rate 0.000863;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.083679; Mean training F1 0.937125; Mean validation loss 0.066738; Mean validation F1 0.937265; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.083533; Mean training F1 0.937196; Mean validation loss 0.079020; Mean validation F1 0.935038; Learning rate 0.000846;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.096692; Mean training F1 0.928494; Mean validation loss 0.061796; Mean validation F1 0.936990; Learning rate 0.000837;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.083964; Mean training F1 0.936702; Mean validation loss 0.080806; Mean validation F1 0.937781; Learning rate 0.000828;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.082948; Mean training F1 0.937157; Mean validation loss 0.057059; Mean validation F1 0.936405; Learning rate 0.000818;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.082749; Mean training F1 0.937544; Mean validation loss 0.075980; Mean validation F1 0.937707; Learning rate 0.000809;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.083212; Mean training F1 0.937380; Mean validation loss 0.084074; Mean validation F1 0.936277; Learning rate 0.000799;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.082247; Mean training F1 0.937822; Mean validation loss 0.074664; Mean validation F1 0.937618; Learning rate 0.000789;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.082173; Mean training F1 0.938117; Mean validation loss 0.075197; Mean validation F1 0.937448; Learning rate 0.000779;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.082563; Mean training F1 0.937835; Mean validation loss 0.061183; Mean validation F1 0.938000; Learning rate 0.000769;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.082448; Mean training F1 0.937852; Mean validation loss 0.083763; Mean validation F1 0.937958; Learning rate 0.000759;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.081973; Mean training F1 0.938077; Mean validation loss 0.085185; Mean validation F1 0.938214; Learning rate 0.000748;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.082168; Mean training F1 0.937811; Mean validation loss 0.064130; Mean validation F1 0.936493; Learning rate 0.000737;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.084580; Mean training F1 0.936355; Mean validation loss 0.088983; Mean validation F1 0.938231; Learning rate 0.000726;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.081857; Mean training F1 0.938075; Mean validation loss 0.039058; Mean validation F1 0.937466; Learning rate 0.000716;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.081909; Mean training F1 0.937970; Mean validation loss 0.071545; Mean validation F1 0.937512; Learning rate 0.000704;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.082269; Mean training F1 0.938040; Mean validation loss 0.102459; Mean validation F1 0.937387; Learning rate 0.000693;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.081988; Mean training F1 0.937800; Mean validation loss 0.062221; Mean validation F1 0.937800; Learning rate 0.000682;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.081454; Mean training F1 0.938295; Mean validation loss 0.058736; Mean validation F1 0.935766; Learning rate 0.000670;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.081580; Mean training F1 0.938283; Mean validation loss 0.114426; Mean validation F1 0.938504; Learning rate 0.000659;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.081320; Mean training F1 0.938369; Mean validation loss 0.079432; Mean validation F1 0.937320; Learning rate 0.000647;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.081129; Mean training F1 0.938354; Mean validation loss 0.074714; Mean validation F1 0.938606; Learning rate 0.000635;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.081173; Mean training F1 0.938274; Mean validation loss 0.125322; Mean validation F1 0.938128; Learning rate 0.000624;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.081198; Mean training F1 0.938393; Mean validation loss 0.097749; Mean validation F1 0.937721; Learning rate 0.000612;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.081342; Mean training F1 0.938313; Mean validation loss 0.109902; Mean validation F1 0.938085; Learning rate 0.000600;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.081030; Mean training F1 0.938369; Mean validation loss 0.045113; Mean validation F1 0.937867; Learning rate 0.000588;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.081005; Mean training F1 0.938507; Mean validation loss 0.070924; Mean validation F1 0.938326; Learning rate 0.000576;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.080726; Mean training F1 0.938710; Mean validation loss 0.066853; Mean validation F1 0.937866; Learning rate 0.000564;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.081205; Mean training F1 0.937953; Mean validation loss 0.047436; Mean validation F1 0.937204; Learning rate 0.000552;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.080813; Mean training F1 0.938562; Mean validation loss 0.065987; Mean validation F1 0.938125; Learning rate 0.000539;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.081328; Mean training F1 0.938147; Mean validation loss 0.067567; Mean validation F1 0.938001; Learning rate 0.000527;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.080722; Mean training F1 0.938649; Mean validation loss 0.088060; Mean validation F1 0.938363; Learning rate 0.000515;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.081049; Mean training F1 0.938255; Mean validation loss 0.102641; Mean validation F1 0.937959; Learning rate 0.000503;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.080944; Mean training F1 0.938443; Mean validation loss 0.064368; Mean validation F1 0.937693; Learning rate 0.000491;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.080625; Mean training F1 0.938758; Mean validation loss 0.090675; Mean validation F1 0.938806; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.080362; Mean training F1 0.938868; Mean validation loss 0.097246; Mean validation F1 0.938627; Learning rate 0.000466;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.080418; Mean training F1 0.938742; Mean validation loss 0.101456; Mean validation F1 0.937913; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.080265; Mean training F1 0.939051; Mean validation loss 0.075328; Mean validation F1 0.938339; Learning rate 0.000442;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.080132; Mean training F1 0.938927; Mean validation loss 0.109805; Mean validation F1 0.938144; Learning rate 0.000430;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.080079; Mean training F1 0.938864; Mean validation loss 0.074679; Mean validation F1 0.938639; Learning rate 0.000418;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.080069; Mean training F1 0.938844; Mean validation loss 0.060494; Mean validation F1 0.936849; Learning rate 0.000406;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.080343; Mean training F1 0.938810; Mean validation loss 0.067415; Mean validation F1 0.938514; Learning rate 0.000394;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.079594; Mean training F1 0.939212; Mean validation loss 0.097484; Mean validation F1 0.936399; Learning rate 0.000382;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.079842; Mean training F1 0.939051; Mean validation loss 0.064662; Mean validation F1 0.938771; Learning rate 0.000370;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.079619; Mean training F1 0.939314; Mean validation loss 0.080122; Mean validation F1 0.938481; Learning rate 0.000358;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.079619; Mean training F1 0.939093; Mean validation loss 0.083602; Mean validation F1 0.938337; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.079516; Mean training F1 0.939191; Mean validation loss 0.030956; Mean validation F1 0.938011; Learning rate 0.000335;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.079660; Mean training F1 0.939054; Mean validation loss 0.095091; Mean validation F1 0.936903; Learning rate 0.000324;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.079335; Mean training F1 0.939374; Mean validation loss 0.068696; Mean validation F1 0.937787; Learning rate 0.000312;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.079302; Mean training F1 0.939287; Mean validation loss 0.042448; Mean validation F1 0.938588; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.079149; Mean training F1 0.939359; Mean validation loss 0.067755; Mean validation F1 0.938102; Learning rate 0.000290;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.078996; Mean training F1 0.939504; Mean validation loss 0.091622; Mean validation F1 0.938421; Learning rate 0.000279;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.078972; Mean training F1 0.939550; Mean validation loss 0.076066; Mean validation F1 0.938316; Learning rate 0.000268;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.078922; Mean training F1 0.939634; Mean validation loss 0.077693; Mean validation F1 0.938298; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.079039; Mean training F1 0.939495; Mean validation loss 0.104044; Mean validation F1 0.938670; Learning rate 0.000247;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.078971; Mean training F1 0.939524; Mean validation loss 0.081477; Mean validation F1 0.937998; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.078969; Mean training F1 0.939585; Mean validation loss 0.128349; Mean validation F1 0.938383; Learning rate 0.000226;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.078830; Mean training F1 0.939659; Mean validation loss 0.096286; Mean validation F1 0.938661; Learning rate 0.000216;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.078669; Mean training F1 0.939653; Mean validation loss 0.069888; Mean validation F1 0.938784; Learning rate 0.000206;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.078648; Mean training F1 0.939690; Mean validation loss 0.069648; Mean validation F1 0.938452; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.078525; Mean training F1 0.939872; Mean validation loss 0.095792; Mean validation F1 0.938130; Learning rate 0.000187;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.078561; Mean training F1 0.939774; Mean validation loss 0.079340; Mean validation F1 0.938529; Learning rate 0.000178;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.078444; Mean training F1 0.939922; Mean validation loss 0.091151; Mean validation F1 0.938757; Learning rate 0.000169;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.078332; Mean training F1 0.939887; Mean validation loss 0.080120; Mean validation F1 0.938381; Learning rate 0.000160;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.078267; Mean training F1 0.939902; Mean validation loss 0.107709; Mean validation F1 0.938673; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.078246; Mean training F1 0.939926; Mean validation loss 0.049920; Mean validation F1 0.938596; Learning rate 0.000142;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.078126; Mean training F1 0.939972; Mean validation loss 0.069480; Mean validation F1 0.938078; Learning rate 0.000134;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.078066; Mean training F1 0.939965; Mean validation loss 0.058480; Mean validation F1 0.938285; Learning rate 0.000126;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.078111; Mean training F1 0.939909; Mean validation loss 0.072989; Mean validation F1 0.938620; Learning rate 0.000118;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.078029; Mean training F1 0.940045; Mean validation loss 0.088296; Mean validation F1 0.938385; Learning rate 0.000111;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.077983; Mean training F1 0.940093; Mean validation loss 0.074747; Mean validation F1 0.938521; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.077907; Mean training F1 0.940018; Mean validation loss 0.079471; Mean validation F1 0.938676; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.077859; Mean training F1 0.940126; Mean validation loss 0.080577; Mean validation F1 0.938702; Learning rate 0.000089;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.077822; Mean training F1 0.940142; Mean validation loss 0.093933; Mean validation F1 0.938670; Learning rate 0.000082;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.077789; Mean training F1 0.940141; Mean validation loss 0.069450; Mean validation F1 0.938600; Learning rate 0.000076;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.077748; Mean training F1 0.940113; Mean validation loss 0.090786; Mean validation F1 0.938669; Learning rate 0.000070;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.077717; Mean training F1 0.940170; Mean validation loss 0.070580; Mean validation F1 0.938655; Learning rate 0.000064;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.077659; Mean training F1 0.940190; Mean validation loss 0.049379; Mean validation F1 0.938553; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.077614; Mean training F1 0.940101; Mean validation loss 0.115942; Mean validation F1 0.938785; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.077585; Mean training F1 0.940282; Mean validation loss 0.050386; Mean validation F1 0.938649; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.077568; Mean training F1 0.940263; Mean validation loss 0.105715; Mean validation F1 0.938505; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.077529; Mean training F1 0.940200; Mean validation loss 0.050623; Mean validation F1 0.938677; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.077502; Mean training F1 0.940289; Mean validation loss 0.083957; Mean validation F1 0.938802; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.077477; Mean training F1 0.940359; Mean validation loss 0.102087; Mean validation F1 0.938688; Learning rate 0.000030;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.077452; Mean training F1 0.940326; Mean validation loss 0.108553; Mean validation F1 0.938774; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.077433; Mean training F1 0.940422; Mean validation loss 0.058680; Mean validation F1 0.938778; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.077402; Mean training F1 0.940328; Mean validation loss 0.092133; Mean validation F1 0.938759; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.077378; Mean training F1 0.940383; Mean validation loss 0.074715; Mean validation F1 0.938818; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.077377; Mean training F1 0.940387; Mean validation loss 0.079695; Mean validation F1 0.938739; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.077359; Mean training F1 0.940409; Mean validation loss 0.081765; Mean validation F1 0.938818; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.077339; Mean training F1 0.940360; Mean validation loss 0.092416; Mean validation F1 0.938884; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.077329; Mean training F1 0.940371; Mean validation loss 0.063807; Mean validation F1 0.938878; Learning rate 0.000009;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.077316; Mean training F1 0.940433; Mean validation loss 0.090842; Mean validation F1 0.938700; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.077306; Mean training F1 0.940383; Mean validation loss 0.105063; Mean validation F1 0.938709; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.077299; Mean training F1 0.940453; Mean validation loss 0.073976; Mean validation F1 0.938842; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.077298; Mean training F1 0.940406; Mean validation loss 0.067753; Mean validation F1 0.938792; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.077289; Mean training F1 0.940353; Mean validation loss 0.099383; Mean validation F1 0.938697; Learning rate 0.000005;\n",
    "################################################################\n",
    "Training/validation for fold 2/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.738883; Mean training F1 0.568160; Mean validation loss 0.328471; Mean validation F1 0.767359; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.235716; Mean training F1 0.866304; Mean validation loss 0.251217; Mean validation F1 0.916215; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.111666; Mean training F1 0.926675; Mean validation loss 0.093454; Mean validation F1 0.928979; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.097828; Mean training F1 0.931780; Mean validation loss 0.071565; Mean validation F1 0.932198; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.094110; Mean training F1 0.932170; Mean validation loss 0.104587; Mean validation F1 0.932975; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.089737; Mean training F1 0.934734; Mean validation loss 0.082854; Mean validation F1 0.933932; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.093265; Mean training F1 0.932205; Mean validation loss 0.112008; Mean validation F1 0.930152; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.092065; Mean training F1 0.932128; Mean validation loss 0.071453; Mean validation F1 0.934114; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.087214; Mean training F1 0.935983; Mean validation loss 0.069973; Mean validation F1 0.933809; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.088804; Mean training F1 0.934508; Mean validation loss 0.051108; Mean validation F1 0.934151; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.086282; Mean training F1 0.936218; Mean validation loss 0.056267; Mean validation F1 0.934467; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.086139; Mean training F1 0.936167; Mean validation loss 0.078869; Mean validation F1 0.934577; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.086020; Mean training F1 0.935999; Mean validation loss 0.068953; Mean validation F1 0.935101; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.194186; Mean training F1 0.896472; Mean validation loss 0.053285; Mean validation F1 0.930370; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.091210; Mean training F1 0.934472; Mean validation loss 0.144420; Mean validation F1 0.933497; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.088013; Mean training F1 0.935748; Mean validation loss 0.084848; Mean validation F1 0.934002; Learning rate 0.000962;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.087097; Mean training F1 0.936005; Mean validation loss 0.065916; Mean validation F1 0.934754; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.086771; Mean training F1 0.936000; Mean validation loss 0.120961; Mean validation F1 0.932962; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.086925; Mean training F1 0.935708; Mean validation loss 0.119358; Mean validation F1 0.935021; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.085646; Mean training F1 0.936599; Mean validation loss 0.066553; Mean validation F1 0.934721; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.085740; Mean training F1 0.936367; Mean validation loss 0.129220; Mean validation F1 0.935675; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.085391; Mean training F1 0.936321; Mean validation loss 0.095694; Mean validation F1 0.934972; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.085035; Mean training F1 0.936469; Mean validation loss 0.091282; Mean validation F1 0.934991; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.084637; Mean training F1 0.936830; Mean validation loss 0.094912; Mean validation F1 0.935213; Learning rate 0.000916;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.084642; Mean training F1 0.936769; Mean validation loss 0.089540; Mean validation F1 0.935248; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.084597; Mean training F1 0.936898; Mean validation loss 0.095083; Mean validation F1 0.935462; Learning rate 0.000902;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.084779; Mean training F1 0.936613; Mean validation loss 0.081309; Mean validation F1 0.935457; Learning rate 0.000895;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.084189; Mean training F1 0.937038; Mean validation loss 0.071440; Mean validation F1 0.935875; Learning rate 0.000887;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.091194; Mean training F1 0.933112; Mean validation loss 0.066699; Mean validation F1 0.935519; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.084479; Mean training F1 0.937112; Mean validation loss 0.085435; Mean validation F1 0.935269; Learning rate 0.000871;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.084295; Mean training F1 0.936980; Mean validation loss 0.079564; Mean validation F1 0.935880; Learning rate 0.000863;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.084553; Mean training F1 0.937020; Mean validation loss 0.108732; Mean validation F1 0.935179; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.083618; Mean training F1 0.937366; Mean validation loss 0.102528; Mean validation F1 0.935537; Learning rate 0.000846;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.084956; Mean training F1 0.936598; Mean validation loss 0.079501; Mean validation F1 0.933474; Learning rate 0.000837;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.083834; Mean training F1 0.937059; Mean validation loss 0.093356; Mean validation F1 0.935927; Learning rate 0.000828;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.085545; Mean training F1 0.936320; Mean validation loss 0.122784; Mean validation F1 0.936064; Learning rate 0.000818;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.083437; Mean training F1 0.937591; Mean validation loss 0.054209; Mean validation F1 0.935262; Learning rate 0.000809;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.083628; Mean training F1 0.936976; Mean validation loss 0.081730; Mean validation F1 0.936252; Learning rate 0.000799;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.083164; Mean training F1 0.937541; Mean validation loss 0.084508; Mean validation F1 0.931771; Learning rate 0.000789;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.083416; Mean training F1 0.937252; Mean validation loss 0.091509; Mean validation F1 0.935054; Learning rate 0.000779;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.082997; Mean training F1 0.937226; Mean validation loss 0.051391; Mean validation F1 0.928123; Learning rate 0.000769;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.083177; Mean training F1 0.937203; Mean validation loss 0.107987; Mean validation F1 0.936486; Learning rate 0.000759;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.082653; Mean training F1 0.937693; Mean validation loss 0.087404; Mean validation F1 0.936034; Learning rate 0.000748;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.082351; Mean training F1 0.937858; Mean validation loss 0.069201; Mean validation F1 0.935969; Learning rate 0.000737;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.082488; Mean training F1 0.937817; Mean validation loss 0.057102; Mean validation F1 0.934943; Learning rate 0.000726;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.084153; Mean training F1 0.936180; Mean validation loss 0.081747; Mean validation F1 0.934225; Learning rate 0.000716;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.082592; Mean training F1 0.937585; Mean validation loss 0.060484; Mean validation F1 0.935277; Learning rate 0.000704;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.082357; Mean training F1 0.937952; Mean validation loss 0.096274; Mean validation F1 0.936014; Learning rate 0.000693;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.082175; Mean training F1 0.937844; Mean validation loss 0.067959; Mean validation F1 0.936714; Learning rate 0.000682;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.082662; Mean training F1 0.937465; Mean validation loss 0.077502; Mean validation F1 0.936691; Learning rate 0.000670;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.081960; Mean training F1 0.938130; Mean validation loss 0.080051; Mean validation F1 0.936102; Learning rate 0.000659;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.082002; Mean training F1 0.937899; Mean validation loss 0.066565; Mean validation F1 0.935029; Learning rate 0.000647;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.082657; Mean training F1 0.937431; Mean validation loss 0.065271; Mean validation F1 0.936466; Learning rate 0.000635;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.081801; Mean training F1 0.938179; Mean validation loss 0.096164; Mean validation F1 0.936920; Learning rate 0.000624;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.081621; Mean training F1 0.938288; Mean validation loss 0.074305; Mean validation F1 0.936797; Learning rate 0.000612;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.081598; Mean training F1 0.938086; Mean validation loss 0.076662; Mean validation F1 0.935317; Learning rate 0.000600;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.081633; Mean training F1 0.938170; Mean validation loss 0.070317; Mean validation F1 0.936658; Learning rate 0.000588;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.081489; Mean training F1 0.938131; Mean validation loss 0.090437; Mean validation F1 0.935386; Learning rate 0.000576;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.081230; Mean training F1 0.938176; Mean validation loss 0.117929; Mean validation F1 0.936350; Learning rate 0.000564;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.081422; Mean training F1 0.938249; Mean validation loss 0.063278; Mean validation F1 0.935501; Learning rate 0.000552;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.081456; Mean training F1 0.938138; Mean validation loss 0.101607; Mean validation F1 0.936635; Learning rate 0.000539;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.081844; Mean training F1 0.937748; Mean validation loss 0.084044; Mean validation F1 0.936286; Learning rate 0.000527;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.081074; Mean training F1 0.938379; Mean validation loss 0.093020; Mean validation F1 0.935604; Learning rate 0.000515;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.081518; Mean training F1 0.938217; Mean validation loss 0.070591; Mean validation F1 0.934947; Learning rate 0.000503;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.081015; Mean training F1 0.938577; Mean validation loss 0.055673; Mean validation F1 0.936672; Learning rate 0.000491;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.080785; Mean training F1 0.938713; Mean validation loss 0.069304; Mean validation F1 0.936886; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.080608; Mean training F1 0.938614; Mean validation loss 0.084070; Mean validation F1 0.936892; Learning rate 0.000466;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.080736; Mean training F1 0.938619; Mean validation loss 0.084487; Mean validation F1 0.936091; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.080682; Mean training F1 0.938571; Mean validation loss 0.032299; Mean validation F1 0.936253; Learning rate 0.000442;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.080437; Mean training F1 0.938719; Mean validation loss 0.068792; Mean validation F1 0.936147; Learning rate 0.000430;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.080569; Mean training F1 0.938693; Mean validation loss 0.084363; Mean validation F1 0.937027; Learning rate 0.000418;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.079933; Mean training F1 0.939033; Mean validation loss 0.119480; Mean validation F1 0.936716; Learning rate 0.000406;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.080028; Mean training F1 0.938912; Mean validation loss 0.068005; Mean validation F1 0.936714; Learning rate 0.000394;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.079883; Mean training F1 0.938940; Mean validation loss 0.071234; Mean validation F1 0.936371; Learning rate 0.000382;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.080159; Mean training F1 0.938898; Mean validation loss 0.037464; Mean validation F1 0.936846; Learning rate 0.000370;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.080108; Mean training F1 0.938818; Mean validation loss 0.098958; Mean validation F1 0.937008; Learning rate 0.000358;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.079958; Mean training F1 0.938896; Mean validation loss 0.076214; Mean validation F1 0.936855; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.080026; Mean training F1 0.938702; Mean validation loss 0.093651; Mean validation F1 0.936550; Learning rate 0.000335;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.080887; Mean training F1 0.938813; Mean validation loss 0.053908; Mean validation F1 0.936900; Learning rate 0.000324;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.080019; Mean training F1 0.939128; Mean validation loss 0.078389; Mean validation F1 0.936891; Learning rate 0.000312;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.079540; Mean training F1 0.939226; Mean validation loss 0.083537; Mean validation F1 0.936737; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.079347; Mean training F1 0.939444; Mean validation loss 0.085875; Mean validation F1 0.936835; Learning rate 0.000290;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.079552; Mean training F1 0.939043; Mean validation loss 0.045567; Mean validation F1 0.936524; Learning rate 0.000279;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.079253; Mean training F1 0.939395; Mean validation loss 0.074219; Mean validation F1 0.937239; Learning rate 0.000268;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.079436; Mean training F1 0.939218; Mean validation loss 0.077172; Mean validation F1 0.937084; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.079238; Mean training F1 0.939438; Mean validation loss 0.071562; Mean validation F1 0.937303; Learning rate 0.000247;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.079157; Mean training F1 0.939344; Mean validation loss 0.068566; Mean validation F1 0.937220; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.079067; Mean training F1 0.939479; Mean validation loss 0.094895; Mean validation F1 0.937152; Learning rate 0.000226;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.079025; Mean training F1 0.939525; Mean validation loss 0.122912; Mean validation F1 0.937386; Learning rate 0.000216;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.078927; Mean training F1 0.939511; Mean validation loss 0.121337; Mean validation F1 0.937100; Learning rate 0.000206;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.078947; Mean training F1 0.939515; Mean validation loss 0.093903; Mean validation F1 0.937438; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.078861; Mean training F1 0.939517; Mean validation loss 0.079178; Mean validation F1 0.937508; Learning rate 0.000187;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.078728; Mean training F1 0.939670; Mean validation loss 0.052629; Mean validation F1 0.936991; Learning rate 0.000178;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.078836; Mean training F1 0.939525; Mean validation loss 0.101178; Mean validation F1 0.937295; Learning rate 0.000169;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.078607; Mean training F1 0.939752; Mean validation loss 0.095019; Mean validation F1 0.937291; Learning rate 0.000160;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.078587; Mean training F1 0.939783; Mean validation loss 0.069672; Mean validation F1 0.937317; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.078481; Mean training F1 0.939790; Mean validation loss 0.105460; Mean validation F1 0.937284; Learning rate 0.000142;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.078432; Mean training F1 0.939820; Mean validation loss 0.091903; Mean validation F1 0.937467; Learning rate 0.000134;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.078439; Mean training F1 0.939766; Mean validation loss 0.079645; Mean validation F1 0.937459; Learning rate 0.000126;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.078388; Mean training F1 0.939970; Mean validation loss 0.089512; Mean validation F1 0.937300; Learning rate 0.000118;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.078421; Mean training F1 0.939841; Mean validation loss 0.069154; Mean validation F1 0.936809; Learning rate 0.000111;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.078339; Mean training F1 0.939855; Mean validation loss 0.082785; Mean validation F1 0.937191; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.078311; Mean training F1 0.939963; Mean validation loss 0.074645; Mean validation F1 0.937376; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.078298; Mean training F1 0.939850; Mean validation loss 0.073272; Mean validation F1 0.937287; Learning rate 0.000089;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.078220; Mean training F1 0.939955; Mean validation loss 0.079753; Mean validation F1 0.937389; Learning rate 0.000082;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.078147; Mean training F1 0.940037; Mean validation loss 0.076705; Mean validation F1 0.937575; Learning rate 0.000076;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.078075; Mean training F1 0.940042; Mean validation loss 0.087867; Mean validation F1 0.937389; Learning rate 0.000070;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.078065; Mean training F1 0.940008; Mean validation loss 0.114966; Mean validation F1 0.937471; Learning rate 0.000064;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.078018; Mean training F1 0.940104; Mean validation loss 0.087786; Mean validation F1 0.937405; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.078030; Mean training F1 0.940057; Mean validation loss 0.069438; Mean validation F1 0.937333; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.077968; Mean training F1 0.940149; Mean validation loss 0.075857; Mean validation F1 0.937535; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.077979; Mean training F1 0.940063; Mean validation loss 0.093137; Mean validation F1 0.937457; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.077898; Mean training F1 0.940169; Mean validation loss 0.070152; Mean validation F1 0.937618; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.077879; Mean training F1 0.940162; Mean validation loss 0.079415; Mean validation F1 0.937600; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.077862; Mean training F1 0.940139; Mean validation loss 0.055804; Mean validation F1 0.937513; Learning rate 0.000030;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.077835; Mean training F1 0.940196; Mean validation loss 0.061431; Mean validation F1 0.937486; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.077796; Mean training F1 0.940284; Mean validation loss 0.082237; Mean validation F1 0.937434; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.077792; Mean training F1 0.940255; Mean validation loss 0.048353; Mean validation F1 0.937372; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.077779; Mean training F1 0.940215; Mean validation loss 0.077597; Mean validation F1 0.937425; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.077759; Mean training F1 0.940255; Mean validation loss 0.056132; Mean validation F1 0.937537; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.077737; Mean training F1 0.940280; Mean validation loss 0.101882; Mean validation F1 0.937341; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.077735; Mean training F1 0.940282; Mean validation loss 0.053888; Mean validation F1 0.937495; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.077721; Mean training F1 0.940258; Mean validation loss 0.069805; Mean validation F1 0.937545; Learning rate 0.000009;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.077719; Mean training F1 0.940250; Mean validation loss 0.070682; Mean validation F1 0.937545; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.077700; Mean training F1 0.940279; Mean validation loss 0.116576; Mean validation F1 0.937440; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.077693; Mean training F1 0.940284; Mean validation loss 0.042082; Mean validation F1 0.937403; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.077698; Mean training F1 0.940269; Mean validation loss 0.092400; Mean validation F1 0.937581; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.077688; Mean training F1 0.940296; Mean validation loss 0.105453; Mean validation F1 0.937573; Learning rate 0.000005;\n",
    "################################################################\n",
    "Training/validation for fold 3/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.752330; Mean training F1 0.574897; Mean validation loss 0.447970; Mean validation F1 0.798380; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.213444; Mean training F1 0.883411; Mean validation loss 0.096968; Mean validation F1 0.917608; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.129254; Mean training F1 0.916073; Mean validation loss 0.102614; Mean validation F1 0.922291; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.099670; Mean training F1 0.931024; Mean validation loss 0.084689; Mean validation F1 0.931507; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.094465; Mean training F1 0.931418; Mean validation loss 0.096982; Mean validation F1 0.928866; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.089873; Mean training F1 0.934643; Mean validation loss 0.078455; Mean validation F1 0.932370; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.089398; Mean training F1 0.934620; Mean validation loss 0.145292; Mean validation F1 0.933644; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.088530; Mean training F1 0.934573; Mean validation loss 0.061206; Mean validation F1 0.934841; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.091414; Mean training F1 0.933752; Mean validation loss 0.247169; Mean validation F1 0.910559; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.107137; Mean training F1 0.923883; Mean validation loss 0.111334; Mean validation F1 0.934129; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.086845; Mean training F1 0.935355; Mean validation loss 0.101509; Mean validation F1 0.934105; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.086308; Mean training F1 0.935843; Mean validation loss 0.080763; Mean validation F1 0.935569; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.085237; Mean training F1 0.936421; Mean validation loss 0.138579; Mean validation F1 0.934761; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.085533; Mean training F1 0.936025; Mean validation loss 0.090578; Mean validation F1 0.935241; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.084818; Mean training F1 0.936732; Mean validation loss 0.061848; Mean validation F1 0.935356; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.084570; Mean training F1 0.936911; Mean validation loss 0.105058; Mean validation F1 0.936136; Learning rate 0.000962;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.084820; Mean training F1 0.936660; Mean validation loss 0.086717; Mean validation F1 0.935707; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.084085; Mean training F1 0.936950; Mean validation loss 0.093356; Mean validation F1 0.935153; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.084543; Mean training F1 0.936652; Mean validation loss 0.080232; Mean validation F1 0.934591; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.083832; Mean training F1 0.937060; Mean validation loss 0.060140; Mean validation F1 0.935063; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.083283; Mean training F1 0.937556; Mean validation loss 0.068661; Mean validation F1 0.935627; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.084120; Mean training F1 0.936361; Mean validation loss 0.087793; Mean validation F1 0.934964; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.084062; Mean training F1 0.936684; Mean validation loss 0.039667; Mean validation F1 0.935398; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.082916; Mean training F1 0.937464; Mean validation loss 0.103416; Mean validation F1 0.936237; Learning rate 0.000916;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.083050; Mean training F1 0.937452; Mean validation loss 0.073667; Mean validation F1 0.934639; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.088696; Mean training F1 0.933478; Mean validation loss 0.083036; Mean validation F1 0.935391; Learning rate 0.000902;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.084235; Mean training F1 0.936735; Mean validation loss 0.087922; Mean validation F1 0.936361; Learning rate 0.000895;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.082894; Mean training F1 0.937510; Mean validation loss 0.104108; Mean validation F1 0.935881; Learning rate 0.000887;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.083112; Mean training F1 0.937325; Mean validation loss 0.096247; Mean validation F1 0.933318; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.082605; Mean training F1 0.937336; Mean validation loss 0.094742; Mean validation F1 0.936129; Learning rate 0.000871;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.082623; Mean training F1 0.937517; Mean validation loss 0.071923; Mean validation F1 0.936236; Learning rate 0.000863;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.082343; Mean training F1 0.937671; Mean validation loss 0.057074; Mean validation F1 0.935419; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.085436; Mean training F1 0.936132; Mean validation loss 0.087619; Mean validation F1 0.932551; Learning rate 0.000846;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.085975; Mean training F1 0.935651; Mean validation loss 0.080864; Mean validation F1 0.936569; Learning rate 0.000837;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.083421; Mean training F1 0.936894; Mean validation loss 0.080773; Mean validation F1 0.935035; Learning rate 0.000828;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.082499; Mean training F1 0.937594; Mean validation loss 0.110156; Mean validation F1 0.936447; Learning rate 0.000818;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.081977; Mean training F1 0.937822; Mean validation loss 0.145296; Mean validation F1 0.937111; Learning rate 0.000809;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.081956; Mean training F1 0.937919; Mean validation loss 0.066185; Mean validation F1 0.936902; Learning rate 0.000799;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.081919; Mean training F1 0.938013; Mean validation loss 0.073496; Mean validation F1 0.935724; Learning rate 0.000789;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.081556; Mean training F1 0.938107; Mean validation loss 0.046323; Mean validation F1 0.936282; Learning rate 0.000779;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.081649; Mean training F1 0.938056; Mean validation loss 0.087597; Mean validation F1 0.936797; Learning rate 0.000769;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.081538; Mean training F1 0.938223; Mean validation loss 0.097520; Mean validation F1 0.936573; Learning rate 0.000759;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.081917; Mean training F1 0.937648; Mean validation loss 0.065823; Mean validation F1 0.936602; Learning rate 0.000748;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.081021; Mean training F1 0.938402; Mean validation loss 0.071934; Mean validation F1 0.936591; Learning rate 0.000737;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.081274; Mean training F1 0.938189; Mean validation loss 0.057942; Mean validation F1 0.936641; Learning rate 0.000726;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.080898; Mean training F1 0.938536; Mean validation loss 0.113376; Mean validation F1 0.936399; Learning rate 0.000716;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.081821; Mean training F1 0.937845; Mean validation loss 0.059535; Mean validation F1 0.935904; Learning rate 0.000704;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.081040; Mean training F1 0.938391; Mean validation loss 0.109137; Mean validation F1 0.936845; Learning rate 0.000693;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.081094; Mean training F1 0.938402; Mean validation loss 0.084273; Mean validation F1 0.936228; Learning rate 0.000682;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.081101; Mean training F1 0.937950; Mean validation loss 0.077185; Mean validation F1 0.934273; Learning rate 0.000670;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.081184; Mean training F1 0.937902; Mean validation loss 0.045057; Mean validation F1 0.936117; Learning rate 0.000659;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.080775; Mean training F1 0.938132; Mean validation loss 0.073167; Mean validation F1 0.936673; Learning rate 0.000647;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.080221; Mean training F1 0.938769; Mean validation loss 0.061997; Mean validation F1 0.937110; Learning rate 0.000635;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.080347; Mean training F1 0.938619; Mean validation loss 0.088993; Mean validation F1 0.935654; Learning rate 0.000624;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.080322; Mean training F1 0.938665; Mean validation loss 0.088629; Mean validation F1 0.936307; Learning rate 0.000612;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.080223; Mean training F1 0.938650; Mean validation loss 0.092631; Mean validation F1 0.936588; Learning rate 0.000600;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.080141; Mean training F1 0.938892; Mean validation loss 0.055881; Mean validation F1 0.936151; Learning rate 0.000588;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.079967; Mean training F1 0.939090; Mean validation loss 0.073317; Mean validation F1 0.936390; Learning rate 0.000576;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.079724; Mean training F1 0.938963; Mean validation loss 0.099095; Mean validation F1 0.934872; Learning rate 0.000564;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.079904; Mean training F1 0.938990; Mean validation loss 0.121224; Mean validation F1 0.936863; Learning rate 0.000552;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.079616; Mean training F1 0.939075; Mean validation loss 0.076475; Mean validation F1 0.937003; Learning rate 0.000539;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.079785; Mean training F1 0.939047; Mean validation loss 0.079740; Mean validation F1 0.936768; Learning rate 0.000527;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.079691; Mean training F1 0.938917; Mean validation loss 0.073632; Mean validation F1 0.936919; Learning rate 0.000515;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.079804; Mean training F1 0.938900; Mean validation loss 0.107646; Mean validation F1 0.937085; Learning rate 0.000503;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.079386; Mean training F1 0.939123; Mean validation loss 0.099172; Mean validation F1 0.937092; Learning rate 0.000491;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.080963; Mean training F1 0.938408; Mean validation loss 0.107135; Mean validation F1 0.937251; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.079576; Mean training F1 0.938949; Mean validation loss 0.079805; Mean validation F1 0.937112; Learning rate 0.000466;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.079209; Mean training F1 0.939264; Mean validation loss 0.047671; Mean validation F1 0.935905; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.079338; Mean training F1 0.939298; Mean validation loss 0.071858; Mean validation F1 0.936477; Learning rate 0.000442;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.079319; Mean training F1 0.939274; Mean validation loss 0.072516; Mean validation F1 0.936506; Learning rate 0.000430;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.078946; Mean training F1 0.939470; Mean validation loss 0.090367; Mean validation F1 0.936840; Learning rate 0.000418;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.078954; Mean training F1 0.939439; Mean validation loss 0.084700; Mean validation F1 0.936982; Learning rate 0.000406;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.078776; Mean training F1 0.939465; Mean validation loss 0.096759; Mean validation F1 0.937121; Learning rate 0.000394;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.078750; Mean training F1 0.939482; Mean validation loss 0.080171; Mean validation F1 0.936444; Learning rate 0.000382;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.078604; Mean training F1 0.939524; Mean validation loss 0.091764; Mean validation F1 0.937094; Learning rate 0.000370;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.078655; Mean training F1 0.939464; Mean validation loss 0.055374; Mean validation F1 0.936727; Learning rate 0.000358;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.078444; Mean training F1 0.939653; Mean validation loss 0.087660; Mean validation F1 0.936215; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.078455; Mean training F1 0.939643; Mean validation loss 0.088891; Mean validation F1 0.936900; Learning rate 0.000335;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.078374; Mean training F1 0.939678; Mean validation loss 0.110128; Mean validation F1 0.936567; Learning rate 0.000324;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.078379; Mean training F1 0.939589; Mean validation loss 0.075022; Mean validation F1 0.937215; Learning rate 0.000312;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.078577; Mean training F1 0.939579; Mean validation loss 0.062033; Mean validation F1 0.936798; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.078192; Mean training F1 0.939756; Mean validation loss 0.081354; Mean validation F1 0.936497; Learning rate 0.000290;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.078044; Mean training F1 0.939867; Mean validation loss 0.057929; Mean validation F1 0.936982; Learning rate 0.000279;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.077979; Mean training F1 0.940034; Mean validation loss 0.074816; Mean validation F1 0.937238; Learning rate 0.000268;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.077954; Mean training F1 0.939915; Mean validation loss 0.108111; Mean validation F1 0.937009; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.077827; Mean training F1 0.940137; Mean validation loss 0.119839; Mean validation F1 0.937186; Learning rate 0.000247;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.077764; Mean training F1 0.940013; Mean validation loss 0.101239; Mean validation F1 0.937157; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.077687; Mean training F1 0.940133; Mean validation loss 0.108423; Mean validation F1 0.937155; Learning rate 0.000226;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.077673; Mean training F1 0.940178; Mean validation loss 0.084999; Mean validation F1 0.937084; Learning rate 0.000216;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.077616; Mean training F1 0.940080; Mean validation loss 0.070996; Mean validation F1 0.936159; Learning rate 0.000206;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.077500; Mean training F1 0.940090; Mean validation loss 0.079117; Mean validation F1 0.936911; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.077494; Mean training F1 0.940143; Mean validation loss 0.055356; Mean validation F1 0.936977; Learning rate 0.000187;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.077407; Mean training F1 0.940365; Mean validation loss 0.068439; Mean validation F1 0.937128; Learning rate 0.000178;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.077354; Mean training F1 0.940243; Mean validation loss 0.107447; Mean validation F1 0.937152; Learning rate 0.000169;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.077291; Mean training F1 0.940435; Mean validation loss 0.095604; Mean validation F1 0.937015; Learning rate 0.000160;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.077291; Mean training F1 0.940341; Mean validation loss 0.060325; Mean validation F1 0.937055; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.077145; Mean training F1 0.940367; Mean validation loss 0.074122; Mean validation F1 0.937116; Learning rate 0.000142;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.077063; Mean training F1 0.940487; Mean validation loss 0.070546; Mean validation F1 0.937124; Learning rate 0.000134;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.077047; Mean training F1 0.940406; Mean validation loss 0.099262; Mean validation F1 0.937105; Learning rate 0.000126;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.077055; Mean training F1 0.940438; Mean validation loss 0.090121; Mean validation F1 0.937206; Learning rate 0.000118;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.076967; Mean training F1 0.940639; Mean validation loss 0.084525; Mean validation F1 0.937246; Learning rate 0.000111;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.076923; Mean training F1 0.940521; Mean validation loss 0.095012; Mean validation F1 0.937223; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.076863; Mean training F1 0.940694; Mean validation loss 0.051252; Mean validation F1 0.937085; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.076798; Mean training F1 0.940592; Mean validation loss 0.117898; Mean validation F1 0.937046; Learning rate 0.000089;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.076777; Mean training F1 0.940573; Mean validation loss 0.102617; Mean validation F1 0.937170; Learning rate 0.000082;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.076722; Mean training F1 0.940683; Mean validation loss 0.041023; Mean validation F1 0.936622; Learning rate 0.000076;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.076689; Mean training F1 0.940576; Mean validation loss 0.066078; Mean validation F1 0.936968; Learning rate 0.000070;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.076704; Mean training F1 0.940572; Mean validation loss 0.071840; Mean validation F1 0.937164; Learning rate 0.000064;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.076613; Mean training F1 0.940776; Mean validation loss 0.070060; Mean validation F1 0.937138; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.076580; Mean training F1 0.940817; Mean validation loss 0.059333; Mean validation F1 0.937239; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.076522; Mean training F1 0.940813; Mean validation loss 0.071550; Mean validation F1 0.937040; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.076507; Mean training F1 0.940843; Mean validation loss 0.080881; Mean validation F1 0.937147; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.076465; Mean training F1 0.940792; Mean validation loss 0.083627; Mean validation F1 0.937199; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.076448; Mean training F1 0.940886; Mean validation loss 0.049536; Mean validation F1 0.937194; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.076418; Mean training F1 0.940863; Mean validation loss 0.063640; Mean validation F1 0.937077; Learning rate 0.000030;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.076387; Mean training F1 0.940908; Mean validation loss 0.066509; Mean validation F1 0.937090; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.076366; Mean training F1 0.940890; Mean validation loss 0.082960; Mean validation F1 0.937192; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.076344; Mean training F1 0.940936; Mean validation loss 0.088458; Mean validation F1 0.937114; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.076329; Mean training F1 0.940926; Mean validation loss 0.064327; Mean validation F1 0.937140; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.076300; Mean training F1 0.940968; Mean validation loss 0.041057; Mean validation F1 0.937244; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.076284; Mean training F1 0.940959; Mean validation loss 0.075647; Mean validation F1 0.937259; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.076275; Mean training F1 0.941024; Mean validation loss 0.062822; Mean validation F1 0.937190; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.076267; Mean training F1 0.941014; Mean validation loss 0.083972; Mean validation F1 0.937263; Learning rate 0.000009;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.076249; Mean training F1 0.940956; Mean validation loss 0.070893; Mean validation F1 0.937243; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.076241; Mean training F1 0.941004; Mean validation loss 0.098016; Mean validation F1 0.937207; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.076233; Mean training F1 0.940989; Mean validation loss 0.106923; Mean validation F1 0.937184; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.076230; Mean training F1 0.941010; Mean validation loss 0.072039; Mean validation F1 0.937161; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.076225; Mean training F1 0.941023; Mean validation loss 0.070704; Mean validation F1 0.937252; Learning rate 0.000005;\n",
    "################################################################\n",
    "Training/validation for fold 4/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.839332; Mean training F1 0.530606; Mean validation loss 0.431663; Mean validation F1 0.700329; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.308021; Mean training F1 0.828062; Mean validation loss 0.199248; Mean validation F1 0.893289; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.158808; Mean training F1 0.905496; Mean validation loss 0.145437; Mean validation F1 0.918318; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.126911; Mean training F1 0.918202; Mean validation loss 0.117626; Mean validation F1 0.872444; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.107307; Mean training F1 0.925908; Mean validation loss 0.067799; Mean validation F1 0.934842; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.094210; Mean training F1 0.931818; Mean validation loss 0.115955; Mean validation F1 0.936197; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.091186; Mean training F1 0.933499; Mean validation loss 0.094066; Mean validation F1 0.933588; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.089233; Mean training F1 0.935268; Mean validation loss 0.117044; Mean validation F1 0.937162; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.089026; Mean training F1 0.935182; Mean validation loss 0.053993; Mean validation F1 0.936376; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.088040; Mean training F1 0.935787; Mean validation loss 0.080410; Mean validation F1 0.937403; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.088588; Mean training F1 0.935231; Mean validation loss 0.063733; Mean validation F1 0.937464; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.088821; Mean training F1 0.935106; Mean validation loss 0.116945; Mean validation F1 0.936985; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.088109; Mean training F1 0.935180; Mean validation loss 0.094698; Mean validation F1 0.937686; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.087861; Mean training F1 0.935039; Mean validation loss 0.067132; Mean validation F1 0.937452; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.086732; Mean training F1 0.936155; Mean validation loss 0.092074; Mean validation F1 0.937385; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.086142; Mean training F1 0.936548; Mean validation loss 0.107301; Mean validation F1 0.937425; Learning rate 0.000962;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.109445; Mean training F1 0.924419; Mean validation loss 0.148153; Mean validation F1 0.831825; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.098543; Mean training F1 0.929586; Mean validation loss 0.133589; Mean validation F1 0.937218; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.086277; Mean training F1 0.936387; Mean validation loss 0.076122; Mean validation F1 0.937415; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.085890; Mean training F1 0.936610; Mean validation loss 0.053828; Mean validation F1 0.937438; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.085881; Mean training F1 0.936560; Mean validation loss 0.127799; Mean validation F1 0.936766; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.085721; Mean training F1 0.936486; Mean validation loss 0.073535; Mean validation F1 0.934153; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.085362; Mean training F1 0.936680; Mean validation loss 0.105862; Mean validation F1 0.937842; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.084795; Mean training F1 0.937092; Mean validation loss 0.076233; Mean validation F1 0.938152; Learning rate 0.000916;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.084934; Mean training F1 0.937007; Mean validation loss 0.058499; Mean validation F1 0.936435; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.084623; Mean training F1 0.937092; Mean validation loss 0.091246; Mean validation F1 0.938283; Learning rate 0.000902;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.084417; Mean training F1 0.936984; Mean validation loss 0.095193; Mean validation F1 0.937463; Learning rate 0.000895;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.084318; Mean training F1 0.937286; Mean validation loss 0.068664; Mean validation F1 0.938370; Learning rate 0.000887;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.084428; Mean training F1 0.937265; Mean validation loss 0.132664; Mean validation F1 0.938066; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.084719; Mean training F1 0.937079; Mean validation loss 0.077937; Mean validation F1 0.936711; Learning rate 0.000871;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.084318; Mean training F1 0.937420; Mean validation loss 0.080173; Mean validation F1 0.937703; Learning rate 0.000863;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.089966; Mean training F1 0.934465; Mean validation loss 0.077285; Mean validation F1 0.936229; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.104425; Mean training F1 0.925946; Mean validation loss 0.117029; Mean validation F1 0.938258; Learning rate 0.000846;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.084545; Mean training F1 0.937007; Mean validation loss 0.078077; Mean validation F1 0.937847; Learning rate 0.000837;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.083797; Mean training F1 0.937334; Mean validation loss 0.068783; Mean validation F1 0.936759; Learning rate 0.000828;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.084144; Mean training F1 0.937218; Mean validation loss 0.101629; Mean validation F1 0.938640; Learning rate 0.000818;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.083585; Mean training F1 0.937599; Mean validation loss 0.107832; Mean validation F1 0.935041; Learning rate 0.000809;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.083605; Mean training F1 0.937552; Mean validation loss 0.104800; Mean validation F1 0.937233; Learning rate 0.000799;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.083819; Mean training F1 0.937441; Mean validation loss 0.075314; Mean validation F1 0.938409; Learning rate 0.000789;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.083182; Mean training F1 0.937805; Mean validation loss 0.051437; Mean validation F1 0.938723; Learning rate 0.000779;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.083513; Mean training F1 0.937661; Mean validation loss 0.048537; Mean validation F1 0.937805; Learning rate 0.000769;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.083772; Mean training F1 0.937459; Mean validation loss 0.072856; Mean validation F1 0.936612; Learning rate 0.000759;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.082929; Mean training F1 0.937960; Mean validation loss 0.091514; Mean validation F1 0.938460; Learning rate 0.000748;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.082957; Mean training F1 0.937883; Mean validation loss 0.065619; Mean validation F1 0.938958; Learning rate 0.000737;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.083547; Mean training F1 0.937105; Mean validation loss 0.070204; Mean validation F1 0.938434; Learning rate 0.000726;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.083066; Mean training F1 0.937443; Mean validation loss 0.072798; Mean validation F1 0.937253; Learning rate 0.000716;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.105146; Mean training F1 0.927716; Mean validation loss 0.117395; Mean validation F1 0.935259; Learning rate 0.000704;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.086113; Mean training F1 0.936493; Mean validation loss 0.098869; Mean validation F1 0.937179; Learning rate 0.000693;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.084531; Mean training F1 0.937207; Mean validation loss 0.046504; Mean validation F1 0.938007; Learning rate 0.000682;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.084242; Mean training F1 0.937448; Mean validation loss 0.074275; Mean validation F1 0.937960; Learning rate 0.000670;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.083554; Mean training F1 0.937642; Mean validation loss 0.101987; Mean validation F1 0.938359; Learning rate 0.000659;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.083671; Mean training F1 0.937246; Mean validation loss 0.067517; Mean validation F1 0.938710; Learning rate 0.000647;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.083157; Mean training F1 0.937879; Mean validation loss 0.066910; Mean validation F1 0.938177; Learning rate 0.000635;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.082897; Mean training F1 0.937669; Mean validation loss 0.061336; Mean validation F1 0.938568; Learning rate 0.000624;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.082614; Mean training F1 0.937984; Mean validation loss 0.065771; Mean validation F1 0.938860; Learning rate 0.000612;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.082579; Mean training F1 0.937894; Mean validation loss 0.061600; Mean validation F1 0.938574; Learning rate 0.000600;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.082385; Mean training F1 0.938251; Mean validation loss 0.065522; Mean validation F1 0.938647; Learning rate 0.000588;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.082623; Mean training F1 0.937802; Mean validation loss 0.090473; Mean validation F1 0.938921; Learning rate 0.000576;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.082398; Mean training F1 0.938093; Mean validation loss 0.049758; Mean validation F1 0.937678; Learning rate 0.000564;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.082336; Mean training F1 0.937926; Mean validation loss 0.089057; Mean validation F1 0.938770; Learning rate 0.000552;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.082206; Mean training F1 0.938198; Mean validation loss 0.062043; Mean validation F1 0.938915; Learning rate 0.000539;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.082051; Mean training F1 0.938161; Mean validation loss 0.093507; Mean validation F1 0.937581; Learning rate 0.000527;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.082070; Mean training F1 0.938230; Mean validation loss 0.106031; Mean validation F1 0.938537; Learning rate 0.000515;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.081907; Mean training F1 0.938336; Mean validation loss 0.078242; Mean validation F1 0.938932; Learning rate 0.000503;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.081795; Mean training F1 0.938594; Mean validation loss 0.091958; Mean validation F1 0.938495; Learning rate 0.000491;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.081762; Mean training F1 0.938328; Mean validation loss 0.075568; Mean validation F1 0.938751; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.081699; Mean training F1 0.938583; Mean validation loss 0.121034; Mean validation F1 0.938469; Learning rate 0.000466;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.081767; Mean training F1 0.938452; Mean validation loss 0.111286; Mean validation F1 0.938965; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.081646; Mean training F1 0.938626; Mean validation loss 0.109446; Mean validation F1 0.939002; Learning rate 0.000442;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.081391; Mean training F1 0.938593; Mean validation loss 0.111257; Mean validation F1 0.938996; Learning rate 0.000430;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.081464; Mean training F1 0.938562; Mean validation loss 0.062745; Mean validation F1 0.938829; Learning rate 0.000418;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.081357; Mean training F1 0.938718; Mean validation loss 0.079349; Mean validation F1 0.938827; Learning rate 0.000406;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.081635; Mean training F1 0.938428; Mean validation loss 0.053684; Mean validation F1 0.938904; Learning rate 0.000394;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.081336; Mean training F1 0.938619; Mean validation loss 0.067996; Mean validation F1 0.938514; Learning rate 0.000382;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.081027; Mean training F1 0.938765; Mean validation loss 0.088109; Mean validation F1 0.938866; Learning rate 0.000370;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.080895; Mean training F1 0.938897; Mean validation loss 0.084449; Mean validation F1 0.938646; Learning rate 0.000358;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.080762; Mean training F1 0.938869; Mean validation loss 0.078304; Mean validation F1 0.938612; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.080844; Mean training F1 0.938883; Mean validation loss 0.088514; Mean validation F1 0.938898; Learning rate 0.000335;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.080708; Mean training F1 0.938959; Mean validation loss 0.031656; Mean validation F1 0.936998; Learning rate 0.000324;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.080593; Mean training F1 0.939036; Mean validation loss 0.058468; Mean validation F1 0.938722; Learning rate 0.000312;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.080544; Mean training F1 0.939122; Mean validation loss 0.077956; Mean validation F1 0.938598; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.080662; Mean training F1 0.938992; Mean validation loss 0.072507; Mean validation F1 0.938960; Learning rate 0.000290;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.080524; Mean training F1 0.938909; Mean validation loss 0.096162; Mean validation F1 0.938449; Learning rate 0.000279;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.080244; Mean training F1 0.939282; Mean validation loss 0.106168; Mean validation F1 0.938983; Learning rate 0.000268;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.080402; Mean training F1 0.939004; Mean validation loss 0.085947; Mean validation F1 0.938891; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.080064; Mean training F1 0.939363; Mean validation loss 0.051574; Mean validation F1 0.938910; Learning rate 0.000247;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.080152; Mean training F1 0.939358; Mean validation loss 0.076100; Mean validation F1 0.938983; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.079996; Mean training F1 0.939331; Mean validation loss 0.082630; Mean validation F1 0.938863; Learning rate 0.000226;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.080074; Mean training F1 0.939146; Mean validation loss 0.063334; Mean validation F1 0.938794; Learning rate 0.000216;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.079949; Mean training F1 0.939283; Mean validation loss 0.073355; Mean validation F1 0.939122; Learning rate 0.000206;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.079888; Mean training F1 0.939336; Mean validation loss 0.093050; Mean validation F1 0.939061; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.079760; Mean training F1 0.939480; Mean validation loss 0.098178; Mean validation F1 0.938983; Learning rate 0.000187;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.079615; Mean training F1 0.939611; Mean validation loss 0.082153; Mean validation F1 0.939235; Learning rate 0.000178;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.079570; Mean training F1 0.939478; Mean validation loss 0.116683; Mean validation F1 0.939061; Learning rate 0.000169;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.079588; Mean training F1 0.939593; Mean validation loss 0.072570; Mean validation F1 0.938994; Learning rate 0.000160;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.079526; Mean training F1 0.939519; Mean validation loss 0.090730; Mean validation F1 0.938984; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.079402; Mean training F1 0.939624; Mean validation loss 0.080648; Mean validation F1 0.939061; Learning rate 0.000142;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.079388; Mean training F1 0.939682; Mean validation loss 0.051098; Mean validation F1 0.938888; Learning rate 0.000134;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.079255; Mean training F1 0.939784; Mean validation loss 0.057465; Mean validation F1 0.938918; Learning rate 0.000126;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.079265; Mean training F1 0.939715; Mean validation loss 0.074077; Mean validation F1 0.938956; Learning rate 0.000118;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.079240; Mean training F1 0.939759; Mean validation loss 0.098266; Mean validation F1 0.939064; Learning rate 0.000111;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.079183; Mean training F1 0.939720; Mean validation loss 0.056523; Mean validation F1 0.939188; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.079088; Mean training F1 0.939828; Mean validation loss 0.076616; Mean validation F1 0.939200; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.079081; Mean training F1 0.939774; Mean validation loss 0.086378; Mean validation F1 0.939032; Learning rate 0.000089;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.079013; Mean training F1 0.939776; Mean validation loss 0.063888; Mean validation F1 0.938961; Learning rate 0.000082;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.078970; Mean training F1 0.939837; Mean validation loss 0.080385; Mean validation F1 0.939082; Learning rate 0.000076;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.078925; Mean training F1 0.939907; Mean validation loss 0.106819; Mean validation F1 0.939159; Learning rate 0.000070;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.078862; Mean training F1 0.939898; Mean validation loss 0.093886; Mean validation F1 0.939123; Learning rate 0.000064;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.078854; Mean training F1 0.939926; Mean validation loss 0.083689; Mean validation F1 0.939091; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.078816; Mean training F1 0.939976; Mean validation loss 0.079672; Mean validation F1 0.939003; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.078764; Mean training F1 0.939940; Mean validation loss 0.100698; Mean validation F1 0.939334; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.078731; Mean training F1 0.939992; Mean validation loss 0.089100; Mean validation F1 0.939188; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.078698; Mean training F1 0.939948; Mean validation loss 0.079461; Mean validation F1 0.939045; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.078678; Mean training F1 0.940004; Mean validation loss 0.051737; Mean validation F1 0.939193; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.078645; Mean training F1 0.940060; Mean validation loss 0.059147; Mean validation F1 0.939090; Learning rate 0.000030;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.078599; Mean training F1 0.940124; Mean validation loss 0.064018; Mean validation F1 0.939172; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.078591; Mean training F1 0.940124; Mean validation loss 0.062748; Mean validation F1 0.939246; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.078556; Mean training F1 0.940086; Mean validation loss 0.098958; Mean validation F1 0.939371; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.078553; Mean training F1 0.940100; Mean validation loss 0.075562; Mean validation F1 0.939175; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.078519; Mean training F1 0.940135; Mean validation loss 0.118379; Mean validation F1 0.939246; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.078507; Mean training F1 0.940126; Mean validation loss 0.074607; Mean validation F1 0.939161; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.078503; Mean training F1 0.940121; Mean validation loss 0.027971; Mean validation F1 0.939298; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.078489; Mean training F1 0.940103; Mean validation loss 0.071184; Mean validation F1 0.939240; Learning rate 0.000009;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.078471; Mean training F1 0.940135; Mean validation loss 0.061386; Mean validation F1 0.939243; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.078466; Mean training F1 0.940127; Mean validation loss 0.058003; Mean validation F1 0.939211; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.078456; Mean training F1 0.940115; Mean validation loss 0.050015; Mean validation F1 0.939215; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.078450; Mean training F1 0.940149; Mean validation loss 0.096625; Mean validation F1 0.939264; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.078446; Mean training F1 0.940119; Mean validation loss 0.034950; Mean validation F1 0.939173; Learning rate 0.000005;\n",
    "################################################################\n",
    "Training/validation for fold 5/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.748670; Mean training F1 0.584220; Mean validation loss 0.451185; Mean validation F1 0.790139; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.218695; Mean training F1 0.877580; Mean validation loss 0.150204; Mean validation F1 0.910341; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.115152; Mean training F1 0.923636; Mean validation loss 0.110617; Mean validation F1 0.931303; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.097520; Mean training F1 0.931978; Mean validation loss 0.084938; Mean validation F1 0.933159; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.093813; Mean training F1 0.933214; Mean validation loss 0.096180; Mean validation F1 0.934934; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.093603; Mean training F1 0.933674; Mean validation loss 0.104090; Mean validation F1 0.934890; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.092034; Mean training F1 0.933648; Mean validation loss 0.091198; Mean validation F1 0.936003; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.090966; Mean training F1 0.934067; Mean validation loss 0.051307; Mean validation F1 0.921980; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.093499; Mean training F1 0.932770; Mean validation loss 0.126530; Mean validation F1 0.935811; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.088645; Mean training F1 0.935303; Mean validation loss 0.093710; Mean validation F1 0.936405; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.087497; Mean training F1 0.936186; Mean validation loss 0.113777; Mean validation F1 0.936456; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.086764; Mean training F1 0.936418; Mean validation loss 0.095155; Mean validation F1 0.936352; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.087388; Mean training F1 0.935908; Mean validation loss 0.107608; Mean validation F1 0.937026; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.087287; Mean training F1 0.936110; Mean validation loss 0.119841; Mean validation F1 0.937254; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.090405; Mean training F1 0.932904; Mean validation loss 0.072611; Mean validation F1 0.933727; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.088161; Mean training F1 0.935067; Mean validation loss 0.093422; Mean validation F1 0.935943; Learning rate 0.000962;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.085887; Mean training F1 0.936653; Mean validation loss 0.062039; Mean validation F1 0.936884; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.086402; Mean training F1 0.936533; Mean validation loss 0.077191; Mean validation F1 0.935856; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.086401; Mean training F1 0.936503; Mean validation loss 0.071763; Mean validation F1 0.936842; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.085140; Mean training F1 0.937207; Mean validation loss 0.112053; Mean validation F1 0.936651; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.086109; Mean training F1 0.936272; Mean validation loss 0.110781; Mean validation F1 0.936008; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.085638; Mean training F1 0.936450; Mean validation loss 0.062157; Mean validation F1 0.937511; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.085846; Mean training F1 0.936538; Mean validation loss 0.078395; Mean validation F1 0.935088; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.085492; Mean training F1 0.936871; Mean validation loss 0.071933; Mean validation F1 0.931487; Learning rate 0.000916;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.085590; Mean training F1 0.936236; Mean validation loss 0.083290; Mean validation F1 0.936527; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.084799; Mean training F1 0.936805; Mean validation loss 0.085317; Mean validation F1 0.936240; Learning rate 0.000902;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.085417; Mean training F1 0.937154; Mean validation loss 0.064118; Mean validation F1 0.937908; Learning rate 0.000895;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.085069; Mean training F1 0.936928; Mean validation loss 0.079049; Mean validation F1 0.937089; Learning rate 0.000887;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.084086; Mean training F1 0.937429; Mean validation loss 0.054456; Mean validation F1 0.936995; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.085156; Mean training F1 0.936021; Mean validation loss 0.086594; Mean validation F1 0.937725; Learning rate 0.000871;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.086051; Mean training F1 0.936371; Mean validation loss 0.150871; Mean validation F1 0.923527; Learning rate 0.000863;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.092086; Mean training F1 0.932891; Mean validation loss 0.061875; Mean validation F1 0.936770; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.083951; Mean training F1 0.937638; Mean validation loss 0.078628; Mean validation F1 0.937300; Learning rate 0.000846;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.083867; Mean training F1 0.937398; Mean validation loss 0.053374; Mean validation F1 0.935589; Learning rate 0.000837;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.084100; Mean training F1 0.937437; Mean validation loss 0.076529; Mean validation F1 0.937159; Learning rate 0.000828;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.083314; Mean training F1 0.937624; Mean validation loss 0.082679; Mean validation F1 0.938041; Learning rate 0.000818;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.082930; Mean training F1 0.938076; Mean validation loss 0.085131; Mean validation F1 0.935736; Learning rate 0.000809;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.083415; Mean training F1 0.937471; Mean validation loss 0.064457; Mean validation F1 0.937540; Learning rate 0.000799;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.083519; Mean training F1 0.937783; Mean validation loss 0.078019; Mean validation F1 0.937765; Learning rate 0.000789;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.085082; Mean training F1 0.935680; Mean validation loss 0.077341; Mean validation F1 0.937648; Learning rate 0.000779;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.082678; Mean training F1 0.938001; Mean validation loss 0.069797; Mean validation F1 0.937616; Learning rate 0.000769;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.082853; Mean training F1 0.938124; Mean validation loss 0.071136; Mean validation F1 0.937599; Learning rate 0.000759;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.083005; Mean training F1 0.937969; Mean validation loss 0.064191; Mean validation F1 0.937765; Learning rate 0.000748;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.082517; Mean training F1 0.938020; Mean validation loss 0.087587; Mean validation F1 0.936400; Learning rate 0.000737;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.082974; Mean training F1 0.937931; Mean validation loss 0.085039; Mean validation F1 0.935687; Learning rate 0.000726;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.082827; Mean training F1 0.937872; Mean validation loss 0.087376; Mean validation F1 0.937344; Learning rate 0.000716;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.082510; Mean training F1 0.937917; Mean validation loss 0.051642; Mean validation F1 0.936837; Learning rate 0.000704;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.082353; Mean training F1 0.937982; Mean validation loss 0.060853; Mean validation F1 0.937777; Learning rate 0.000693;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.081612; Mean training F1 0.938575; Mean validation loss 0.118612; Mean validation F1 0.938121; Learning rate 0.000682;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.081725; Mean training F1 0.938407; Mean validation loss 0.082049; Mean validation F1 0.937687; Learning rate 0.000670;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.081920; Mean training F1 0.938185; Mean validation loss 0.089588; Mean validation F1 0.937338; Learning rate 0.000659;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.081829; Mean training F1 0.938170; Mean validation loss 0.093864; Mean validation F1 0.937818; Learning rate 0.000647;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.081988; Mean training F1 0.938397; Mean validation loss 0.102924; Mean validation F1 0.937532; Learning rate 0.000635;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.081584; Mean training F1 0.938299; Mean validation loss 0.069564; Mean validation F1 0.937778; Learning rate 0.000624;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.081072; Mean training F1 0.938773; Mean validation loss 0.077017; Mean validation F1 0.938027; Learning rate 0.000612;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.081178; Mean training F1 0.938745; Mean validation loss 0.059498; Mean validation F1 0.938332; Learning rate 0.000600;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.081667; Mean training F1 0.938287; Mean validation loss 0.078278; Mean validation F1 0.937647; Learning rate 0.000588;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.081332; Mean training F1 0.938557; Mean validation loss 0.060097; Mean validation F1 0.937960; Learning rate 0.000576;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.081128; Mean training F1 0.938731; Mean validation loss 0.073006; Mean validation F1 0.937933; Learning rate 0.000564;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.081051; Mean training F1 0.938608; Mean validation loss 0.072349; Mean validation F1 0.936787; Learning rate 0.000552;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.080856; Mean training F1 0.938763; Mean validation loss 0.075226; Mean validation F1 0.937240; Learning rate 0.000539;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.080824; Mean training F1 0.938803; Mean validation loss 0.061101; Mean validation F1 0.937940; Learning rate 0.000527;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.080799; Mean training F1 0.938869; Mean validation loss 0.069044; Mean validation F1 0.937855; Learning rate 0.000515;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.080430; Mean training F1 0.939194; Mean validation loss 0.044844; Mean validation F1 0.938011; Learning rate 0.000503;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.080452; Mean training F1 0.939120; Mean validation loss 0.043039; Mean validation F1 0.936281; Learning rate 0.000491;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.080787; Mean training F1 0.938730; Mean validation loss 0.063735; Mean validation F1 0.937685; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.080361; Mean training F1 0.938937; Mean validation loss 0.097455; Mean validation F1 0.938126; Learning rate 0.000466;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.080271; Mean training F1 0.939062; Mean validation loss 0.064660; Mean validation F1 0.938317; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.079966; Mean training F1 0.939413; Mean validation loss 0.067325; Mean validation F1 0.938412; Learning rate 0.000442;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.080262; Mean training F1 0.939015; Mean validation loss 0.096577; Mean validation F1 0.938285; Learning rate 0.000430;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.079851; Mean training F1 0.939366; Mean validation loss 0.103211; Mean validation F1 0.938334; Learning rate 0.000418;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.079735; Mean training F1 0.939412; Mean validation loss 0.075378; Mean validation F1 0.938105; Learning rate 0.000406;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.079872; Mean training F1 0.939307; Mean validation loss 0.113535; Mean validation F1 0.938014; Learning rate 0.000394;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.079739; Mean training F1 0.939564; Mean validation loss 0.115692; Mean validation F1 0.938308; Learning rate 0.000382;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.079418; Mean training F1 0.939443; Mean validation loss 0.090111; Mean validation F1 0.937990; Learning rate 0.000370;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.079358; Mean training F1 0.939671; Mean validation loss 0.099686; Mean validation F1 0.938317; Learning rate 0.000358;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.079333; Mean training F1 0.939613; Mean validation loss 0.070623; Mean validation F1 0.938066; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.079205; Mean training F1 0.939649; Mean validation loss 0.109244; Mean validation F1 0.938319; Learning rate 0.000335;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.079282; Mean training F1 0.939436; Mean validation loss 0.091069; Mean validation F1 0.938098; Learning rate 0.000324;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.079016; Mean training F1 0.939674; Mean validation loss 0.072520; Mean validation F1 0.938318; Learning rate 0.000312;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.078915; Mean training F1 0.939915; Mean validation loss 0.074131; Mean validation F1 0.938262; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.078724; Mean training F1 0.940012; Mean validation loss 0.073311; Mean validation F1 0.938112; Learning rate 0.000290;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.078635; Mean training F1 0.939966; Mean validation loss 0.084286; Mean validation F1 0.938330; Learning rate 0.000279;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.078596; Mean training F1 0.940043; Mean validation loss 0.101497; Mean validation F1 0.938351; Learning rate 0.000268;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.078466; Mean training F1 0.940065; Mean validation loss 0.065939; Mean validation F1 0.938232; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.078390; Mean training F1 0.940149; Mean validation loss 0.096885; Mean validation F1 0.938404; Learning rate 0.000247;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.078411; Mean training F1 0.940130; Mean validation loss 0.106604; Mean validation F1 0.938256; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.078218; Mean training F1 0.940162; Mean validation loss 0.091715; Mean validation F1 0.938376; Learning rate 0.000226;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.078070; Mean training F1 0.940405; Mean validation loss 0.080237; Mean validation F1 0.938173; Learning rate 0.000216;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.078129; Mean training F1 0.940211; Mean validation loss 0.066364; Mean validation F1 0.938333; Learning rate 0.000206;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.078066; Mean training F1 0.940312; Mean validation loss 0.082028; Mean validation F1 0.938432; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.077999; Mean training F1 0.940311; Mean validation loss 0.100386; Mean validation F1 0.938283; Learning rate 0.000187;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.077857; Mean training F1 0.940377; Mean validation loss 0.077685; Mean validation F1 0.938456; Learning rate 0.000178;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.077700; Mean training F1 0.940490; Mean validation loss 0.062819; Mean validation F1 0.938083; Learning rate 0.000169;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.077764; Mean training F1 0.940400; Mean validation loss 0.087278; Mean validation F1 0.938268; Learning rate 0.000160;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.077721; Mean training F1 0.940319; Mean validation loss 0.092453; Mean validation F1 0.938494; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.077562; Mean training F1 0.940511; Mean validation loss 0.096219; Mean validation F1 0.938229; Learning rate 0.000142;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.077484; Mean training F1 0.940535; Mean validation loss 0.087178; Mean validation F1 0.937917; Learning rate 0.000134;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.077336; Mean training F1 0.940696; Mean validation loss 0.058040; Mean validation F1 0.938263; Learning rate 0.000126;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.077389; Mean training F1 0.940635; Mean validation loss 0.065288; Mean validation F1 0.938407; Learning rate 0.000118;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.077268; Mean training F1 0.940758; Mean validation loss 0.090328; Mean validation F1 0.938435; Learning rate 0.000111;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.077253; Mean training F1 0.940710; Mean validation loss 0.106112; Mean validation F1 0.938429; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.077137; Mean training F1 0.940797; Mean validation loss 0.070650; Mean validation F1 0.938494; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.077080; Mean training F1 0.940755; Mean validation loss 0.053203; Mean validation F1 0.938315; Learning rate 0.000089;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.077024; Mean training F1 0.940810; Mean validation loss 0.078854; Mean validation F1 0.938373; Learning rate 0.000082;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.076977; Mean training F1 0.940768; Mean validation loss 0.077577; Mean validation F1 0.938340; Learning rate 0.000076;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.076909; Mean training F1 0.940860; Mean validation loss 0.076435; Mean validation F1 0.938551; Learning rate 0.000070;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.076863; Mean training F1 0.940924; Mean validation loss 0.058703; Mean validation F1 0.938427; Learning rate 0.000064;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.076854; Mean training F1 0.940920; Mean validation loss 0.056050; Mean validation F1 0.938428; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.076821; Mean training F1 0.940918; Mean validation loss 0.062808; Mean validation F1 0.938280; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.076782; Mean training F1 0.940911; Mean validation loss 0.067723; Mean validation F1 0.938329; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.076725; Mean training F1 0.940977; Mean validation loss 0.078568; Mean validation F1 0.938464; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.076682; Mean training F1 0.941020; Mean validation loss 0.071805; Mean validation F1 0.938440; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.076674; Mean training F1 0.940983; Mean validation loss 0.079434; Mean validation F1 0.938400; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.076625; Mean training F1 0.941017; Mean validation loss 0.074576; Mean validation F1 0.938436; Learning rate 0.000030;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.076594; Mean training F1 0.941057; Mean validation loss 0.089387; Mean validation F1 0.938371; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.076574; Mean training F1 0.941088; Mean validation loss 0.113016; Mean validation F1 0.938495; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.076554; Mean training F1 0.941047; Mean validation loss 0.063179; Mean validation F1 0.938436; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.076525; Mean training F1 0.941099; Mean validation loss 0.085562; Mean validation F1 0.938486; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.076518; Mean training F1 0.941099; Mean validation loss 0.067960; Mean validation F1 0.938479; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.076506; Mean training F1 0.941079; Mean validation loss 0.060586; Mean validation F1 0.938407; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.076477; Mean training F1 0.941143; Mean validation loss 0.059052; Mean validation F1 0.938489; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.076461; Mean training F1 0.941126; Mean validation loss 0.075435; Mean validation F1 0.938386; Learning rate 0.000009;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.076448; Mean training F1 0.941187; Mean validation loss 0.083566; Mean validation F1 0.938333; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.076440; Mean training F1 0.941142; Mean validation loss 0.078547; Mean validation F1 0.938490; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.076431; Mean training F1 0.941173; Mean validation loss 0.112125; Mean validation F1 0.938452; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.076426; Mean training F1 0.941140; Mean validation loss 0.115241; Mean validation F1 0.938430; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.076419; Mean training F1 0.941160; Mean validation loss 0.060549; Mean validation F1 0.938433; Learning rate 0.000005;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-------- fold 0 --------\n",
    "model validation loss: 0.102; validation f1: 0.941;\n",
    "-------- fold 1 --------\n",
    "model validation loss: 0.081; validation f1: 0.935;\n",
    "-------- fold 2 --------\n",
    "model validation loss: 0.049; validation f1: 0.938;\n",
    "-------- fold 3 --------\n",
    "model validation loss: 0.053; validation f1: 0.939;\n",
    "-------- fold 4 --------\n",
    "model validation loss: 0.071; validation f1: 0.939;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "################################################################\n",
    "Training/validation for fold 1/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.740774; Mean training F1 0.578768; Mean validation loss 0.323142; Mean validation F1 0.744957; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.244340; Mean training F1 0.858650; Mean validation loss 0.121092; Mean validation F1 0.925070; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.115140; Mean training F1 0.924322; Mean validation loss 0.097521; Mean validation F1 0.934063; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.096252; Mean training F1 0.932259; Mean validation loss 0.104519; Mean validation F1 0.936700; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.093182; Mean training F1 0.932865; Mean validation loss 0.063443; Mean validation F1 0.936006; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.094904; Mean training F1 0.932614; Mean validation loss 0.098115; Mean validation F1 0.937539; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.090618; Mean training F1 0.933972; Mean validation loss 0.094707; Mean validation F1 0.938266; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.103816; Mean training F1 0.926971; Mean validation loss 0.086055; Mean validation F1 0.935881; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.090002; Mean training F1 0.934266; Mean validation loss 0.095431; Mean validation F1 0.937109; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.088917; Mean training F1 0.934629; Mean validation loss 0.118538; Mean validation F1 0.938337; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.087755; Mean training F1 0.935320; Mean validation loss 0.105735; Mean validation F1 0.938681; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.087787; Mean training F1 0.935582; Mean validation loss 0.087362; Mean validation F1 0.938300; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.087484; Mean training F1 0.935380; Mean validation loss 0.073475; Mean validation F1 0.938685; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.088476; Mean training F1 0.934758; Mean validation loss 0.078505; Mean validation F1 0.938762; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.087019; Mean training F1 0.935933; Mean validation loss 0.092975; Mean validation F1 0.939149; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.087101; Mean training F1 0.935880; Mean validation loss 0.128732; Mean validation F1 0.934103; Learning rate 0.000962;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.087593; Mean training F1 0.935493; Mean validation loss 0.078769; Mean validation F1 0.938014; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.156343; Mean training F1 0.907183; Mean validation loss 0.081151; Mean validation F1 0.938191; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.088413; Mean training F1 0.935681; Mean validation loss 0.053244; Mean validation F1 0.938264; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.087544; Mean training F1 0.935688; Mean validation loss 0.096965; Mean validation F1 0.939394; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.086686; Mean training F1 0.936205; Mean validation loss 0.073234; Mean validation F1 0.937867; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.086341; Mean training F1 0.936402; Mean validation loss 0.048905; Mean validation F1 0.938863; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.086244; Mean training F1 0.936379; Mean validation loss 0.081444; Mean validation F1 0.938875; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.085979; Mean training F1 0.936514; Mean validation loss 0.093537; Mean validation F1 0.938767; Learning rate 0.000916;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.085787; Mean training F1 0.936663; Mean validation loss 0.084326; Mean validation F1 0.939071; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.085468; Mean training F1 0.936687; Mean validation loss 0.069126; Mean validation F1 0.939634; Learning rate 0.000902;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.085335; Mean training F1 0.936797; Mean validation loss 0.099217; Mean validation F1 0.938893; Learning rate 0.000895;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.092210; Mean training F1 0.933152; Mean validation loss 0.100168; Mean validation F1 0.937536; Learning rate 0.000887;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.085869; Mean training F1 0.936402; Mean validation loss 0.078023; Mean validation F1 0.938906; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.085414; Mean training F1 0.936570; Mean validation loss 0.081024; Mean validation F1 0.939180; Learning rate 0.000871;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.085148; Mean training F1 0.936555; Mean validation loss 0.079762; Mean validation F1 0.939391; Learning rate 0.000863;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.085069; Mean training F1 0.936698; Mean validation loss 0.122261; Mean validation F1 0.938490; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.084763; Mean training F1 0.936654; Mean validation loss 0.111474; Mean validation F1 0.939274; Learning rate 0.000846;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.084591; Mean training F1 0.936964; Mean validation loss 0.094148; Mean validation F1 0.939833; Learning rate 0.000837;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.084081; Mean training F1 0.937177; Mean validation loss 0.069445; Mean validation F1 0.939869; Learning rate 0.000828;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.084687; Mean training F1 0.936742; Mean validation loss 0.083141; Mean validation F1 0.939760; Learning rate 0.000818;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.084732; Mean training F1 0.936632; Mean validation loss 0.097817; Mean validation F1 0.939771; Learning rate 0.000809;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.085124; Mean training F1 0.936283; Mean validation loss 0.077819; Mean validation F1 0.939053; Learning rate 0.000799;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.084120; Mean training F1 0.937051; Mean validation loss 0.095232; Mean validation F1 0.939170; Learning rate 0.000789;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.084327; Mean training F1 0.936682; Mean validation loss 0.087350; Mean validation F1 0.939881; Learning rate 0.000779;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.083930; Mean training F1 0.937299; Mean validation loss 0.072512; Mean validation F1 0.940114; Learning rate 0.000769;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.083557; Mean training F1 0.937295; Mean validation loss 0.094660; Mean validation F1 0.939836; Learning rate 0.000759;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.084259; Mean training F1 0.936767; Mean validation loss 0.064732; Mean validation F1 0.939833; Learning rate 0.000748;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.083346; Mean training F1 0.937560; Mean validation loss 0.083032; Mean validation F1 0.939742; Learning rate 0.000737;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.083606; Mean training F1 0.937300; Mean validation loss 0.079965; Mean validation F1 0.939013; Learning rate 0.000726;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.083564; Mean training F1 0.937109; Mean validation loss 0.136546; Mean validation F1 0.939887; Learning rate 0.000716;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.083590; Mean training F1 0.937215; Mean validation loss 0.069648; Mean validation F1 0.938896; Learning rate 0.000704;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.084022; Mean training F1 0.937121; Mean validation loss 0.100305; Mean validation F1 0.939324; Learning rate 0.000693;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.083363; Mean training F1 0.937352; Mean validation loss 0.078302; Mean validation F1 0.939202; Learning rate 0.000682;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.084718; Mean training F1 0.936678; Mean validation loss 0.050576; Mean validation F1 0.940056; Learning rate 0.000670;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.083273; Mean training F1 0.937538; Mean validation loss 0.111603; Mean validation F1 0.939883; Learning rate 0.000659;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.083788; Mean training F1 0.937420; Mean validation loss 0.101256; Mean validation F1 0.940012; Learning rate 0.000647;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.086117; Mean training F1 0.935626; Mean validation loss 0.095359; Mean validation F1 0.938181; Learning rate 0.000635;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.083126; Mean training F1 0.937370; Mean validation loss 0.061729; Mean validation F1 0.939097; Learning rate 0.000624;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.083042; Mean training F1 0.937639; Mean validation loss 0.079823; Mean validation F1 0.938319; Learning rate 0.000612;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.083225; Mean training F1 0.937400; Mean validation loss 0.100496; Mean validation F1 0.940013; Learning rate 0.000600;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.082367; Mean training F1 0.937966; Mean validation loss 0.074341; Mean validation F1 0.939416; Learning rate 0.000588;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.082501; Mean training F1 0.937870; Mean validation loss 0.047693; Mean validation F1 0.939414; Learning rate 0.000576;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.082390; Mean training F1 0.938059; Mean validation loss 0.090756; Mean validation F1 0.939056; Learning rate 0.000564;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.082165; Mean training F1 0.938102; Mean validation loss 0.098046; Mean validation F1 0.940064; Learning rate 0.000552;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.082612; Mean training F1 0.937695; Mean validation loss 0.069347; Mean validation F1 0.939708; Learning rate 0.000539;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.081998; Mean training F1 0.938128; Mean validation loss 0.069215; Mean validation F1 0.940105; Learning rate 0.000527;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.082037; Mean training F1 0.937919; Mean validation loss 0.086294; Mean validation F1 0.939490; Learning rate 0.000515;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.081706; Mean training F1 0.938384; Mean validation loss 0.076403; Mean validation F1 0.939232; Learning rate 0.000503;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.081914; Mean training F1 0.938218; Mean validation loss 0.073692; Mean validation F1 0.939692; Learning rate 0.000491;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.082143; Mean training F1 0.937815; Mean validation loss 0.083352; Mean validation F1 0.939688; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.081579; Mean training F1 0.938400; Mean validation loss 0.082835; Mean validation F1 0.939846; Learning rate 0.000466;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.081750; Mean training F1 0.937951; Mean validation loss 0.063026; Mean validation F1 0.939614; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.081590; Mean training F1 0.938290; Mean validation loss 0.064514; Mean validation F1 0.939685; Learning rate 0.000442;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.081427; Mean training F1 0.938409; Mean validation loss 0.087170; Mean validation F1 0.939929; Learning rate 0.000430;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.081266; Mean training F1 0.938498; Mean validation loss 0.092435; Mean validation F1 0.939871; Learning rate 0.000418;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.081254; Mean training F1 0.938481; Mean validation loss 0.089963; Mean validation F1 0.940140; Learning rate 0.000406;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.081277; Mean training F1 0.938407; Mean validation loss 0.080486; Mean validation F1 0.939128; Learning rate 0.000394;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.081437; Mean training F1 0.938367; Mean validation loss 0.061841; Mean validation F1 0.939443; Learning rate 0.000382;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.080828; Mean training F1 0.938661; Mean validation loss 0.058976; Mean validation F1 0.939975; Learning rate 0.000370;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.080912; Mean training F1 0.938693; Mean validation loss 0.117229; Mean validation F1 0.939847; Learning rate 0.000358;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.080696; Mean training F1 0.938706; Mean validation loss 0.063744; Mean validation F1 0.939633; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.080814; Mean training F1 0.938585; Mean validation loss 0.066627; Mean validation F1 0.940123; Learning rate 0.000335;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.080588; Mean training F1 0.938729; Mean validation loss 0.067841; Mean validation F1 0.940174; Learning rate 0.000324;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.080396; Mean training F1 0.938941; Mean validation loss 0.092383; Mean validation F1 0.939937; Learning rate 0.000312;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.080507; Mean training F1 0.938911; Mean validation loss 0.067178; Mean validation F1 0.940258; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.080188; Mean training F1 0.938907; Mean validation loss 0.087490; Mean validation F1 0.940224; Learning rate 0.000290;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.080231; Mean training F1 0.938968; Mean validation loss 0.123167; Mean validation F1 0.940183; Learning rate 0.000279;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.080261; Mean training F1 0.939015; Mean validation loss 0.100644; Mean validation F1 0.940022; Learning rate 0.000268;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.080138; Mean training F1 0.938965; Mean validation loss 0.075040; Mean validation F1 0.940176; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.079953; Mean training F1 0.939215; Mean validation loss 0.055166; Mean validation F1 0.939522; Learning rate 0.000247;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.079986; Mean training F1 0.939054; Mean validation loss 0.061161; Mean validation F1 0.940277; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.080030; Mean training F1 0.939009; Mean validation loss 0.104754; Mean validation F1 0.940379; Learning rate 0.000226;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.079787; Mean training F1 0.939203; Mean validation loss 0.073663; Mean validation F1 0.940310; Learning rate 0.000216;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.079729; Mean training F1 0.939077; Mean validation loss 0.040477; Mean validation F1 0.940112; Learning rate 0.000206;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.079634; Mean training F1 0.939192; Mean validation loss 0.079379; Mean validation F1 0.939937; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.079596; Mean training F1 0.939478; Mean validation loss 0.080496; Mean validation F1 0.940260; Learning rate 0.000187;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.079448; Mean training F1 0.939483; Mean validation loss 0.069091; Mean validation F1 0.940187; Learning rate 0.000178;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.079389; Mean training F1 0.939557; Mean validation loss 0.076864; Mean validation F1 0.940352; Learning rate 0.000169;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.079380; Mean training F1 0.939483; Mean validation loss 0.075618; Mean validation F1 0.940207; Learning rate 0.000160;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.079315; Mean training F1 0.939466; Mean validation loss 0.062242; Mean validation F1 0.940353; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.079126; Mean training F1 0.939695; Mean validation loss 0.120893; Mean validation F1 0.940471; Learning rate 0.000142;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.079096; Mean training F1 0.939681; Mean validation loss 0.064536; Mean validation F1 0.939485; Learning rate 0.000134;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.079055; Mean training F1 0.939638; Mean validation loss 0.112159; Mean validation F1 0.940474; Learning rate 0.000126;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.079010; Mean training F1 0.939651; Mean validation loss 0.079665; Mean validation F1 0.940258; Learning rate 0.000118;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.078943; Mean training F1 0.939709; Mean validation loss 0.104914; Mean validation F1 0.940356; Learning rate 0.000111;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.078892; Mean training F1 0.939698; Mean validation loss 0.055768; Mean validation F1 0.940338; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.078872; Mean training F1 0.939801; Mean validation loss 0.075315; Mean validation F1 0.940372; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.078824; Mean training F1 0.939780; Mean validation loss 0.054248; Mean validation F1 0.940331; Learning rate 0.000089;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.078704; Mean training F1 0.939925; Mean validation loss 0.050496; Mean validation F1 0.940474; Learning rate 0.000082;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.078655; Mean training F1 0.939892; Mean validation loss 0.071060; Mean validation F1 0.940151; Learning rate 0.000076;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.078647; Mean training F1 0.939926; Mean validation loss 0.065259; Mean validation F1 0.940481; Learning rate 0.000070;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.078568; Mean training F1 0.939894; Mean validation loss 0.115968; Mean validation F1 0.940367; Learning rate 0.000064;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.078578; Mean training F1 0.939893; Mean validation loss 0.056365; Mean validation F1 0.940277; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.078522; Mean training F1 0.939963; Mean validation loss 0.104155; Mean validation F1 0.940525; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.078465; Mean training F1 0.940060; Mean validation loss 0.082962; Mean validation F1 0.940289; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.078439; Mean training F1 0.940037; Mean validation loss 0.079297; Mean validation F1 0.940378; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.078402; Mean training F1 0.940089; Mean validation loss 0.066397; Mean validation F1 0.940494; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.078380; Mean training F1 0.940061; Mean validation loss 0.055315; Mean validation F1 0.940454; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.078349; Mean training F1 0.940137; Mean validation loss 0.079161; Mean validation F1 0.940462; Learning rate 0.000030;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.078308; Mean training F1 0.940067; Mean validation loss 0.078149; Mean validation F1 0.940633; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.078298; Mean training F1 0.940138; Mean validation loss 0.072341; Mean validation F1 0.940409; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.078267; Mean training F1 0.940085; Mean validation loss 0.061735; Mean validation F1 0.940461; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.078252; Mean training F1 0.940113; Mean validation loss 0.088388; Mean validation F1 0.940563; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.078238; Mean training F1 0.940181; Mean validation loss 0.067254; Mean validation F1 0.940358; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.078211; Mean training F1 0.940173; Mean validation loss 0.055198; Mean validation F1 0.940559; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.078202; Mean training F1 0.940188; Mean validation loss 0.065029; Mean validation F1 0.940655; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.078191; Mean training F1 0.940133; Mean validation loss 0.066296; Mean validation F1 0.940436; Learning rate 0.000009;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.078176; Mean training F1 0.940189; Mean validation loss 0.082083; Mean validation F1 0.940620; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.078172; Mean training F1 0.940189; Mean validation loss 0.083383; Mean validation F1 0.940564; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.078160; Mean training F1 0.940205; Mean validation loss 0.076243; Mean validation F1 0.940555; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.078153; Mean training F1 0.940190; Mean validation loss 0.101791; Mean validation F1 0.940700; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.078148; Mean training F1 0.940198; Mean validation loss 0.089084; Mean validation F1 0.940654; Learning rate 0.000005;\n",
    "################################################################\n",
    "Training/validation for fold 2/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.759181; Mean training F1 0.562373; Mean validation loss 0.337859; Mean validation F1 0.791148; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.196341; Mean training F1 0.886050; Mean validation loss 0.170253; Mean validation F1 0.902989; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.126795; Mean training F1 0.914902; Mean validation loss 0.096322; Mean validation F1 0.920017; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.097427; Mean training F1 0.931124; Mean validation loss 0.091841; Mean validation F1 0.927203; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.090636; Mean training F1 0.934116; Mean validation loss 0.122664; Mean validation F1 0.930140; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.089538; Mean training F1 0.934401; Mean validation loss 0.067140; Mean validation F1 0.927494; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.087507; Mean training F1 0.934920; Mean validation loss 0.127435; Mean validation F1 0.930157; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.086371; Mean training F1 0.935681; Mean validation loss 0.101592; Mean validation F1 0.931310; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.086020; Mean training F1 0.935537; Mean validation loss 0.102948; Mean validation F1 0.931104; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.085128; Mean training F1 0.935718; Mean validation loss 0.106310; Mean validation F1 0.932254; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.084551; Mean training F1 0.936304; Mean validation loss 0.094319; Mean validation F1 0.931463; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.099786; Mean training F1 0.922257; Mean validation loss 0.179809; Mean validation F1 0.892455; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.093132; Mean training F1 0.930679; Mean validation loss 0.096885; Mean validation F1 0.931271; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.084156; Mean training F1 0.936935; Mean validation loss 0.087716; Mean validation F1 0.932759; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.083086; Mean training F1 0.937428; Mean validation loss 0.063408; Mean validation F1 0.933628; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.083457; Mean training F1 0.937009; Mean validation loss 0.071603; Mean validation F1 0.930806; Learning rate 0.000962;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.083079; Mean training F1 0.937122; Mean validation loss 0.060555; Mean validation F1 0.931815; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.082323; Mean training F1 0.937691; Mean validation loss 0.050723; Mean validation F1 0.931484; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.082183; Mean training F1 0.937733; Mean validation loss 0.077469; Mean validation F1 0.933502; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.082420; Mean training F1 0.937511; Mean validation loss 0.076048; Mean validation F1 0.932419; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.084328; Mean training F1 0.936338; Mean validation loss 0.067931; Mean validation F1 0.932792; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.082485; Mean training F1 0.937290; Mean validation loss 0.080730; Mean validation F1 0.933465; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.082194; Mean training F1 0.937277; Mean validation loss 0.124288; Mean validation F1 0.932627; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.083069; Mean training F1 0.936864; Mean validation loss 0.096843; Mean validation F1 0.933192; Learning rate 0.000916;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.081509; Mean training F1 0.937936; Mean validation loss 0.093929; Mean validation F1 0.933647; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.173631; Mean training F1 0.901600; Mean validation loss 0.081338; Mean validation F1 0.927949; Learning rate 0.000902;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.085047; Mean training F1 0.936647; Mean validation loss 0.123424; Mean validation F1 0.932701; Learning rate 0.000895;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.083332; Mean training F1 0.937268; Mean validation loss 0.087363; Mean validation F1 0.932788; Learning rate 0.000887;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.082683; Mean training F1 0.937666; Mean validation loss 0.079175; Mean validation F1 0.933296; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.082103; Mean training F1 0.937749; Mean validation loss 0.108687; Mean validation F1 0.933097; Learning rate 0.000871;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.081773; Mean training F1 0.937938; Mean validation loss 0.081643; Mean validation F1 0.933385; Learning rate 0.000863;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.081406; Mean training F1 0.938090; Mean validation loss 0.046718; Mean validation F1 0.932570; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.081379; Mean training F1 0.938208; Mean validation loss 0.140824; Mean validation F1 0.933715; Learning rate 0.000846;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.081294; Mean training F1 0.938014; Mean validation loss 0.095428; Mean validation F1 0.933390; Learning rate 0.000837;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.080998; Mean training F1 0.938269; Mean validation loss 0.122570; Mean validation F1 0.932892; Learning rate 0.000828;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.081274; Mean training F1 0.937969; Mean validation loss 0.096514; Mean validation F1 0.933300; Learning rate 0.000818;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.080689; Mean training F1 0.938460; Mean validation loss 0.090468; Mean validation F1 0.932615; Learning rate 0.000809;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.080813; Mean training F1 0.938312; Mean validation loss 0.079353; Mean validation F1 0.933430; Learning rate 0.000799;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.080543; Mean training F1 0.938405; Mean validation loss 0.103733; Mean validation F1 0.933310; Learning rate 0.000789;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.081166; Mean training F1 0.937776; Mean validation loss 0.049769; Mean validation F1 0.929518; Learning rate 0.000779;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.081183; Mean training F1 0.937466; Mean validation loss 0.071176; Mean validation F1 0.933765; Learning rate 0.000769;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.080254; Mean training F1 0.938639; Mean validation loss 0.073239; Mean validation F1 0.933061; Learning rate 0.000759;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.080084; Mean training F1 0.938673; Mean validation loss 0.075669; Mean validation F1 0.934151; Learning rate 0.000748;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.080252; Mean training F1 0.938521; Mean validation loss 0.057202; Mean validation F1 0.934387; Learning rate 0.000737;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.079968; Mean training F1 0.938699; Mean validation loss 0.080543; Mean validation F1 0.933127; Learning rate 0.000726;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.080298; Mean training F1 0.938276; Mean validation loss 0.071356; Mean validation F1 0.934121; Learning rate 0.000716;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.080138; Mean training F1 0.938468; Mean validation loss 0.078065; Mean validation F1 0.932339; Learning rate 0.000704;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.080295; Mean training F1 0.938319; Mean validation loss 0.103412; Mean validation F1 0.934308; Learning rate 0.000693;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.079994; Mean training F1 0.938571; Mean validation loss 0.065579; Mean validation F1 0.932617; Learning rate 0.000682;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.079964; Mean training F1 0.938464; Mean validation loss 0.068061; Mean validation F1 0.934432; Learning rate 0.000670;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.079853; Mean training F1 0.938695; Mean validation loss 0.069440; Mean validation F1 0.933483; Learning rate 0.000659;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.080778; Mean training F1 0.937669; Mean validation loss 0.028329; Mean validation F1 0.932979; Learning rate 0.000647;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.079803; Mean training F1 0.938823; Mean validation loss 0.037671; Mean validation F1 0.933861; Learning rate 0.000635;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.079369; Mean training F1 0.939027; Mean validation loss 0.071444; Mean validation F1 0.934590; Learning rate 0.000624;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.079519; Mean training F1 0.938880; Mean validation loss 0.069446; Mean validation F1 0.927606; Learning rate 0.000612;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.079596; Mean training F1 0.938575; Mean validation loss 0.108050; Mean validation F1 0.933700; Learning rate 0.000600;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.079357; Mean training F1 0.938965; Mean validation loss 0.068456; Mean validation F1 0.934569; Learning rate 0.000588;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.079203; Mean training F1 0.938940; Mean validation loss 0.101471; Mean validation F1 0.934587; Learning rate 0.000576;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.079434; Mean training F1 0.938617; Mean validation loss 0.098797; Mean validation F1 0.932794; Learning rate 0.000564;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.079418; Mean training F1 0.938607; Mean validation loss 0.055976; Mean validation F1 0.933809; Learning rate 0.000552;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.078954; Mean training F1 0.939206; Mean validation loss 0.101209; Mean validation F1 0.934028; Learning rate 0.000539;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.078897; Mean training F1 0.939164; Mean validation loss 0.072116; Mean validation F1 0.933747; Learning rate 0.000527;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.088484; Mean training F1 0.933988; Mean validation loss 0.104334; Mean validation F1 0.934167; Learning rate 0.000515;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.079055; Mean training F1 0.939138; Mean validation loss 0.097855; Mean validation F1 0.934993; Learning rate 0.000503;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.078857; Mean training F1 0.939219; Mean validation loss 0.072629; Mean validation F1 0.934704; Learning rate 0.000491;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.078741; Mean training F1 0.939301; Mean validation loss 0.083206; Mean validation F1 0.934750; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.078542; Mean training F1 0.939459; Mean validation loss 0.034984; Mean validation F1 0.934927; Learning rate 0.000466;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.078509; Mean training F1 0.939407; Mean validation loss 0.055808; Mean validation F1 0.934791; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.078357; Mean training F1 0.939542; Mean validation loss 0.088629; Mean validation F1 0.934829; Learning rate 0.000442;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.078396; Mean training F1 0.939547; Mean validation loss 0.085312; Mean validation F1 0.934715; Learning rate 0.000430;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.078487; Mean training F1 0.939370; Mean validation loss 0.133759; Mean validation F1 0.934784; Learning rate 0.000418;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.078313; Mean training F1 0.939460; Mean validation loss 0.057700; Mean validation F1 0.934225; Learning rate 0.000406;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.078358; Mean training F1 0.939415; Mean validation loss 0.082500; Mean validation F1 0.935069; Learning rate 0.000394;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.078276; Mean training F1 0.939540; Mean validation loss 0.069935; Mean validation F1 0.934792; Learning rate 0.000382;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.078039; Mean training F1 0.939720; Mean validation loss 0.091152; Mean validation F1 0.934948; Learning rate 0.000370;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.077993; Mean training F1 0.939648; Mean validation loss 0.098131; Mean validation F1 0.934859; Learning rate 0.000358;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.077793; Mean training F1 0.939892; Mean validation loss 0.054440; Mean validation F1 0.935050; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.078018; Mean training F1 0.939675; Mean validation loss 0.119041; Mean validation F1 0.934953; Learning rate 0.000335;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.077847; Mean training F1 0.939693; Mean validation loss 0.071001; Mean validation F1 0.934330; Learning rate 0.000324;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.077725; Mean training F1 0.939866; Mean validation loss 0.104611; Mean validation F1 0.934854; Learning rate 0.000312;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.077633; Mean training F1 0.940023; Mean validation loss 0.066328; Mean validation F1 0.935107; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.077676; Mean training F1 0.939982; Mean validation loss 0.097067; Mean validation F1 0.934896; Learning rate 0.000290;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.077430; Mean training F1 0.940081; Mean validation loss 0.080798; Mean validation F1 0.935227; Learning rate 0.000279;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.077459; Mean training F1 0.940009; Mean validation loss 0.087222; Mean validation F1 0.934583; Learning rate 0.000268;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.077348; Mean training F1 0.940123; Mean validation loss 0.061554; Mean validation F1 0.934999; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.077257; Mean training F1 0.940166; Mean validation loss 0.075441; Mean validation F1 0.935090; Learning rate 0.000247;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.077208; Mean training F1 0.940188; Mean validation loss 0.078185; Mean validation F1 0.934758; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.077167; Mean training F1 0.940156; Mean validation loss 0.093876; Mean validation F1 0.935074; Learning rate 0.000226;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.077087; Mean training F1 0.940302; Mean validation loss 0.098086; Mean validation F1 0.934980; Learning rate 0.000216;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.077113; Mean training F1 0.940318; Mean validation loss 0.083467; Mean validation F1 0.934710; Learning rate 0.000206;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.077130; Mean training F1 0.940128; Mean validation loss 0.058889; Mean validation F1 0.934592; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.077082; Mean training F1 0.940198; Mean validation loss 0.103134; Mean validation F1 0.934729; Learning rate 0.000187;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.076897; Mean training F1 0.940293; Mean validation loss 0.089567; Mean validation F1 0.935224; Learning rate 0.000178;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.076792; Mean training F1 0.940393; Mean validation loss 0.061419; Mean validation F1 0.935072; Learning rate 0.000169;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.076786; Mean training F1 0.940403; Mean validation loss 0.065243; Mean validation F1 0.935002; Learning rate 0.000160;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.076654; Mean training F1 0.940580; Mean validation loss 0.100694; Mean validation F1 0.934904; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.076581; Mean training F1 0.940593; Mean validation loss 0.084450; Mean validation F1 0.934922; Learning rate 0.000142;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.076602; Mean training F1 0.940519; Mean validation loss 0.066861; Mean validation F1 0.935039; Learning rate 0.000134;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.076527; Mean training F1 0.940620; Mean validation loss 0.084264; Mean validation F1 0.934867; Learning rate 0.000126;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.076479; Mean training F1 0.940583; Mean validation loss 0.070875; Mean validation F1 0.934942; Learning rate 0.000118;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.076434; Mean training F1 0.940620; Mean validation loss 0.061343; Mean validation F1 0.935056; Learning rate 0.000111;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.076364; Mean training F1 0.940691; Mean validation loss 0.084302; Mean validation F1 0.934996; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.076370; Mean training F1 0.940683; Mean validation loss 0.048683; Mean validation F1 0.934879; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.076364; Mean training F1 0.940669; Mean validation loss 0.066944; Mean validation F1 0.934880; Learning rate 0.000089;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.076261; Mean training F1 0.940671; Mean validation loss 0.071582; Mean validation F1 0.934671; Learning rate 0.000082;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.076237; Mean training F1 0.940683; Mean validation loss 0.102103; Mean validation F1 0.935079; Learning rate 0.000076;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.076163; Mean training F1 0.940791; Mean validation loss 0.060982; Mean validation F1 0.934826; Learning rate 0.000070;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.076162; Mean training F1 0.940870; Mean validation loss 0.088591; Mean validation F1 0.934991; Learning rate 0.000064;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.076112; Mean training F1 0.940900; Mean validation loss 0.078147; Mean validation F1 0.935025; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.076078; Mean training F1 0.940890; Mean validation loss 0.076152; Mean validation F1 0.934968; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.076079; Mean training F1 0.940838; Mean validation loss 0.052842; Mean validation F1 0.935035; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.076015; Mean training F1 0.940856; Mean validation loss 0.044043; Mean validation F1 0.935099; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.075997; Mean training F1 0.940891; Mean validation loss 0.058588; Mean validation F1 0.935014; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.075970; Mean training F1 0.940902; Mean validation loss 0.095098; Mean validation F1 0.934842; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.075950; Mean training F1 0.940863; Mean validation loss 0.074326; Mean validation F1 0.935044; Learning rate 0.000030;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.075939; Mean training F1 0.940914; Mean validation loss 0.082715; Mean validation F1 0.934939; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.075902; Mean training F1 0.941000; Mean validation loss 0.062225; Mean validation F1 0.935009; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.075873; Mean training F1 0.940966; Mean validation loss 0.062658; Mean validation F1 0.934896; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.075862; Mean training F1 0.940955; Mean validation loss 0.062627; Mean validation F1 0.934976; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.075854; Mean training F1 0.940977; Mean validation loss 0.056837; Mean validation F1 0.934995; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.075829; Mean training F1 0.941058; Mean validation loss 0.083818; Mean validation F1 0.934881; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.075825; Mean training F1 0.941035; Mean validation loss 0.073485; Mean validation F1 0.934969; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.075815; Mean training F1 0.941012; Mean validation loss 0.083016; Mean validation F1 0.935006; Learning rate 0.000009;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.075796; Mean training F1 0.941047; Mean validation loss 0.047288; Mean validation F1 0.934971; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.075789; Mean training F1 0.941045; Mean validation loss 0.085096; Mean validation F1 0.934978; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.075780; Mean training F1 0.941078; Mean validation loss 0.115263; Mean validation F1 0.935026; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.075774; Mean training F1 0.941038; Mean validation loss 0.088779; Mean validation F1 0.934879; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.075775; Mean training F1 0.941034; Mean validation loss 0.072044; Mean validation F1 0.934942; Learning rate 0.000005;\n",
    "################################################################\n",
    "Training/validation for fold 3/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.787794; Mean training F1 0.555842; Mean validation loss 0.304934; Mean validation F1 0.748425; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.268501; Mean training F1 0.846319; Mean validation loss 0.176221; Mean validation F1 0.902369; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.151227; Mean training F1 0.908682; Mean validation loss 0.169090; Mean validation F1 0.910510; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.121701; Mean training F1 0.920428; Mean validation loss 0.127996; Mean validation F1 0.928232; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.095765; Mean training F1 0.929938; Mean validation loss 0.064769; Mean validation F1 0.932688; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.090346; Mean training F1 0.934346; Mean validation loss 0.106000; Mean validation F1 0.933777; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.089392; Mean training F1 0.934403; Mean validation loss 0.045123; Mean validation F1 0.932152; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.088849; Mean training F1 0.934894; Mean validation loss 0.091559; Mean validation F1 0.934387; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.087663; Mean training F1 0.935308; Mean validation loss 0.119818; Mean validation F1 0.932593; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.089385; Mean training F1 0.933845; Mean validation loss 0.091650; Mean validation F1 0.935358; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.085762; Mean training F1 0.936498; Mean validation loss 0.096923; Mean validation F1 0.934000; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.085798; Mean training F1 0.936330; Mean validation loss 0.069831; Mean validation F1 0.934892; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.087263; Mean training F1 0.935275; Mean validation loss 0.086520; Mean validation F1 0.933148; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.086285; Mean training F1 0.936020; Mean validation loss 0.085132; Mean validation F1 0.935557; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.141461; Mean training F1 0.908287; Mean validation loss 0.113781; Mean validation F1 0.930868; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.090347; Mean training F1 0.934244; Mean validation loss 0.111953; Mean validation F1 0.934345; Learning rate 0.000962;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.087887; Mean training F1 0.935250; Mean validation loss 0.074481; Mean validation F1 0.933214; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.086830; Mean training F1 0.936085; Mean validation loss 0.054209; Mean validation F1 0.935053; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.086052; Mean training F1 0.936351; Mean validation loss 0.103783; Mean validation F1 0.935551; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.085784; Mean training F1 0.936462; Mean validation loss 0.111369; Mean validation F1 0.935376; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.085006; Mean training F1 0.936985; Mean validation loss 0.064361; Mean validation F1 0.935497; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.084967; Mean training F1 0.936854; Mean validation loss 0.089515; Mean validation F1 0.932617; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.084855; Mean training F1 0.936697; Mean validation loss 0.104032; Mean validation F1 0.934371; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.084615; Mean training F1 0.936670; Mean validation loss 0.092555; Mean validation F1 0.935686; Learning rate 0.000916;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.085009; Mean training F1 0.936204; Mean validation loss 0.103049; Mean validation F1 0.935337; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.084377; Mean training F1 0.937060; Mean validation loss 0.071338; Mean validation F1 0.935377; Learning rate 0.000902;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.084962; Mean training F1 0.936948; Mean validation loss 0.098327; Mean validation F1 0.936497; Learning rate 0.000895;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.084444; Mean training F1 0.937184; Mean validation loss 0.060386; Mean validation F1 0.935341; Learning rate 0.000887;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.084171; Mean training F1 0.936627; Mean validation loss 0.065840; Mean validation F1 0.936377; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.083503; Mean training F1 0.937325; Mean validation loss 0.072978; Mean validation F1 0.934908; Learning rate 0.000871;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.083548; Mean training F1 0.937354; Mean validation loss 0.077413; Mean validation F1 0.936300; Learning rate 0.000863;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.084127; Mean training F1 0.936988; Mean validation loss 0.113051; Mean validation F1 0.935109; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.083812; Mean training F1 0.937310; Mean validation loss 0.095865; Mean validation F1 0.936487; Learning rate 0.000846;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.083189; Mean training F1 0.937672; Mean validation loss 0.068039; Mean validation F1 0.936157; Learning rate 0.000837;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.083435; Mean training F1 0.937173; Mean validation loss 0.089686; Mean validation F1 0.934936; Learning rate 0.000828;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.083502; Mean training F1 0.937262; Mean validation loss 0.106408; Mean validation F1 0.936096; Learning rate 0.000818;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.083218; Mean training F1 0.937480; Mean validation loss 0.067351; Mean validation F1 0.934226; Learning rate 0.000809;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.082948; Mean training F1 0.937624; Mean validation loss 0.077822; Mean validation F1 0.936546; Learning rate 0.000799;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.082653; Mean training F1 0.937868; Mean validation loss 0.110604; Mean validation F1 0.936695; Learning rate 0.000789;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.084521; Mean training F1 0.935529; Mean validation loss 0.060735; Mean validation F1 0.931248; Learning rate 0.000779;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.083352; Mean training F1 0.937472; Mean validation loss 0.092967; Mean validation F1 0.936361; Learning rate 0.000769;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.082552; Mean training F1 0.937955; Mean validation loss 0.084108; Mean validation F1 0.935950; Learning rate 0.000759;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.082722; Mean training F1 0.937844; Mean validation loss 0.070823; Mean validation F1 0.936357; Learning rate 0.000748;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.082464; Mean training F1 0.937849; Mean validation loss 0.089511; Mean validation F1 0.936093; Learning rate 0.000737;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.082756; Mean training F1 0.937629; Mean validation loss 0.105616; Mean validation F1 0.936642; Learning rate 0.000726;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.082138; Mean training F1 0.938055; Mean validation loss 0.074638; Mean validation F1 0.933778; Learning rate 0.000716;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.081691; Mean training F1 0.938415; Mean validation loss 0.089248; Mean validation F1 0.936164; Learning rate 0.000704;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.082212; Mean training F1 0.938126; Mean validation loss 0.090775; Mean validation F1 0.936747; Learning rate 0.000693;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.082714; Mean training F1 0.937643; Mean validation loss 0.052485; Mean validation F1 0.935695; Learning rate 0.000682;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.081801; Mean training F1 0.938195; Mean validation loss 0.124048; Mean validation F1 0.936769; Learning rate 0.000670;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.081603; Mean training F1 0.938366; Mean validation loss 0.086758; Mean validation F1 0.936983; Learning rate 0.000659;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.081900; Mean training F1 0.938130; Mean validation loss 0.065071; Mean validation F1 0.936319; Learning rate 0.000647;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.082224; Mean training F1 0.937877; Mean validation loss 0.100554; Mean validation F1 0.935795; Learning rate 0.000635;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.081825; Mean training F1 0.938186; Mean validation loss 0.055209; Mean validation F1 0.936117; Learning rate 0.000624;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.081612; Mean training F1 0.938408; Mean validation loss 0.083081; Mean validation F1 0.936816; Learning rate 0.000612;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.081445; Mean training F1 0.938557; Mean validation loss 0.076886; Mean validation F1 0.937217; Learning rate 0.000600;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.081308; Mean training F1 0.938686; Mean validation loss 0.071673; Mean validation F1 0.935967; Learning rate 0.000588;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.082269; Mean training F1 0.937870; Mean validation loss 0.069528; Mean validation F1 0.936774; Learning rate 0.000576;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.081384; Mean training F1 0.938508; Mean validation loss 0.078580; Mean validation F1 0.937353; Learning rate 0.000564;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.081364; Mean training F1 0.938329; Mean validation loss 0.100547; Mean validation F1 0.936915; Learning rate 0.000552;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.080911; Mean training F1 0.938709; Mean validation loss 0.057275; Mean validation F1 0.936281; Learning rate 0.000539;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.080683; Mean training F1 0.938838; Mean validation loss 0.056448; Mean validation F1 0.936528; Learning rate 0.000527;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.080770; Mean training F1 0.938896; Mean validation loss 0.066494; Mean validation F1 0.937342; Learning rate 0.000515;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.080538; Mean training F1 0.939057; Mean validation loss 0.109129; Mean validation F1 0.936860; Learning rate 0.000503;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.081167; Mean training F1 0.938296; Mean validation loss 0.073244; Mean validation F1 0.935150; Learning rate 0.000491;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.081112; Mean training F1 0.938735; Mean validation loss 0.096642; Mean validation F1 0.936804; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.080514; Mean training F1 0.938998; Mean validation loss 0.084108; Mean validation F1 0.936924; Learning rate 0.000466;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.080441; Mean training F1 0.938875; Mean validation loss 0.075594; Mean validation F1 0.936764; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.080262; Mean training F1 0.939064; Mean validation loss 0.094325; Mean validation F1 0.936339; Learning rate 0.000442;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.080675; Mean training F1 0.939005; Mean validation loss 0.079089; Mean validation F1 0.937245; Learning rate 0.000430;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.080026; Mean training F1 0.939168; Mean validation loss 0.110583; Mean validation F1 0.936911; Learning rate 0.000418;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.080884; Mean training F1 0.938948; Mean validation loss 0.061897; Mean validation F1 0.935699; Learning rate 0.000406;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.082949; Mean training F1 0.937977; Mean validation loss 0.102100; Mean validation F1 0.936601; Learning rate 0.000394;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.080137; Mean training F1 0.939145; Mean validation loss 0.065646; Mean validation F1 0.936791; Learning rate 0.000382;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.080047; Mean training F1 0.939288; Mean validation loss 0.042954; Mean validation F1 0.936490; Learning rate 0.000370;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.079759; Mean training F1 0.939417; Mean validation loss 0.067388; Mean validation F1 0.936832; Learning rate 0.000358;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.079685; Mean training F1 0.939368; Mean validation loss 0.065959; Mean validation F1 0.937122; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.079677; Mean training F1 0.939509; Mean validation loss 0.093521; Mean validation F1 0.936932; Learning rate 0.000335;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.079607; Mean training F1 0.939585; Mean validation loss 0.064943; Mean validation F1 0.936423; Learning rate 0.000324;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.079580; Mean training F1 0.939427; Mean validation loss 0.060414; Mean validation F1 0.936594; Learning rate 0.000312;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.079494; Mean training F1 0.939466; Mean validation loss 0.054806; Mean validation F1 0.936951; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.079336; Mean training F1 0.939627; Mean validation loss 0.095768; Mean validation F1 0.937139; Learning rate 0.000290;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.079417; Mean training F1 0.939695; Mean validation loss 0.043450; Mean validation F1 0.936362; Learning rate 0.000279;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.079336; Mean training F1 0.939643; Mean validation loss 0.064654; Mean validation F1 0.936743; Learning rate 0.000268;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.079310; Mean training F1 0.939518; Mean validation loss 0.068744; Mean validation F1 0.937260; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.079215; Mean training F1 0.939772; Mean validation loss 0.091980; Mean validation F1 0.936934; Learning rate 0.000247;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.079027; Mean training F1 0.939812; Mean validation loss 0.055553; Mean validation F1 0.937149; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.078909; Mean training F1 0.939893; Mean validation loss 0.095953; Mean validation F1 0.937041; Learning rate 0.000226;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.079024; Mean training F1 0.939846; Mean validation loss 0.066027; Mean validation F1 0.936811; Learning rate 0.000216;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.078802; Mean training F1 0.939923; Mean validation loss 0.045135; Mean validation F1 0.937328; Learning rate 0.000206;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.078847; Mean training F1 0.939929; Mean validation loss 0.082541; Mean validation F1 0.937241; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.078742; Mean training F1 0.940011; Mean validation loss 0.071945; Mean validation F1 0.937190; Learning rate 0.000187;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.078657; Mean training F1 0.940097; Mean validation loss 0.051353; Mean validation F1 0.937419; Learning rate 0.000178;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.078608; Mean training F1 0.940095; Mean validation loss 0.084823; Mean validation F1 0.937407; Learning rate 0.000169;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.078597; Mean training F1 0.940111; Mean validation loss 0.080911; Mean validation F1 0.937624; Learning rate 0.000160;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.078501; Mean training F1 0.940041; Mean validation loss 0.077334; Mean validation F1 0.937554; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.078422; Mean training F1 0.940209; Mean validation loss 0.068517; Mean validation F1 0.937434; Learning rate 0.000142;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.078322; Mean training F1 0.940260; Mean validation loss 0.091926; Mean validation F1 0.937369; Learning rate 0.000134;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.078369; Mean training F1 0.940108; Mean validation loss 0.081266; Mean validation F1 0.937504; Learning rate 0.000126;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.078286; Mean training F1 0.940318; Mean validation loss 0.053376; Mean validation F1 0.937234; Learning rate 0.000118;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.078153; Mean training F1 0.940369; Mean validation loss 0.051554; Mean validation F1 0.937286; Learning rate 0.000111;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.078175; Mean training F1 0.940320; Mean validation loss 0.082393; Mean validation F1 0.937616; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.078156; Mean training F1 0.940207; Mean validation loss 0.078884; Mean validation F1 0.937067; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.078108; Mean training F1 0.940246; Mean validation loss 0.049355; Mean validation F1 0.937683; Learning rate 0.000089;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.078090; Mean training F1 0.940294; Mean validation loss 0.108256; Mean validation F1 0.937371; Learning rate 0.000082;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.077971; Mean training F1 0.940384; Mean validation loss 0.067097; Mean validation F1 0.937408; Learning rate 0.000076;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.077974; Mean training F1 0.940447; Mean validation loss 0.069850; Mean validation F1 0.937494; Learning rate 0.000070;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.077907; Mean training F1 0.940449; Mean validation loss 0.071943; Mean validation F1 0.937675; Learning rate 0.000064;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.077828; Mean training F1 0.940532; Mean validation loss 0.078563; Mean validation F1 0.937261; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.077806; Mean training F1 0.940524; Mean validation loss 0.069961; Mean validation F1 0.937461; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.077774; Mean training F1 0.940543; Mean validation loss 0.086862; Mean validation F1 0.937416; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.077793; Mean training F1 0.940563; Mean validation loss 0.080093; Mean validation F1 0.937454; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.077707; Mean training F1 0.940526; Mean validation loss 0.108235; Mean validation F1 0.937664; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.077697; Mean training F1 0.940526; Mean validation loss 0.107210; Mean validation F1 0.937517; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.077676; Mean training F1 0.940625; Mean validation loss 0.064196; Mean validation F1 0.937635; Learning rate 0.000030;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.077652; Mean training F1 0.940599; Mean validation loss 0.095915; Mean validation F1 0.937479; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.077607; Mean training F1 0.940618; Mean validation loss 0.067677; Mean validation F1 0.937446; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.077585; Mean training F1 0.940608; Mean validation loss 0.085693; Mean validation F1 0.937571; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.077569; Mean training F1 0.940660; Mean validation loss 0.054607; Mean validation F1 0.937569; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.077544; Mean training F1 0.940704; Mean validation loss 0.077194; Mean validation F1 0.937444; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.077538; Mean training F1 0.940685; Mean validation loss 0.122595; Mean validation F1 0.937550; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.077533; Mean training F1 0.940739; Mean validation loss 0.116766; Mean validation F1 0.937509; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.077510; Mean training F1 0.940710; Mean validation loss 0.059503; Mean validation F1 0.937560; Learning rate 0.000009;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.077504; Mean training F1 0.940778; Mean validation loss 0.120566; Mean validation F1 0.937549; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.077489; Mean training F1 0.940694; Mean validation loss 0.097586; Mean validation F1 0.937559; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.077482; Mean training F1 0.940707; Mean validation loss 0.057803; Mean validation F1 0.937645; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.077478; Mean training F1 0.940735; Mean validation loss 0.092285; Mean validation F1 0.937576; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.077473; Mean training F1 0.940735; Mean validation loss 0.061810; Mean validation F1 0.937531; Learning rate 0.000005;\n",
    "################################################################\n",
    "Training/validation for fold 4/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.771668; Mean training F1 0.550021; Mean validation loss 0.458488; Mean validation F1 0.750129; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.274836; Mean training F1 0.845936; Mean validation loss 0.188494; Mean validation F1 0.915449; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.122111; Mean training F1 0.922311; Mean validation loss 0.072364; Mean validation F1 0.931731; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.102345; Mean training F1 0.927408; Mean validation loss 0.087835; Mean validation F1 0.933049; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.097304; Mean training F1 0.930067; Mean validation loss 0.057932; Mean validation F1 0.933646; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.091236; Mean training F1 0.934432; Mean validation loss 0.090125; Mean validation F1 0.932498; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.089318; Mean training F1 0.935069; Mean validation loss 0.076365; Mean validation F1 0.936378; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.089703; Mean training F1 0.934980; Mean validation loss 0.103705; Mean validation F1 0.899459; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.135530; Mean training F1 0.917793; Mean validation loss 0.077440; Mean validation F1 0.936337; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.089340; Mean training F1 0.935419; Mean validation loss 0.096721; Mean validation F1 0.936513; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.088160; Mean training F1 0.935888; Mean validation loss 0.112364; Mean validation F1 0.937049; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.087746; Mean training F1 0.935947; Mean validation loss 0.057693; Mean validation F1 0.937177; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.087598; Mean training F1 0.935998; Mean validation loss 0.054504; Mean validation F1 0.935539; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.087389; Mean training F1 0.936202; Mean validation loss 0.091595; Mean validation F1 0.937519; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.087239; Mean training F1 0.935772; Mean validation loss 0.092204; Mean validation F1 0.937041; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.102632; Mean training F1 0.926958; Mean validation loss 0.062545; Mean validation F1 0.936419; Learning rate 0.000962;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.088291; Mean training F1 0.935329; Mean validation loss 0.089550; Mean validation F1 0.935785; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.087224; Mean training F1 0.936092; Mean validation loss 0.079978; Mean validation F1 0.936062; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.086680; Mean training F1 0.936300; Mean validation loss 0.079634; Mean validation F1 0.937279; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.086318; Mean training F1 0.936386; Mean validation loss 0.093940; Mean validation F1 0.937730; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.086234; Mean training F1 0.936452; Mean validation loss 0.091010; Mean validation F1 0.936303; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.086297; Mean training F1 0.936434; Mean validation loss 0.094668; Mean validation F1 0.937007; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.086556; Mean training F1 0.935919; Mean validation loss 0.081649; Mean validation F1 0.936357; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.086183; Mean training F1 0.936565; Mean validation loss 0.087089; Mean validation F1 0.937107; Learning rate 0.000916;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.085711; Mean training F1 0.936537; Mean validation loss 0.102041; Mean validation F1 0.937788; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.085902; Mean training F1 0.936051; Mean validation loss 0.094272; Mean validation F1 0.937770; Learning rate 0.000902;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.084876; Mean training F1 0.936884; Mean validation loss 0.107927; Mean validation F1 0.937524; Learning rate 0.000895;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.084543; Mean training F1 0.937314; Mean validation loss 0.111298; Mean validation F1 0.937050; Learning rate 0.000887;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.084494; Mean training F1 0.937365; Mean validation loss 0.090173; Mean validation F1 0.937472; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.085965; Mean training F1 0.936015; Mean validation loss 0.079093; Mean validation F1 0.937537; Learning rate 0.000871;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.085053; Mean training F1 0.937026; Mean validation loss 0.090390; Mean validation F1 0.938010; Learning rate 0.000863;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.084373; Mean training F1 0.937172; Mean validation loss 0.082077; Mean validation F1 0.938237; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.085448; Mean training F1 0.936898; Mean validation loss 0.062491; Mean validation F1 0.937869; Learning rate 0.000846;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.084746; Mean training F1 0.936851; Mean validation loss 0.090893; Mean validation F1 0.937521; Learning rate 0.000837;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.084386; Mean training F1 0.937249; Mean validation loss 0.060989; Mean validation F1 0.936575; Learning rate 0.000828;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.084077; Mean training F1 0.936850; Mean validation loss 0.065474; Mean validation F1 0.938674; Learning rate 0.000818;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.083651; Mean training F1 0.937591; Mean validation loss 0.077952; Mean validation F1 0.937295; Learning rate 0.000809;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.083606; Mean training F1 0.937692; Mean validation loss 0.124169; Mean validation F1 0.938099; Learning rate 0.000799;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.083828; Mean training F1 0.937432; Mean validation loss 0.076153; Mean validation F1 0.937395; Learning rate 0.000789;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.083435; Mean training F1 0.937759; Mean validation loss 0.062781; Mean validation F1 0.938149; Learning rate 0.000779;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.083554; Mean training F1 0.937597; Mean validation loss 0.105666; Mean validation F1 0.935172; Learning rate 0.000769;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.084455; Mean training F1 0.936861; Mean validation loss 0.080754; Mean validation F1 0.937116; Learning rate 0.000759;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.082902; Mean training F1 0.938027; Mean validation loss 0.068480; Mean validation F1 0.937725; Learning rate 0.000748;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.082950; Mean training F1 0.937765; Mean validation loss 0.069531; Mean validation F1 0.938379; Learning rate 0.000737;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.083253; Mean training F1 0.937511; Mean validation loss 0.085829; Mean validation F1 0.938371; Learning rate 0.000726;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.082709; Mean training F1 0.937928; Mean validation loss 0.105522; Mean validation F1 0.938041; Learning rate 0.000716;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.083224; Mean training F1 0.937663; Mean validation loss 0.092191; Mean validation F1 0.938116; Learning rate 0.000704;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.082723; Mean training F1 0.938175; Mean validation loss 0.099697; Mean validation F1 0.938626; Learning rate 0.000693;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.083252; Mean training F1 0.937588; Mean validation loss 0.060651; Mean validation F1 0.938319; Learning rate 0.000682;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.082661; Mean training F1 0.938103; Mean validation loss 0.092124; Mean validation F1 0.938274; Learning rate 0.000670;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.082487; Mean training F1 0.938079; Mean validation loss 0.059007; Mean validation F1 0.937506; Learning rate 0.000659;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.082440; Mean training F1 0.938123; Mean validation loss 0.088731; Mean validation F1 0.938156; Learning rate 0.000647;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.089317; Mean training F1 0.935214; Mean validation loss 0.109353; Mean validation F1 0.937435; Learning rate 0.000635;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.083502; Mean training F1 0.937580; Mean validation loss 0.117419; Mean validation F1 0.938532; Learning rate 0.000624;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.082712; Mean training F1 0.938028; Mean validation loss 0.060078; Mean validation F1 0.938306; Learning rate 0.000612;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.082159; Mean training F1 0.938386; Mean validation loss 0.081626; Mean validation F1 0.938805; Learning rate 0.000600;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.082811; Mean training F1 0.937874; Mean validation loss 0.125767; Mean validation F1 0.937013; Learning rate 0.000588;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.082602; Mean training F1 0.937919; Mean validation loss 0.088568; Mean validation F1 0.938221; Learning rate 0.000576;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.082176; Mean training F1 0.938254; Mean validation loss 0.077922; Mean validation F1 0.936450; Learning rate 0.000564;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.082160; Mean training F1 0.938181; Mean validation loss 0.069817; Mean validation F1 0.938306; Learning rate 0.000552;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.082118; Mean training F1 0.938290; Mean validation loss 0.057872; Mean validation F1 0.938496; Learning rate 0.000539;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.081777; Mean training F1 0.938473; Mean validation loss 0.086872; Mean validation F1 0.938434; Learning rate 0.000527;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.081805; Mean training F1 0.938482; Mean validation loss 0.063911; Mean validation F1 0.938778; Learning rate 0.000515;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.081624; Mean training F1 0.938442; Mean validation loss 0.101527; Mean validation F1 0.938288; Learning rate 0.000503;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.081495; Mean training F1 0.938542; Mean validation loss 0.105673; Mean validation F1 0.938105; Learning rate 0.000491;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.081810; Mean training F1 0.938520; Mean validation loss 0.066991; Mean validation F1 0.938247; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.081470; Mean training F1 0.938516; Mean validation loss 0.091743; Mean validation F1 0.938668; Learning rate 0.000466;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.081310; Mean training F1 0.938712; Mean validation loss 0.069465; Mean validation F1 0.938713; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.081300; Mean training F1 0.938734; Mean validation loss 0.057957; Mean validation F1 0.937799; Learning rate 0.000442;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.081264; Mean training F1 0.938585; Mean validation loss 0.074437; Mean validation F1 0.938225; Learning rate 0.000430;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.081076; Mean training F1 0.938871; Mean validation loss 0.056604; Mean validation F1 0.938224; Learning rate 0.000418;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.080913; Mean training F1 0.938895; Mean validation loss 0.079753; Mean validation F1 0.938607; Learning rate 0.000406;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.080841; Mean training F1 0.938973; Mean validation loss 0.070692; Mean validation F1 0.938515; Learning rate 0.000394;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.080808; Mean training F1 0.939018; Mean validation loss 0.063321; Mean validation F1 0.938593; Learning rate 0.000382;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.080839; Mean training F1 0.938990; Mean validation loss 0.090410; Mean validation F1 0.938769; Learning rate 0.000370;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.080735; Mean training F1 0.939051; Mean validation loss 0.068127; Mean validation F1 0.938060; Learning rate 0.000358;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.080788; Mean training F1 0.938934; Mean validation loss 0.076722; Mean validation F1 0.938963; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.080660; Mean training F1 0.939131; Mean validation loss 0.063032; Mean validation F1 0.937762; Learning rate 0.000335;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.080661; Mean training F1 0.938931; Mean validation loss 0.111979; Mean validation F1 0.938715; Learning rate 0.000324;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.080628; Mean training F1 0.939060; Mean validation loss 0.112503; Mean validation F1 0.938553; Learning rate 0.000312;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.080609; Mean training F1 0.939085; Mean validation loss 0.076929; Mean validation F1 0.938786; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.080298; Mean training F1 0.939123; Mean validation loss 0.077823; Mean validation F1 0.938636; Learning rate 0.000290;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.080325; Mean training F1 0.939051; Mean validation loss 0.089156; Mean validation F1 0.938219; Learning rate 0.000279;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.080198; Mean training F1 0.939227; Mean validation loss 0.066473; Mean validation F1 0.938866; Learning rate 0.000268;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.080081; Mean training F1 0.939319; Mean validation loss 0.072045; Mean validation F1 0.938674; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.079979; Mean training F1 0.939463; Mean validation loss 0.081988; Mean validation F1 0.938646; Learning rate 0.000247;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.080025; Mean training F1 0.939151; Mean validation loss 0.086743; Mean validation F1 0.938734; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.079885; Mean training F1 0.939387; Mean validation loss 0.069308; Mean validation F1 0.938928; Learning rate 0.000226;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.079813; Mean training F1 0.939562; Mean validation loss 0.093927; Mean validation F1 0.938960; Learning rate 0.000216;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.079862; Mean training F1 0.939504; Mean validation loss 0.028681; Mean validation F1 0.938893; Learning rate 0.000206;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.079864; Mean training F1 0.939379; Mean validation loss 0.087035; Mean validation F1 0.938590; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.079639; Mean training F1 0.939668; Mean validation loss 0.069810; Mean validation F1 0.938637; Learning rate 0.000187;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.079607; Mean training F1 0.939507; Mean validation loss 0.043464; Mean validation F1 0.938498; Learning rate 0.000178;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.079498; Mean training F1 0.939728; Mean validation loss 0.098091; Mean validation F1 0.938745; Learning rate 0.000169;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.079494; Mean training F1 0.939651; Mean validation loss 0.072227; Mean validation F1 0.939000; Learning rate 0.000160;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.079460; Mean training F1 0.939712; Mean validation loss 0.074040; Mean validation F1 0.938917; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.079409; Mean training F1 0.939650; Mean validation loss 0.089617; Mean validation F1 0.938829; Learning rate 0.000142;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.079296; Mean training F1 0.939765; Mean validation loss 0.068849; Mean validation F1 0.938881; Learning rate 0.000134;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.079313; Mean training F1 0.939727; Mean validation loss 0.081600; Mean validation F1 0.939017; Learning rate 0.000126;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.079214; Mean training F1 0.939873; Mean validation loss 0.095921; Mean validation F1 0.938849; Learning rate 0.000118;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.079142; Mean training F1 0.939874; Mean validation loss 0.076852; Mean validation F1 0.938857; Learning rate 0.000111;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.079119; Mean training F1 0.939904; Mean validation loss 0.083431; Mean validation F1 0.938890; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.079054; Mean training F1 0.939984; Mean validation loss 0.087584; Mean validation F1 0.938936; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.078987; Mean training F1 0.939943; Mean validation loss 0.087353; Mean validation F1 0.938793; Learning rate 0.000089;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.078986; Mean training F1 0.939958; Mean validation loss 0.052686; Mean validation F1 0.939039; Learning rate 0.000082;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.078926; Mean training F1 0.940001; Mean validation loss 0.084614; Mean validation F1 0.938862; Learning rate 0.000076;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.078907; Mean training F1 0.939983; Mean validation loss 0.041678; Mean validation F1 0.938753; Learning rate 0.000070;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.078862; Mean training F1 0.940147; Mean validation loss 0.089962; Mean validation F1 0.939022; Learning rate 0.000064;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.078806; Mean training F1 0.940116; Mean validation loss 0.066115; Mean validation F1 0.938870; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.078785; Mean training F1 0.940100; Mean validation loss 0.070568; Mean validation F1 0.938875; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.078771; Mean training F1 0.940168; Mean validation loss 0.064728; Mean validation F1 0.938962; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.078737; Mean training F1 0.940093; Mean validation loss 0.081697; Mean validation F1 0.938900; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.078699; Mean training F1 0.940120; Mean validation loss 0.115880; Mean validation F1 0.938688; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.078676; Mean training F1 0.940132; Mean validation loss 0.086467; Mean validation F1 0.938714; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.078648; Mean training F1 0.940215; Mean validation loss 0.077931; Mean validation F1 0.938973; Learning rate 0.000030;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.078611; Mean training F1 0.940214; Mean validation loss 0.110063; Mean validation F1 0.938784; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.078606; Mean training F1 0.940192; Mean validation loss 0.055349; Mean validation F1 0.938911; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.078567; Mean training F1 0.940193; Mean validation loss 0.069982; Mean validation F1 0.938898; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.078552; Mean training F1 0.940211; Mean validation loss 0.089593; Mean validation F1 0.938970; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.078530; Mean training F1 0.940240; Mean validation loss 0.086458; Mean validation F1 0.938920; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.078522; Mean training F1 0.940260; Mean validation loss 0.079892; Mean validation F1 0.938912; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.078505; Mean training F1 0.940247; Mean validation loss 0.050394; Mean validation F1 0.939032; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.078494; Mean training F1 0.940313; Mean validation loss 0.088337; Mean validation F1 0.938907; Learning rate 0.000009;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.078485; Mean training F1 0.940264; Mean validation loss 0.080371; Mean validation F1 0.938966; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.078467; Mean training F1 0.940217; Mean validation loss 0.072487; Mean validation F1 0.938933; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.078463; Mean training F1 0.940251; Mean validation loss 0.083306; Mean validation F1 0.938983; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.078458; Mean training F1 0.940291; Mean validation loss 0.076536; Mean validation F1 0.939022; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.078457; Mean training F1 0.940298; Mean validation loss 0.078419; Mean validation F1 0.938894; Learning rate 0.000005;\n",
    "################################################################\n",
    "Training/validation for fold 5/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.814147; Mean training F1 0.541200; Mean validation loss 0.480659; Mean validation F1 0.740165; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.265388; Mean training F1 0.847564; Mean validation loss 0.234083; Mean validation F1 0.908566; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.119982; Mean training F1 0.916778; Mean validation loss 0.098696; Mean validation F1 0.931788; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.098357; Mean training F1 0.930724; Mean validation loss 0.122657; Mean validation F1 0.933466; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.102762; Mean training F1 0.925655; Mean validation loss 0.134629; Mean validation F1 0.935979; Learning rate 0.000997;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.090459; Mean training F1 0.934655; Mean validation loss 0.115047; Mean validation F1 0.936269; Learning rate 0.000995;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.090255; Mean training F1 0.935112; Mean validation loss 0.076936; Mean validation F1 0.936213; Learning rate 0.000993;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.089653; Mean training F1 0.935316; Mean validation loss 0.088210; Mean validation F1 0.936402; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.089409; Mean training F1 0.935216; Mean validation loss 0.062117; Mean validation F1 0.936731; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.088634; Mean training F1 0.935480; Mean validation loss 0.137582; Mean validation F1 0.934874; Learning rate 0.000985;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.087893; Mean training F1 0.935553; Mean validation loss 0.084979; Mean validation F1 0.936375; Learning rate 0.000982;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.094513; Mean training F1 0.932375; Mean validation loss 0.076807; Mean validation F1 0.936901; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.087458; Mean training F1 0.935998; Mean validation loss 0.122978; Mean validation F1 0.936905; Learning rate 0.000975;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.086878; Mean training F1 0.936359; Mean validation loss 0.089706; Mean validation F1 0.937865; Learning rate 0.000971;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.086751; Mean training F1 0.936321; Mean validation loss 0.066935; Mean validation F1 0.936849; Learning rate 0.000967;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.086455; Mean training F1 0.936309; Mean validation loss 0.105656; Mean validation F1 0.936412; Learning rate 0.000962;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.088482; Mean training F1 0.934665; Mean validation loss 0.091291; Mean validation F1 0.936363; Learning rate 0.000958;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.086769; Mean training F1 0.936080; Mean validation loss 0.065351; Mean validation F1 0.937807; Learning rate 0.000953;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.086789; Mean training F1 0.935631; Mean validation loss 0.102113; Mean validation F1 0.936747; Learning rate 0.000947;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.085896; Mean training F1 0.936388; Mean validation loss 0.100828; Mean validation F1 0.935167; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.085718; Mean training F1 0.936693; Mean validation loss 0.054071; Mean validation F1 0.937992; Learning rate 0.000936;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.085241; Mean training F1 0.937019; Mean validation loss 0.072114; Mean validation F1 0.937409; Learning rate 0.000930;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.102681; Mean training F1 0.925142; Mean validation loss 0.090619; Mean validation F1 0.936832; Learning rate 0.000923;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.085955; Mean training F1 0.936620; Mean validation loss 0.074298; Mean validation F1 0.937558; Learning rate 0.000916;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.085245; Mean training F1 0.937145; Mean validation loss 0.061561; Mean validation F1 0.936753; Learning rate 0.000910;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.085230; Mean training F1 0.936861; Mean validation loss 0.070298; Mean validation F1 0.937691; Learning rate 0.000902;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.085265; Mean training F1 0.936567; Mean validation loss 0.098975; Mean validation F1 0.937614; Learning rate 0.000895;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.084601; Mean training F1 0.937279; Mean validation loss 0.108501; Mean validation F1 0.937714; Learning rate 0.000887;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.086000; Mean training F1 0.936196; Mean validation loss 0.068579; Mean validation F1 0.935073; Learning rate 0.000880;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.084261; Mean training F1 0.937171; Mean validation loss 0.090687; Mean validation F1 0.937621; Learning rate 0.000871;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.084411; Mean training F1 0.937194; Mean validation loss 0.073833; Mean validation F1 0.937888; Learning rate 0.000863;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.083809; Mean training F1 0.937791; Mean validation loss 0.048113; Mean validation F1 0.938211; Learning rate 0.000855;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.083804; Mean training F1 0.937584; Mean validation loss 0.087223; Mean validation F1 0.938050; Learning rate 0.000846;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.084161; Mean training F1 0.937296; Mean validation loss 0.106341; Mean validation F1 0.937427; Learning rate 0.000837;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.084615; Mean training F1 0.936831; Mean validation loss 0.084748; Mean validation F1 0.937940; Learning rate 0.000828;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.085459; Mean training F1 0.936111; Mean validation loss 0.113148; Mean validation F1 0.936917; Learning rate 0.000818;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.084169; Mean training F1 0.937165; Mean validation loss 0.069328; Mean validation F1 0.937097; Learning rate 0.000809;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.084221; Mean training F1 0.937268; Mean validation loss 0.102599; Mean validation F1 0.938467; Learning rate 0.000799;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.083751; Mean training F1 0.937473; Mean validation loss 0.084356; Mean validation F1 0.938383; Learning rate 0.000789;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.083740; Mean training F1 0.937563; Mean validation loss 0.096709; Mean validation F1 0.938503; Learning rate 0.000779;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.083888; Mean training F1 0.937496; Mean validation loss 0.085979; Mean validation F1 0.937667; Learning rate 0.000769;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.083811; Mean training F1 0.937399; Mean validation loss 0.098108; Mean validation F1 0.938090; Learning rate 0.000759;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.083093; Mean training F1 0.937956; Mean validation loss 0.092653; Mean validation F1 0.938550; Learning rate 0.000748;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.082815; Mean training F1 0.938031; Mean validation loss 0.077107; Mean validation F1 0.938500; Learning rate 0.000737;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.083395; Mean training F1 0.937869; Mean validation loss 0.071499; Mean validation F1 0.938336; Learning rate 0.000726;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.083160; Mean training F1 0.937787; Mean validation loss 0.088498; Mean validation F1 0.938276; Learning rate 0.000716;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.083299; Mean training F1 0.937819; Mean validation loss 0.100154; Mean validation F1 0.938530; Learning rate 0.000704;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.086858; Mean training F1 0.935788; Mean validation loss 0.079127; Mean validation F1 0.936363; Learning rate 0.000693;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.083693; Mean training F1 0.937487; Mean validation loss 0.050864; Mean validation F1 0.938175; Learning rate 0.000682;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.083100; Mean training F1 0.937631; Mean validation loss 0.068454; Mean validation F1 0.938119; Learning rate 0.000670;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.082608; Mean training F1 0.938116; Mean validation loss 0.066580; Mean validation F1 0.938582; Learning rate 0.000659;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.082465; Mean training F1 0.938212; Mean validation loss 0.091946; Mean validation F1 0.938447; Learning rate 0.000647;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.082567; Mean training F1 0.938056; Mean validation loss 0.089703; Mean validation F1 0.935492; Learning rate 0.000635;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.082380; Mean training F1 0.938124; Mean validation loss 0.090643; Mean validation F1 0.938351; Learning rate 0.000624;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.082226; Mean training F1 0.938527; Mean validation loss 0.100529; Mean validation F1 0.938581; Learning rate 0.000612;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.082327; Mean training F1 0.938030; Mean validation loss 0.084715; Mean validation F1 0.938104; Learning rate 0.000600;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.082127; Mean training F1 0.938392; Mean validation loss 0.066608; Mean validation F1 0.938741; Learning rate 0.000588;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.082378; Mean training F1 0.938136; Mean validation loss 0.079113; Mean validation F1 0.938605; Learning rate 0.000576;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.081906; Mean training F1 0.938556; Mean validation loss 0.060126; Mean validation F1 0.938588; Learning rate 0.000564;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.082131; Mean training F1 0.938502; Mean validation loss 0.068252; Mean validation F1 0.938308; Learning rate 0.000552;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.082225; Mean training F1 0.938224; Mean validation loss 0.099011; Mean validation F1 0.937679; Learning rate 0.000539;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.081917; Mean training F1 0.938658; Mean validation loss 0.090028; Mean validation F1 0.937947; Learning rate 0.000527;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.081992; Mean training F1 0.938397; Mean validation loss 0.088944; Mean validation F1 0.938678; Learning rate 0.000515;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.081964; Mean training F1 0.938489; Mean validation loss 0.076772; Mean validation F1 0.938446; Learning rate 0.000503;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.081577; Mean training F1 0.938725; Mean validation loss 0.056990; Mean validation F1 0.938491; Learning rate 0.000491;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.081512; Mean training F1 0.938603; Mean validation loss 0.094989; Mean validation F1 0.938301; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.081322; Mean training F1 0.938850; Mean validation loss 0.054323; Mean validation F1 0.938209; Learning rate 0.000466;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.081538; Mean training F1 0.938718; Mean validation loss 0.106701; Mean validation F1 0.938756; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.081124; Mean training F1 0.938909; Mean validation loss 0.066409; Mean validation F1 0.938843; Learning rate 0.000442;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.081218; Mean training F1 0.938846; Mean validation loss 0.072113; Mean validation F1 0.939017; Learning rate 0.000430;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.081206; Mean training F1 0.938938; Mean validation loss 0.129575; Mean validation F1 0.938748; Learning rate 0.000418;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.081014; Mean training F1 0.938967; Mean validation loss 0.117342; Mean validation F1 0.938732; Learning rate 0.000406;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.080957; Mean training F1 0.938914; Mean validation loss 0.092929; Mean validation F1 0.938577; Learning rate 0.000394;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.080789; Mean training F1 0.939212; Mean validation loss 0.067154; Mean validation F1 0.938870; Learning rate 0.000382;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.080779; Mean training F1 0.939090; Mean validation loss 0.081314; Mean validation F1 0.939046; Learning rate 0.000370;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.080584; Mean training F1 0.939287; Mean validation loss 0.078846; Mean validation F1 0.938496; Learning rate 0.000358;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.080718; Mean training F1 0.939268; Mean validation loss 0.050155; Mean validation F1 0.938398; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.080672; Mean training F1 0.939106; Mean validation loss 0.059896; Mean validation F1 0.938821; Learning rate 0.000335;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.080509; Mean training F1 0.939294; Mean validation loss 0.096575; Mean validation F1 0.938765; Learning rate 0.000324;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.080407; Mean training F1 0.939300; Mean validation loss 0.073024; Mean validation F1 0.938736; Learning rate 0.000312;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.080412; Mean training F1 0.939156; Mean validation loss 0.068751; Mean validation F1 0.938201; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.080155; Mean training F1 0.939446; Mean validation loss 0.090400; Mean validation F1 0.939008; Learning rate 0.000290;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.080153; Mean training F1 0.939431; Mean validation loss 0.080680; Mean validation F1 0.938766; Learning rate 0.000279;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.080375; Mean training F1 0.939314; Mean validation loss 0.091748; Mean validation F1 0.938716; Learning rate 0.000268;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.080067; Mean training F1 0.939586; Mean validation loss 0.096766; Mean validation F1 0.938880; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.079931; Mean training F1 0.939588; Mean validation loss 0.122217; Mean validation F1 0.939070; Learning rate 0.000247;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.079967; Mean training F1 0.939490; Mean validation loss 0.078449; Mean validation F1 0.938414; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.079870; Mean training F1 0.939765; Mean validation loss 0.088663; Mean validation F1 0.938598; Learning rate 0.000226;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.079948; Mean training F1 0.939508; Mean validation loss 0.080334; Mean validation F1 0.938780; Learning rate 0.000216;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.079692; Mean training F1 0.939830; Mean validation loss 0.088773; Mean validation F1 0.938975; Learning rate 0.000206;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.079661; Mean training F1 0.939805; Mean validation loss 0.106368; Mean validation F1 0.938693; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.079631; Mean training F1 0.939762; Mean validation loss 0.087737; Mean validation F1 0.938742; Learning rate 0.000187;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.079506; Mean training F1 0.939911; Mean validation loss 0.065751; Mean validation F1 0.938671; Learning rate 0.000178;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.079514; Mean training F1 0.939824; Mean validation loss 0.097025; Mean validation F1 0.939073; Learning rate 0.000169;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.079348; Mean training F1 0.939924; Mean validation loss 0.068245; Mean validation F1 0.939068; Learning rate 0.000160;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.079373; Mean training F1 0.939904; Mean validation loss 0.069876; Mean validation F1 0.939166; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.079349; Mean training F1 0.939880; Mean validation loss 0.070745; Mean validation F1 0.938958; Learning rate 0.000142;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.079279; Mean training F1 0.939873; Mean validation loss 0.094010; Mean validation F1 0.938992; Learning rate 0.000134;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.079185; Mean training F1 0.939972; Mean validation loss 0.082674; Mean validation F1 0.939161; Learning rate 0.000126;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.079092; Mean training F1 0.939988; Mean validation loss 0.088008; Mean validation F1 0.939069; Learning rate 0.000118;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.079126; Mean training F1 0.939924; Mean validation loss 0.069068; Mean validation F1 0.938910; Learning rate 0.000111;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.078981; Mean training F1 0.940131; Mean validation loss 0.069674; Mean validation F1 0.939088; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.079017; Mean training F1 0.940066; Mean validation loss 0.102076; Mean validation F1 0.938916; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.078917; Mean training F1 0.940095; Mean validation loss 0.071857; Mean validation F1 0.939031; Learning rate 0.000089;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.078861; Mean training F1 0.940243; Mean validation loss 0.069144; Mean validation F1 0.938994; Learning rate 0.000082;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.078833; Mean training F1 0.940184; Mean validation loss 0.078463; Mean validation F1 0.938913; Learning rate 0.000076;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.078835; Mean training F1 0.940184; Mean validation loss 0.124202; Mean validation F1 0.939047; Learning rate 0.000070;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.078773; Mean training F1 0.940225; Mean validation loss 0.050815; Mean validation F1 0.938951; Learning rate 0.000064;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.078713; Mean training F1 0.940333; Mean validation loss 0.077672; Mean validation F1 0.939024; Learning rate 0.000058;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.078699; Mean training F1 0.940362; Mean validation loss 0.094411; Mean validation F1 0.939023; Learning rate 0.000053;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.078643; Mean training F1 0.940328; Mean validation loss 0.072066; Mean validation F1 0.938995; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.078627; Mean training F1 0.940428; Mean validation loss 0.065093; Mean validation F1 0.939090; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.078606; Mean training F1 0.940364; Mean validation loss 0.093078; Mean validation F1 0.939127; Learning rate 0.000039;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.078571; Mean training F1 0.940362; Mean validation loss 0.065275; Mean validation F1 0.939084; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.078543; Mean training F1 0.940427; Mean validation loss 0.074570; Mean validation F1 0.939018; Learning rate 0.000030;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.078517; Mean training F1 0.940384; Mean validation loss 0.066843; Mean validation F1 0.939145; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.078495; Mean training F1 0.940477; Mean validation loss 0.079025; Mean validation F1 0.939139; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.078459; Mean training F1 0.940397; Mean validation loss 0.079135; Mean validation F1 0.938993; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.078450; Mean training F1 0.940440; Mean validation loss 0.094515; Mean validation F1 0.939183; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.078442; Mean training F1 0.940481; Mean validation loss 0.099522; Mean validation F1 0.939117; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.078428; Mean training F1 0.940417; Mean validation loss 0.068628; Mean validation F1 0.939057; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.078407; Mean training F1 0.940466; Mean validation loss 0.090686; Mean validation F1 0.939129; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.078393; Mean training F1 0.940514; Mean validation loss 0.043763; Mean validation F1 0.939124; Learning rate 0.000009;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.078384; Mean training F1 0.940483; Mean validation loss 0.081147; Mean validation F1 0.939036; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.078373; Mean training F1 0.940473; Mean validation loss 0.084302; Mean validation F1 0.939202; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.078369; Mean training F1 0.940517; Mean validation loss 0.096886; Mean validation F1 0.939215; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.078363; Mean training F1 0.940540; Mean validation loss 0.070665; Mean validation F1 0.939229; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.078364; Mean training F1 0.940523; Mean validation loss 0.087226; Mean validation F1 0.939203; Learning rate 0.000005;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-------- fold 0 --------\n",
    "model validation loss: 0.107; validation f1: 0.941;\n",
    "-------- fold 1 --------\n",
    "model validation loss: 0.049; validation f1: 0.934;\n",
    "-------- fold 2 --------\n",
    "model validation loss: 0.091; validation f1: 0.938;\n",
    "-------- fold 3 --------\n",
    "model validation loss: 0.073; validation f1: 0.940;\n",
    "-------- fold 4 --------\n",
    "model validation loss: 0.075; validation f1: 0.939;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "################################################################\n",
    "Training/validation for fold 1/5;\n",
    "===========================================================\n",
    "Epoch 001/096 - Mean training loss 0.781633; Mean training F1 0.553002; Mean validation loss 0.412809; Mean validation F1 0.766302; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/096 - Mean training loss 0.261983; Mean training F1 0.859350; Mean validation loss 0.227335; Mean validation F1 0.901282; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 003/096 - Mean training loss 0.178007; Mean training F1 0.895909; Mean validation loss 0.200260; Mean validation F1 0.914850; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 004/096 - Mean training loss 0.134092; Mean training F1 0.915491; Mean validation loss 0.080251; Mean validation F1 0.931673; Learning rate 0.000996;\n",
    "===========================================================\n",
    "Epoch 005/096 - Mean training loss 0.101646; Mean training F1 0.929089; Mean validation loss 0.099819; Mean validation F1 0.936699; Learning rate 0.000994;\n",
    "===========================================================\n",
    "Epoch 006/096 - Mean training loss 0.095201; Mean training F1 0.932064; Mean validation loss 0.088729; Mean validation F1 0.935807; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 007/096 - Mean training loss 0.092859; Mean training F1 0.933430; Mean validation loss 0.073633; Mean validation F1 0.934309; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 008/096 - Mean training loss 0.093573; Mean training F1 0.931454; Mean validation loss 0.140850; Mean validation F1 0.938138; Learning rate 0.000984;\n",
    "===========================================================\n",
    "Epoch 009/096 - Mean training loss 0.089503; Mean training F1 0.934797; Mean validation loss 0.060738; Mean validation F1 0.937944; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 010/096 - Mean training loss 0.141612; Mean training F1 0.906454; Mean validation loss 0.127296; Mean validation F1 0.901391; Learning rate 0.000974;\n",
    "===========================================================\n",
    "Epoch 011/096 - Mean training loss 0.094788; Mean training F1 0.931791; Mean validation loss 0.085189; Mean validation F1 0.936724; Learning rate 0.000969;\n",
    "===========================================================\n",
    "Epoch 012/096 - Mean training loss 0.089199; Mean training F1 0.935149; Mean validation loss 0.098268; Mean validation F1 0.937406; Learning rate 0.000963;\n",
    "===========================================================\n",
    "Epoch 013/096 - Mean training loss 0.088318; Mean training F1 0.935515; Mean validation loss 0.035736; Mean validation F1 0.938002; Learning rate 0.000956;\n",
    "===========================================================\n",
    "Epoch 014/096 - Mean training loss 0.088026; Mean training F1 0.935420; Mean validation loss 0.069937; Mean validation F1 0.938388; Learning rate 0.000949;\n",
    "===========================================================\n",
    "Epoch 015/096 - Mean training loss 0.087992; Mean training F1 0.935621; Mean validation loss 0.076171; Mean validation F1 0.938521; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 016/096 - Mean training loss 0.087366; Mean training F1 0.935681; Mean validation loss 0.082512; Mean validation F1 0.938560; Learning rate 0.000934;\n",
    "===========================================================\n",
    "Epoch 017/096 - Mean training loss 0.087980; Mean training F1 0.935583; Mean validation loss 0.055329; Mean validation F1 0.937896; Learning rate 0.000926;\n",
    "===========================================================\n",
    "Epoch 018/096 - Mean training loss 0.087576; Mean training F1 0.935585; Mean validation loss 0.081457; Mean validation F1 0.936810; Learning rate 0.000917;\n",
    "===========================================================\n",
    "Epoch 019/096 - Mean training loss 0.087624; Mean training F1 0.935660; Mean validation loss 0.063963; Mean validation F1 0.937392; Learning rate 0.000908;\n",
    "===========================================================\n",
    "Epoch 020/096 - Mean training loss 0.087016; Mean training F1 0.936094; Mean validation loss 0.101678; Mean validation F1 0.939724; Learning rate 0.000898;\n",
    "===========================================================\n",
    "Epoch 021/096 - Mean training loss 0.086274; Mean training F1 0.936352; Mean validation loss 0.081030; Mean validation F1 0.938444; Learning rate 0.000888;\n",
    "===========================================================\n",
    "Epoch 022/096 - Mean training loss 0.086407; Mean training F1 0.936237; Mean validation loss 0.071360; Mean validation F1 0.938917; Learning rate 0.000878;\n",
    "===========================================================\n",
    "Epoch 023/096 - Mean training loss 0.086090; Mean training F1 0.936535; Mean validation loss 0.099004; Mean validation F1 0.939214; Learning rate 0.000867;\n",
    "===========================================================\n",
    "Epoch 024/096 - Mean training loss 0.086886; Mean training F1 0.935604; Mean validation loss 0.085522; Mean validation F1 0.938870; Learning rate 0.000856;\n",
    "===========================================================\n",
    "Epoch 025/096 - Mean training loss 0.086054; Mean training F1 0.936387; Mean validation loss 0.070791; Mean validation F1 0.938601; Learning rate 0.000844;\n",
    "===========================================================\n",
    "Epoch 026/096 - Mean training loss 0.085658; Mean training F1 0.936639; Mean validation loss 0.097455; Mean validation F1 0.938912; Learning rate 0.000832;\n",
    "===========================================================\n",
    "Epoch 027/096 - Mean training loss 0.085226; Mean training F1 0.937010; Mean validation loss 0.086390; Mean validation F1 0.939018; Learning rate 0.000820;\n",
    "===========================================================\n",
    "Epoch 028/096 - Mean training loss 0.087281; Mean training F1 0.935091; Mean validation loss 0.097088; Mean validation F1 0.939804; Learning rate 0.000807;\n",
    "===========================================================\n",
    "Epoch 029/096 - Mean training loss 0.085538; Mean training F1 0.936775; Mean validation loss 0.051526; Mean validation F1 0.939362; Learning rate 0.000794;\n",
    "===========================================================\n",
    "Epoch 030/096 - Mean training loss 0.086680; Mean training F1 0.935778; Mean validation loss 0.076377; Mean validation F1 0.938687; Learning rate 0.000781;\n",
    "===========================================================\n",
    "Epoch 031/096 - Mean training loss 0.086245; Mean training F1 0.936273; Mean validation loss 0.057200; Mean validation F1 0.938451; Learning rate 0.000767;\n",
    "===========================================================\n",
    "Epoch 032/096 - Mean training loss 0.084974; Mean training F1 0.937101; Mean validation loss 0.069085; Mean validation F1 0.938706; Learning rate 0.000753;\n",
    "===========================================================\n",
    "Epoch 033/096 - Mean training loss 0.084679; Mean training F1 0.937117; Mean validation loss 0.066366; Mean validation F1 0.939309; Learning rate 0.000739;\n",
    "===========================================================\n",
    "Epoch 034/096 - Mean training loss 0.084766; Mean training F1 0.937184; Mean validation loss 0.093857; Mean validation F1 0.939059; Learning rate 0.000724;\n",
    "===========================================================\n",
    "Epoch 035/096 - Mean training loss 0.085089; Mean training F1 0.936569; Mean validation loss 0.083715; Mean validation F1 0.938494; Learning rate 0.000710;\n",
    "===========================================================\n",
    "Epoch 036/096 - Mean training loss 0.084418; Mean training F1 0.937031; Mean validation loss 0.059908; Mean validation F1 0.938586; Learning rate 0.000695;\n",
    "===========================================================\n",
    "Epoch 037/096 - Mean training loss 0.084466; Mean training F1 0.936918; Mean validation loss 0.133200; Mean validation F1 0.939829; Learning rate 0.000680;\n",
    "===========================================================\n",
    "Epoch 038/096 - Mean training loss 0.083896; Mean training F1 0.937493; Mean validation loss 0.100102; Mean validation F1 0.939651; Learning rate 0.000665;\n",
    "===========================================================\n",
    "Epoch 039/096 - Mean training loss 0.084589; Mean training F1 0.937093; Mean validation loss 0.072560; Mean validation F1 0.938249; Learning rate 0.000649;\n",
    "===========================================================\n",
    "Epoch 040/096 - Mean training loss 0.084148; Mean training F1 0.937240; Mean validation loss 0.086210; Mean validation F1 0.938434; Learning rate 0.000634;\n",
    "===========================================================\n",
    "Epoch 041/096 - Mean training loss 0.084463; Mean training F1 0.936949; Mean validation loss 0.081103; Mean validation F1 0.939274; Learning rate 0.000618;\n",
    "===========================================================\n",
    "Epoch 042/096 - Mean training loss 0.084264; Mean training F1 0.937024; Mean validation loss 0.062746; Mean validation F1 0.939249; Learning rate 0.000602;\n",
    "===========================================================\n",
    "Epoch 043/096 - Mean training loss 0.083325; Mean training F1 0.937824; Mean validation loss 0.094868; Mean validation F1 0.939783; Learning rate 0.000586;\n",
    "===========================================================\n",
    "Epoch 044/096 - Mean training loss 0.083286; Mean training F1 0.937732; Mean validation loss 0.090414; Mean validation F1 0.940102; Learning rate 0.000570;\n",
    "===========================================================\n",
    "Epoch 045/096 - Mean training loss 0.102585; Mean training F1 0.923650; Mean validation loss 0.130771; Mean validation F1 0.933253; Learning rate 0.000554;\n",
    "===========================================================\n",
    "Epoch 046/096 - Mean training loss 0.088873; Mean training F1 0.934698; Mean validation loss 0.088191; Mean validation F1 0.938272; Learning rate 0.000538;\n",
    "===========================================================\n",
    "Epoch 047/096 - Mean training loss 0.084537; Mean training F1 0.936968; Mean validation loss 0.054124; Mean validation F1 0.939712; Learning rate 0.000522;\n",
    "===========================================================\n",
    "Epoch 048/096 - Mean training loss 0.083645; Mean training F1 0.937522; Mean validation loss 0.096849; Mean validation F1 0.940002; Learning rate 0.000506;\n",
    "===========================================================\n",
    "Epoch 049/096 - Mean training loss 0.083462; Mean training F1 0.937672; Mean validation loss 0.113205; Mean validation F1 0.940016; Learning rate 0.000489;\n",
    "===========================================================\n",
    "Epoch 050/096 - Mean training loss 0.083508; Mean training F1 0.937435; Mean validation loss 0.061859; Mean validation F1 0.939197; Learning rate 0.000473;\n",
    "===========================================================\n",
    "Epoch 051/096 - Mean training loss 0.083153; Mean training F1 0.937708; Mean validation loss 0.063504; Mean validation F1 0.939989; Learning rate 0.000457;\n",
    "===========================================================\n",
    "Epoch 052/096 - Mean training loss 0.082961; Mean training F1 0.937798; Mean validation loss 0.097192; Mean validation F1 0.940010; Learning rate 0.000441;\n",
    "===========================================================\n",
    "Epoch 053/096 - Mean training loss 0.082968; Mean training F1 0.937854; Mean validation loss 0.084846; Mean validation F1 0.939689; Learning rate 0.000425;\n",
    "===========================================================\n",
    "Epoch 054/096 - Mean training loss 0.083456; Mean training F1 0.937590; Mean validation loss 0.053251; Mean validation F1 0.939848; Learning rate 0.000409;\n",
    "===========================================================\n",
    "Epoch 055/096 - Mean training loss 0.082635; Mean training F1 0.937955; Mean validation loss 0.073831; Mean validation F1 0.939850; Learning rate 0.000393;\n",
    "===========================================================\n",
    "Epoch 056/096 - Mean training loss 0.082742; Mean training F1 0.937893; Mean validation loss 0.078202; Mean validation F1 0.939559; Learning rate 0.000377;\n",
    "===========================================================\n",
    "Epoch 057/096 - Mean training loss 0.082728; Mean training F1 0.938015; Mean validation loss 0.069343; Mean validation F1 0.940232; Learning rate 0.000362;\n",
    "===========================================================\n",
    "Epoch 058/096 - Mean training loss 0.082498; Mean training F1 0.938190; Mean validation loss 0.098570; Mean validation F1 0.939938; Learning rate 0.000346;\n",
    "===========================================================\n",
    "Epoch 059/096 - Mean training loss 0.082428; Mean training F1 0.938149; Mean validation loss 0.067996; Mean validation F1 0.940307; Learning rate 0.000331;\n",
    "===========================================================\n",
    "Epoch 060/096 - Mean training loss 0.082369; Mean training F1 0.938052; Mean validation loss 0.080549; Mean validation F1 0.940003; Learning rate 0.000316;\n",
    "===========================================================\n",
    "Epoch 061/096 - Mean training loss 0.082161; Mean training F1 0.938190; Mean validation loss 0.067339; Mean validation F1 0.940188; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 062/096 - Mean training loss 0.082167; Mean training F1 0.938337; Mean validation loss 0.110540; Mean validation F1 0.940189; Learning rate 0.000287;\n",
    "===========================================================\n",
    "Epoch 063/096 - Mean training loss 0.081899; Mean training F1 0.938396; Mean validation loss 0.060367; Mean validation F1 0.940011; Learning rate 0.000272;\n",
    "===========================================================\n",
    "Epoch 064/096 - Mean training loss 0.082032; Mean training F1 0.938250; Mean validation loss 0.064517; Mean validation F1 0.940359; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 065/096 - Mean training loss 0.081877; Mean training F1 0.938443; Mean validation loss 0.101256; Mean validation F1 0.939939; Learning rate 0.000244;\n",
    "===========================================================\n",
    "Epoch 066/096 - Mean training loss 0.081839; Mean training F1 0.938489; Mean validation loss 0.074373; Mean validation F1 0.939770; Learning rate 0.000230;\n",
    "===========================================================\n",
    "Epoch 067/096 - Mean training loss 0.081671; Mean training F1 0.938452; Mean validation loss 0.087162; Mean validation F1 0.940069; Learning rate 0.000217;\n",
    "===========================================================\n",
    "Epoch 068/096 - Mean training loss 0.081780; Mean training F1 0.938440; Mean validation loss 0.082698; Mean validation F1 0.940303; Learning rate 0.000204;\n",
    "===========================================================\n",
    "Epoch 069/096 - Mean training loss 0.081650; Mean training F1 0.938428; Mean validation loss 0.085629; Mean validation F1 0.940190; Learning rate 0.000191;\n",
    "===========================================================\n",
    "Epoch 070/096 - Mean training loss 0.081616; Mean training F1 0.938469; Mean validation loss 0.061089; Mean validation F1 0.940007; Learning rate 0.000179;\n",
    "===========================================================\n",
    "Epoch 071/096 - Mean training loss 0.081492; Mean training F1 0.938593; Mean validation loss 0.098063; Mean validation F1 0.940329; Learning rate 0.000167;\n",
    "===========================================================\n",
    "Epoch 072/096 - Mean training loss 0.081463; Mean training F1 0.938613; Mean validation loss 0.066613; Mean validation F1 0.939967; Learning rate 0.000155;\n",
    "===========================================================\n",
    "Epoch 073/096 - Mean training loss 0.081461; Mean training F1 0.938638; Mean validation loss 0.107404; Mean validation F1 0.940527; Learning rate 0.000144;\n",
    "===========================================================\n",
    "Epoch 074/096 - Mean training loss 0.081361; Mean training F1 0.938595; Mean validation loss 0.071343; Mean validation F1 0.940515; Learning rate 0.000133;\n",
    "===========================================================\n",
    "Epoch 075/096 - Mean training loss 0.081223; Mean training F1 0.938782; Mean validation loss 0.052674; Mean validation F1 0.939334; Learning rate 0.000123;\n",
    "===========================================================\n",
    "Epoch 076/096 - Mean training loss 0.081210; Mean training F1 0.938610; Mean validation loss 0.073499; Mean validation F1 0.940297; Learning rate 0.000113;\n",
    "===========================================================\n",
    "Epoch 077/096 - Mean training loss 0.081175; Mean training F1 0.938802; Mean validation loss 0.083867; Mean validation F1 0.940094; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 078/096 - Mean training loss 0.081151; Mean training F1 0.938738; Mean validation loss 0.105408; Mean validation F1 0.940388; Learning rate 0.000094;\n",
    "===========================================================\n",
    "Epoch 079/096 - Mean training loss 0.081123; Mean training F1 0.938837; Mean validation loss 0.076650; Mean validation F1 0.940457; Learning rate 0.000085;\n",
    "===========================================================\n",
    "Epoch 080/096 - Mean training loss 0.081095; Mean training F1 0.938818; Mean validation loss 0.079675; Mean validation F1 0.940519; Learning rate 0.000077;\n",
    "===========================================================\n",
    "Epoch 081/096 - Mean training loss 0.081055; Mean training F1 0.938761; Mean validation loss 0.091190; Mean validation F1 0.940493; Learning rate 0.000069;\n",
    "===========================================================\n",
    "Epoch 082/096 - Mean training loss 0.080974; Mean training F1 0.938899; Mean validation loss 0.051645; Mean validation F1 0.940259; Learning rate 0.000062;\n",
    "===========================================================\n",
    "Epoch 083/096 - Mean training loss 0.080944; Mean training F1 0.938941; Mean validation loss 0.060831; Mean validation F1 0.940220; Learning rate 0.000055;\n",
    "===========================================================\n",
    "Epoch 084/096 - Mean training loss 0.080961; Mean training F1 0.938867; Mean validation loss 0.083580; Mean validation F1 0.940361; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 085/096 - Mean training loss 0.080858; Mean training F1 0.938888; Mean validation loss 0.065490; Mean validation F1 0.940229; Learning rate 0.000042;\n",
    "===========================================================\n",
    "Epoch 086/096 - Mean training loss 0.080860; Mean training F1 0.938843; Mean validation loss 0.090887; Mean validation F1 0.940424; Learning rate 0.000037;\n",
    "===========================================================\n",
    "Epoch 087/096 - Mean training loss 0.080802; Mean training F1 0.938914; Mean validation loss 0.042099; Mean validation F1 0.940446; Learning rate 0.000032;\n",
    "===========================================================\n",
    "Epoch 088/096 - Mean training loss 0.080770; Mean training F1 0.939016; Mean validation loss 0.041644; Mean validation F1 0.940312; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 089/096 - Mean training loss 0.080750; Mean training F1 0.938956; Mean validation loss 0.098602; Mean validation F1 0.940418; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 090/096 - Mean training loss 0.080742; Mean training F1 0.938993; Mean validation loss 0.107095; Mean validation F1 0.940463; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 091/096 - Mean training loss 0.080707; Mean training F1 0.938967; Mean validation loss 0.075413; Mean validation F1 0.940384; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 092/096 - Mean training loss 0.080699; Mean training F1 0.939055; Mean validation loss 0.056152; Mean validation F1 0.940401; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 093/096 - Mean training loss 0.080690; Mean training F1 0.939015; Mean validation loss 0.069408; Mean validation F1 0.940305; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 094/096 - Mean training loss 0.080688; Mean training F1 0.939031; Mean validation loss 0.063590; Mean validation F1 0.940351; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 095/096 - Mean training loss 0.080676; Mean training F1 0.939005; Mean validation loss 0.070513; Mean validation F1 0.940514; Learning rate 0.000010;\n",
    "===========================================================\n",
    "Epoch 096/096 - Mean training loss 0.080669; Mean training F1 0.939059; Mean validation loss 0.145814; Mean validation F1 0.940417; Learning rate 0.000010;\n",
    "################################################################\n",
    "Training/validation for fold 2/5;\n",
    "===========================================================\n",
    "Epoch 001/096 - Mean training loss 0.814389; Mean training F1 0.531903; Mean validation loss 0.469490; Mean validation F1 0.758003; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/096 - Mean training loss 0.229337; Mean training F1 0.868913; Mean validation loss 0.183394; Mean validation F1 0.905002; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 003/096 - Mean training loss 0.113867; Mean training F1 0.925528; Mean validation loss 0.109205; Mean validation F1 0.914826; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 004/096 - Mean training loss 0.101049; Mean training F1 0.930571; Mean validation loss 0.089966; Mean validation F1 0.920528; Learning rate 0.000996;\n",
    "===========================================================\n",
    "Epoch 005/096 - Mean training loss 0.131180; Mean training F1 0.917635; Mean validation loss 0.124653; Mean validation F1 0.918180; Learning rate 0.000994;\n",
    "===========================================================\n",
    "Epoch 006/096 - Mean training loss 0.094386; Mean training F1 0.932020; Mean validation loss 0.078371; Mean validation F1 0.926392; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 007/096 - Mean training loss 0.089290; Mean training F1 0.934332; Mean validation loss 0.052228; Mean validation F1 0.927983; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 008/096 - Mean training loss 0.090690; Mean training F1 0.931807; Mean validation loss 0.055807; Mean validation F1 0.927376; Learning rate 0.000984;\n",
    "===========================================================\n",
    "Epoch 009/096 - Mean training loss 0.084779; Mean training F1 0.936435; Mean validation loss 0.100343; Mean validation F1 0.929321; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 010/096 - Mean training loss 0.084301; Mean training F1 0.936374; Mean validation loss 0.086669; Mean validation F1 0.929630; Learning rate 0.000974;\n",
    "===========================================================\n",
    "Epoch 011/096 - Mean training loss 0.085257; Mean training F1 0.935362; Mean validation loss 0.099059; Mean validation F1 0.930134; Learning rate 0.000969;\n",
    "===========================================================\n",
    "Epoch 012/096 - Mean training loss 0.083859; Mean training F1 0.936338; Mean validation loss 0.085371; Mean validation F1 0.928816; Learning rate 0.000963;\n",
    "===========================================================\n",
    "Epoch 013/096 - Mean training loss 0.082924; Mean training F1 0.937208; Mean validation loss 0.139567; Mean validation F1 0.927707; Learning rate 0.000956;\n",
    "===========================================================\n",
    "Epoch 014/096 - Mean training loss 0.084969; Mean training F1 0.934950; Mean validation loss 0.080194; Mean validation F1 0.929985; Learning rate 0.000949;\n",
    "===========================================================\n",
    "Epoch 015/096 - Mean training loss 0.082742; Mean training F1 0.936861; Mean validation loss 0.074917; Mean validation F1 0.930847; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 016/096 - Mean training loss 0.082390; Mean training F1 0.937041; Mean validation loss 0.062571; Mean validation F1 0.930967; Learning rate 0.000934;\n",
    "===========================================================\n",
    "Epoch 017/096 - Mean training loss 0.082205; Mean training F1 0.937203; Mean validation loss 0.065676; Mean validation F1 0.931359; Learning rate 0.000926;\n",
    "===========================================================\n",
    "Epoch 018/096 - Mean training loss 0.082842; Mean training F1 0.936777; Mean validation loss 0.115834; Mean validation F1 0.931166; Learning rate 0.000917;\n",
    "===========================================================\n",
    "Epoch 019/096 - Mean training loss 0.081086; Mean training F1 0.938047; Mean validation loss 0.090987; Mean validation F1 0.931935; Learning rate 0.000908;\n",
    "===========================================================\n",
    "Epoch 020/096 - Mean training loss 0.081480; Mean training F1 0.937531; Mean validation loss 0.085555; Mean validation F1 0.931450; Learning rate 0.000898;\n",
    "===========================================================\n",
    "Epoch 021/096 - Mean training loss 0.082401; Mean training F1 0.936985; Mean validation loss 0.083600; Mean validation F1 0.931103; Learning rate 0.000888;\n",
    "===========================================================\n",
    "Epoch 022/096 - Mean training loss 0.081028; Mean training F1 0.937907; Mean validation loss 0.036092; Mean validation F1 0.928091; Learning rate 0.000878;\n",
    "===========================================================\n",
    "Epoch 023/096 - Mean training loss 0.080840; Mean training F1 0.938062; Mean validation loss 0.069556; Mean validation F1 0.931138; Learning rate 0.000867;\n",
    "===========================================================\n",
    "Epoch 024/096 - Mean training loss 0.081544; Mean training F1 0.937522; Mean validation loss 0.060348; Mean validation F1 0.931748; Learning rate 0.000856;\n",
    "===========================================================\n",
    "Epoch 025/096 - Mean training loss 0.081062; Mean training F1 0.937508; Mean validation loss 0.092877; Mean validation F1 0.928435; Learning rate 0.000844;\n",
    "===========================================================\n",
    "Epoch 026/096 - Mean training loss 0.081805; Mean training F1 0.937108; Mean validation loss 0.073620; Mean validation F1 0.929279; Learning rate 0.000832;\n",
    "===========================================================\n",
    "Epoch 027/096 - Mean training loss 0.080235; Mean training F1 0.938367; Mean validation loss 0.100215; Mean validation F1 0.931710; Learning rate 0.000820;\n",
    "===========================================================\n",
    "Epoch 028/096 - Mean training loss 0.080425; Mean training F1 0.938028; Mean validation loss 0.068542; Mean validation F1 0.932531; Learning rate 0.000807;\n",
    "===========================================================\n",
    "Epoch 029/096 - Mean training loss 0.081132; Mean training F1 0.937508; Mean validation loss 0.073986; Mean validation F1 0.928988; Learning rate 0.000794;\n",
    "===========================================================\n",
    "Epoch 030/096 - Mean training loss 0.080135; Mean training F1 0.938373; Mean validation loss 0.092231; Mean validation F1 0.931973; Learning rate 0.000781;\n",
    "===========================================================\n",
    "Epoch 031/096 - Mean training loss 0.080919; Mean training F1 0.937366; Mean validation loss 0.102107; Mean validation F1 0.931652; Learning rate 0.000767;\n",
    "===========================================================\n",
    "Epoch 032/096 - Mean training loss 0.102965; Mean training F1 0.924805; Mean validation loss 0.090413; Mean validation F1 0.925046; Learning rate 0.000753;\n",
    "===========================================================\n",
    "Epoch 033/096 - Mean training loss 0.083287; Mean training F1 0.936584; Mean validation loss 0.073130; Mean validation F1 0.931546; Learning rate 0.000739;\n",
    "===========================================================\n",
    "Epoch 034/096 - Mean training loss 0.081475; Mean training F1 0.937868; Mean validation loss 0.083879; Mean validation F1 0.931535; Learning rate 0.000724;\n",
    "===========================================================\n",
    "Epoch 035/096 - Mean training loss 0.080754; Mean training F1 0.938105; Mean validation loss 0.113554; Mean validation F1 0.932476; Learning rate 0.000710;\n",
    "===========================================================\n",
    "Epoch 036/096 - Mean training loss 0.080798; Mean training F1 0.937915; Mean validation loss 0.127157; Mean validation F1 0.931912; Learning rate 0.000695;\n",
    "===========================================================\n",
    "Epoch 037/096 - Mean training loss 0.080566; Mean training F1 0.938050; Mean validation loss 0.133541; Mean validation F1 0.932722; Learning rate 0.000680;\n",
    "===========================================================\n",
    "Epoch 038/096 - Mean training loss 0.080112; Mean training F1 0.938411; Mean validation loss 0.099930; Mean validation F1 0.932990; Learning rate 0.000665;\n",
    "===========================================================\n",
    "Epoch 039/096 - Mean training loss 0.079971; Mean training F1 0.938617; Mean validation loss 0.094778; Mean validation F1 0.932231; Learning rate 0.000649;\n",
    "===========================================================\n",
    "Epoch 040/096 - Mean training loss 0.079950; Mean training F1 0.938496; Mean validation loss 0.067846; Mean validation F1 0.932266; Learning rate 0.000634;\n",
    "===========================================================\n",
    "Epoch 041/096 - Mean training loss 0.080040; Mean training F1 0.938306; Mean validation loss 0.061921; Mean validation F1 0.932465; Learning rate 0.000618;\n",
    "===========================================================\n",
    "Epoch 042/096 - Mean training loss 0.079792; Mean training F1 0.938505; Mean validation loss 0.065680; Mean validation F1 0.932296; Learning rate 0.000602;\n",
    "===========================================================\n",
    "Epoch 043/096 - Mean training loss 0.079322; Mean training F1 0.938894; Mean validation loss 0.073955; Mean validation F1 0.932765; Learning rate 0.000586;\n",
    "===========================================================\n",
    "Epoch 044/096 - Mean training loss 0.079436; Mean training F1 0.938737; Mean validation loss 0.059299; Mean validation F1 0.932662; Learning rate 0.000570;\n",
    "===========================================================\n",
    "Epoch 045/096 - Mean training loss 0.079629; Mean training F1 0.938612; Mean validation loss 0.078029; Mean validation F1 0.932894; Learning rate 0.000554;\n",
    "===========================================================\n",
    "Epoch 046/096 - Mean training loss 0.079325; Mean training F1 0.938696; Mean validation loss 0.071474; Mean validation F1 0.933127; Learning rate 0.000538;\n",
    "===========================================================\n",
    "Epoch 047/096 - Mean training loss 0.079260; Mean training F1 0.938967; Mean validation loss 0.086492; Mean validation F1 0.933014; Learning rate 0.000522;\n",
    "===========================================================\n",
    "Epoch 048/096 - Mean training loss 0.078974; Mean training F1 0.939071; Mean validation loss 0.102479; Mean validation F1 0.933121; Learning rate 0.000506;\n",
    "===========================================================\n",
    "Epoch 049/096 - Mean training loss 0.079151; Mean training F1 0.939053; Mean validation loss 0.083263; Mean validation F1 0.933374; Learning rate 0.000489;\n",
    "===========================================================\n",
    "Epoch 050/096 - Mean training loss 0.078905; Mean training F1 0.938949; Mean validation loss 0.080377; Mean validation F1 0.932698; Learning rate 0.000473;\n",
    "===========================================================\n",
    "Epoch 051/096 - Mean training loss 0.078850; Mean training F1 0.938993; Mean validation loss 0.091041; Mean validation F1 0.933201; Learning rate 0.000457;\n",
    "===========================================================\n",
    "Epoch 052/096 - Mean training loss 0.079024; Mean training F1 0.938901; Mean validation loss 0.074479; Mean validation F1 0.932685; Learning rate 0.000441;\n",
    "===========================================================\n",
    "Epoch 053/096 - Mean training loss 0.078527; Mean training F1 0.939259; Mean validation loss 0.103897; Mean validation F1 0.931995; Learning rate 0.000425;\n",
    "===========================================================\n",
    "Epoch 054/096 - Mean training loss 0.078789; Mean training F1 0.939045; Mean validation loss 0.083629; Mean validation F1 0.930530; Learning rate 0.000409;\n",
    "===========================================================\n",
    "Epoch 055/096 - Mean training loss 0.078804; Mean training F1 0.939122; Mean validation loss 0.076833; Mean validation F1 0.932250; Learning rate 0.000393;\n",
    "===========================================================\n",
    "Epoch 056/096 - Mean training loss 0.078255; Mean training F1 0.939409; Mean validation loss 0.054079; Mean validation F1 0.932542; Learning rate 0.000377;\n",
    "===========================================================\n",
    "Epoch 057/096 - Mean training loss 0.078437; Mean training F1 0.939147; Mean validation loss 0.085100; Mean validation F1 0.932961; Learning rate 0.000362;\n",
    "===========================================================\n",
    "Epoch 058/096 - Mean training loss 0.078405; Mean training F1 0.939287; Mean validation loss 0.090127; Mean validation F1 0.933377; Learning rate 0.000346;\n",
    "===========================================================\n",
    "Epoch 059/096 - Mean training loss 0.078258; Mean training F1 0.939488; Mean validation loss 0.087680; Mean validation F1 0.933167; Learning rate 0.000331;\n",
    "===========================================================\n",
    "Epoch 060/096 - Mean training loss 0.078437; Mean training F1 0.939207; Mean validation loss 0.058433; Mean validation F1 0.931630; Learning rate 0.000316;\n",
    "===========================================================\n",
    "Epoch 061/096 - Mean training loss 0.078302; Mean training F1 0.939343; Mean validation loss 0.088210; Mean validation F1 0.933377; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 062/096 - Mean training loss 0.077944; Mean training F1 0.939688; Mean validation loss 0.072003; Mean validation F1 0.932343; Learning rate 0.000287;\n",
    "===========================================================\n",
    "Epoch 063/096 - Mean training loss 0.077916; Mean training F1 0.939503; Mean validation loss 0.103317; Mean validation F1 0.933154; Learning rate 0.000272;\n",
    "===========================================================\n",
    "Epoch 064/096 - Mean training loss 0.077915; Mean training F1 0.939502; Mean validation loss 0.084684; Mean validation F1 0.932724; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 065/096 - Mean training loss 0.077775; Mean training F1 0.939630; Mean validation loss 0.076397; Mean validation F1 0.933297; Learning rate 0.000244;\n",
    "===========================================================\n",
    "Epoch 066/096 - Mean training loss 0.077848; Mean training F1 0.939615; Mean validation loss 0.087502; Mean validation F1 0.933143; Learning rate 0.000230;\n",
    "===========================================================\n",
    "Epoch 067/096 - Mean training loss 0.077856; Mean training F1 0.939589; Mean validation loss 0.075288; Mean validation F1 0.933097; Learning rate 0.000217;\n",
    "===========================================================\n",
    "Epoch 068/096 - Mean training loss 0.077632; Mean training F1 0.939699; Mean validation loss 0.087782; Mean validation F1 0.933138; Learning rate 0.000204;\n",
    "===========================================================\n",
    "Epoch 069/096 - Mean training loss 0.077657; Mean training F1 0.939773; Mean validation loss 0.061281; Mean validation F1 0.933625; Learning rate 0.000191;\n",
    "===========================================================\n",
    "Epoch 070/096 - Mean training loss 0.077590; Mean training F1 0.939718; Mean validation loss 0.064558; Mean validation F1 0.933205; Learning rate 0.000179;\n",
    "===========================================================\n",
    "Epoch 071/096 - Mean training loss 0.077681; Mean training F1 0.939691; Mean validation loss 0.102835; Mean validation F1 0.933340; Learning rate 0.000167;\n",
    "===========================================================\n",
    "Epoch 072/096 - Mean training loss 0.077539; Mean training F1 0.939722; Mean validation loss 0.103151; Mean validation F1 0.933731; Learning rate 0.000155;\n",
    "===========================================================\n",
    "Epoch 073/096 - Mean training loss 0.077400; Mean training F1 0.939805; Mean validation loss 0.065791; Mean validation F1 0.933652; Learning rate 0.000144;\n",
    "===========================================================\n",
    "Epoch 074/096 - Mean training loss 0.077504; Mean training F1 0.939669; Mean validation loss 0.044035; Mean validation F1 0.933470; Learning rate 0.000133;\n",
    "===========================================================\n",
    "Epoch 075/096 - Mean training loss 0.077311; Mean training F1 0.939891; Mean validation loss 0.095358; Mean validation F1 0.933585; Learning rate 0.000123;\n",
    "===========================================================\n",
    "Epoch 076/096 - Mean training loss 0.077277; Mean training F1 0.939967; Mean validation loss 0.081773; Mean validation F1 0.933500; Learning rate 0.000113;\n",
    "===========================================================\n",
    "Epoch 077/096 - Mean training loss 0.077217; Mean training F1 0.939942; Mean validation loss 0.075006; Mean validation F1 0.933440; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 078/096 - Mean training loss 0.077167; Mean training F1 0.939986; Mean validation loss 0.067719; Mean validation F1 0.933680; Learning rate 0.000094;\n",
    "===========================================================\n",
    "Epoch 079/096 - Mean training loss 0.077113; Mean training F1 0.940014; Mean validation loss 0.071208; Mean validation F1 0.933854; Learning rate 0.000085;\n",
    "===========================================================\n",
    "Epoch 080/096 - Mean training loss 0.077151; Mean training F1 0.939944; Mean validation loss 0.067924; Mean validation F1 0.933608; Learning rate 0.000077;\n",
    "===========================================================\n",
    "Epoch 081/096 - Mean training loss 0.077100; Mean training F1 0.940018; Mean validation loss 0.067855; Mean validation F1 0.933891; Learning rate 0.000069;\n",
    "===========================================================\n",
    "Epoch 082/096 - Mean training loss 0.077034; Mean training F1 0.940062; Mean validation loss 0.071657; Mean validation F1 0.933785; Learning rate 0.000062;\n",
    "===========================================================\n",
    "Epoch 083/096 - Mean training loss 0.076981; Mean training F1 0.940029; Mean validation loss 0.105258; Mean validation F1 0.933713; Learning rate 0.000055;\n",
    "===========================================================\n",
    "Epoch 084/096 - Mean training loss 0.076988; Mean training F1 0.940080; Mean validation loss 0.084434; Mean validation F1 0.933791; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 085/096 - Mean training loss 0.076933; Mean training F1 0.940054; Mean validation loss 0.079574; Mean validation F1 0.933899; Learning rate 0.000042;\n",
    "===========================================================\n",
    "Epoch 086/096 - Mean training loss 0.076896; Mean training F1 0.940167; Mean validation loss 0.045384; Mean validation F1 0.933878; Learning rate 0.000037;\n",
    "===========================================================\n",
    "Epoch 087/096 - Mean training loss 0.076904; Mean training F1 0.940119; Mean validation loss 0.081878; Mean validation F1 0.933837; Learning rate 0.000032;\n",
    "===========================================================\n",
    "Epoch 088/096 - Mean training loss 0.076875; Mean training F1 0.940176; Mean validation loss 0.065260; Mean validation F1 0.933873; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 089/096 - Mean training loss 0.076848; Mean training F1 0.940189; Mean validation loss 0.049093; Mean validation F1 0.934078; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 090/096 - Mean training loss 0.076821; Mean training F1 0.940119; Mean validation loss 0.096540; Mean validation F1 0.933974; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 091/096 - Mean training loss 0.076806; Mean training F1 0.940126; Mean validation loss 0.082197; Mean validation F1 0.933973; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 092/096 - Mean training loss 0.076805; Mean training F1 0.940130; Mean validation loss 0.098085; Mean validation F1 0.934011; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 093/096 - Mean training loss 0.076786; Mean training F1 0.940156; Mean validation loss 0.069115; Mean validation F1 0.934013; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 094/096 - Mean training loss 0.076775; Mean training F1 0.940213; Mean validation loss 0.071131; Mean validation F1 0.933997; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 095/096 - Mean training loss 0.076772; Mean training F1 0.940199; Mean validation loss 0.077480; Mean validation F1 0.933967; Learning rate 0.000010;\n",
    "===========================================================\n",
    "Epoch 096/096 - Mean training loss 0.076762; Mean training F1 0.940165; Mean validation loss 0.096719; Mean validation F1 0.933915; Learning rate 0.000010;\n",
    "################################################################\n",
    "Training/validation for fold 3/5;\n",
    "===========================================================\n",
    "Epoch 001/096 - Mean training loss 0.782493; Mean training F1 0.544202; Mean validation loss 0.401294; Mean validation F1 0.733587; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/096 - Mean training loss 0.262992; Mean training F1 0.857229; Mean validation loss 0.133050; Mean validation F1 0.882154; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 003/096 - Mean training loss 0.146601; Mean training F1 0.910504; Mean validation loss 0.180128; Mean validation F1 0.892433; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 004/096 - Mean training loss 0.107647; Mean training F1 0.926948; Mean validation loss 0.065302; Mean validation F1 0.929503; Learning rate 0.000996;\n",
    "===========================================================\n",
    "Epoch 005/096 - Mean training loss 0.100213; Mean training F1 0.928569; Mean validation loss 0.137271; Mean validation F1 0.932103; Learning rate 0.000994;\n",
    "===========================================================\n",
    "Epoch 006/096 - Mean training loss 0.091462; Mean training F1 0.934055; Mean validation loss 0.117434; Mean validation F1 0.934081; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 007/096 - Mean training loss 0.089445; Mean training F1 0.935129; Mean validation loss 0.103406; Mean validation F1 0.934037; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 008/096 - Mean training loss 0.090316; Mean training F1 0.934604; Mean validation loss 0.082860; Mean validation F1 0.934887; Learning rate 0.000984;\n",
    "===========================================================\n",
    "Epoch 009/096 - Mean training loss 0.088966; Mean training F1 0.935040; Mean validation loss 0.083001; Mean validation F1 0.935401; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 010/096 - Mean training loss 0.087686; Mean training F1 0.935281; Mean validation loss 0.075496; Mean validation F1 0.933695; Learning rate 0.000974;\n",
    "===========================================================\n",
    "Epoch 011/096 - Mean training loss 0.096590; Mean training F1 0.932342; Mean validation loss 0.162001; Mean validation F1 0.886021; Learning rate 0.000969;\n",
    "===========================================================\n",
    "Epoch 012/096 - Mean training loss 0.133703; Mean training F1 0.918724; Mean validation loss 0.088729; Mean validation F1 0.934033; Learning rate 0.000963;\n",
    "===========================================================\n",
    "Epoch 013/096 - Mean training loss 0.087462; Mean training F1 0.936140; Mean validation loss 0.076404; Mean validation F1 0.935638; Learning rate 0.000956;\n",
    "===========================================================\n",
    "Epoch 014/096 - Mean training loss 0.086564; Mean training F1 0.936370; Mean validation loss 0.059902; Mean validation F1 0.935676; Learning rate 0.000949;\n",
    "===========================================================\n",
    "Epoch 015/096 - Mean training loss 0.086226; Mean training F1 0.936553; Mean validation loss 0.068301; Mean validation F1 0.935607; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 016/096 - Mean training loss 0.086230; Mean training F1 0.936253; Mean validation loss 0.062677; Mean validation F1 0.935897; Learning rate 0.000934;\n",
    "===========================================================\n",
    "Epoch 017/096 - Mean training loss 0.085812; Mean training F1 0.936581; Mean validation loss 0.109349; Mean validation F1 0.929586; Learning rate 0.000926;\n",
    "===========================================================\n",
    "Epoch 018/096 - Mean training loss 0.085609; Mean training F1 0.936705; Mean validation loss 0.053000; Mean validation F1 0.933679; Learning rate 0.000917;\n",
    "===========================================================\n",
    "Epoch 019/096 - Mean training loss 0.085252; Mean training F1 0.936902; Mean validation loss 0.070629; Mean validation F1 0.934819; Learning rate 0.000908;\n",
    "===========================================================\n",
    "Epoch 020/096 - Mean training loss 0.085689; Mean training F1 0.936658; Mean validation loss 0.097579; Mean validation F1 0.936363; Learning rate 0.000898;\n",
    "===========================================================\n",
    "Epoch 021/096 - Mean training loss 0.085087; Mean training F1 0.936754; Mean validation loss 0.081257; Mean validation F1 0.936046; Learning rate 0.000888;\n",
    "===========================================================\n",
    "Epoch 022/096 - Mean training loss 0.084493; Mean training F1 0.937304; Mean validation loss 0.122982; Mean validation F1 0.934931; Learning rate 0.000878;\n",
    "===========================================================\n",
    "Epoch 023/096 - Mean training loss 0.085681; Mean training F1 0.936446; Mean validation loss 0.087449; Mean validation F1 0.935890; Learning rate 0.000867;\n",
    "===========================================================\n",
    "Epoch 024/096 - Mean training loss 0.084180; Mean training F1 0.937490; Mean validation loss 0.094693; Mean validation F1 0.933845; Learning rate 0.000856;\n",
    "===========================================================\n",
    "Epoch 025/096 - Mean training loss 0.084409; Mean training F1 0.936997; Mean validation loss 0.082594; Mean validation F1 0.934707; Learning rate 0.000844;\n",
    "===========================================================\n",
    "Epoch 026/096 - Mean training loss 0.084226; Mean training F1 0.937039; Mean validation loss 0.081024; Mean validation F1 0.936933; Learning rate 0.000832;\n",
    "===========================================================\n",
    "Epoch 027/096 - Mean training loss 0.084177; Mean training F1 0.937520; Mean validation loss 0.081629; Mean validation F1 0.936680; Learning rate 0.000820;\n",
    "===========================================================\n",
    "Epoch 028/096 - Mean training loss 0.083569; Mean training F1 0.937689; Mean validation loss 0.077791; Mean validation F1 0.936984; Learning rate 0.000807;\n",
    "===========================================================\n",
    "Epoch 029/096 - Mean training loss 0.083928; Mean training F1 0.937412; Mean validation loss 0.058227; Mean validation F1 0.937043; Learning rate 0.000794;\n",
    "===========================================================\n",
    "Epoch 030/096 - Mean training loss 0.083414; Mean training F1 0.937770; Mean validation loss 0.079162; Mean validation F1 0.935387; Learning rate 0.000781;\n",
    "===========================================================\n",
    "Epoch 031/096 - Mean training loss 0.083107; Mean training F1 0.937871; Mean validation loss 0.136871; Mean validation F1 0.936972; Learning rate 0.000767;\n",
    "===========================================================\n",
    "Epoch 032/096 - Mean training loss 0.083658; Mean training F1 0.937671; Mean validation loss 0.048453; Mean validation F1 0.936544; Learning rate 0.000753;\n",
    "===========================================================\n",
    "Epoch 033/096 - Mean training loss 0.083157; Mean training F1 0.937856; Mean validation loss 0.143647; Mean validation F1 0.937108; Learning rate 0.000739;\n",
    "===========================================================\n",
    "Epoch 034/096 - Mean training loss 0.091071; Mean training F1 0.933278; Mean validation loss 0.108225; Mean validation F1 0.918146; Learning rate 0.000724;\n",
    "===========================================================\n",
    "Epoch 035/096 - Mean training loss 0.090199; Mean training F1 0.932510; Mean validation loss 0.047702; Mean validation F1 0.936039; Learning rate 0.000710;\n",
    "===========================================================\n",
    "Epoch 036/096 - Mean training loss 0.083373; Mean training F1 0.937591; Mean validation loss 0.125080; Mean validation F1 0.936968; Learning rate 0.000695;\n",
    "===========================================================\n",
    "Epoch 037/096 - Mean training loss 0.083208; Mean training F1 0.937701; Mean validation loss 0.075552; Mean validation F1 0.935433; Learning rate 0.000680;\n",
    "===========================================================\n",
    "Epoch 038/096 - Mean training loss 0.084524; Mean training F1 0.937205; Mean validation loss 0.050859; Mean validation F1 0.936109; Learning rate 0.000665;\n",
    "===========================================================\n",
    "Epoch 039/096 - Mean training loss 0.082892; Mean training F1 0.937797; Mean validation loss 0.111532; Mean validation F1 0.936948; Learning rate 0.000649;\n",
    "===========================================================\n",
    "Epoch 040/096 - Mean training loss 0.082621; Mean training F1 0.937919; Mean validation loss 0.083878; Mean validation F1 0.936567; Learning rate 0.000634;\n",
    "===========================================================\n",
    "Epoch 041/096 - Mean training loss 0.082919; Mean training F1 0.937822; Mean validation loss 0.054776; Mean validation F1 0.936696; Learning rate 0.000618;\n",
    "===========================================================\n",
    "Epoch 042/096 - Mean training loss 0.082403; Mean training F1 0.938209; Mean validation loss 0.063617; Mean validation F1 0.937292; Learning rate 0.000602;\n",
    "===========================================================\n",
    "Epoch 043/096 - Mean training loss 0.082304; Mean training F1 0.938092; Mean validation loss 0.078510; Mean validation F1 0.935149; Learning rate 0.000586;\n",
    "===========================================================\n",
    "Epoch 044/096 - Mean training loss 0.081912; Mean training F1 0.938470; Mean validation loss 0.089584; Mean validation F1 0.936425; Learning rate 0.000570;\n",
    "===========================================================\n",
    "Epoch 045/096 - Mean training loss 0.082013; Mean training F1 0.938369; Mean validation loss 0.077729; Mean validation F1 0.937098; Learning rate 0.000554;\n",
    "===========================================================\n",
    "Epoch 046/096 - Mean training loss 0.081915; Mean training F1 0.938402; Mean validation loss 0.088013; Mean validation F1 0.936987; Learning rate 0.000538;\n",
    "===========================================================\n",
    "Epoch 047/096 - Mean training loss 0.081976; Mean training F1 0.938242; Mean validation loss 0.099995; Mean validation F1 0.937063; Learning rate 0.000522;\n",
    "===========================================================\n",
    "Epoch 048/096 - Mean training loss 0.082056; Mean training F1 0.938372; Mean validation loss 0.089368; Mean validation F1 0.936857; Learning rate 0.000506;\n",
    "===========================================================\n",
    "Epoch 049/096 - Mean training loss 0.081852; Mean training F1 0.938564; Mean validation loss 0.090396; Mean validation F1 0.937009; Learning rate 0.000489;\n",
    "===========================================================\n",
    "Epoch 050/096 - Mean training loss 0.081517; Mean training F1 0.938693; Mean validation loss 0.077386; Mean validation F1 0.937537; Learning rate 0.000473;\n",
    "===========================================================\n",
    "Epoch 051/096 - Mean training loss 0.081692; Mean training F1 0.938636; Mean validation loss 0.080793; Mean validation F1 0.937396; Learning rate 0.000457;\n",
    "===========================================================\n",
    "Epoch 052/096 - Mean training loss 0.081732; Mean training F1 0.938349; Mean validation loss 0.075692; Mean validation F1 0.937569; Learning rate 0.000441;\n",
    "===========================================================\n",
    "Epoch 053/096 - Mean training loss 0.081613; Mean training F1 0.938369; Mean validation loss 0.070050; Mean validation F1 0.937173; Learning rate 0.000425;\n",
    "===========================================================\n",
    "Epoch 054/096 - Mean training loss 0.081205; Mean training F1 0.938778; Mean validation loss 0.118138; Mean validation F1 0.937453; Learning rate 0.000409;\n",
    "===========================================================\n",
    "Epoch 055/096 - Mean training loss 0.081467; Mean training F1 0.938482; Mean validation loss 0.094309; Mean validation F1 0.937133; Learning rate 0.000393;\n",
    "===========================================================\n",
    "Epoch 056/096 - Mean training loss 0.086437; Mean training F1 0.936480; Mean validation loss 0.064855; Mean validation F1 0.936255; Learning rate 0.000377;\n",
    "===========================================================\n",
    "Epoch 057/096 - Mean training loss 0.082353; Mean training F1 0.938133; Mean validation loss 0.091763; Mean validation F1 0.937093; Learning rate 0.000362;\n",
    "===========================================================\n",
    "Epoch 058/096 - Mean training loss 0.081544; Mean training F1 0.938538; Mean validation loss 0.078550; Mean validation F1 0.936079; Learning rate 0.000346;\n",
    "===========================================================\n",
    "Epoch 059/096 - Mean training loss 0.081438; Mean training F1 0.938482; Mean validation loss 0.083750; Mean validation F1 0.936812; Learning rate 0.000331;\n",
    "===========================================================\n",
    "Epoch 060/096 - Mean training loss 0.081142; Mean training F1 0.938734; Mean validation loss 0.071596; Mean validation F1 0.937215; Learning rate 0.000316;\n",
    "===========================================================\n",
    "Epoch 061/096 - Mean training loss 0.081091; Mean training F1 0.938737; Mean validation loss 0.090903; Mean validation F1 0.937271; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 062/096 - Mean training loss 0.081071; Mean training F1 0.938872; Mean validation loss 0.079269; Mean validation F1 0.936950; Learning rate 0.000287;\n",
    "===========================================================\n",
    "Epoch 063/096 - Mean training loss 0.080803; Mean training F1 0.938905; Mean validation loss 0.102092; Mean validation F1 0.937298; Learning rate 0.000272;\n",
    "===========================================================\n",
    "Epoch 064/096 - Mean training loss 0.080830; Mean training F1 0.938910; Mean validation loss 0.048447; Mean validation F1 0.937402; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 065/096 - Mean training loss 0.080713; Mean training F1 0.939002; Mean validation loss 0.069231; Mean validation F1 0.937410; Learning rate 0.000244;\n",
    "===========================================================\n",
    "Epoch 066/096 - Mean training loss 0.080777; Mean training F1 0.939110; Mean validation loss 0.022250; Mean validation F1 0.937201; Learning rate 0.000230;\n",
    "===========================================================\n",
    "Epoch 067/096 - Mean training loss 0.080597; Mean training F1 0.938996; Mean validation loss 0.121557; Mean validation F1 0.937668; Learning rate 0.000217;\n",
    "===========================================================\n",
    "Epoch 068/096 - Mean training loss 0.080652; Mean training F1 0.939002; Mean validation loss 0.077767; Mean validation F1 0.937410; Learning rate 0.000204;\n",
    "===========================================================\n",
    "Epoch 069/096 - Mean training loss 0.080528; Mean training F1 0.939222; Mean validation loss 0.079333; Mean validation F1 0.937827; Learning rate 0.000191;\n",
    "===========================================================\n",
    "Epoch 070/096 - Mean training loss 0.080431; Mean training F1 0.939145; Mean validation loss 0.102696; Mean validation F1 0.937742; Learning rate 0.000179;\n",
    "===========================================================\n",
    "Epoch 071/096 - Mean training loss 0.080382; Mean training F1 0.939151; Mean validation loss 0.051782; Mean validation F1 0.937327; Learning rate 0.000167;\n",
    "===========================================================\n",
    "Epoch 072/096 - Mean training loss 0.080223; Mean training F1 0.939165; Mean validation loss 0.088175; Mean validation F1 0.937420; Learning rate 0.000155;\n",
    "===========================================================\n",
    "Epoch 073/096 - Mean training loss 0.080152; Mean training F1 0.939222; Mean validation loss 0.074692; Mean validation F1 0.937532; Learning rate 0.000144;\n",
    "===========================================================\n",
    "Epoch 074/096 - Mean training loss 0.080204; Mean training F1 0.939253; Mean validation loss 0.061612; Mean validation F1 0.937397; Learning rate 0.000133;\n",
    "===========================================================\n",
    "Epoch 075/096 - Mean training loss 0.080188; Mean training F1 0.939253; Mean validation loss 0.058376; Mean validation F1 0.937639; Learning rate 0.000123;\n",
    "===========================================================\n",
    "Epoch 076/096 - Mean training loss 0.080020; Mean training F1 0.939317; Mean validation loss 0.061067; Mean validation F1 0.937526; Learning rate 0.000113;\n",
    "===========================================================\n",
    "Epoch 077/096 - Mean training loss 0.080082; Mean training F1 0.939319; Mean validation loss 0.093733; Mean validation F1 0.937905; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 078/096 - Mean training loss 0.079944; Mean training F1 0.939454; Mean validation loss 0.063296; Mean validation F1 0.937838; Learning rate 0.000094;\n",
    "===========================================================\n",
    "Epoch 079/096 - Mean training loss 0.079950; Mean training F1 0.939478; Mean validation loss 0.102829; Mean validation F1 0.937843; Learning rate 0.000085;\n",
    "===========================================================\n",
    "Epoch 080/096 - Mean training loss 0.079866; Mean training F1 0.939468; Mean validation loss 0.049421; Mean validation F1 0.937895; Learning rate 0.000077;\n",
    "===========================================================\n",
    "Epoch 081/096 - Mean training loss 0.079865; Mean training F1 0.939437; Mean validation loss 0.099754; Mean validation F1 0.937680; Learning rate 0.000069;\n",
    "===========================================================\n",
    "Epoch 082/096 - Mean training loss 0.079842; Mean training F1 0.939449; Mean validation loss 0.061354; Mean validation F1 0.937676; Learning rate 0.000062;\n",
    "===========================================================\n",
    "Epoch 083/096 - Mean training loss 0.079786; Mean training F1 0.939440; Mean validation loss 0.105710; Mean validation F1 0.937826; Learning rate 0.000055;\n",
    "===========================================================\n",
    "Epoch 084/096 - Mean training loss 0.079785; Mean training F1 0.939424; Mean validation loss 0.084792; Mean validation F1 0.937769; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 085/096 - Mean training loss 0.079697; Mean training F1 0.939495; Mean validation loss 0.069863; Mean validation F1 0.937617; Learning rate 0.000042;\n",
    "===========================================================\n",
    "Epoch 086/096 - Mean training loss 0.079680; Mean training F1 0.939475; Mean validation loss 0.079715; Mean validation F1 0.937792; Learning rate 0.000037;\n",
    "===========================================================\n",
    "Epoch 087/096 - Mean training loss 0.079659; Mean training F1 0.939521; Mean validation loss 0.080199; Mean validation F1 0.937857; Learning rate 0.000032;\n",
    "===========================================================\n",
    "Epoch 088/096 - Mean training loss 0.079660; Mean training F1 0.939607; Mean validation loss 0.106754; Mean validation F1 0.937877; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 089/096 - Mean training loss 0.079622; Mean training F1 0.939565; Mean validation loss 0.067934; Mean validation F1 0.937813; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 090/096 - Mean training loss 0.079588; Mean training F1 0.939588; Mean validation loss 0.072644; Mean validation F1 0.937859; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 091/096 - Mean training loss 0.079564; Mean training F1 0.939592; Mean validation loss 0.095518; Mean validation F1 0.937819; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 092/096 - Mean training loss 0.079557; Mean training F1 0.939600; Mean validation loss 0.054131; Mean validation F1 0.937639; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 093/096 - Mean training loss 0.079545; Mean training F1 0.939586; Mean validation loss 0.090699; Mean validation F1 0.937932; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 094/096 - Mean training loss 0.079538; Mean training F1 0.939592; Mean validation loss 0.070184; Mean validation F1 0.937879; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 095/096 - Mean training loss 0.079528; Mean training F1 0.939629; Mean validation loss 0.117663; Mean validation F1 0.937814; Learning rate 0.000010;\n",
    "===========================================================\n",
    "Epoch 096/096 - Mean training loss 0.079521; Mean training F1 0.939615; Mean validation loss 0.074538; Mean validation F1 0.937898; Learning rate 0.000010;\n",
    "################################################################\n",
    "Training/validation for fold 4/5;\n",
    "===========================================================\n",
    "Epoch 001/096 - Mean training loss 0.822519; Mean training F1 0.530989; Mean validation loss 0.445897; Mean validation F1 0.730828; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/096 - Mean training loss 0.264794; Mean training F1 0.857394; Mean validation loss 0.093873; Mean validation F1 0.909696; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 003/096 - Mean training loss 0.115820; Mean training F1 0.924304; Mean validation loss 0.056774; Mean validation F1 0.912253; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 004/096 - Mean training loss 0.133397; Mean training F1 0.912247; Mean validation loss 0.049406; Mean validation F1 0.933318; Learning rate 0.000996;\n",
    "===========================================================\n",
    "Epoch 005/096 - Mean training loss 0.094990; Mean training F1 0.932585; Mean validation loss 0.075137; Mean validation F1 0.935069; Learning rate 0.000994;\n",
    "===========================================================\n",
    "Epoch 006/096 - Mean training loss 0.091940; Mean training F1 0.934010; Mean validation loss 0.064380; Mean validation F1 0.936279; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 007/096 - Mean training loss 0.090694; Mean training F1 0.934358; Mean validation loss 0.101871; Mean validation F1 0.937280; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 008/096 - Mean training loss 0.090273; Mean training F1 0.934148; Mean validation loss 0.063539; Mean validation F1 0.937144; Learning rate 0.000984;\n",
    "===========================================================\n",
    "Epoch 009/096 - Mean training loss 0.089273; Mean training F1 0.935022; Mean validation loss 0.099953; Mean validation F1 0.936848; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 010/096 - Mean training loss 0.089439; Mean training F1 0.934600; Mean validation loss 0.046611; Mean validation F1 0.936660; Learning rate 0.000974;\n",
    "===========================================================\n",
    "Epoch 011/096 - Mean training loss 0.088122; Mean training F1 0.935528; Mean validation loss 0.119006; Mean validation F1 0.937472; Learning rate 0.000969;\n",
    "===========================================================\n",
    "Epoch 012/096 - Mean training loss 0.088051; Mean training F1 0.935539; Mean validation loss 0.102438; Mean validation F1 0.932474; Learning rate 0.000963;\n",
    "===========================================================\n",
    "Epoch 013/096 - Mean training loss 0.088719; Mean training F1 0.934667; Mean validation loss 0.081210; Mean validation F1 0.938717; Learning rate 0.000956;\n",
    "===========================================================\n",
    "Epoch 014/096 - Mean training loss 0.087019; Mean training F1 0.936055; Mean validation loss 0.082832; Mean validation F1 0.938435; Learning rate 0.000949;\n",
    "===========================================================\n",
    "Epoch 015/096 - Mean training loss 0.087194; Mean training F1 0.935832; Mean validation loss 0.059346; Mean validation F1 0.933041; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 016/096 - Mean training loss 0.089861; Mean training F1 0.933525; Mean validation loss 0.103517; Mean validation F1 0.938718; Learning rate 0.000934;\n",
    "===========================================================\n",
    "Epoch 017/096 - Mean training loss 0.213311; Mean training F1 0.882328; Mean validation loss 0.141293; Mean validation F1 0.924765; Learning rate 0.000926;\n",
    "===========================================================\n",
    "Epoch 018/096 - Mean training loss 0.097972; Mean training F1 0.931997; Mean validation loss 0.110097; Mean validation F1 0.937012; Learning rate 0.000917;\n",
    "===========================================================\n",
    "Epoch 019/096 - Mean training loss 0.091416; Mean training F1 0.934689; Mean validation loss 0.110658; Mean validation F1 0.937342; Learning rate 0.000908;\n",
    "===========================================================\n",
    "Epoch 020/096 - Mean training loss 0.089847; Mean training F1 0.935405; Mean validation loss 0.100610; Mean validation F1 0.937368; Learning rate 0.000898;\n",
    "===========================================================\n",
    "Epoch 021/096 - Mean training loss 0.088566; Mean training F1 0.935989; Mean validation loss 0.084553; Mean validation F1 0.937752; Learning rate 0.000888;\n",
    "===========================================================\n",
    "Epoch 022/096 - Mean training loss 0.087879; Mean training F1 0.936132; Mean validation loss 0.096647; Mean validation F1 0.938165; Learning rate 0.000878;\n",
    "===========================================================\n",
    "Epoch 023/096 - Mean training loss 0.088076; Mean training F1 0.935789; Mean validation loss 0.105056; Mean validation F1 0.937295; Learning rate 0.000867;\n",
    "===========================================================\n",
    "Epoch 024/096 - Mean training loss 0.087483; Mean training F1 0.936162; Mean validation loss 0.061106; Mean validation F1 0.938419; Learning rate 0.000856;\n",
    "===========================================================\n",
    "Epoch 025/096 - Mean training loss 0.087507; Mean training F1 0.936125; Mean validation loss 0.076394; Mean validation F1 0.938113; Learning rate 0.000844;\n",
    "===========================================================\n",
    "Epoch 026/096 - Mean training loss 0.087012; Mean training F1 0.936319; Mean validation loss 0.087110; Mean validation F1 0.938662; Learning rate 0.000832;\n",
    "===========================================================\n",
    "Epoch 027/096 - Mean training loss 0.086535; Mean training F1 0.936600; Mean validation loss 0.072907; Mean validation F1 0.936811; Learning rate 0.000820;\n",
    "===========================================================\n",
    "Epoch 028/096 - Mean training loss 0.086596; Mean training F1 0.936418; Mean validation loss 0.100030; Mean validation F1 0.937927; Learning rate 0.000807;\n",
    "===========================================================\n",
    "Epoch 029/096 - Mean training loss 0.086567; Mean training F1 0.936360; Mean validation loss 0.075460; Mean validation F1 0.938363; Learning rate 0.000794;\n",
    "===========================================================\n",
    "Epoch 030/096 - Mean training loss 0.085845; Mean training F1 0.936918; Mean validation loss 0.103722; Mean validation F1 0.938518; Learning rate 0.000781;\n",
    "===========================================================\n",
    "Epoch 031/096 - Mean training loss 0.085847; Mean training F1 0.937014; Mean validation loss 0.069801; Mean validation F1 0.938474; Learning rate 0.000767;\n",
    "===========================================================\n",
    "Epoch 032/096 - Mean training loss 0.085826; Mean training F1 0.936757; Mean validation loss 0.081526; Mean validation F1 0.939117; Learning rate 0.000753;\n",
    "===========================================================\n",
    "Epoch 033/096 - Mean training loss 0.085418; Mean training F1 0.936856; Mean validation loss 0.073682; Mean validation F1 0.938280; Learning rate 0.000739;\n",
    "===========================================================\n",
    "Epoch 034/096 - Mean training loss 0.085842; Mean training F1 0.936951; Mean validation loss 0.059058; Mean validation F1 0.938661; Learning rate 0.000724;\n",
    "===========================================================\n",
    "Epoch 035/096 - Mean training loss 0.085270; Mean training F1 0.937010; Mean validation loss 0.105829; Mean validation F1 0.935960; Learning rate 0.000710;\n",
    "===========================================================\n",
    "Epoch 036/096 - Mean training loss 0.085323; Mean training F1 0.937019; Mean validation loss 0.106179; Mean validation F1 0.938798; Learning rate 0.000695;\n",
    "===========================================================\n",
    "Epoch 037/096 - Mean training loss 0.085159; Mean training F1 0.936943; Mean validation loss 0.078706; Mean validation F1 0.938760; Learning rate 0.000680;\n",
    "===========================================================\n",
    "Epoch 038/096 - Mean training loss 0.084785; Mean training F1 0.937345; Mean validation loss 0.076454; Mean validation F1 0.938995; Learning rate 0.000665;\n",
    "===========================================================\n",
    "Epoch 039/096 - Mean training loss 0.085259; Mean training F1 0.936890; Mean validation loss 0.099968; Mean validation F1 0.938250; Learning rate 0.000649;\n",
    "===========================================================\n",
    "Epoch 040/096 - Mean training loss 0.085374; Mean training F1 0.936797; Mean validation loss 0.106219; Mean validation F1 0.939014; Learning rate 0.000634;\n",
    "===========================================================\n",
    "Epoch 041/096 - Mean training loss 0.084444; Mean training F1 0.937437; Mean validation loss 0.100536; Mean validation F1 0.938931; Learning rate 0.000618;\n",
    "===========================================================\n",
    "Epoch 042/096 - Mean training loss 0.084212; Mean training F1 0.937416; Mean validation loss 0.080354; Mean validation F1 0.938933; Learning rate 0.000602;\n",
    "===========================================================\n",
    "Epoch 043/096 - Mean training loss 0.084138; Mean training F1 0.937495; Mean validation loss 0.082283; Mean validation F1 0.938386; Learning rate 0.000586;\n",
    "===========================================================\n",
    "Epoch 044/096 - Mean training loss 0.084215; Mean training F1 0.937474; Mean validation loss 0.080872; Mean validation F1 0.939190; Learning rate 0.000570;\n",
    "===========================================================\n",
    "Epoch 045/096 - Mean training loss 0.084531; Mean training F1 0.937001; Mean validation loss 0.074062; Mean validation F1 0.938015; Learning rate 0.000554;\n",
    "===========================================================\n",
    "Epoch 046/096 - Mean training loss 0.084136; Mean training F1 0.937216; Mean validation loss 0.110348; Mean validation F1 0.939059; Learning rate 0.000538;\n",
    "===========================================================\n",
    "Epoch 047/096 - Mean training loss 0.083689; Mean training F1 0.937807; Mean validation loss 0.115245; Mean validation F1 0.939128; Learning rate 0.000522;\n",
    "===========================================================\n",
    "Epoch 048/096 - Mean training loss 0.083603; Mean training F1 0.937765; Mean validation loss 0.042995; Mean validation F1 0.939499; Learning rate 0.000506;\n",
    "===========================================================\n",
    "Epoch 049/096 - Mean training loss 0.083639; Mean training F1 0.937682; Mean validation loss 0.062571; Mean validation F1 0.939501; Learning rate 0.000489;\n",
    "===========================================================\n",
    "Epoch 050/096 - Mean training loss 0.083571; Mean training F1 0.937692; Mean validation loss 0.086298; Mean validation F1 0.939349; Learning rate 0.000473;\n",
    "===========================================================\n",
    "Epoch 051/096 - Mean training loss 0.083255; Mean training F1 0.937992; Mean validation loss 0.091233; Mean validation F1 0.938706; Learning rate 0.000457;\n",
    "===========================================================\n",
    "Epoch 052/096 - Mean training loss 0.083129; Mean training F1 0.937923; Mean validation loss 0.098701; Mean validation F1 0.939406; Learning rate 0.000441;\n",
    "===========================================================\n",
    "Epoch 053/096 - Mean training loss 0.083340; Mean training F1 0.937798; Mean validation loss 0.080698; Mean validation F1 0.939440; Learning rate 0.000425;\n",
    "===========================================================\n",
    "Epoch 054/096 - Mean training loss 0.085059; Mean training F1 0.937020; Mean validation loss 0.127962; Mean validation F1 0.938506; Learning rate 0.000409;\n",
    "===========================================================\n",
    "Epoch 055/096 - Mean training loss 0.091389; Mean training F1 0.932591; Mean validation loss 0.070638; Mean validation F1 0.939048; Learning rate 0.000393;\n",
    "===========================================================\n",
    "Epoch 056/096 - Mean training loss 0.083472; Mean training F1 0.937907; Mean validation loss 0.077879; Mean validation F1 0.938601; Learning rate 0.000377;\n",
    "===========================================================\n",
    "Epoch 057/096 - Mean training loss 0.083411; Mean training F1 0.937698; Mean validation loss 0.117474; Mean validation F1 0.939097; Learning rate 0.000362;\n",
    "===========================================================\n",
    "Epoch 058/096 - Mean training loss 0.082986; Mean training F1 0.938028; Mean validation loss 0.088841; Mean validation F1 0.939406; Learning rate 0.000346;\n",
    "===========================================================\n",
    "Epoch 059/096 - Mean training loss 0.082693; Mean training F1 0.938167; Mean validation loss 0.070878; Mean validation F1 0.939470; Learning rate 0.000331;\n",
    "===========================================================\n",
    "Epoch 060/096 - Mean training loss 0.082845; Mean training F1 0.938089; Mean validation loss 0.071650; Mean validation F1 0.939736; Learning rate 0.000316;\n",
    "===========================================================\n",
    "Epoch 061/096 - Mean training loss 0.082518; Mean training F1 0.938217; Mean validation loss 0.094209; Mean validation F1 0.939674; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 062/096 - Mean training loss 0.082536; Mean training F1 0.938295; Mean validation loss 0.077001; Mean validation F1 0.938921; Learning rate 0.000287;\n",
    "===========================================================\n",
    "Epoch 063/096 - Mean training loss 0.082385; Mean training F1 0.938311; Mean validation loss 0.115901; Mean validation F1 0.939729; Learning rate 0.000272;\n",
    "===========================================================\n",
    "Epoch 064/096 - Mean training loss 0.082330; Mean training F1 0.938258; Mean validation loss 0.065644; Mean validation F1 0.939205; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 065/096 - Mean training loss 0.082262; Mean training F1 0.938404; Mean validation loss 0.078993; Mean validation F1 0.939725; Learning rate 0.000244;\n",
    "===========================================================\n",
    "Epoch 066/096 - Mean training loss 0.082111; Mean training F1 0.938502; Mean validation loss 0.104914; Mean validation F1 0.939851; Learning rate 0.000230;\n",
    "===========================================================\n",
    "Epoch 067/096 - Mean training loss 0.082164; Mean training F1 0.938454; Mean validation loss 0.078586; Mean validation F1 0.939426; Learning rate 0.000217;\n",
    "===========================================================\n",
    "Epoch 068/096 - Mean training loss 0.081918; Mean training F1 0.938573; Mean validation loss 0.100956; Mean validation F1 0.939756; Learning rate 0.000204;\n",
    "===========================================================\n",
    "Epoch 069/096 - Mean training loss 0.081737; Mean training F1 0.938670; Mean validation loss 0.089187; Mean validation F1 0.939258; Learning rate 0.000191;\n",
    "===========================================================\n",
    "Epoch 070/096 - Mean training loss 0.081851; Mean training F1 0.938428; Mean validation loss 0.076911; Mean validation F1 0.939334; Learning rate 0.000179;\n",
    "===========================================================\n",
    "Epoch 071/096 - Mean training loss 0.081753; Mean training F1 0.938614; Mean validation loss 0.076705; Mean validation F1 0.939634; Learning rate 0.000167;\n",
    "===========================================================\n",
    "Epoch 072/096 - Mean training loss 0.081697; Mean training F1 0.938570; Mean validation loss 0.090505; Mean validation F1 0.939937; Learning rate 0.000155;\n",
    "===========================================================\n",
    "Epoch 073/096 - Mean training loss 0.081561; Mean training F1 0.938662; Mean validation loss 0.101635; Mean validation F1 0.939785; Learning rate 0.000144;\n",
    "===========================================================\n",
    "Epoch 074/096 - Mean training loss 0.081506; Mean training F1 0.938715; Mean validation loss 0.050533; Mean validation F1 0.939725; Learning rate 0.000133;\n",
    "===========================================================\n",
    "Epoch 075/096 - Mean training loss 0.081544; Mean training F1 0.938570; Mean validation loss 0.029284; Mean validation F1 0.939963; Learning rate 0.000123;\n",
    "===========================================================\n",
    "Epoch 076/096 - Mean training loss 0.081374; Mean training F1 0.938792; Mean validation loss 0.096688; Mean validation F1 0.939941; Learning rate 0.000113;\n",
    "===========================================================\n",
    "Epoch 077/096 - Mean training loss 0.081339; Mean training F1 0.938745; Mean validation loss 0.126693; Mean validation F1 0.939720; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 078/096 - Mean training loss 0.081255; Mean training F1 0.938814; Mean validation loss 0.083306; Mean validation F1 0.939724; Learning rate 0.000094;\n",
    "===========================================================\n",
    "Epoch 079/096 - Mean training loss 0.081197; Mean training F1 0.938844; Mean validation loss 0.100287; Mean validation F1 0.939706; Learning rate 0.000085;\n",
    "===========================================================\n",
    "Epoch 080/096 - Mean training loss 0.081214; Mean training F1 0.938910; Mean validation loss 0.065948; Mean validation F1 0.939782; Learning rate 0.000077;\n",
    "===========================================================\n",
    "Epoch 081/096 - Mean training loss 0.081152; Mean training F1 0.938853; Mean validation loss 0.098222; Mean validation F1 0.939866; Learning rate 0.000069;\n",
    "===========================================================\n",
    "Epoch 082/096 - Mean training loss 0.081075; Mean training F1 0.938941; Mean validation loss 0.087187; Mean validation F1 0.939992; Learning rate 0.000062;\n",
    "===========================================================\n",
    "Epoch 083/096 - Mean training loss 0.081061; Mean training F1 0.938991; Mean validation loss 0.076269; Mean validation F1 0.939861; Learning rate 0.000055;\n",
    "===========================================================\n",
    "Epoch 084/096 - Mean training loss 0.081002; Mean training F1 0.938970; Mean validation loss 0.044130; Mean validation F1 0.940034; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 085/096 - Mean training loss 0.080961; Mean training F1 0.939067; Mean validation loss 0.042221; Mean validation F1 0.939727; Learning rate 0.000042;\n",
    "===========================================================\n",
    "Epoch 086/096 - Mean training loss 0.080898; Mean training F1 0.939034; Mean validation loss 0.073411; Mean validation F1 0.940034; Learning rate 0.000037;\n",
    "===========================================================\n",
    "Epoch 087/096 - Mean training loss 0.080865; Mean training F1 0.939105; Mean validation loss 0.062924; Mean validation F1 0.939794; Learning rate 0.000032;\n",
    "===========================================================\n",
    "Epoch 088/096 - Mean training loss 0.080852; Mean training F1 0.939055; Mean validation loss 0.077422; Mean validation F1 0.939945; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 089/096 - Mean training loss 0.080818; Mean training F1 0.939089; Mean validation loss 0.090327; Mean validation F1 0.939961; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 090/096 - Mean training loss 0.080810; Mean training F1 0.939066; Mean validation loss 0.069376; Mean validation F1 0.939744; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 091/096 - Mean training loss 0.080805; Mean training F1 0.939095; Mean validation loss 0.070339; Mean validation F1 0.939833; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 092/096 - Mean training loss 0.080767; Mean training F1 0.939049; Mean validation loss 0.099036; Mean validation F1 0.939859; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 093/096 - Mean training loss 0.080753; Mean training F1 0.939150; Mean validation loss 0.093636; Mean validation F1 0.939911; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 094/096 - Mean training loss 0.080742; Mean training F1 0.939191; Mean validation loss 0.106249; Mean validation F1 0.939901; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 095/096 - Mean training loss 0.080727; Mean training F1 0.939220; Mean validation loss 0.085172; Mean validation F1 0.939880; Learning rate 0.000010;\n",
    "===========================================================\n",
    "Epoch 096/096 - Mean training loss 0.080722; Mean training F1 0.939191; Mean validation loss 0.087238; Mean validation F1 0.940008; Learning rate 0.000010;\n",
    "################################################################\n",
    "Training/validation for fold 5/5;\n",
    "===========================================================\n",
    "Epoch 001/096 - Mean training loss 0.827274; Mean training F1 0.517451; Mean validation loss 0.593668; Mean validation F1 0.738054; Learning rate 0.001000;\n",
    "===========================================================\n",
    "Epoch 002/096 - Mean training loss 0.294775; Mean training F1 0.839073; Mean validation loss 0.140100; Mean validation F1 0.902356; Learning rate 0.000999;\n",
    "===========================================================\n",
    "Epoch 003/096 - Mean training loss 0.162022; Mean training F1 0.904254; Mean validation loss 0.134153; Mean validation F1 0.903391; Learning rate 0.000998;\n",
    "===========================================================\n",
    "Epoch 004/096 - Mean training loss 0.118569; Mean training F1 0.921312; Mean validation loss 0.114595; Mean validation F1 0.934263; Learning rate 0.000996;\n",
    "===========================================================\n",
    "Epoch 005/096 - Mean training loss 0.096956; Mean training F1 0.932416; Mean validation loss 0.075877; Mean validation F1 0.935579; Learning rate 0.000994;\n",
    "===========================================================\n",
    "Epoch 006/096 - Mean training loss 0.094709; Mean training F1 0.933285; Mean validation loss 0.056622; Mean validation F1 0.934732; Learning rate 0.000991;\n",
    "===========================================================\n",
    "Epoch 007/096 - Mean training loss 0.093118; Mean training F1 0.933999; Mean validation loss 0.116652; Mean validation F1 0.930786; Learning rate 0.000988;\n",
    "===========================================================\n",
    "Epoch 008/096 - Mean training loss 0.092685; Mean training F1 0.933822; Mean validation loss 0.115539; Mean validation F1 0.936847; Learning rate 0.000984;\n",
    "===========================================================\n",
    "Epoch 009/096 - Mean training loss 0.093442; Mean training F1 0.932689; Mean validation loss 0.092979; Mean validation F1 0.935918; Learning rate 0.000979;\n",
    "===========================================================\n",
    "Epoch 010/096 - Mean training loss 0.093409; Mean training F1 0.933040; Mean validation loss 0.099291; Mean validation F1 0.937067; Learning rate 0.000974;\n",
    "===========================================================\n",
    "Epoch 011/096 - Mean training loss 0.088909; Mean training F1 0.935795; Mean validation loss 0.087002; Mean validation F1 0.936677; Learning rate 0.000969;\n",
    "===========================================================\n",
    "Epoch 012/096 - Mean training loss 0.106072; Mean training F1 0.924450; Mean validation loss 0.078938; Mean validation F1 0.911981; Learning rate 0.000963;\n",
    "===========================================================\n",
    "Epoch 013/096 - Mean training loss 0.090792; Mean training F1 0.934220; Mean validation loss 0.077556; Mean validation F1 0.932718; Learning rate 0.000956;\n",
    "===========================================================\n",
    "Epoch 014/096 - Mean training loss 0.088881; Mean training F1 0.935340; Mean validation loss 0.111562; Mean validation F1 0.936717; Learning rate 0.000949;\n",
    "===========================================================\n",
    "Epoch 015/096 - Mean training loss 0.088976; Mean training F1 0.934892; Mean validation loss 0.083797; Mean validation F1 0.936537; Learning rate 0.000942;\n",
    "===========================================================\n",
    "Epoch 016/096 - Mean training loss 0.088104; Mean training F1 0.935750; Mean validation loss 0.115846; Mean validation F1 0.937465; Learning rate 0.000934;\n",
    "===========================================================\n",
    "Epoch 017/096 - Mean training loss 0.086868; Mean training F1 0.936470; Mean validation loss 0.096767; Mean validation F1 0.937514; Learning rate 0.000926;\n",
    "===========================================================\n",
    "Epoch 018/096 - Mean training loss 0.087369; Mean training F1 0.936160; Mean validation loss 0.052579; Mean validation F1 0.936040; Learning rate 0.000917;\n",
    "===========================================================\n",
    "Epoch 019/096 - Mean training loss 0.086322; Mean training F1 0.936642; Mean validation loss 0.127808; Mean validation F1 0.937293; Learning rate 0.000908;\n",
    "===========================================================\n",
    "Epoch 020/096 - Mean training loss 0.086991; Mean training F1 0.936146; Mean validation loss 0.062237; Mean validation F1 0.937336; Learning rate 0.000898;\n",
    "===========================================================\n",
    "Epoch 021/096 - Mean training loss 0.086576; Mean training F1 0.936364; Mean validation loss 0.115117; Mean validation F1 0.937773; Learning rate 0.000888;\n",
    "===========================================================\n",
    "Epoch 022/096 - Mean training loss 0.086494; Mean training F1 0.936232; Mean validation loss 0.076762; Mean validation F1 0.936126; Learning rate 0.000878;\n",
    "===========================================================\n",
    "Epoch 023/096 - Mean training loss 0.085842; Mean training F1 0.936633; Mean validation loss 0.094994; Mean validation F1 0.937437; Learning rate 0.000867;\n",
    "===========================================================\n",
    "Epoch 024/096 - Mean training loss 0.085778; Mean training F1 0.936632; Mean validation loss 0.091814; Mean validation F1 0.935948; Learning rate 0.000856;\n",
    "===========================================================\n",
    "Epoch 025/096 - Mean training loss 0.086623; Mean training F1 0.936021; Mean validation loss 0.096353; Mean validation F1 0.937438; Learning rate 0.000844;\n",
    "===========================================================\n",
    "Epoch 026/096 - Mean training loss 0.085557; Mean training F1 0.936502; Mean validation loss 0.072107; Mean validation F1 0.937369; Learning rate 0.000832;\n",
    "===========================================================\n",
    "Epoch 027/096 - Mean training loss 0.085411; Mean training F1 0.936810; Mean validation loss 0.078653; Mean validation F1 0.937742; Learning rate 0.000820;\n",
    "===========================================================\n",
    "Epoch 028/096 - Mean training loss 0.087348; Mean training F1 0.935638; Mean validation loss 0.082748; Mean validation F1 0.936637; Learning rate 0.000807;\n",
    "===========================================================\n",
    "Epoch 029/096 - Mean training loss 0.084719; Mean training F1 0.937442; Mean validation loss 0.092786; Mean validation F1 0.937310; Learning rate 0.000794;\n",
    "===========================================================\n",
    "Epoch 030/096 - Mean training loss 0.085424; Mean training F1 0.936302; Mean validation loss 0.098501; Mean validation F1 0.935848; Learning rate 0.000781;\n",
    "===========================================================\n",
    "Epoch 031/096 - Mean training loss 0.084424; Mean training F1 0.937250; Mean validation loss 0.067925; Mean validation F1 0.936808; Learning rate 0.000767;\n",
    "===========================================================\n",
    "Epoch 032/096 - Mean training loss 0.084434; Mean training F1 0.937386; Mean validation loss 0.035691; Mean validation F1 0.933655; Learning rate 0.000753;\n",
    "===========================================================\n",
    "Epoch 033/096 - Mean training loss 0.084134; Mean training F1 0.937279; Mean validation loss 0.078826; Mean validation F1 0.937281; Learning rate 0.000739;\n",
    "===========================================================\n",
    "Epoch 034/096 - Mean training loss 0.084686; Mean training F1 0.937032; Mean validation loss 0.075029; Mean validation F1 0.937477; Learning rate 0.000724;\n",
    "===========================================================\n",
    "Epoch 035/096 - Mean training loss 0.083862; Mean training F1 0.937689; Mean validation loss 0.055692; Mean validation F1 0.938299; Learning rate 0.000710;\n",
    "===========================================================\n",
    "Epoch 036/096 - Mean training loss 0.084489; Mean training F1 0.937176; Mean validation loss 0.065795; Mean validation F1 0.938324; Learning rate 0.000695;\n",
    "===========================================================\n",
    "Epoch 037/096 - Mean training loss 0.083960; Mean training F1 0.937372; Mean validation loss 0.092055; Mean validation F1 0.936470; Learning rate 0.000680;\n",
    "===========================================================\n",
    "Epoch 038/096 - Mean training loss 0.084323; Mean training F1 0.937339; Mean validation loss 0.064044; Mean validation F1 0.936499; Learning rate 0.000665;\n",
    "===========================================================\n",
    "Epoch 039/096 - Mean training loss 0.084029; Mean training F1 0.937169; Mean validation loss 0.087501; Mean validation F1 0.937564; Learning rate 0.000649;\n",
    "===========================================================\n",
    "Epoch 040/096 - Mean training loss 0.083565; Mean training F1 0.937474; Mean validation loss 0.082408; Mean validation F1 0.938423; Learning rate 0.000634;\n",
    "===========================================================\n",
    "Epoch 041/096 - Mean training loss 0.082978; Mean training F1 0.937925; Mean validation loss 0.056467; Mean validation F1 0.938518; Learning rate 0.000618;\n",
    "===========================================================\n",
    "Epoch 042/096 - Mean training loss 0.083232; Mean training F1 0.937664; Mean validation loss 0.076483; Mean validation F1 0.937867; Learning rate 0.000602;\n",
    "===========================================================\n",
    "Epoch 043/096 - Mean training loss 0.083087; Mean training F1 0.937665; Mean validation loss 0.052899; Mean validation F1 0.933242; Learning rate 0.000586;\n",
    "===========================================================\n",
    "Epoch 044/096 - Mean training loss 0.083226; Mean training F1 0.937756; Mean validation loss 0.094815; Mean validation F1 0.938343; Learning rate 0.000570;\n",
    "===========================================================\n",
    "Epoch 045/096 - Mean training loss 0.082711; Mean training F1 0.938026; Mean validation loss 0.068244; Mean validation F1 0.938517; Learning rate 0.000554;\n",
    "===========================================================\n",
    "Epoch 046/096 - Mean training loss 0.082890; Mean training F1 0.937690; Mean validation loss 0.086999; Mean validation F1 0.938097; Learning rate 0.000538;\n",
    "===========================================================\n",
    "Epoch 047/096 - Mean training loss 0.082894; Mean training F1 0.937832; Mean validation loss 0.057548; Mean validation F1 0.938172; Learning rate 0.000522;\n",
    "===========================================================\n",
    "Epoch 048/096 - Mean training loss 0.082551; Mean training F1 0.938054; Mean validation loss 0.081196; Mean validation F1 0.938678; Learning rate 0.000506;\n",
    "===========================================================\n",
    "Epoch 049/096 - Mean training loss 0.081792; Mean training F1 0.938489; Mean validation loss 0.089212; Mean validation F1 0.937576; Learning rate 0.000489;\n",
    "===========================================================\n",
    "Epoch 050/096 - Mean training loss 0.081982; Mean training F1 0.938345; Mean validation loss 0.067466; Mean validation F1 0.936085; Learning rate 0.000473;\n",
    "===========================================================\n",
    "Epoch 051/096 - Mean training loss 0.082085; Mean training F1 0.938261; Mean validation loss 0.090342; Mean validation F1 0.938562; Learning rate 0.000457;\n",
    "===========================================================\n",
    "Epoch 052/096 - Mean training loss 0.081884; Mean training F1 0.938264; Mean validation loss 0.073756; Mean validation F1 0.938353; Learning rate 0.000441;\n",
    "===========================================================\n",
    "Epoch 053/096 - Mean training loss 0.081903; Mean training F1 0.938282; Mean validation loss 0.083281; Mean validation F1 0.938310; Learning rate 0.000425;\n",
    "===========================================================\n",
    "Epoch 054/096 - Mean training loss 0.081667; Mean training F1 0.938637; Mean validation loss 0.067067; Mean validation F1 0.938380; Learning rate 0.000409;\n",
    "===========================================================\n",
    "Epoch 055/096 - Mean training loss 0.081524; Mean training F1 0.938653; Mean validation loss 0.099746; Mean validation F1 0.938331; Learning rate 0.000393;\n",
    "===========================================================\n",
    "Epoch 056/096 - Mean training loss 0.083392; Mean training F1 0.937793; Mean validation loss 0.070869; Mean validation F1 0.938436; Learning rate 0.000377;\n",
    "===========================================================\n",
    "Epoch 057/096 - Mean training loss 0.081650; Mean training F1 0.938494; Mean validation loss 0.113015; Mean validation F1 0.938723; Learning rate 0.000362;\n",
    "===========================================================\n",
    "Epoch 058/096 - Mean training loss 0.081312; Mean training F1 0.938656; Mean validation loss 0.074541; Mean validation F1 0.937918; Learning rate 0.000346;\n",
    "===========================================================\n",
    "Epoch 059/096 - Mean training loss 0.081447; Mean training F1 0.938642; Mean validation loss 0.094846; Mean validation F1 0.938344; Learning rate 0.000331;\n",
    "===========================================================\n",
    "Epoch 060/096 - Mean training loss 0.081094; Mean training F1 0.938770; Mean validation loss 0.051933; Mean validation F1 0.938703; Learning rate 0.000316;\n",
    "===========================================================\n",
    "Epoch 061/096 - Mean training loss 0.081002; Mean training F1 0.938981; Mean validation loss 0.052066; Mean validation F1 0.938656; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 062/096 - Mean training loss 0.080772; Mean training F1 0.938989; Mean validation loss 0.082560; Mean validation F1 0.938769; Learning rate 0.000287;\n",
    "===========================================================\n",
    "Epoch 063/096 - Mean training loss 0.080733; Mean training F1 0.939009; Mean validation loss 0.100314; Mean validation F1 0.938599; Learning rate 0.000272;\n",
    "===========================================================\n",
    "Epoch 064/096 - Mean training loss 0.080770; Mean training F1 0.939014; Mean validation loss 0.071681; Mean validation F1 0.938520; Learning rate 0.000258;\n",
    "===========================================================\n",
    "Epoch 065/096 - Mean training loss 0.080785; Mean training F1 0.939026; Mean validation loss 0.072974; Mean validation F1 0.938747; Learning rate 0.000244;\n",
    "===========================================================\n",
    "Epoch 066/096 - Mean training loss 0.080590; Mean training F1 0.939029; Mean validation loss 0.104715; Mean validation F1 0.938525; Learning rate 0.000230;\n",
    "===========================================================\n",
    "Epoch 067/096 - Mean training loss 0.080629; Mean training F1 0.939065; Mean validation loss 0.071216; Mean validation F1 0.938651; Learning rate 0.000217;\n",
    "===========================================================\n",
    "Epoch 068/096 - Mean training loss 0.080665; Mean training F1 0.939102; Mean validation loss 0.073136; Mean validation F1 0.938676; Learning rate 0.000204;\n",
    "===========================================================\n",
    "Epoch 069/096 - Mean training loss 0.080444; Mean training F1 0.939239; Mean validation loss 0.112388; Mean validation F1 0.938692; Learning rate 0.000191;\n",
    "===========================================================\n",
    "Epoch 070/096 - Mean training loss 0.080253; Mean training F1 0.939405; Mean validation loss 0.085884; Mean validation F1 0.938930; Learning rate 0.000179;\n",
    "===========================================================\n",
    "Epoch 071/096 - Mean training loss 0.080278; Mean training F1 0.939324; Mean validation loss 0.088168; Mean validation F1 0.938761; Learning rate 0.000167;\n",
    "===========================================================\n",
    "Epoch 072/096 - Mean training loss 0.080264; Mean training F1 0.939122; Mean validation loss 0.074711; Mean validation F1 0.938411; Learning rate 0.000155;\n",
    "===========================================================\n",
    "Epoch 073/096 - Mean training loss 0.080135; Mean training F1 0.939430; Mean validation loss 0.077903; Mean validation F1 0.938568; Learning rate 0.000144;\n",
    "===========================================================\n",
    "Epoch 074/096 - Mean training loss 0.080092; Mean training F1 0.939321; Mean validation loss 0.077710; Mean validation F1 0.938820; Learning rate 0.000133;\n",
    "===========================================================\n",
    "Epoch 075/096 - Mean training loss 0.080005; Mean training F1 0.939497; Mean validation loss 0.075597; Mean validation F1 0.938876; Learning rate 0.000123;\n",
    "===========================================================\n",
    "Epoch 076/096 - Mean training loss 0.079995; Mean training F1 0.939450; Mean validation loss 0.069082; Mean validation F1 0.938829; Learning rate 0.000113;\n",
    "===========================================================\n",
    "Epoch 077/096 - Mean training loss 0.079928; Mean training F1 0.939423; Mean validation loss 0.082381; Mean validation F1 0.938865; Learning rate 0.000103;\n",
    "===========================================================\n",
    "Epoch 078/096 - Mean training loss 0.079909; Mean training F1 0.939352; Mean validation loss 0.094431; Mean validation F1 0.938791; Learning rate 0.000094;\n",
    "===========================================================\n",
    "Epoch 079/096 - Mean training loss 0.079848; Mean training F1 0.939467; Mean validation loss 0.059024; Mean validation F1 0.938882; Learning rate 0.000085;\n",
    "===========================================================\n",
    "Epoch 080/096 - Mean training loss 0.079760; Mean training F1 0.939598; Mean validation loss 0.075146; Mean validation F1 0.939071; Learning rate 0.000077;\n",
    "===========================================================\n",
    "Epoch 081/096 - Mean training loss 0.079704; Mean training F1 0.939604; Mean validation loss 0.090981; Mean validation F1 0.939008; Learning rate 0.000069;\n",
    "===========================================================\n",
    "Epoch 082/096 - Mean training loss 0.079674; Mean training F1 0.939583; Mean validation loss 0.082462; Mean validation F1 0.938890; Learning rate 0.000062;\n",
    "===========================================================\n",
    "Epoch 083/096 - Mean training loss 0.079657; Mean training F1 0.939685; Mean validation loss 0.106357; Mean validation F1 0.938837; Learning rate 0.000055;\n",
    "===========================================================\n",
    "Epoch 084/096 - Mean training loss 0.079610; Mean training F1 0.939586; Mean validation loss 0.115958; Mean validation F1 0.938954; Learning rate 0.000048;\n",
    "===========================================================\n",
    "Epoch 085/096 - Mean training loss 0.079543; Mean training F1 0.939671; Mean validation loss 0.099545; Mean validation F1 0.939023; Learning rate 0.000042;\n",
    "===========================================================\n",
    "Epoch 086/096 - Mean training loss 0.079544; Mean training F1 0.939669; Mean validation loss 0.074048; Mean validation F1 0.938931; Learning rate 0.000037;\n",
    "===========================================================\n",
    "Epoch 087/096 - Mean training loss 0.079528; Mean training F1 0.939656; Mean validation loss 0.067933; Mean validation F1 0.938853; Learning rate 0.000032;\n",
    "===========================================================\n",
    "Epoch 088/096 - Mean training loss 0.079477; Mean training F1 0.939666; Mean validation loss 0.102361; Mean validation F1 0.938822; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 089/096 - Mean training loss 0.079443; Mean training F1 0.939791; Mean validation loss 0.095576; Mean validation F1 0.939020; Learning rate 0.000023;\n",
    "===========================================================\n",
    "Epoch 090/096 - Mean training loss 0.079443; Mean training F1 0.939697; Mean validation loss 0.068304; Mean validation F1 0.939013; Learning rate 0.000020;\n",
    "===========================================================\n",
    "Epoch 091/096 - Mean training loss 0.079419; Mean training F1 0.939731; Mean validation loss 0.113775; Mean validation F1 0.938985; Learning rate 0.000017;\n",
    "===========================================================\n",
    "Epoch 092/096 - Mean training loss 0.079393; Mean training F1 0.939788; Mean validation loss 0.073489; Mean validation F1 0.938988; Learning rate 0.000015;\n",
    "===========================================================\n",
    "Epoch 093/096 - Mean training loss 0.079398; Mean training F1 0.939736; Mean validation loss 0.049179; Mean validation F1 0.938898; Learning rate 0.000013;\n",
    "===========================================================\n",
    "Epoch 094/096 - Mean training loss 0.079379; Mean training F1 0.939751; Mean validation loss 0.055850; Mean validation F1 0.939055; Learning rate 0.000011;\n",
    "===========================================================\n",
    "Epoch 095/096 - Mean training loss 0.079357; Mean training F1 0.939751; Mean validation loss 0.065192; Mean validation F1 0.938986; Learning rate 0.000010;\n",
    "===========================================================\n",
    "Epoch 096/096 - Mean training loss 0.079357; Mean training F1 0.939769; Mean validation loss 0.095364; Mean validation F1 0.938918; Learning rate 0.000010;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
