{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import math\n",
    "import warnings\n",
    "import gc\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import bloscpack as bp\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold, train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 10000)\n",
    "pd.set_option('display.max_rows', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/batch_ids_trn.pkl', 'rb') as f:\n",
    "    batch_id_trn = pickle.load(f)\n",
    "with open('../input/batch_ids_tst.pkl', 'rb') as f:\n",
    "    batch_id_tst = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_w500 = bp.unpack_ndarray_from_file('../input/feats_tblr/trn_dat_all_w500_fixed.bp')\n",
    "trn_orig = pd.read_pickle('../input/feats_tblr/trn_dat_orig_v2_all.pkl')\n",
    "trn_orig = trn_orig.loc[:, [c for c in trn_orig.columns if c not in ('time', 'batch', 'open_channels')]]\n",
    "\n",
    "trn = np.concatenate([trn_orig.values, trn_w500], axis=1)\n",
    "del trn_orig, trn_w500\n",
    "\n",
    "lbl = pd.read_pickle('../input/feats_tblr/trn_lbl_orig_v2_all.pkl').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_w500 = bp.unpack_ndarray_from_file(\n",
    "    os.path.join(\n",
    "        '../input/feats_tblr',\n",
    "        [f for f in os.listdir('../input/feats_tblr') if ('tst' in f) and ('w500' in f)][0]\n",
    "    )\n",
    ")\n",
    "tst_orig = pd.read_pickle('../input/feats_tblr/tst_dat_orig_v2_all.pkl')\n",
    "tst_orig = tst_orig.loc[:, [c for c in tst_orig.columns if c not in ('time', 'batch', 'open_channels')]]\n",
    "\n",
    "tst = np.concatenate([tst_orig.values, tst_w500], axis=1)\n",
    "del tst_orig, tst_w500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 66)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 column has std of zero.\n",
      "067 / 067\r"
     ]
    }
   ],
   "source": [
    "for c in range(trn.shape[1]):\n",
    "    # drop useless column\n",
    "    if np.nanstd(trn[:, c]) == 0:\n",
    "        print('{} column has std of zero.'.format(c))\n",
    "        continue\n",
    "        \n",
    "    # process infinite value\n",
    "    isinf = ~np.isfinite(trn[:, c])\n",
    "    trn[:, c][trn[:, c] == np.inf] = np.nanmax(trn[:, c][~isinf])\n",
    "    trn[:, c][trn[:, c] == -np.inf] = np.nanmin(trn[:, c][~isinf])\n",
    "    \n",
    "    #isinf = ~np.isfinite(tst[:, c])\n",
    "    #tst[:, c][tst[:, c] == np.inf] = np.nanmax(tst[:, c][~isinf])\n",
    "    #tst[:, c][tst[:, c] == -np.inf] = np.nanmin(tst[:, c][~isinf])\n",
    "    \n",
    "    # process nan\n",
    "    isnan_trn = np.isnan(trn[:, c])\n",
    "    c_avg = np.nanmean(trn[:, c])\n",
    "    c_std = np.nanstd(trn[:, c])\n",
    "    \n",
    "    if isnan_trn.sum() > 0:\n",
    "        trn[:, c][isnan_trn] = c_avg\n",
    "    \n",
    "    #isnan_tst = np.isnan(tst[:, c])\n",
    "    #if isnan_tst.sum() > 0:\n",
    "    #    tst[:, c][isnan_tst] = c_avg\n",
    "    \n",
    "    # finally scale\n",
    "    trn[:, c] = (trn[:, c] - c_avg) / c_std\n",
    "    #tst[:, c] = (tst[:, c] - c_avg) / c_std\n",
    "    \n",
    "    # show progress\n",
    "    print('{:03d} / {:03d}'.format(c+1, trn.shape[1]), end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "for c in [79, 89, 99, 109, 119, 129, 139, 149, 159, 169, 179, 189, 199, 209, 219, 229, 700, 759, 768, 1046, 1105, 1114]:\n",
    "    print(np.nanstd(trn[:, c]), np.nanstd(tst[:, c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = np.delete(trn, [79, 89, 99, 109, 119, 129, 139, 149, 159, 169, 179, 189, 199, 209, 219, 229, 700, 759, 768, 1046, 1105, 1114], axis=1)\n",
    "tst = np.delete(tst, [79, 89, 99, 109, 119, 129, 139, 149, 159, 169, 179, 189, 199, 209, 219, 229, 700, 759, 768, 1046, 1105, 1114], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp.pack_ndarray_to_file(trn, '../input/feats_tblr/trn_dat_all_origv2_w500.bp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp.pack_ndarray_to_file(tst, '../input/feats_tblr/tst_dat_all_origv2_w500.bp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_f_v2 = sorted([f for f in os.listdir('../input') if ('trn' in f) and ('v2' in f) and ('dat' in f) and ('w100' in f)])\n",
    "trn_v2 = np.concatenate([bp.unpack_ndarray_from_file(os.path.join('../input/', f)) for f in trn_f_v2], axis=0)\n",
    "\n",
    "tst_f_v2 = sorted([f for f in os.listdir('../input') if ('tst' in f) and ('v2' in f) and ('dat' in f) and ('w100' in f)])\n",
    "tst_f_v2 = tst_f_v2[:1] + tst_f_v2[11:] + tst_f_v2[1:11]\n",
    "tst_v2 = np.concatenate([bp.unpack_ndarray_from_file(os.path.join('../input/', f)) for f in tst_f_v2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 column has std of zero.\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for c in range(trn_v2.shape[1]):\n",
    "    # drop useless column\n",
    "    if np.nanstd(trn_v2[:, c]) == 0:\n",
    "        print('{} column has std of zero.'.format(c))\n",
    "        print(np.nanstd(tst_v2[:, c]))\n",
    "        continue\n",
    "        \n",
    "    # process infinite value\n",
    "    isinf = ~np.isfinite(trn_v2[:, c])\n",
    "    trn_v2[:, c][trn_v2[:, c] == np.inf] = np.nanmax(trn_v2[:, c][~isinf])\n",
    "    trn_v2[:, c][trn_v2[:, c] == -np.inf] = np.nanmin(trn_v2[:, c][~isinf])\n",
    "    \n",
    "    isinf = ~np.isfinite(tst_v2[:, c])\n",
    "    tst_v2[:, c][tst_v2[:, c] == np.inf] = np.nanmax(tst_v2[:, c][~isinf])\n",
    "    tst_v2[:, c][tst_v2[:, c] == -np.inf] = np.nanmin(tst_v2[:, c][~isinf])\n",
    "    \n",
    "    # process nan\n",
    "    isnan_trn = np.isnan(trn_v2[:, c])\n",
    "    c_avg = np.nanmean(trn_v2[:, c])\n",
    "    c_std = np.nanstd(trn_v2[:, c])\n",
    "    \n",
    "    if isnan_trn.sum() > 0:\n",
    "        trn_v2[:, c][isnan_trn] = c_avg\n",
    "    \n",
    "    isnan_tst = np.isnan(tst_v2[:, c])\n",
    "    if isnan_tst.sum() > 0:\n",
    "        tst_v2[:, c][isnan_tst] = c_avg\n",
    "    \n",
    "    # finally scale\n",
    "    trn_v2[:, c] = (trn_v2[:, c] - c_avg) / c_std\n",
    "    tst_v2[:, c] = (tst_v2[:, c] - c_avg) / c_std\n",
    "    \n",
    "    # show progress\n",
    "    print('{:03d} / {:03d}'.format(c+1, trn_v2.shape[1]), end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_v2 = np.delete(trn_v2, [78], axis=1)\n",
    "tst_v2 = np.delete(tst_v2, [78], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp.pack_ndarray_to_file(trn_v2, '../input/trn_dat_v2_w100_welch.bp')\n",
    "bp.pack_ndarray_to_file(tst_v2, '../input/tst_dat_v2_w100_welch.bp')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trn = bp.unpack_ndarray_from_file('../input/trn_datv2_g0_w50.bp')\n",
    "feat = bp.unpack_ndarray_from_file('../input/trn_featv2_g0_w50.bp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
