{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import bloscpack as bp\n",
    "\n",
    "from tsfresh.feature_extraction import feature_calculators\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold, GroupKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from NNs import WaveTRSFM_Classifier, Wave_Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc035c96cb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda:0'\n",
    "EPOCHS = 96\n",
    "BATCHSIZE = 64\n",
    "SEED = 19550423\n",
    "LR = 0.0005\n",
    "SPLITS = 5\n",
    "\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_tag = 's500'\n",
    "wndw_tag = 'w500'\n",
    "vers_tag = 'basicwithnew2'\n",
    "trn_fs = sorted([f for f in os.listdir('../input/feats_srs') if (('trn_srs_dat' in f) and (step_tag in f) and (wndw_tag in f) and (vers_tag in f))])\n",
    "lbl_fs = sorted([f for f in os.listdir('../input/feats_srs') if ('trn_srs_lbl' in f) and (step_tag in f) and (wndw_tag in f) and (vers_tag in f)])\n",
    "\n",
    "tst_fs = sorted([f for f in os.listdir('../input/feats_srs') if (('tst_srs_dat' in f) and (step_tag in f) and (wndw_tag in f) and (vers_tag in f))])\n",
    "tst_fs = [tst_fs[i] for i in [0, 11, 12, 13, 14, 15, 16, 17, 18, 19]] + tst_fs[1:11]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tst_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_dat_all = np.concatenate(\n",
    "    [bp.unpack_ndarray_from_file(os.path.join('../input/feats_srs', f)) for f in trn_fs],\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "series_lbl_all = [bp.unpack_ndarray_from_file(os.path.join('../input/feats_srs', f)) for f in lbl_fs]\n",
    "\n",
    "series_bch_all = np.concatenate(\n",
    "    [np.ones(shape=(arr.shape[0],)) * i for i, arr in zip([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], series_lbl_all)],\n",
    "    axis=0\n",
    ").astype(int)\n",
    "\n",
    "series_lbl_all = np.concatenate(\n",
    "    series_lbl_all,\n",
    "    axis=0\n",
    ")[:, :, None]\n",
    "\n",
    "series_dat_tst = np.concatenate(\n",
    "    [bp.unpack_ndarray_from_file(os.path.join('../input/feats_srs', f)) for f in tst_fs],\n",
    "    axis=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 42 / 42; \r"
     ]
    }
   ],
   "source": [
    "for i in range(series_dat_all.shape[-1]):\n",
    "\n",
    "    avg = series_dat_all[:, :, i].mean()\n",
    "    std = series_dat_all[:, :, i].std()\n",
    "    series_dat_all[:, :, i] = (series_dat_all[:, :, i] - avg) / std\n",
    "    series_dat_tst[:, :, i] = (series_dat_tst[:, :, i] - avg) / std\n",
    "    \n",
    "    #print('---------')\n",
    "    #print('{:d} - max {:.3f}; min {:.3f};'.format(i, series_dat_all[:, :, i].max(), series_dat_all[:, :, i].min()))\n",
    "    #print('{:d} - max {:.3f}; min {:.3f};'.format(i, series_dat_tst[:, :, i].max(), series_dat_tst[:, :, i].min()))\n",
    "    print('progress: {:02d} / {:02d}; '.format(i+1, series_dat_all.shape[-1]), end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit = 1000\n",
    "series_dat_all = np.concatenate([series_dat_all[4*unit:5*unit], series_dat_all[9*unit:10*unit]], 0)\n",
    "series_lbl_all = np.concatenate([series_lbl_all[4*unit:5*unit], series_lbl_all[9*unit:10*unit]], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_ent = [feature_calculators.binned_entropy(lst, max_bins=20) for lst in series_dat_all[:, :, 0].tolist()]\n",
    "bin_ent = pd.qcut(pd.Series(bin_ent), q=10, duplicates='drop')\n",
    "\n",
    "skf_trgt = [str(a) + '_' + str(b) for a, b in zip(series_bch_all, bin_ent)]\n",
    "us = np.unique(skf_trgt)\n",
    "umap = {u: i for u, i in zip(us, range(len(us)))}\n",
    "skf_trgt = [umap[u] for u in skf_trgt]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "us, cs = np.unique(skf_trgt, return_counts=True)\n",
    "for u, c in zip(us, cs):\n",
    "    print(u, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Waveset(Dataset):\n",
    "    def __init__(self, data, labels=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "        \n",
    "        if self.labels is None:\n",
    "            return data.astype(np.float32)\n",
    "        else:\n",
    "            labels = self.labels[idx]\n",
    "            return (data.astype(np.float32), labels.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_train_validate(\n",
    "    model, optimizer, criterion, scheduler,\n",
    "    training_loader, validation_loaders, fold_number,\n",
    "    save_path='./saved_models/wavenet_model_fold{:03d}_checkpoint.pth',\n",
    "    early_stopping=15,\n",
    "):\n",
    "    assert isinstance(validation_loaders, dict)\n",
    "\n",
    "    trn_losses = [np.nan]\n",
    "    vld_losses = [np.nan]\n",
    "    vld_f1s = [np.nan]\n",
    "    \n",
    "    last_best = 0\n",
    "\n",
    "    for epc in range(EPOCHS):\n",
    "        print('===========================================================')\n",
    "\n",
    "        epoch_trn_losses = []\n",
    "        epoch_trn_lbls = []\n",
    "        epoch_trn_prds = []\n",
    "        \n",
    "        # ------ training ------\n",
    "        model.train()\n",
    "        for i, (trn_batch_dat, trn_batch_lbl) in enumerate(training_loader):\n",
    "            trn_batch_dat, trn_batch_lbl = trn_batch_dat.to(DEVICE), trn_batch_lbl.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            trn_batch_prd = model(trn_batch_dat)\n",
    "            trn_batch_prd = trn_batch_prd.view(-1, trn_batch_prd.size(-1))\n",
    "            trn_batch_lbl = trn_batch_lbl.view(-1)\n",
    "            loss = criterion(trn_batch_prd, trn_batch_lbl)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_trn_losses.append(loss.item())\n",
    "            epoch_trn_lbls.append(trn_batch_lbl.detach().cpu().numpy())\n",
    "            epoch_trn_prds.append(trn_batch_prd.detach().cpu().numpy())\n",
    "\n",
    "            #print(\n",
    "            #    'Epoch {:03d}/{:03d} - Training batch {:04d}/{:04d}: Training loss {:.6f};'.format(\n",
    "            #        epc + 1, EPOCHS, i + 1, len(training_loader), epoch_trn_losses[-1],\n",
    "            #    ), \n",
    "            #    end='\\r'\n",
    "            #)\n",
    "\n",
    "        # ------ validation ------\n",
    "        model.eval()\n",
    "        \n",
    "        grp_vld_metrics = {}\n",
    "        epoch_vld_losses = []\n",
    "        epoch_vld_lbls = []\n",
    "        epoch_vld_prds = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (grp, ldr) in enumerate(validation_loaders.items()):\n",
    "                \n",
    "                epoch_grp_vld_losses = []\n",
    "                epoch_grp_vld_lbls = []\n",
    "                epoch_grp_vld_prds = []\n",
    "\n",
    "                for j, (vld_batch_dat, vld_batch_lbl) in enumerate(ldr):\n",
    "                    vld_batch_dat, vld_batch_lbl = vld_batch_dat.to(DEVICE), vld_batch_lbl.to(DEVICE)\n",
    "\n",
    "                    vld_batch_prd = model(vld_batch_dat)\n",
    "                    vld_batch_prd = vld_batch_prd.view(-1, vld_batch_prd.size(-1))\n",
    "                    vld_batch_lbl = vld_batch_lbl.view(-1)\n",
    "                    loss = criterion(vld_batch_prd, vld_batch_lbl)\n",
    "\n",
    "                    epoch_grp_vld_losses.append(loss.item())\n",
    "                    epoch_grp_vld_lbls.append(vld_batch_lbl.detach().cpu().numpy())\n",
    "                    epoch_grp_vld_prds.append(vld_batch_prd.detach().cpu().numpy())\n",
    "                    if grp == 'vld':\n",
    "                        epoch_vld_losses.append(epoch_grp_vld_losses[-1])\n",
    "                        epoch_vld_lbls.append(epoch_grp_vld_lbls[-1])\n",
    "                        epoch_vld_prds.append(epoch_grp_vld_prds[-1])\n",
    "                    \n",
    "                epoch_grp_vld_lbls = np.concatenate(epoch_grp_vld_lbls, axis=0)\n",
    "                epoch_grp_vld_prds = np.concatenate(epoch_grp_vld_prds, axis=0).argmax(1)\n",
    "                \n",
    "                grp_f1_vld = f1_score(\n",
    "                    epoch_grp_vld_lbls, \n",
    "                    epoch_grp_vld_prds,\n",
    "                    labels=list(range(11)), \n",
    "                    average='macro'\n",
    "                )\n",
    "                \n",
    "                grp_vld_metrics.update({grp: {'f1': grp_f1_vld, 'loss': np.mean(epoch_grp_vld_losses)}})\n",
    "\n",
    "                #print('Validation progress: {:03d}/{:03d} group done;'.format(i + 1, len(validation_loaders)), end='\\r')\n",
    "\n",
    "        # ------ epoch end ------\n",
    "        epoch_trn_lbls = np.concatenate(epoch_trn_lbls, axis=0)\n",
    "        epoch_trn_prds = np.concatenate(epoch_trn_prds, axis=0).argmax(1)\n",
    "\n",
    "        f1_trn = f1_score(\n",
    "            epoch_trn_lbls, \n",
    "            epoch_trn_prds,\n",
    "            labels=list(range(11)), \n",
    "            average='macro'\n",
    "        )\n",
    "        \n",
    "        epoch_vld_lbls = np.concatenate(epoch_vld_lbls, axis=0)\n",
    "        epoch_vld_prds = np.concatenate(epoch_vld_prds, axis=0).argmax(1)\n",
    "\n",
    "        f1_vld = f1_score(\n",
    "            epoch_vld_lbls, \n",
    "            epoch_vld_prds,\n",
    "            labels=list(range(11)), \n",
    "            average='macro'\n",
    "        )\n",
    "\n",
    "\n",
    "        print(\n",
    "            'Epoch {:03d}/{:03d} - Mean training loss {:.6f}; Mean training F1 {:.6f}; Mean validation loss {:.6f}; Mean validation F1 {:.6f}; Learning rate {:.6f};'.format(\n",
    "                epc + 1, EPOCHS, np.mean(epoch_trn_losses), f1_trn, np.mean(epoch_vld_losses), f1_vld, scheduler.get_lr()[0],\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        print('Validation metrics:')\n",
    "        for g, m in grp_vld_metrics.items():\n",
    "            print('Group {}: f1 - {:.6f}; loss - {:.6f};'.format(g, m['f1'], m['loss']))\n",
    "        \n",
    "        if f1_vld > np.nanmax(vld_f1s):\n",
    "            torch.save(\n",
    "                {\n",
    "                    'epoch': epc + 1,\n",
    "                    'model': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'f1': f1_vld,\n",
    "                    'loss': np.mean(epoch_vld_losses),\n",
    "                }, \n",
    "                save_path.format(fold_number)\n",
    "            )\n",
    "            \n",
    "            last_best = epc\n",
    "            \n",
    "        if epc - last_best > early_stopping:\n",
    "            break\n",
    "\n",
    "        vld_f1s.append(f1_vld)\n",
    "\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FOLDS = 5\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################\n",
      "Training/validation for fold 1/5;\n",
      "===========================================================\n",
      "Epoch 001/096 - Mean training loss 1.226612; Mean training F1 0.229727; Mean validation loss 0.602162; Mean validation F1 0.345172; Learning rate 0.000500;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.345172; loss - 0.602162;\n",
      "===========================================================\n",
      "Epoch 002/096 - Mean training loss 0.491087; Mean training F1 0.452115; Mean validation loss 0.400436; Mean validation F1 0.441639; Learning rate 0.000500;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.441639; loss - 0.400436;\n",
      "===========================================================\n",
      "Epoch 003/096 - Mean training loss 0.409109; Mean training F1 0.525209; Mean validation loss 0.403052; Mean validation F1 0.529972; Learning rate 0.000499;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.529972; loss - 0.403052;\n",
      "===========================================================\n",
      "Epoch 004/096 - Mean training loss 0.364194; Mean training F1 0.576893; Mean validation loss 0.320373; Mean validation F1 0.552968; Learning rate 0.000498;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.552968; loss - 0.320373;\n",
      "===========================================================\n",
      "Epoch 005/096 - Mean training loss 0.371546; Mean training F1 0.590202; Mean validation loss 0.406582; Mean validation F1 0.587009; Learning rate 0.000497;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.587009; loss - 0.406582;\n",
      "===========================================================\n",
      "Epoch 006/096 - Mean training loss 0.349697; Mean training F1 0.594076; Mean validation loss 0.462582; Mean validation F1 0.555891; Learning rate 0.000496;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.555891; loss - 0.462582;\n",
      "===========================================================\n",
      "Epoch 007/096 - Mean training loss 0.429610; Mean training F1 0.567084; Mean validation loss 0.394426; Mean validation F1 0.517182; Learning rate 0.000494;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.517182; loss - 0.394426;\n",
      "===========================================================\n",
      "Epoch 008/096 - Mean training loss 0.376295; Mean training F1 0.591603; Mean validation loss 0.333786; Mean validation F1 0.598511; Learning rate 0.000492;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.598511; loss - 0.333786;\n",
      "===========================================================\n",
      "Epoch 009/096 - Mean training loss 0.334375; Mean training F1 0.612991; Mean validation loss 0.300249; Mean validation F1 0.626009; Learning rate 0.000490;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.626009; loss - 0.300249;\n",
      "===========================================================\n",
      "Epoch 010/096 - Mean training loss 0.415298; Mean training F1 0.565581; Mean validation loss 0.344013; Mean validation F1 0.605173; Learning rate 0.000487;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.605173; loss - 0.344013;\n",
      "===========================================================\n",
      "Epoch 011/096 - Mean training loss 0.374947; Mean training F1 0.624757; Mean validation loss 0.323510; Mean validation F1 0.595119; Learning rate 0.000484;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.595119; loss - 0.323510;\n",
      "===========================================================\n",
      "Epoch 012/096 - Mean training loss 0.341285; Mean training F1 0.605761; Mean validation loss 0.333413; Mean validation F1 0.665599; Learning rate 0.000481;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.665599; loss - 0.333413;\n",
      "===========================================================\n",
      "Epoch 013/096 - Mean training loss 0.339021; Mean training F1 0.619952; Mean validation loss 0.344334; Mean validation F1 0.614934; Learning rate 0.000478;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.614934; loss - 0.344334;\n",
      "===========================================================\n",
      "Epoch 014/096 - Mean training loss 0.324997; Mean training F1 0.630289; Mean validation loss 0.312999; Mean validation F1 0.608199; Learning rate 0.000475;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.608199; loss - 0.312999;\n",
      "===========================================================\n",
      "Epoch 015/096 - Mean training loss 0.330766; Mean training F1 0.639336; Mean validation loss 0.305738; Mean validation F1 0.663487; Learning rate 0.000471;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.663487; loss - 0.305738;\n",
      "===========================================================\n",
      "Epoch 016/096 - Mean training loss 0.316823; Mean training F1 0.650370; Mean validation loss 0.320370; Mean validation F1 0.628004; Learning rate 0.000467;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.628004; loss - 0.320370;\n",
      "===========================================================\n",
      "Epoch 017/096 - Mean training loss 0.344003; Mean training F1 0.635607; Mean validation loss 0.330872; Mean validation F1 0.657696; Learning rate 0.000463;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.657696; loss - 0.330872;\n",
      "===========================================================\n",
      "Epoch 018/096 - Mean training loss 0.353640; Mean training F1 0.637734; Mean validation loss 0.384565; Mean validation F1 0.670551; Learning rate 0.000459;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.670551; loss - 0.384565;\n",
      "===========================================================\n",
      "Epoch 019/096 - Mean training loss 0.341257; Mean training F1 0.649988; Mean validation loss 0.339626; Mean validation F1 0.595745; Learning rate 0.000454;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.595745; loss - 0.339626;\n",
      "===========================================================\n",
      "Epoch 020/096 - Mean training loss 0.330310; Mean training F1 0.647141; Mean validation loss 0.295895; Mean validation F1 0.704196; Learning rate 0.000449;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.704196; loss - 0.295895;\n",
      "===========================================================\n",
      "Epoch 021/096 - Mean training loss 0.314528; Mean training F1 0.654507; Mean validation loss 0.283083; Mean validation F1 0.696426; Learning rate 0.000444;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.696426; loss - 0.283083;\n",
      "===========================================================\n",
      "Epoch 022/096 - Mean training loss 0.302589; Mean training F1 0.675835; Mean validation loss 0.283979; Mean validation F1 0.713233; Learning rate 0.000439;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.713233; loss - 0.283979;\n",
      "===========================================================\n",
      "Epoch 023/096 - Mean training loss 0.321088; Mean training F1 0.670314; Mean validation loss 0.292544; Mean validation F1 0.709859; Learning rate 0.000433;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.709859; loss - 0.292544;\n",
      "===========================================================\n",
      "Epoch 024/096 - Mean training loss 0.319757; Mean training F1 0.662978; Mean validation loss 0.290550; Mean validation F1 0.634098; Learning rate 0.000428;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.634098; loss - 0.290550;\n",
      "===========================================================\n",
      "Epoch 025/096 - Mean training loss 0.318711; Mean training F1 0.650967; Mean validation loss 0.292202; Mean validation F1 0.661655; Learning rate 0.000422;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.661655; loss - 0.292202;\n",
      "===========================================================\n",
      "Epoch 026/096 - Mean training loss 0.304300; Mean training F1 0.673892; Mean validation loss 0.295183; Mean validation F1 0.696138; Learning rate 0.000416;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.696138; loss - 0.295183;\n",
      "===========================================================\n",
      "Epoch 027/096 - Mean training loss 0.302320; Mean training F1 0.688405; Mean validation loss 0.286145; Mean validation F1 0.700622; Learning rate 0.000410;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.700622; loss - 0.286145;\n",
      "===========================================================\n",
      "Epoch 028/096 - Mean training loss 0.319756; Mean training F1 0.668091; Mean validation loss 0.284013; Mean validation F1 0.638355; Learning rate 0.000403;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.638355; loss - 0.284013;\n",
      "===========================================================\n",
      "Epoch 029/096 - Mean training loss 0.306926; Mean training F1 0.681677; Mean validation loss 0.308518; Mean validation F1 0.703583; Learning rate 0.000397;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.703583; loss - 0.308518;\n",
      "===========================================================\n",
      "Epoch 030/096 - Mean training loss 0.310487; Mean training F1 0.683773; Mean validation loss 0.292680; Mean validation F1 0.700317; Learning rate 0.000390;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.700317; loss - 0.292680;\n",
      "===========================================================\n",
      "Epoch 031/096 - Mean training loss 0.305312; Mean training F1 0.687879; Mean validation loss 0.299200; Mean validation F1 0.704621; Learning rate 0.000383;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.704621; loss - 0.299200;\n",
      "===========================================================\n",
      "Epoch 032/096 - Mean training loss 0.301014; Mean training F1 0.690700; Mean validation loss 0.288500; Mean validation F1 0.630767; Learning rate 0.000377;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.630767; loss - 0.288500;\n",
      "===========================================================\n",
      "Epoch 033/096 - Mean training loss 0.303137; Mean training F1 0.672830; Mean validation loss 0.307537; Mean validation F1 0.657369; Learning rate 0.000369;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.657369; loss - 0.307537;\n",
      "===========================================================\n",
      "Epoch 034/096 - Mean training loss 0.301472; Mean training F1 0.693565; Mean validation loss 0.290470; Mean validation F1 0.658723; Learning rate 0.000362;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.658723; loss - 0.290470;\n",
      "===========================================================\n",
      "Epoch 035/096 - Mean training loss 0.299045; Mean training F1 0.698187; Mean validation loss 0.284940; Mean validation F1 0.712060; Learning rate 0.000355;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.712060; loss - 0.284940;\n",
      "===========================================================\n",
      "Epoch 036/096 - Mean training loss 0.305525; Mean training F1 0.677636; Mean validation loss 0.289262; Mean validation F1 0.690833; Learning rate 0.000347;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.690833; loss - 0.289262;\n",
      "===========================================================\n",
      "Epoch 037/096 - Mean training loss 0.298627; Mean training F1 0.694815; Mean validation loss 0.286373; Mean validation F1 0.660730; Learning rate 0.000340;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.660730; loss - 0.286373;\n",
      "===========================================================\n",
      "Epoch 038/096 - Mean training loss 0.305709; Mean training F1 0.687375; Mean validation loss 0.288096; Mean validation F1 0.714204; Learning rate 0.000332;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.714204; loss - 0.288096;\n",
      "===========================================================\n",
      "Epoch 039/096 - Mean training loss 0.297698; Mean training F1 0.701494; Mean validation loss 0.281606; Mean validation F1 0.710996; Learning rate 0.000325;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.710996; loss - 0.281606;\n",
      "===========================================================\n",
      "Epoch 040/096 - Mean training loss 0.297791; Mean training F1 0.699159; Mean validation loss 0.283530; Mean validation F1 0.714608; Learning rate 0.000317;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.714608; loss - 0.283530;\n",
      "===========================================================\n",
      "Epoch 041/096 - Mean training loss 0.300923; Mean training F1 0.698787; Mean validation loss 0.280557; Mean validation F1 0.702135; Learning rate 0.000309;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.702135; loss - 0.280557;\n",
      "===========================================================\n",
      "Epoch 042/096 - Mean training loss 0.296566; Mean training F1 0.697649; Mean validation loss 0.279127; Mean validation F1 0.716475; Learning rate 0.000301;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.716475; loss - 0.279127;\n",
      "===========================================================\n",
      "Epoch 043/096 - Mean training loss 0.297828; Mean training F1 0.703604; Mean validation loss 0.311465; Mean validation F1 0.699966; Learning rate 0.000293;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.699966; loss - 0.311465;\n",
      "===========================================================\n",
      "Epoch 044/096 - Mean training loss 0.297198; Mean training F1 0.704341; Mean validation loss 0.281168; Mean validation F1 0.703696; Learning rate 0.000285;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.703696; loss - 0.281168;\n",
      "===========================================================\n",
      "Epoch 045/096 - Mean training loss 0.297877; Mean training F1 0.711306; Mean validation loss 0.325592; Mean validation F1 0.713187; Learning rate 0.000277;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.713187; loss - 0.325592;\n",
      "===========================================================\n",
      "Epoch 046/096 - Mean training loss 0.303943; Mean training F1 0.698607; Mean validation loss 0.281815; Mean validation F1 0.714416; Learning rate 0.000269;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.714416; loss - 0.281815;\n",
      "===========================================================\n",
      "Epoch 047/096 - Mean training loss 0.303421; Mean training F1 0.715385; Mean validation loss 0.291283; Mean validation F1 0.712872; Learning rate 0.000261;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.712872; loss - 0.291283;\n",
      "===========================================================\n",
      "Epoch 048/096 - Mean training loss 0.293038; Mean training F1 0.723136; Mean validation loss 0.286834; Mean validation F1 0.776615; Learning rate 0.000253;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.776615; loss - 0.286834;\n",
      "===========================================================\n",
      "Epoch 049/096 - Mean training loss 0.294056; Mean training F1 0.723902; Mean validation loss 0.308049; Mean validation F1 0.683450; Learning rate 0.000245;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.683450; loss - 0.308049;\n",
      "===========================================================\n",
      "Epoch 050/096 - Mean training loss 0.300245; Mean training F1 0.712072; Mean validation loss 0.281293; Mean validation F1 0.691799; Learning rate 0.000237;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.691799; loss - 0.281293;\n",
      "===========================================================\n",
      "Epoch 051/096 - Mean training loss 0.291344; Mean training F1 0.740125; Mean validation loss 0.279863; Mean validation F1 0.775023; Learning rate 0.000228;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.775023; loss - 0.279863;\n",
      "===========================================================\n",
      "Epoch 052/096 - Mean training loss 0.291143; Mean training F1 0.740333; Mean validation loss 0.286276; Mean validation F1 0.774117; Learning rate 0.000220;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.774117; loss - 0.286276;\n",
      "===========================================================\n",
      "Epoch 053/096 - Mean training loss 0.296587; Mean training F1 0.738432; Mean validation loss 0.282617; Mean validation F1 0.779071; Learning rate 0.000212;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.779071; loss - 0.282617;\n",
      "===========================================================\n",
      "Epoch 054/096 - Mean training loss 0.293706; Mean training F1 0.739296; Mean validation loss 0.283558; Mean validation F1 0.710576; Learning rate 0.000204;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.710576; loss - 0.283558;\n",
      "===========================================================\n",
      "Epoch 055/096 - Mean training loss 0.294913; Mean training F1 0.758194; Mean validation loss 0.282874; Mean validation F1 0.772219; Learning rate 0.000197;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.772219; loss - 0.282874;\n",
      "===========================================================\n",
      "Epoch 056/096 - Mean training loss 0.293867; Mean training F1 0.740347; Mean validation loss 0.279812; Mean validation F1 0.781385; Learning rate 0.000189;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.781385; loss - 0.279812;\n",
      "===========================================================\n",
      "Epoch 057/096 - Mean training loss 0.290094; Mean training F1 0.756132; Mean validation loss 0.280139; Mean validation F1 0.759358; Learning rate 0.000181;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.759358; loss - 0.280139;\n",
      "===========================================================\n",
      "Epoch 058/096 - Mean training loss 0.290263; Mean training F1 0.764190; Mean validation loss 0.281670; Mean validation F1 0.778120; Learning rate 0.000173;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.778120; loss - 0.281670;\n",
      "===========================================================\n",
      "Epoch 059/096 - Mean training loss 0.290628; Mean training F1 0.764814; Mean validation loss 0.278133; Mean validation F1 0.781364; Learning rate 0.000166;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.781364; loss - 0.278133;\n",
      "===========================================================\n",
      "Epoch 060/096 - Mean training loss 0.297512; Mean training F1 0.759902; Mean validation loss 0.282681; Mean validation F1 0.740038; Learning rate 0.000158;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.740038; loss - 0.282681;\n",
      "===========================================================\n",
      "Epoch 061/096 - Mean training loss 0.292433; Mean training F1 0.760928; Mean validation loss 0.286720; Mean validation F1 0.779177; Learning rate 0.000151;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.779177; loss - 0.286720;\n",
      "===========================================================\n",
      "Epoch 062/096 - Mean training loss 0.290413; Mean training F1 0.770301; Mean validation loss 0.280721; Mean validation F1 0.780561; Learning rate 0.000143;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.780561; loss - 0.280721;\n",
      "===========================================================\n",
      "Epoch 063/096 - Mean training loss 0.290284; Mean training F1 0.766294; Mean validation loss 0.279739; Mean validation F1 0.784814; Learning rate 0.000136;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.784814; loss - 0.279739;\n",
      "===========================================================\n",
      "Epoch 064/096 - Mean training loss 0.293088; Mean training F1 0.768704; Mean validation loss 0.285422; Mean validation F1 0.769038; Learning rate 0.000129;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.769038; loss - 0.285422;\n",
      "===========================================================\n",
      "Epoch 065/096 - Mean training loss 0.291752; Mean training F1 0.768150; Mean validation loss 0.279517; Mean validation F1 0.777898; Learning rate 0.000122;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.777898; loss - 0.279517;\n",
      "===========================================================\n",
      "Epoch 066/096 - Mean training loss 0.286416; Mean training F1 0.771110; Mean validation loss 0.277620; Mean validation F1 0.782350; Learning rate 0.000115;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.782350; loss - 0.277620;\n",
      "===========================================================\n",
      "Epoch 067/096 - Mean training loss 0.290157; Mean training F1 0.772506; Mean validation loss 0.285278; Mean validation F1 0.781805; Learning rate 0.000109;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.781805; loss - 0.285278;\n",
      "===========================================================\n",
      "Epoch 068/096 - Mean training loss 0.288807; Mean training F1 0.771838; Mean validation loss 0.279261; Mean validation F1 0.785283; Learning rate 0.000102;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.785283; loss - 0.279261;\n",
      "===========================================================\n",
      "Epoch 069/096 - Mean training loss 0.289474; Mean training F1 0.779031; Mean validation loss 0.277843; Mean validation F1 0.780984; Learning rate 0.000096;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.780984; loss - 0.277843;\n",
      "===========================================================\n",
      "Epoch 070/096 - Mean training loss 0.288049; Mean training F1 0.777591; Mean validation loss 0.279161; Mean validation F1 0.781545; Learning rate 0.000090;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.781545; loss - 0.279161;\n",
      "===========================================================\n",
      "Epoch 071/096 - Mean training loss 0.287695; Mean training F1 0.775190; Mean validation loss 0.281029; Mean validation F1 0.786789; Learning rate 0.000084;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.786789; loss - 0.281029;\n",
      "===========================================================\n",
      "Epoch 072/096 - Mean training loss 0.287397; Mean training F1 0.771244; Mean validation loss 0.279774; Mean validation F1 0.781639; Learning rate 0.000078;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.781639; loss - 0.279774;\n",
      "===========================================================\n",
      "Epoch 073/096 - Mean training loss 0.287681; Mean training F1 0.772668; Mean validation loss 0.278293; Mean validation F1 0.782538; Learning rate 0.000072;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.782538; loss - 0.278293;\n",
      "===========================================================\n",
      "Epoch 074/096 - Mean training loss 0.286447; Mean training F1 0.781719; Mean validation loss 0.277828; Mean validation F1 0.785897; Learning rate 0.000067;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.785897; loss - 0.277828;\n",
      "===========================================================\n",
      "Epoch 075/096 - Mean training loss 0.286422; Mean training F1 0.777179; Mean validation loss 0.277610; Mean validation F1 0.779753; Learning rate 0.000061;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.779753; loss - 0.277610;\n",
      "===========================================================\n",
      "Epoch 076/096 - Mean training loss 0.287386; Mean training F1 0.777140; Mean validation loss 0.279332; Mean validation F1 0.782502; Learning rate 0.000056;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.782502; loss - 0.279332;\n",
      "===========================================================\n",
      "Epoch 077/096 - Mean training loss 0.286648; Mean training F1 0.777666; Mean validation loss 0.278223; Mean validation F1 0.786739; Learning rate 0.000052;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.786739; loss - 0.278223;\n",
      "===========================================================\n",
      "Epoch 078/096 - Mean training loss 0.284929; Mean training F1 0.779756; Mean validation loss 0.277533; Mean validation F1 0.786546; Learning rate 0.000047;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.786546; loss - 0.277533;\n",
      "===========================================================\n",
      "Epoch 079/096 - Mean training loss 0.285421; Mean training F1 0.776376; Mean validation loss 0.277344; Mean validation F1 0.785984; Learning rate 0.000043;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.785984; loss - 0.277344;\n",
      "===========================================================\n",
      "Epoch 080/096 - Mean training loss 0.286353; Mean training F1 0.777571; Mean validation loss 0.277890; Mean validation F1 0.785291; Learning rate 0.000038;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.785291; loss - 0.277890;\n",
      "===========================================================\n",
      "Epoch 081/096 - Mean training loss 0.284702; Mean training F1 0.784751; Mean validation loss 0.277743; Mean validation F1 0.782499; Learning rate 0.000034;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.782499; loss - 0.277743;\n",
      "===========================================================\n",
      "Epoch 082/096 - Mean training loss 0.284817; Mean training F1 0.781050; Mean validation loss 0.277682; Mean validation F1 0.783200; Learning rate 0.000031;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.783200; loss - 0.277682;\n",
      "===========================================================\n",
      "Epoch 083/096 - Mean training loss 0.284213; Mean training F1 0.780334; Mean validation loss 0.277142; Mean validation F1 0.779050; Learning rate 0.000027;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.779050; loss - 0.277142;\n",
      "===========================================================\n",
      "Epoch 084/096 - Mean training loss 0.284181; Mean training F1 0.781216; Mean validation loss 0.277266; Mean validation F1 0.782957; Learning rate 0.000024;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.782957; loss - 0.277266;\n",
      "===========================================================\n",
      "Epoch 085/096 - Mean training loss 0.284169; Mean training F1 0.780091; Mean validation loss 0.277318; Mean validation F1 0.786183; Learning rate 0.000021;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.786183; loss - 0.277318;\n",
      "===========================================================\n",
      "Epoch 086/096 - Mean training loss 0.285756; Mean training F1 0.777691; Mean validation loss 0.276937; Mean validation F1 0.786923; Learning rate 0.000018;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.786923; loss - 0.276937;\n",
      "===========================================================\n",
      "Epoch 087/096 - Mean training loss 0.284453; Mean training F1 0.781249; Mean validation loss 0.277031; Mean validation F1 0.781192; Learning rate 0.000016;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.781192; loss - 0.277031;\n",
      "===========================================================\n",
      "Epoch 088/096 - Mean training loss 0.285112; Mean training F1 0.779609; Mean validation loss 0.277280; Mean validation F1 0.783670; Learning rate 0.000014;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.783670; loss - 0.277280;\n",
      "===========================================================\n",
      "Epoch 089/096 - Mean training loss 0.284204; Mean training F1 0.784695; Mean validation loss 0.276917; Mean validation F1 0.783122; Learning rate 0.000012;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.783122; loss - 0.276917;\n",
      "===========================================================\n",
      "Epoch 090/096 - Mean training loss 0.284745; Mean training F1 0.783044; Mean validation loss 0.277083; Mean validation F1 0.783921; Learning rate 0.000010;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.783921; loss - 0.277083;\n",
      "===========================================================\n",
      "Epoch 091/096 - Mean training loss 0.285293; Mean training F1 0.778487; Mean validation loss 0.277154; Mean validation F1 0.787249; Learning rate 0.000008;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.787249; loss - 0.277154;\n",
      "===========================================================\n",
      "Epoch 092/096 - Mean training loss 0.284415; Mean training F1 0.783577; Mean validation loss 0.276875; Mean validation F1 0.782422; Learning rate 0.000007;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.782422; loss - 0.276875;\n",
      "===========================================================\n",
      "Epoch 093/096 - Mean training loss 0.283566; Mean training F1 0.786824; Mean validation loss 0.276944; Mean validation F1 0.784031; Learning rate 0.000006;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.784031; loss - 0.276944;\n",
      "===========================================================\n",
      "Epoch 094/096 - Mean training loss 0.284440; Mean training F1 0.785841; Mean validation loss 0.276994; Mean validation F1 0.783481; Learning rate 0.000006;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.783481; loss - 0.276994;\n",
      "===========================================================\n",
      "Epoch 095/096 - Mean training loss 0.284357; Mean training F1 0.781399; Mean validation loss 0.276888; Mean validation F1 0.782706; Learning rate 0.000005;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.782706; loss - 0.276888;\n",
      "===========================================================\n",
      "Epoch 096/096 - Mean training loss 0.284029; Mean training F1 0.781881; Mean validation loss 0.276841; Mean validation F1 0.783050; Learning rate 0.000005;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.783050; loss - 0.276841;\n",
      "################################################################\n",
      "Training/validation for fold 2/5;\n",
      "===========================================================\n",
      "Epoch 001/096 - Mean training loss 1.435402; Mean training F1 0.154393; Mean validation loss 1.019753; Mean validation F1 0.216332; Learning rate 0.000500;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.216332; loss - 1.019753;\n",
      "===========================================================\n",
      "Epoch 002/096 - Mean training loss 0.655581; Mean training F1 0.348880; Mean validation loss 0.703511; Mean validation F1 0.391515; Learning rate 0.000500;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.391515; loss - 0.703511;\n",
      "===========================================================\n",
      "Epoch 003/096 - Mean training loss 0.581240; Mean training F1 0.441499; Mean validation loss 0.493455; Mean validation F1 0.439970; Learning rate 0.000499;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.439970; loss - 0.493455;\n",
      "===========================================================\n",
      "Epoch 004/096 - Mean training loss 0.437712; Mean training F1 0.487343; Mean validation loss 0.459271; Mean validation F1 0.477608; Learning rate 0.000498;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.477608; loss - 0.459271;\n",
      "===========================================================\n",
      "Epoch 005/096 - Mean training loss 0.399371; Mean training F1 0.530935; Mean validation loss 0.363065; Mean validation F1 0.595980; Learning rate 0.000497;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.595980; loss - 0.363065;\n",
      "===========================================================\n",
      "Epoch 006/096 - Mean training loss 0.360589; Mean training F1 0.591247; Mean validation loss 0.322240; Mean validation F1 0.590175; Learning rate 0.000496;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.590175; loss - 0.322240;\n",
      "===========================================================\n",
      "Epoch 007/096 - Mean training loss 0.374360; Mean training F1 0.594010; Mean validation loss 0.480947; Mean validation F1 0.543576; Learning rate 0.000494;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.543576; loss - 0.480947;\n",
      "===========================================================\n",
      "Epoch 008/096 - Mean training loss 0.386504; Mean training F1 0.567861; Mean validation loss 0.321196; Mean validation F1 0.630793; Learning rate 0.000492;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.630793; loss - 0.321196;\n",
      "===========================================================\n",
      "Epoch 009/096 - Mean training loss 0.401038; Mean training F1 0.575827; Mean validation loss 0.421856; Mean validation F1 0.577652; Learning rate 0.000490;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.577652; loss - 0.421856;\n",
      "===========================================================\n",
      "Epoch 010/096 - Mean training loss 0.384353; Mean training F1 0.586247; Mean validation loss 0.407792; Mean validation F1 0.519527; Learning rate 0.000487;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.519527; loss - 0.407792;\n",
      "===========================================================\n",
      "Epoch 011/096 - Mean training loss 0.347774; Mean training F1 0.595880; Mean validation loss 0.322476; Mean validation F1 0.600343; Learning rate 0.000484;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.600343; loss - 0.322476;\n",
      "===========================================================\n",
      "Epoch 012/096 - Mean training loss 0.352230; Mean training F1 0.605659; Mean validation loss 0.430714; Mean validation F1 0.520793; Learning rate 0.000481;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.520793; loss - 0.430714;\n",
      "===========================================================\n",
      "Epoch 013/096 - Mean training loss 0.390820; Mean training F1 0.583213; Mean validation loss 0.335420; Mean validation F1 0.645653; Learning rate 0.000478;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.645653; loss - 0.335420;\n",
      "===========================================================\n",
      "Epoch 014/096 - Mean training loss 0.333129; Mean training F1 0.620729; Mean validation loss 0.299397; Mean validation F1 0.644099; Learning rate 0.000475;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.644099; loss - 0.299397;\n",
      "===========================================================\n",
      "Epoch 015/096 - Mean training loss 0.321261; Mean training F1 0.627971; Mean validation loss 0.289306; Mean validation F1 0.635754; Learning rate 0.000471;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.635754; loss - 0.289306;\n",
      "===========================================================\n",
      "Epoch 016/096 - Mean training loss 0.342803; Mean training F1 0.636511; Mean validation loss 0.336798; Mean validation F1 0.554153; Learning rate 0.000467;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.554153; loss - 0.336798;\n",
      "===========================================================\n",
      "Epoch 017/096 - Mean training loss 0.349681; Mean training F1 0.625121; Mean validation loss 0.298232; Mean validation F1 0.638309; Learning rate 0.000463;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.638309; loss - 0.298232;\n",
      "===========================================================\n",
      "Epoch 018/096 - Mean training loss 0.333498; Mean training F1 0.640580; Mean validation loss 0.312131; Mean validation F1 0.679948; Learning rate 0.000459;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.679948; loss - 0.312131;\n",
      "===========================================================\n",
      "Epoch 019/096 - Mean training loss 0.318438; Mean training F1 0.657504; Mean validation loss 0.290116; Mean validation F1 0.658858; Learning rate 0.000454;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.658858; loss - 0.290116;\n",
      "===========================================================\n",
      "Epoch 020/096 - Mean training loss 0.327165; Mean training F1 0.654463; Mean validation loss 0.290579; Mean validation F1 0.706345; Learning rate 0.000449;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.706345; loss - 0.290579;\n",
      "===========================================================\n",
      "Epoch 021/096 - Mean training loss 0.306358; Mean training F1 0.684583; Mean validation loss 0.291800; Mean validation F1 0.696080; Learning rate 0.000444;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.696080; loss - 0.291800;\n",
      "===========================================================\n",
      "Epoch 022/096 - Mean training loss 0.329424; Mean training F1 0.676858; Mean validation loss 0.310656; Mean validation F1 0.597664; Learning rate 0.000439;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.597664; loss - 0.310656;\n",
      "===========================================================\n",
      "Epoch 023/096 - Mean training loss 0.336732; Mean training F1 0.662468; Mean validation loss 0.321004; Mean validation F1 0.614454; Learning rate 0.000433;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.614454; loss - 0.321004;\n",
      "===========================================================\n",
      "Epoch 024/096 - Mean training loss 0.323088; Mean training F1 0.667316; Mean validation loss 0.385306; Mean validation F1 0.678287; Learning rate 0.000428;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.678287; loss - 0.385306;\n",
      "===========================================================\n",
      "Epoch 025/096 - Mean training loss 0.324240; Mean training F1 0.672389; Mean validation loss 0.305427; Mean validation F1 0.626440; Learning rate 0.000422;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.626440; loss - 0.305427;\n",
      "===========================================================\n",
      "Epoch 026/096 - Mean training loss 0.310488; Mean training F1 0.674548; Mean validation loss 0.288464; Mean validation F1 0.712823; Learning rate 0.000416;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.712823; loss - 0.288464;\n",
      "===========================================================\n",
      "Epoch 027/096 - Mean training loss 0.307072; Mean training F1 0.691118; Mean validation loss 0.300660; Mean validation F1 0.709772; Learning rate 0.000410;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.709772; loss - 0.300660;\n",
      "===========================================================\n",
      "Epoch 028/096 - Mean training loss 0.321470; Mean training F1 0.687479; Mean validation loss 0.295860; Mean validation F1 0.675572; Learning rate 0.000403;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.675572; loss - 0.295860;\n",
      "===========================================================\n",
      "Epoch 029/096 - Mean training loss 0.318629; Mean training F1 0.667156; Mean validation loss 0.310555; Mean validation F1 0.685994; Learning rate 0.000397;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.685994; loss - 0.310555;\n",
      "===========================================================\n",
      "Epoch 030/096 - Mean training loss 0.313919; Mean training F1 0.680078; Mean validation loss 0.300483; Mean validation F1 0.698618; Learning rate 0.000390;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.698618; loss - 0.300483;\n",
      "===========================================================\n",
      "Epoch 031/096 - Mean training loss 0.348354; Mean training F1 0.644180; Mean validation loss 0.303306; Mean validation F1 0.700865; Learning rate 0.000383;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.700865; loss - 0.303306;\n",
      "===========================================================\n",
      "Epoch 032/096 - Mean training loss 0.303415; Mean training F1 0.687702; Mean validation loss 0.286516; Mean validation F1 0.713652; Learning rate 0.000377;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.713652; loss - 0.286516;\n",
      "===========================================================\n",
      "Epoch 033/096 - Mean training loss 0.306176; Mean training F1 0.693751; Mean validation loss 0.289376; Mean validation F1 0.675777; Learning rate 0.000369;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.675777; loss - 0.289376;\n",
      "===========================================================\n",
      "Epoch 034/096 - Mean training loss 0.317233; Mean training F1 0.684259; Mean validation loss 0.291708; Mean validation F1 0.694406; Learning rate 0.000362;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.694406; loss - 0.291708;\n",
      "===========================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5d76e913c0a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mfold_number\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfld\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./saved_models/wavenet_model_basicwithnew3_BN_groupstudy_fold{:03d}_checkpoint.pth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     )\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m#break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ac029ec0108c>\u001b[0m in \u001b[0;36mfold_train_validate\u001b[0;34m(model, optimizer, criterion, scheduler, training_loader, validation_loaders, fold_number, save_path, early_stopping)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mtrn_batch_prd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_batch_dat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mtrn_batch_prd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrn_batch_prd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_batch_prd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mtrn_batch_lbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrn_batch_lbl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/kaggle/ion_switching/code/NNs.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# [batch, feature, sequence] => [sequence, batch, feature]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRSFM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;31m# [sequence, batch, feature] => [batch, sequence, feature]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             output = self.layers[i](output, src_mask=mask,\n\u001b[0;32m--> 176\u001b[0;31m                                     src_key_padding_mask=src_key_padding_mask)\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \"\"\"\n\u001b[1;32m    282\u001b[0m         src2 = self.self_attn(src, src, src, attn_mask=src_mask,\n\u001b[0;32m--> 283\u001b[0;31m                               key_padding_mask=src_key_padding_mask)[0]\n\u001b[0m\u001b[1;32m    284\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML/lib/python3.7/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[1;32m    817\u001b[0m                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                 \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneed_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 attn_mask=attn_mask)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[1;32m   3218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3219\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muse_separate_proj_weight\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3220\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3221\u001b[0m             \u001b[0;31m# self-attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3222\u001b[0m             \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for fld, (ndcs_trn, ndcs_vld) in enumerate(skf.split(series_dat_all, skf_trgt)):\n",
    "    print('################################################################')\n",
    "    print('Training/validation for fold {:d}/{:d};'.format(fld+1, N_FOLDS))\n",
    "    \n",
    "    # setup fold data\n",
    "    dat_trn, lbl_trn = series_dat_all[ndcs_trn], series_lbl_all[ndcs_trn]\n",
    "    dat_vld, lbl_vld = series_dat_all[ndcs_vld], series_lbl_all[ndcs_vld]\n",
    "    \n",
    "    waveset_trn = Waveset(dat_trn, lbl_trn)\n",
    "    waveset_vld = Waveset(dat_vld, lbl_vld)\n",
    "\n",
    "    loader_trn = DataLoader(waveset_trn, BATCHSIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    loader_vld = DataLoader(waveset_vld, BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    \n",
    "    unit = 500\n",
    "    vld_loaders = {\n",
    "        'vld': loader_vld,\n",
    "        #'g0': DataLoader(Waveset(series_dat_all[0*unit:1*unit], series_lbl_all[0*unit:1*unit]), BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True),\n",
    "        #'g1': DataLoader(Waveset(series_dat_all[1*unit:2*unit], series_lbl_all[1*unit:2*unit]), BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True),\n",
    "        #'g2': DataLoader(Waveset(series_dat_all[2*unit:3*unit], series_lbl_all[2*unit:3*unit]), BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True),\n",
    "        #'g3': DataLoader(Waveset(series_dat_all[3*unit:4*unit], series_lbl_all[3*unit:4*unit]), BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True),\n",
    "        #'g4': DataLoader(Waveset(series_dat_all[4*unit:5*unit], series_lbl_all[4*unit:5*unit]), BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True),\n",
    "        #'g5': DataLoader(Waveset(series_dat_all[5*unit:6*unit], series_lbl_all[5*unit:6*unit]), BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True),\n",
    "        #'g6': DataLoader(Waveset(series_dat_all[6*unit:7*unit], series_lbl_all[6*unit:7*unit]), BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True),\n",
    "        #'g7': DataLoader(Waveset(series_dat_all[7*unit:8*unit], series_lbl_all[7*unit:8*unit]), BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True),\n",
    "        #'g8': DataLoader(Waveset(series_dat_all[8*unit:9*unit], series_lbl_all[8*unit:9*unit]), BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True),\n",
    "        #'g9': DataLoader(Waveset(series_dat_all[9*unit:10*unit], series_lbl_all[9*unit:10*unit]), BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True),\n",
    "    }\n",
    "    \n",
    "    # setup fold model\n",
    "    mdl = WaveTRSFM_Classifier(series_dat_all.shape[-1]).to(DEVICE)\n",
    "    critrn = nn.CrossEntropyLoss()\n",
    "    optimzr = torch.optim.AdamW(mdl.parameters(), lr=LR)\n",
    "    schdlr = torch.optim.lr_scheduler.CosineAnnealingLR(optimzr, T_max=EPOCHS, eta_min=LR/100)\n",
    "    \n",
    "    # run\n",
    "    fold_train_validate(\n",
    "        model=mdl, optimizer=optimzr, criterion=critrn,\n",
    "        scheduler=schdlr, training_loader=loader_trn, validation_loaders=vld_loaders,\n",
    "        fold_number=fld,\n",
    "        save_path='./saved_models/wavenet_model_basicwithnew3_BN_groupstudy_fold{:03d}_checkpoint.pth',\n",
    "        early_stopping=25\n",
    "    )\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv', dtype={'time': str, 'open_channels': 'Int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_pred = np.zeros(shape=(submission.shape[0], 11))\n",
    "\n",
    "# waveset_tst = Waveset(series_tst)\n",
    "# loader_tst = DataLoader(waveset_tst, BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "for fld in range(5):\n",
    "    print('-------- fold {:d} --------'.format(fld))\n",
    "    fld_weight = torch.load('./saved_models/waveTRSFM_model_basicwithnew2_fold{:03d}_checkpoint.pth'.format(fld))\n",
    "    print('model validation loss: {:.3f}; validation f1: {:.3f};'.format(fld_weight['loss'], fld_weight['f1']))\n",
    "#     mdl = WaveTRSFM_Classifier(series_trn.shape[-1]).to(DEVICE)\n",
    "#     mdl.load_state_dict(fld_weight['model'])\n",
    "#     mdl.eval()\n",
    "#     with torch.no_grad():\n",
    "#         tst_fold_prd = []\n",
    "#         for tst_batch_dat in loader_tst:\n",
    "#             tst_batch_prd = mdl(tst_batch_dat.to(DEVICE))\n",
    "#             tst_batch_prd = tst_batch_prd.view(-1, tst_batch_prd.size(-1)).detach().cpu().numpy()\n",
    "#             tst_fold_prd.append(tst_batch_prd)\n",
    "            \n",
    "#         submission_pred += np.concatenate(tst_fold_prd, 0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "submission['open_channels'] = submission_pred.argmax(1)\n",
    "submission.to_csv(\"../submissions/sub0_waveTRSFM_basicwithnew2_cvbyentropy_meanstdnorm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train all full data, lr 0.0005"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-------- fold 0 --------\n",
    "model validation loss: 0.095; validation f1: 0.939;\n",
    "-------- fold 1 --------\n",
    "model validation loss: 0.062; validation f1: 0.937;\n",
    "-------- fold 2 --------\n",
    "model validation loss: 0.095; validation f1: 0.937;\n",
    "-------- fold 3 --------\n",
    "model validation loss: 0.061; validation f1: 0.939;\n",
    "-------- fold 4 --------\n",
    "model validation loss: 0.061; validation f1: 0.939;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "################################################################\n",
    "Training/validation for fold 1/5;\n",
    "===========================================================\n",
    "Epoch 001/096 - Mean training loss 0.830562; Mean training F1 0.606319; Mean validation loss 0.462108; Mean validation F1 0.781263; Learning rate 0.000500;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.781263; loss - 0.462108;\n",
    "Group g4: f1 - 0.344227; loss - 1.057367;\n",
    "Group g9: f1 - 0.342235; loss - 1.081927;\n",
    "===========================================================\n",
    "Epoch 002/096 - Mean training loss 0.350422; Mean training F1 0.833843; Mean validation loss 0.212503; Mean validation F1 0.900474; Learning rate 0.000500;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.900474; loss - 0.212503;\n",
    "Group g4: f1 - 0.445994; loss - 0.612860;\n",
    "Group g9: f1 - 0.442408; loss - 0.639302;\n",
    "===========================================================\n",
    "Epoch 003/096 - Mean training loss 0.202482; Mean training F1 0.897108; Mean validation loss 0.148787; Mean validation F1 0.918353; Learning rate 0.000499;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.918353; loss - 0.148787;\n",
    "Group g4: f1 - 0.519896; loss - 0.451263;\n",
    "Group g9: f1 - 0.514248; loss - 0.472359;\n",
    "===========================================================\n",
    "Epoch 004/096 - Mean training loss 0.169083; Mean training F1 0.905481; Mean validation loss 0.150327; Mean validation F1 0.918189; Learning rate 0.000498;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.918189; loss - 0.150327;\n",
    "Group g4: f1 - 0.575655; loss - 0.359367;\n",
    "Group g9: f1 - 0.575915; loss - 0.363197;\n",
    "===========================================================\n",
    "Epoch 005/096 - Mean training loss 0.166904; Mean training F1 0.905946; Mean validation loss 0.161927; Mean validation F1 0.904244; Learning rate 0.000497;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.904244; loss - 0.161927;\n",
    "Group g4: f1 - 0.600310; loss - 0.328800;\n",
    "Group g9: f1 - 0.598651; loss - 0.331456;\n",
    "===========================================================\n",
    "Epoch 006/096 - Mean training loss 0.147829; Mean training F1 0.913963; Mean validation loss 0.128067; Mean validation F1 0.923470; Learning rate 0.000496;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.923470; loss - 0.128067;\n",
    "Group g4: f1 - 0.569160; loss - 0.390062;\n",
    "Group g9: f1 - 0.560858; loss - 0.413006;\n",
    "===========================================================\n",
    "Epoch 007/096 - Mean training loss 0.138881; Mean training F1 0.915441; Mean validation loss 0.850137; Mean validation F1 0.696577; Learning rate 0.000494;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.696577; loss - 0.850137;\n",
    "Group g4: f1 - 0.638195; loss - 0.335757;\n",
    "Group g9: f1 - 0.634826; loss - 0.337943;\n",
    "===========================================================\n",
    "Epoch 008/096 - Mean training loss 0.129698; Mean training F1 0.918908; Mean validation loss 0.109220; Mean validation F1 0.930193; Learning rate 0.000492;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.930193; loss - 0.109220;\n",
    "Group g4: f1 - 0.641093; loss - 0.304612;\n",
    "Group g9: f1 - 0.636097; loss - 0.307770;\n",
    "===========================================================\n",
    "Epoch 009/096 - Mean training loss 0.114419; Mean training F1 0.925138; Mean validation loss 0.102281; Mean validation F1 0.933137; Learning rate 0.000490;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933137; loss - 0.102281;\n",
    "Group g4: f1 - 0.675238; loss - 0.304954;\n",
    "Group g9: f1 - 0.668482; loss - 0.307276;\n",
    "===========================================================\n",
    "Epoch 010/096 - Mean training loss 0.115284; Mean training F1 0.925267; Mean validation loss 0.101006; Mean validation F1 0.934222; Learning rate 0.000487;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934222; loss - 0.101006;\n",
    "Group g4: f1 - 0.681036; loss - 0.298594;\n",
    "Group g9: f1 - 0.674487; loss - 0.301250;\n",
    "===========================================================\n",
    "Epoch 011/096 - Mean training loss 0.109573; Mean training F1 0.926961; Mean validation loss 0.100741; Mean validation F1 0.933885; Learning rate 0.000484;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933885; loss - 0.100741;\n",
    "Group g4: f1 - 0.688030; loss - 0.299403;\n",
    "Group g9: f1 - 0.680201; loss - 0.302364;\n",
    "===========================================================\n",
    "Epoch 012/096 - Mean training loss 0.104599; Mean training F1 0.930421; Mean validation loss 0.097662; Mean validation F1 0.935180; Learning rate 0.000481;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935180; loss - 0.097662;\n",
    "Group g4: f1 - 0.690829; loss - 0.295147;\n",
    "Group g9: f1 - 0.682851; loss - 0.298043;\n",
    "===========================================================\n",
    "Epoch 013/096 - Mean training loss 0.103047; Mean training F1 0.929793; Mean validation loss 0.102800; Mean validation F1 0.933838; Learning rate 0.000478;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933838; loss - 0.102800;\n",
    "Group g4: f1 - 0.687861; loss - 0.300709;\n",
    "Group g9: f1 - 0.677496; loss - 0.303616;\n",
    "===========================================================\n",
    "Epoch 014/096 - Mean training loss 0.104952; Mean training F1 0.929573; Mean validation loss 0.099761; Mean validation F1 0.933968; Learning rate 0.000475;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933968; loss - 0.099761;\n",
    "Group g4: f1 - 0.698181; loss - 0.301800;\n",
    "Group g9: f1 - 0.690878; loss - 0.304824;\n",
    "===========================================================\n",
    "Epoch 015/096 - Mean training loss 0.100720; Mean training F1 0.930767; Mean validation loss 0.097231; Mean validation F1 0.935804; Learning rate 0.000471;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935804; loss - 0.097231;\n",
    "Group g4: f1 - 0.705458; loss - 0.287784;\n",
    "Group g9: f1 - 0.694843; loss - 0.290714;\n",
    "===========================================================\n",
    "Epoch 016/096 - Mean training loss 0.101923; Mean training F1 0.930661; Mean validation loss 0.096926; Mean validation F1 0.936068; Learning rate 0.000467;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936068; loss - 0.096926;\n",
    "Group g4: f1 - 0.706983; loss - 0.285948;\n",
    "Group g9: f1 - 0.702938; loss - 0.288483;\n",
    "===========================================================\n",
    "Epoch 017/096 - Mean training loss 0.102572; Mean training F1 0.929821; Mean validation loss 0.095443; Mean validation F1 0.935946; Learning rate 0.000463;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935946; loss - 0.095443;\n",
    "Group g4: f1 - 0.718414; loss - 0.286405;\n",
    "Group g9: f1 - 0.702182; loss - 0.288853;\n",
    "===========================================================\n",
    "Epoch 018/096 - Mean training loss 0.101511; Mean training F1 0.930346; Mean validation loss 0.106998; Mean validation F1 0.931290; Learning rate 0.000459;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931290; loss - 0.106998;\n",
    "Group g4: f1 - 0.712480; loss - 0.289621;\n",
    "Group g9: f1 - 0.699610; loss - 0.292354;\n",
    "===========================================================\n",
    "Epoch 019/096 - Mean training loss 0.101479; Mean training F1 0.930414; Mean validation loss 0.104684; Mean validation F1 0.933501; Learning rate 0.000454;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933501; loss - 0.104684;\n",
    "Group g4: f1 - 0.708233; loss - 0.289263;\n",
    "Group g9: f1 - 0.702975; loss - 0.291914;\n",
    "===========================================================\n",
    "Epoch 020/096 - Mean training loss 0.095944; Mean training F1 0.933072; Mean validation loss 0.094448; Mean validation F1 0.936287; Learning rate 0.000449;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936287; loss - 0.094448;\n",
    "Group g4: f1 - 0.713276; loss - 0.286869;\n",
    "Group g9: f1 - 0.703445; loss - 0.289743;\n",
    "===========================================================\n",
    "Epoch 021/096 - Mean training loss 0.093186; Mean training F1 0.933692; Mean validation loss 0.097383; Mean validation F1 0.934946; Learning rate 0.000444;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934946; loss - 0.097383;\n",
    "Group g4: f1 - 0.729155; loss - 0.297345;\n",
    "Group g9: f1 - 0.718263; loss - 0.298961;\n",
    "===========================================================\n",
    "Epoch 022/096 - Mean training loss 0.094396; Mean training F1 0.932745; Mean validation loss 0.095980; Mean validation F1 0.934382; Learning rate 0.000439;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934382; loss - 0.095980;\n",
    "Group g4: f1 - 0.717237; loss - 0.298149;\n",
    "Group g9: f1 - 0.708094; loss - 0.301315;\n",
    "===========================================================\n",
    "Epoch 023/096 - Mean training loss 0.095295; Mean training F1 0.932077; Mean validation loss 0.106946; Mean validation F1 0.930624; Learning rate 0.000433;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.930624; loss - 0.106946;\n",
    "Group g4: f1 - 0.714962; loss - 0.300788;\n",
    "Group g9: f1 - 0.702665; loss - 0.303870;\n",
    "===========================================================\n",
    "Epoch 024/096 - Mean training loss 0.093724; Mean training F1 0.933591; Mean validation loss 0.093695; Mean validation F1 0.936225; Learning rate 0.000428;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936225; loss - 0.093695;\n",
    "Group g4: f1 - 0.729764; loss - 0.283905;\n",
    "Group g9: f1 - 0.729722; loss - 0.286707;\n",
    "===========================================================\n",
    "Epoch 025/096 - Mean training loss 0.092636; Mean training F1 0.934347; Mean validation loss 0.093654; Mean validation F1 0.936765; Learning rate 0.000422;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936765; loss - 0.093654;\n",
    "Group g4: f1 - 0.720047; loss - 0.284046;\n",
    "Group g9: f1 - 0.710709; loss - 0.286383;\n",
    "===========================================================\n",
    "Epoch 026/096 - Mean training loss 0.090670; Mean training F1 0.934868; Mean validation loss 0.092079; Mean validation F1 0.937469; Learning rate 0.000416;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937469; loss - 0.092079;\n",
    "Group g4: f1 - 0.725020; loss - 0.283272;\n",
    "Group g9: f1 - 0.721288; loss - 0.285652;\n",
    "===========================================================\n",
    "Epoch 027/096 - Mean training loss 0.090516; Mean training F1 0.934966; Mean validation loss 0.093402; Mean validation F1 0.936705; Learning rate 0.000410;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936705; loss - 0.093402;\n",
    "Group g4: f1 - 0.744916; loss - 0.283197;\n",
    "Group g9: f1 - 0.738250; loss - 0.285814;\n",
    "===========================================================\n",
    "Epoch 028/096 - Mean training loss 0.089673; Mean training F1 0.935282; Mean validation loss 0.092780; Mean validation F1 0.937192; Learning rate 0.000403;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937192; loss - 0.092780;\n",
    "Group g4: f1 - 0.736283; loss - 0.282683;\n",
    "Group g9: f1 - 0.721760; loss - 0.285036;\n",
    "===========================================================\n",
    "Epoch 029/096 - Mean training loss 0.091163; Mean training F1 0.934763; Mean validation loss 0.091549; Mean validation F1 0.937119; Learning rate 0.000397;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937119; loss - 0.091549;\n",
    "Group g4: f1 - 0.723932; loss - 0.283547;\n",
    "Group g9: f1 - 0.718801; loss - 0.285963;\n",
    "===========================================================\n",
    "Epoch 030/096 - Mean training loss 0.089873; Mean training F1 0.935332; Mean validation loss 0.093051; Mean validation F1 0.936570; Learning rate 0.000390;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936570; loss - 0.093051;\n",
    "Group g4: f1 - 0.717221; loss - 0.286743;\n",
    "Group g9: f1 - 0.714246; loss - 0.289664;\n",
    "===========================================================\n",
    "Epoch 031/096 - Mean training loss 0.089762; Mean training F1 0.935210; Mean validation loss 0.093289; Mean validation F1 0.936367; Learning rate 0.000383;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936367; loss - 0.093289;\n",
    "Group g4: f1 - 0.710087; loss - 0.282891;\n",
    "Group g9: f1 - 0.706888; loss - 0.285561;\n",
    "===========================================================\n",
    "Epoch 032/096 - Mean training loss 0.088390; Mean training F1 0.935985; Mean validation loss 0.094867; Mean validation F1 0.936039; Learning rate 0.000377;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936039; loss - 0.094867;\n",
    "Group g4: f1 - 0.730986; loss - 0.290018;\n",
    "Group g9: f1 - 0.723610; loss - 0.292022;\n",
    "===========================================================\n",
    "Epoch 033/096 - Mean training loss 0.088553; Mean training F1 0.935327; Mean validation loss 0.090830; Mean validation F1 0.937862; Learning rate 0.000369;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937862; loss - 0.090830;\n",
    "Group g4: f1 - 0.751252; loss - 0.281181;\n",
    "Group g9: f1 - 0.730355; loss - 0.283593;\n",
    "===========================================================\n",
    "Epoch 034/096 - Mean training loss 0.088544; Mean training F1 0.935325; Mean validation loss 0.094175; Mean validation F1 0.936309; Learning rate 0.000362;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936309; loss - 0.094175;\n",
    "Group g4: f1 - 0.745929; loss - 0.286986;\n",
    "Group g9: f1 - 0.727857; loss - 0.288743;\n",
    "===========================================================\n",
    "Epoch 035/096 - Mean training loss 0.088501; Mean training F1 0.935838; Mean validation loss 0.090686; Mean validation F1 0.937677; Learning rate 0.000355;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937677; loss - 0.090686;\n",
    "Group g4: f1 - 0.767259; loss - 0.280776;\n",
    "Group g9: f1 - 0.762277; loss - 0.283472;\n",
    "===========================================================\n",
    "Epoch 036/096 - Mean training loss 0.088418; Mean training F1 0.935470; Mean validation loss 0.092804; Mean validation F1 0.936711; Learning rate 0.000347;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936711; loss - 0.092804;\n",
    "Group g4: f1 - 0.750576; loss - 0.281886;\n",
    "Group g9: f1 - 0.741085; loss - 0.284496;\n",
    "===========================================================\n",
    "Epoch 037/096 - Mean training loss 0.087578; Mean training F1 0.935756; Mean validation loss 0.093343; Mean validation F1 0.936696; Learning rate 0.000340;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936696; loss - 0.093343;\n",
    "Group g4: f1 - 0.751518; loss - 0.286728;\n",
    "Group g9: f1 - 0.741554; loss - 0.288527;\n",
    "===========================================================\n",
    "Epoch 038/096 - Mean training loss 0.087474; Mean training F1 0.936095; Mean validation loss 0.094886; Mean validation F1 0.936015; Learning rate 0.000332;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936015; loss - 0.094886;\n",
    "Group g4: f1 - 0.765720; loss - 0.287382;\n",
    "Group g9: f1 - 0.759299; loss - 0.289141;\n",
    "===========================================================\n",
    "Epoch 039/096 - Mean training loss 0.087558; Mean training F1 0.935826; Mean validation loss 0.096199; Mean validation F1 0.935413; Learning rate 0.000325;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935413; loss - 0.096199;\n",
    "Group g4: f1 - 0.712841; loss - 0.284103;\n",
    "Group g9: f1 - 0.712250; loss - 0.286431;\n",
    "===========================================================\n",
    "Epoch 040/096 - Mean training loss 0.086798; Mean training F1 0.936336; Mean validation loss 0.091205; Mean validation F1 0.936423; Learning rate 0.000317;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936423; loss - 0.091205;\n",
    "Group g4: f1 - 0.759494; loss - 0.282940;\n",
    "Group g9: f1 - 0.737078; loss - 0.285513;\n",
    "===========================================================\n",
    "Epoch 041/096 - Mean training loss 0.086605; Mean training F1 0.936010; Mean validation loss 0.092449; Mean validation F1 0.937003; Learning rate 0.000309;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937003; loss - 0.092449;\n",
    "Group g4: f1 - 0.736473; loss - 0.281919;\n",
    "Group g9: f1 - 0.728548; loss - 0.283959;\n",
    "===========================================================\n",
    "Epoch 042/096 - Mean training loss 0.085956; Mean training F1 0.936731; Mean validation loss 0.091078; Mean validation F1 0.935898; Learning rate 0.000301;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935898; loss - 0.091078;\n",
    "Group g4: f1 - 0.750062; loss - 0.283207;\n",
    "Group g9: f1 - 0.742055; loss - 0.285888;\n",
    "===========================================================\n",
    "Epoch 043/096 - Mean training loss 0.085532; Mean training F1 0.936685; Mean validation loss 0.091927; Mean validation F1 0.937064; Learning rate 0.000293;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937064; loss - 0.091927;\n",
    "Group g4: f1 - 0.749058; loss - 0.281945;\n",
    "Group g9: f1 - 0.732909; loss - 0.284692;\n",
    "===========================================================\n",
    "Epoch 044/096 - Mean training loss 0.086148; Mean training F1 0.936541; Mean validation loss 0.091093; Mean validation F1 0.937663; Learning rate 0.000285;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937663; loss - 0.091093;\n",
    "Group g4: f1 - 0.762838; loss - 0.279508;\n",
    "Group g9: f1 - 0.750297; loss - 0.281983;\n",
    "===========================================================\n",
    "Epoch 045/096 - Mean training loss 0.087166; Mean training F1 0.935890; Mean validation loss 0.091357; Mean validation F1 0.937007; Learning rate 0.000277;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937007; loss - 0.091357;\n",
    "Group g4: f1 - 0.761117; loss - 0.283112;\n",
    "Group g9: f1 - 0.740573; loss - 0.285956;\n",
    "===========================================================\n",
    "Epoch 046/096 - Mean training loss 0.086740; Mean training F1 0.936320; Mean validation loss 0.090687; Mean validation F1 0.937790; Learning rate 0.000269;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937790; loss - 0.090687;\n",
    "Group g4: f1 - 0.768957; loss - 0.279771;\n",
    "Group g9: f1 - 0.764601; loss - 0.282129;\n",
    "===========================================================\n",
    "Epoch 047/096 - Mean training loss 0.085352; Mean training F1 0.936748; Mean validation loss 0.089849; Mean validation F1 0.938119; Learning rate 0.000261;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938119; loss - 0.089849;\n",
    "Group g4: f1 - 0.761174; loss - 0.280769;\n",
    "Group g9: f1 - 0.741777; loss - 0.282871;\n",
    "===========================================================\n",
    "Epoch 048/096 - Mean training loss 0.084731; Mean training F1 0.937003; Mean validation loss 0.090420; Mean validation F1 0.936740; Learning rate 0.000253;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936740; loss - 0.090420;\n",
    "Group g4: f1 - 0.775092; loss - 0.284480;\n",
    "Group g9: f1 - 0.760656; loss - 0.286448;\n",
    "===========================================================\n",
    "Epoch 049/096 - Mean training loss 0.084798; Mean training F1 0.936932; Mean validation loss 0.090152; Mean validation F1 0.936816; Learning rate 0.000245;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936816; loss - 0.090152;\n",
    "Group g4: f1 - 0.777838; loss - 0.281004;\n",
    "Group g9: f1 - 0.767441; loss - 0.283182;\n",
    "===========================================================\n",
    "Epoch 050/096 - Mean training loss 0.084762; Mean training F1 0.936986; Mean validation loss 0.091356; Mean validation F1 0.936931; Learning rate 0.000237;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936931; loss - 0.091356;\n",
    "Group g4: f1 - 0.775414; loss - 0.283988;\n",
    "Group g9: f1 - 0.767525; loss - 0.286456;\n",
    "===========================================================\n",
    "Epoch 051/096 - Mean training loss 0.084497; Mean training F1 0.937107; Mean validation loss 0.091262; Mean validation F1 0.937295; Learning rate 0.000228;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937295; loss - 0.091262;\n",
    "Group g4: f1 - 0.765131; loss - 0.279470;\n",
    "Group g9: f1 - 0.746798; loss - 0.281879;\n",
    "===========================================================\n",
    "Epoch 052/096 - Mean training loss 0.084184; Mean training F1 0.937118; Mean validation loss 0.089597; Mean validation F1 0.938322; Learning rate 0.000220;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938322; loss - 0.089597;\n",
    "Group g4: f1 - 0.781838; loss - 0.279418;\n",
    "Group g9: f1 - 0.775545; loss - 0.281456;\n",
    "===========================================================\n",
    "Epoch 053/096 - Mean training loss 0.084468; Mean training F1 0.937221; Mean validation loss 0.089195; Mean validation F1 0.937938; Learning rate 0.000212;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937938; loss - 0.089195;\n",
    "Group g4: f1 - 0.770300; loss - 0.279183;\n",
    "Group g9: f1 - 0.763088; loss - 0.281303;\n",
    "===========================================================\n",
    "Epoch 054/096 - Mean training loss 0.084449; Mean training F1 0.937260; Mean validation loss 0.089323; Mean validation F1 0.937838; Learning rate 0.000204;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937838; loss - 0.089323;\n",
    "Group g4: f1 - 0.790064; loss - 0.280279;\n",
    "Group g9: f1 - 0.782984; loss - 0.282487;\n",
    "===========================================================\n",
    "Epoch 055/096 - Mean training loss 0.084639; Mean training F1 0.937180; Mean validation loss 0.090443; Mean validation F1 0.937665; Learning rate 0.000197;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937665; loss - 0.090443;\n",
    "Group g4: f1 - 0.769236; loss - 0.282219;\n",
    "Group g9: f1 - 0.759062; loss - 0.283993;\n",
    "===========================================================\n",
    "Epoch 056/096 - Mean training loss 0.084193; Mean training F1 0.937216; Mean validation loss 0.090132; Mean validation F1 0.938086; Learning rate 0.000189;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938086; loss - 0.090132;\n",
    "Group g4: f1 - 0.772997; loss - 0.281123;\n",
    "Group g9: f1 - 0.764634; loss - 0.283009;\n",
    "===========================================================\n",
    "Epoch 057/096 - Mean training loss 0.083626; Mean training F1 0.937555; Mean validation loss 0.089340; Mean validation F1 0.938236; Learning rate 0.000181;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938236; loss - 0.089340;\n",
    "Group g4: f1 - 0.784354; loss - 0.279698;\n",
    "Group g9: f1 - 0.781167; loss - 0.281563;\n",
    "===========================================================\n",
    "Epoch 058/096 - Mean training loss 0.083778; Mean training F1 0.937454; Mean validation loss 0.089767; Mean validation F1 0.938268; Learning rate 0.000173;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938268; loss - 0.089767;\n",
    "Group g4: f1 - 0.778654; loss - 0.279375;\n",
    "Group g9: f1 - 0.771856; loss - 0.281588;\n",
    "===========================================================\n",
    "Epoch 059/096 - Mean training loss 0.084023; Mean training F1 0.937368; Mean validation loss 0.089747; Mean validation F1 0.938280; Learning rate 0.000166;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938280; loss - 0.089747;\n",
    "Group g4: f1 - 0.778631; loss - 0.279544;\n",
    "Group g9: f1 - 0.774148; loss - 0.281595;\n",
    "===========================================================\n",
    "Epoch 060/096 - Mean training loss 0.083379; Mean training F1 0.937762; Mean validation loss 0.088726; Mean validation F1 0.938429; Learning rate 0.000158;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938429; loss - 0.088726;\n",
    "Group g4: f1 - 0.775500; loss - 0.279151;\n",
    "Group g9: f1 - 0.770927; loss - 0.281136;\n",
    "===========================================================\n",
    "Epoch 061/096 - Mean training loss 0.083209; Mean training F1 0.937746; Mean validation loss 0.091675; Mean validation F1 0.937232; Learning rate 0.000151;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937232; loss - 0.091675;\n",
    "Group g4: f1 - 0.776713; loss - 0.280880;\n",
    "Group g9: f1 - 0.772515; loss - 0.282874;\n",
    "===========================================================\n",
    "Epoch 062/096 - Mean training loss 0.083338; Mean training F1 0.937471; Mean validation loss 0.089019; Mean validation F1 0.938107; Learning rate 0.000143;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938107; loss - 0.089019;\n",
    "Group g4: f1 - 0.780361; loss - 0.278260;\n",
    "Group g9: f1 - 0.771636; loss - 0.280260;\n",
    "===========================================================\n",
    "Epoch 063/096 - Mean training loss 0.082970; Mean training F1 0.937806; Mean validation loss 0.089175; Mean validation F1 0.938276; Learning rate 0.000136;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938276; loss - 0.089175;\n",
    "Group g4: f1 - 0.769125; loss - 0.278780;\n",
    "Group g9: f1 - 0.748522; loss - 0.280803;\n",
    "===========================================================\n",
    "Epoch 064/096 - Mean training loss 0.083396; Mean training F1 0.937618; Mean validation loss 0.091122; Mean validation F1 0.936798; Learning rate 0.000129;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936798; loss - 0.091122;\n",
    "Group g4: f1 - 0.784790; loss - 0.283730;\n",
    "Group g9: f1 - 0.780894; loss - 0.286107;\n",
    "===========================================================\n",
    "Epoch 065/096 - Mean training loss 0.083661; Mean training F1 0.937653; Mean validation loss 0.088446; Mean validation F1 0.938526; Learning rate 0.000122;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938526; loss - 0.088446;\n",
    "Group g4: f1 - 0.774029; loss - 0.278186;\n",
    "Group g9: f1 - 0.759716; loss - 0.280015;\n",
    "===========================================================\n",
    "Epoch 066/096 - Mean training loss 0.083037; Mean training F1 0.937810; Mean validation loss 0.088144; Mean validation F1 0.938566; Learning rate 0.000115;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938566; loss - 0.088144;\n",
    "Group g4: f1 - 0.780458; loss - 0.278262;\n",
    "Group g9: f1 - 0.777077; loss - 0.279978;\n",
    "===========================================================\n",
    "Epoch 067/096 - Mean training loss 0.083020; Mean training F1 0.937511; Mean validation loss 0.089588; Mean validation F1 0.937396; Learning rate 0.000109;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937396; loss - 0.089588;\n",
    "Group g4: f1 - 0.781991; loss - 0.281695;\n",
    "Group g9: f1 - 0.782890; loss - 0.283932;\n",
    "===========================================================\n",
    "Epoch 068/096 - Mean training loss 0.082869; Mean training F1 0.937943; Mean validation loss 0.088554; Mean validation F1 0.938462; Learning rate 0.000102;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938462; loss - 0.088554;\n",
    "Group g4: f1 - 0.779313; loss - 0.278188;\n",
    "Group g9: f1 - 0.767753; loss - 0.279973;\n",
    "===========================================================\n",
    "Epoch 069/096 - Mean training loss 0.082815; Mean training F1 0.938133; Mean validation loss 0.089157; Mean validation F1 0.938166; Learning rate 0.000096;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938166; loss - 0.089157;\n",
    "Group g4: f1 - 0.775637; loss - 0.278205;\n",
    "Group g9: f1 - 0.766721; loss - 0.280176;\n",
    "===========================================================\n",
    "Epoch 070/096 - Mean training loss 0.082703; Mean training F1 0.937853; Mean validation loss 0.088766; Mean validation F1 0.938148; Learning rate 0.000090;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938148; loss - 0.088766;\n",
    "Group g4: f1 - 0.772895; loss - 0.278115;\n",
    "Group g9: f1 - 0.757657; loss - 0.280026;\n",
    "===========================================================\n",
    "Epoch 071/096 - Mean training loss 0.082904; Mean training F1 0.937869; Mean validation loss 0.088443; Mean validation F1 0.938618; Learning rate 0.000084;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938618; loss - 0.088443;\n",
    "Group g4: f1 - 0.785463; loss - 0.277990;\n",
    "Group g9: f1 - 0.784301; loss - 0.279750;\n",
    "===========================================================\n",
    "Epoch 072/096 - Mean training loss 0.082729; Mean training F1 0.938025; Mean validation loss 0.088626; Mean validation F1 0.938500; Learning rate 0.000078;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938500; loss - 0.088626;\n",
    "Group g4: f1 - 0.780509; loss - 0.278054;\n",
    "Group g9: f1 - 0.780898; loss - 0.279909;\n",
    "===========================================================\n",
    "Epoch 073/096 - Mean training loss 0.082417; Mean training F1 0.938092; Mean validation loss 0.088018; Mean validation F1 0.938827; Learning rate 0.000072;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938827; loss - 0.088018;\n",
    "Group g4: f1 - 0.789387; loss - 0.277915;\n",
    "Group g9: f1 - 0.787635; loss - 0.279594;\n",
    "===========================================================\n",
    "Epoch 074/096 - Mean training loss 0.082535; Mean training F1 0.938024; Mean validation loss 0.088057; Mean validation F1 0.938600; Learning rate 0.000067;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938600; loss - 0.088057;\n",
    "Group g4: f1 - 0.787885; loss - 0.277596;\n",
    "Group g9: f1 - 0.785559; loss - 0.279432;\n",
    "===========================================================\n",
    "Epoch 075/096 - Mean training loss 0.082582; Mean training F1 0.938039; Mean validation loss 0.088202; Mean validation F1 0.938563; Learning rate 0.000061;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938563; loss - 0.088202;\n",
    "Group g4: f1 - 0.783460; loss - 0.277826;\n",
    "Group g9: f1 - 0.781943; loss - 0.279616;\n",
    "===========================================================\n",
    "Epoch 076/096 - Mean training loss 0.082252; Mean training F1 0.938034; Mean validation loss 0.088510; Mean validation F1 0.938115; Learning rate 0.000056;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938115; loss - 0.088510;\n",
    "Group g4: f1 - 0.791024; loss - 0.278014;\n",
    "Group g9: f1 - 0.785787; loss - 0.279975;\n",
    "===========================================================\n",
    "Epoch 077/096 - Mean training loss 0.082206; Mean training F1 0.938256; Mean validation loss 0.088255; Mean validation F1 0.938100; Learning rate 0.000052;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938100; loss - 0.088255;\n",
    "Group g4: f1 - 0.784336; loss - 0.278167;\n",
    "Group g9: f1 - 0.779794; loss - 0.279921;\n",
    "===========================================================\n",
    "Epoch 078/096 - Mean training loss 0.082326; Mean training F1 0.938181; Mean validation loss 0.088183; Mean validation F1 0.938556; Learning rate 0.000047;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938556; loss - 0.088183;\n",
    "Group g4: f1 - 0.779660; loss - 0.278253;\n",
    "Group g9: f1 - 0.771718; loss - 0.279965;\n",
    "===========================================================\n",
    "Epoch 079/096 - Mean training loss 0.082982; Mean training F1 0.938048; Mean validation loss 0.087795; Mean validation F1 0.938634; Learning rate 0.000043;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938634; loss - 0.087795;\n",
    "Group g4: f1 - 0.782212; loss - 0.277722;\n",
    "Group g9: f1 - 0.779629; loss - 0.279546;\n",
    "===========================================================\n",
    "Epoch 080/096 - Mean training loss 0.082036; Mean training F1 0.938251; Mean validation loss 0.087922; Mean validation F1 0.938721; Learning rate 0.000038;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938721; loss - 0.087922;\n",
    "Group g4: f1 - 0.783821; loss - 0.277959;\n",
    "Group g9: f1 - 0.774979; loss - 0.279658;\n",
    "===========================================================\n",
    "Epoch 081/096 - Mean training loss 0.082285; Mean training F1 0.938274; Mean validation loss 0.087877; Mean validation F1 0.938712; Learning rate 0.000034;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938712; loss - 0.087877;\n",
    "Group g4: f1 - 0.786159; loss - 0.277589;\n",
    "Group g9: f1 - 0.782725; loss - 0.279308;\n",
    "===========================================================\n",
    "Epoch 082/096 - Mean training loss 0.082133; Mean training F1 0.938176; Mean validation loss 0.088275; Mean validation F1 0.938633; Learning rate 0.000031;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938633; loss - 0.088275;\n",
    "Group g4: f1 - 0.785716; loss - 0.277843;\n",
    "Group g9: f1 - 0.781262; loss - 0.279565;\n",
    "===========================================================\n",
    "Epoch 083/096 - Mean training loss 0.082025; Mean training F1 0.938262; Mean validation loss 0.088003; Mean validation F1 0.938586; Learning rate 0.000027;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938586; loss - 0.088003;\n",
    "Group g4: f1 - 0.786144; loss - 0.277791;\n",
    "Group g9: f1 - 0.783034; loss - 0.279470;\n",
    "===========================================================\n",
    "Epoch 084/096 - Mean training loss 0.082303; Mean training F1 0.938148; Mean validation loss 0.088064; Mean validation F1 0.938530; Learning rate 0.000024;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938530; loss - 0.088064;\n",
    "Group g4: f1 - 0.786844; loss - 0.277592;\n",
    "Group g9: f1 - 0.787932; loss - 0.279308;\n",
    "===========================================================\n",
    "Epoch 085/096 - Mean training loss 0.081695; Mean training F1 0.938373; Mean validation loss 0.087889; Mean validation F1 0.938754; Learning rate 0.000021;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938754; loss - 0.087889;\n",
    "Group g4: f1 - 0.786718; loss - 0.277450;\n",
    "Group g9: f1 - 0.783564; loss - 0.279162;\n",
    "===========================================================\n",
    "Epoch 086/096 - Mean training loss 0.081751; Mean training F1 0.938279; Mean validation loss 0.088063; Mean validation F1 0.938700; Learning rate 0.000018;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938700; loss - 0.088063;\n",
    "Group g4: f1 - 0.784767; loss - 0.277753;\n",
    "Group g9: f1 - 0.783923; loss - 0.279372;\n",
    "===========================================================\n",
    "Epoch 087/096 - Mean training loss 0.081984; Mean training F1 0.938154; Mean validation loss 0.088267; Mean validation F1 0.938532; Learning rate 0.000016;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938532; loss - 0.088267;\n",
    "Group g4: f1 - 0.788314; loss - 0.277560;\n",
    "Group g9: f1 - 0.785754; loss - 0.279266;\n",
    "===========================================================\n",
    "Epoch 088/096 - Mean training loss 0.082058; Mean training F1 0.938233; Mean validation loss 0.087943; Mean validation F1 0.938346; Learning rate 0.000014;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938346; loss - 0.087943;\n",
    "Group g4: f1 - 0.786225; loss - 0.277644;\n",
    "Group g9: f1 - 0.785752; loss - 0.279372;\n",
    "===========================================================\n",
    "Epoch 089/096 - Mean training loss 0.082137; Mean training F1 0.938226; Mean validation loss 0.087875; Mean validation F1 0.938603; Learning rate 0.000012;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938603; loss - 0.087875;\n",
    "Group g4: f1 - 0.785949; loss - 0.277587;\n",
    "Group g9: f1 - 0.781583; loss - 0.279252;\n",
    "===========================================================\n",
    "Epoch 090/096 - Mean training loss 0.082053; Mean training F1 0.938294; Mean validation loss 0.087877; Mean validation F1 0.938720; Learning rate 0.000010;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938720; loss - 0.087877;\n",
    "Group g4: f1 - 0.787009; loss - 0.277412;\n",
    "Group g9: f1 - 0.785793; loss - 0.279223;\n",
    "===========================================================\n",
    "Epoch 091/096 - Mean training loss 0.081935; Mean training F1 0.938281; Mean validation loss 0.087868; Mean validation F1 0.938864; Learning rate 0.000008;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938864; loss - 0.087868;\n",
    "Group g4: f1 - 0.787026; loss - 0.277353;\n",
    "Group g9: f1 - 0.782578; loss - 0.279112;\n",
    "===========================================================\n",
    "Epoch 092/096 - Mean training loss 0.082019; Mean training F1 0.938343; Mean validation loss 0.087902; Mean validation F1 0.938735; Learning rate 0.000007;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938735; loss - 0.087902;\n",
    "Group g4: f1 - 0.787359; loss - 0.277470;\n",
    "Group g9: f1 - 0.785847; loss - 0.279155;\n",
    "===========================================================\n",
    "Epoch 093/096 - Mean training loss 0.081957; Mean training F1 0.938357; Mean validation loss 0.087828; Mean validation F1 0.938846; Learning rate 0.000006;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938846; loss - 0.087828;\n",
    "Group g4: f1 - 0.785694; loss - 0.277580;\n",
    "Group g9: f1 - 0.781153; loss - 0.279258;\n",
    "===========================================================\n",
    "Epoch 094/096 - Mean training loss 0.081892; Mean training F1 0.938465; Mean validation loss 0.088089; Mean validation F1 0.938635; Learning rate 0.000006;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938635; loss - 0.088089;\n",
    "Group g4: f1 - 0.789170; loss - 0.277445;\n",
    "Group g9: f1 - 0.786984; loss - 0.279101;\n",
    "===========================================================\n",
    "Epoch 095/096 - Mean training loss 0.081771; Mean training F1 0.938432; Mean validation loss 0.087934; Mean validation F1 0.938657; Learning rate 0.000005;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938657; loss - 0.087934;\n",
    "Group g4: f1 - 0.788327; loss - 0.277394;\n",
    "Group g9: f1 - 0.785677; loss - 0.279110;\n",
    "===========================================================\n",
    "Epoch 096/096 - Mean training loss 0.081693; Mean training F1 0.938369; Mean validation loss 0.087847; Mean validation F1 0.938713; Learning rate 0.000005;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938713; loss - 0.087847;\n",
    "Group g4: f1 - 0.787281; loss - 0.277350;\n",
    "Group g9: f1 - 0.782503; loss - 0.279092;\n",
    "################################################################\n",
    "Training/validation for fold 2/5;\n",
    "===========================================================\n",
    "Epoch 001/096 - Mean training loss 0.767455; Mean training F1 0.639590; Mean validation loss 0.457595; Mean validation F1 0.799250; Learning rate 0.000500;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.799250; loss - 0.457595;\n",
    "Group g4: f1 - 0.362992; loss - 0.937461;\n",
    "Group g9: f1 - 0.361767; loss - 0.957744;\n",
    "===========================================================\n",
    "Epoch 002/096 - Mean training loss 0.294886; Mean training F1 0.853058; Mean validation loss 0.250473; Mean validation F1 0.889398; Learning rate 0.000500;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.889398; loss - 0.250473;\n",
    "Group g4: f1 - 0.464040; loss - 0.470476;\n",
    "Group g9: f1 - 0.464607; loss - 0.477973;\n",
    "===========================================================\n",
    "Epoch 003/096 - Mean training loss 0.179423; Mean training F1 0.902782; Mean validation loss 0.167612; Mean validation F1 0.913132; Learning rate 0.000499;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.913132; loss - 0.167612;\n",
    "Group g4: f1 - 0.534945; loss - 0.429408;\n",
    "Group g9: f1 - 0.531315; loss - 0.445851;\n",
    "===========================================================\n",
    "Epoch 004/096 - Mean training loss 0.153012; Mean training F1 0.909617; Mean validation loss 0.127788; Mean validation F1 0.926491; Learning rate 0.000498;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.926491; loss - 0.127788;\n",
    "Group g4: f1 - 0.587652; loss - 0.337670;\n",
    "Group g9: f1 - 0.589526; loss - 0.341840;\n",
    "===========================================================\n",
    "Epoch 005/096 - Mean training loss 0.121504; Mean training F1 0.924048; Mean validation loss 0.131403; Mean validation F1 0.923914; Learning rate 0.000497;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.923914; loss - 0.131403;\n",
    "Group g4: f1 - 0.617492; loss - 0.327490;\n",
    "Group g9: f1 - 0.616946; loss - 0.329844;\n",
    "===========================================================\n",
    "Epoch 006/096 - Mean training loss 0.130070; Mean training F1 0.919756; Mean validation loss 0.158904; Mean validation F1 0.912505; Learning rate 0.000496;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.912505; loss - 0.158904;\n",
    "Group g4: f1 - 0.626284; loss - 0.307888;\n",
    "Group g9: f1 - 0.626442; loss - 0.310955;\n",
    "===========================================================\n",
    "Epoch 007/096 - Mean training loss 0.117867; Mean training F1 0.923016; Mean validation loss 0.122131; Mean validation F1 0.925017; Learning rate 0.000494;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.925017; loss - 0.122131;\n",
    "Group g4: f1 - 0.661649; loss - 0.322419;\n",
    "Group g9: f1 - 0.657658; loss - 0.324672;\n",
    "===========================================================\n",
    "Epoch 008/096 - Mean training loss 0.132193; Mean training F1 0.919474; Mean validation loss 0.123665; Mean validation F1 0.926723; Learning rate 0.000492;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.926723; loss - 0.123665;\n",
    "Group g4: f1 - 0.654242; loss - 0.310409;\n",
    "Group g9: f1 - 0.650493; loss - 0.313333;\n",
    "===========================================================\n",
    "Epoch 009/096 - Mean training loss 0.109276; Mean training F1 0.927587; Mean validation loss 0.107237; Mean validation F1 0.931607; Learning rate 0.000490;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931607; loss - 0.107237;\n",
    "Group g4: f1 - 0.676557; loss - 0.297033;\n",
    "Group g9: f1 - 0.668605; loss - 0.300506;\n",
    "===========================================================\n",
    "Epoch 010/096 - Mean training loss 0.108817; Mean training F1 0.926329; Mean validation loss 0.111128; Mean validation F1 0.930957; Learning rate 0.000487;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.930957; loss - 0.111128;\n",
    "Group g4: f1 - 0.691645; loss - 0.304099;\n",
    "Group g9: f1 - 0.679926; loss - 0.306944;\n",
    "===========================================================\n",
    "Epoch 011/096 - Mean training loss 0.103725; Mean training F1 0.929350; Mean validation loss 0.115157; Mean validation F1 0.930975; Learning rate 0.000484;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.930975; loss - 0.115157;\n",
    "Group g4: f1 - 0.687923; loss - 0.302899;\n",
    "Group g9: f1 - 0.672907; loss - 0.307569;\n",
    "===========================================================\n",
    "Epoch 012/096 - Mean training loss 0.100236; Mean training F1 0.930743; Mean validation loss 0.106683; Mean validation F1 0.933651; Learning rate 0.000481;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933651; loss - 0.106683;\n",
    "Group g4: f1 - 0.695131; loss - 0.294411;\n",
    "Group g9: f1 - 0.681659; loss - 0.298825;\n",
    "===========================================================\n",
    "Epoch 013/096 - Mean training loss 0.101002; Mean training F1 0.930529; Mean validation loss 0.108693; Mean validation F1 0.931282; Learning rate 0.000478;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931282; loss - 0.108693;\n",
    "Group g4: f1 - 0.693105; loss - 0.295472;\n",
    "Group g9: f1 - 0.690533; loss - 0.297942;\n",
    "===========================================================\n",
    "Epoch 014/096 - Mean training loss 0.097831; Mean training F1 0.931887; Mean validation loss 0.103118; Mean validation F1 0.934280; Learning rate 0.000475;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934280; loss - 0.103118;\n",
    "Group g4: f1 - 0.715434; loss - 0.288954;\n",
    "Group g9: f1 - 0.701015; loss - 0.291927;\n",
    "===========================================================\n",
    "Epoch 015/096 - Mean training loss 0.099983; Mean training F1 0.931193; Mean validation loss 0.104215; Mean validation F1 0.932970; Learning rate 0.000471;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.932970; loss - 0.104215;\n",
    "Group g4: f1 - 0.703207; loss - 0.294690;\n",
    "Group g9: f1 - 0.699107; loss - 0.296799;\n",
    "===========================================================\n",
    "Epoch 016/096 - Mean training loss 0.097222; Mean training F1 0.931800; Mean validation loss 0.104477; Mean validation F1 0.933926; Learning rate 0.000467;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933926; loss - 0.104477;\n",
    "Group g4: f1 - 0.708486; loss - 0.287938;\n",
    "Group g9: f1 - 0.701171; loss - 0.290764;\n",
    "===========================================================\n",
    "Epoch 017/096 - Mean training loss 0.094865; Mean training F1 0.933265; Mean validation loss 2.473227; Mean validation F1 0.547947; Learning rate 0.000463;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.547947; loss - 2.473227;\n",
    "Group g4: f1 - 0.699808; loss - 0.295063;\n",
    "Group g9: f1 - 0.697508; loss - 0.297417;\n",
    "===========================================================\n",
    "Epoch 018/096 - Mean training loss 0.100333; Mean training F1 0.930619; Mean validation loss 0.104160; Mean validation F1 0.933063; Learning rate 0.000459;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933063; loss - 0.104160;\n",
    "Group g4: f1 - 0.706924; loss - 0.289112;\n",
    "Group g9: f1 - 0.701247; loss - 0.292049;\n",
    "===========================================================\n",
    "Epoch 019/096 - Mean training loss 0.094825; Mean training F1 0.932839; Mean validation loss 0.104812; Mean validation F1 0.932242; Learning rate 0.000454;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.932242; loss - 0.104812;\n",
    "Group g4: f1 - 0.715639; loss - 0.298614;\n",
    "Group g9: f1 - 0.695251; loss - 0.301347;\n",
    "===========================================================\n",
    "Epoch 020/096 - Mean training loss 0.092216; Mean training F1 0.934211; Mean validation loss 0.100596; Mean validation F1 0.935356; Learning rate 0.000449;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935356; loss - 0.100596;\n",
    "Group g4: f1 - 0.727374; loss - 0.283165;\n",
    "Group g9: f1 - 0.715682; loss - 0.285714;\n",
    "===========================================================\n",
    "Epoch 021/096 - Mean training loss 0.093169; Mean training F1 0.934137; Mean validation loss 0.100956; Mean validation F1 0.934775; Learning rate 0.000444;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934775; loss - 0.100956;\n",
    "Group g4: f1 - 0.719481; loss - 0.284662;\n",
    "Group g9: f1 - 0.703451; loss - 0.287424;\n",
    "===========================================================\n",
    "Epoch 022/096 - Mean training loss 0.090293; Mean training F1 0.935056; Mean validation loss 0.100442; Mean validation F1 0.934923; Learning rate 0.000439;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934923; loss - 0.100442;\n",
    "Group g4: f1 - 0.743023; loss - 0.286351;\n",
    "Group g9: f1 - 0.730424; loss - 0.289388;\n",
    "===========================================================\n",
    "Epoch 023/096 - Mean training loss 0.091370; Mean training F1 0.934682; Mean validation loss 0.099756; Mean validation F1 0.935114; Learning rate 0.000433;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935114; loss - 0.099756;\n",
    "Group g4: f1 - 0.719457; loss - 0.288058;\n",
    "Group g9: f1 - 0.709003; loss - 0.291057;\n",
    "===========================================================\n",
    "Epoch 024/096 - Mean training loss 0.092189; Mean training F1 0.934319; Mean validation loss 0.102692; Mean validation F1 0.933886; Learning rate 0.000428;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933886; loss - 0.102692;\n",
    "Group g4: f1 - 0.727485; loss - 0.288587;\n",
    "Group g9: f1 - 0.712811; loss - 0.290869;\n",
    "===========================================================\n",
    "Epoch 025/096 - Mean training loss 0.093378; Mean training F1 0.933487; Mean validation loss 0.099419; Mean validation F1 0.935021; Learning rate 0.000422;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935021; loss - 0.099419;\n",
    "Group g4: f1 - 0.732282; loss - 0.287021;\n",
    "Group g9: f1 - 0.716334; loss - 0.289112;\n",
    "===========================================================\n",
    "Epoch 026/096 - Mean training loss 0.090389; Mean training F1 0.934038; Mean validation loss 0.100089; Mean validation F1 0.934839; Learning rate 0.000416;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934839; loss - 0.100089;\n",
    "Group g4: f1 - 0.752058; loss - 0.285275;\n",
    "Group g9: f1 - 0.733685; loss - 0.288960;\n",
    "===========================================================\n",
    "Epoch 027/096 - Mean training loss 0.088287; Mean training F1 0.935444; Mean validation loss 0.101735; Mean validation F1 0.932710; Learning rate 0.000410;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.932710; loss - 0.101735;\n",
    "Group g4: f1 - 0.744027; loss - 0.301351;\n",
    "Group g9: f1 - 0.730466; loss - 0.303563;\n",
    "===========================================================\n",
    "Epoch 028/096 - Mean training loss 0.088488; Mean training F1 0.935047; Mean validation loss 0.102421; Mean validation F1 0.931408; Learning rate 0.000403;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931408; loss - 0.102421;\n",
    "Group g4: f1 - 0.735314; loss - 0.305851;\n",
    "Group g9: f1 - 0.716519; loss - 0.309377;\n",
    "===========================================================\n",
    "Epoch 029/096 - Mean training loss 0.090076; Mean training F1 0.934683; Mean validation loss 0.101714; Mean validation F1 0.932870; Learning rate 0.000397;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.932870; loss - 0.101714;\n",
    "Group g4: f1 - 0.741296; loss - 0.288775;\n",
    "Group g9: f1 - 0.725581; loss - 0.291762;\n",
    "===========================================================\n",
    "Epoch 030/096 - Mean training loss 0.087586; Mean training F1 0.935837; Mean validation loss 0.096481; Mean validation F1 0.936173; Learning rate 0.000390;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936173; loss - 0.096481;\n",
    "Group g4: f1 - 0.756690; loss - 0.282439;\n",
    "Group g9: f1 - 0.749811; loss - 0.285475;\n",
    "===========================================================\n",
    "Epoch 031/096 - Mean training loss 0.087020; Mean training F1 0.935992; Mean validation loss 0.098596; Mean validation F1 0.934823; Learning rate 0.000383;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934823; loss - 0.098596;\n",
    "Group g4: f1 - 0.747017; loss - 0.286359;\n",
    "Group g9: f1 - 0.728124; loss - 0.289080;\n",
    "===========================================================\n",
    "Epoch 032/096 - Mean training loss 0.087751; Mean training F1 0.935795; Mean validation loss 0.097727; Mean validation F1 0.935383; Learning rate 0.000377;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935383; loss - 0.097727;\n",
    "Group g4: f1 - 0.754052; loss - 0.282735;\n",
    "Group g9: f1 - 0.724855; loss - 0.286837;\n",
    "===========================================================\n",
    "Epoch 033/096 - Mean training loss 0.086720; Mean training F1 0.935943; Mean validation loss 0.097163; Mean validation F1 0.935377; Learning rate 0.000369;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935377; loss - 0.097163;\n",
    "Group g4: f1 - 0.746234; loss - 0.285404;\n",
    "Group g9: f1 - 0.735107; loss - 0.288694;\n",
    "===========================================================\n",
    "Epoch 034/096 - Mean training loss 0.086079; Mean training F1 0.936229; Mean validation loss 0.096746; Mean validation F1 0.936080; Learning rate 0.000362;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936080; loss - 0.096746;\n",
    "Group g4: f1 - 0.763885; loss - 0.281799;\n",
    "Group g9: f1 - 0.761583; loss - 0.284654;\n",
    "===========================================================\n",
    "Epoch 035/096 - Mean training loss 0.085584; Mean training F1 0.936579; Mean validation loss 0.096313; Mean validation F1 0.936020; Learning rate 0.000355;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936020; loss - 0.096313;\n",
    "Group g4: f1 - 0.759385; loss - 0.281918;\n",
    "Group g9: f1 - 0.745836; loss - 0.284427;\n",
    "===========================================================\n",
    "Epoch 036/096 - Mean training loss 0.085592; Mean training F1 0.936364; Mean validation loss 0.095345; Mean validation F1 0.936079; Learning rate 0.000347;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936079; loss - 0.095345;\n",
    "Group g4: f1 - 0.768925; loss - 0.283340;\n",
    "Group g9: f1 - 0.756616; loss - 0.285376;\n",
    "===========================================================\n",
    "Epoch 037/096 - Mean training loss 0.087616; Mean training F1 0.935866; Mean validation loss 0.337776; Mean validation F1 0.855325; Learning rate 0.000340;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.855325; loss - 0.337776;\n",
    "Group g4: f1 - 0.424821; loss - 1.159881;\n",
    "Group g9: f1 - 0.424336; loss - 1.208244;\n",
    "===========================================================\n",
    "Epoch 038/096 - Mean training loss 0.110556; Mean training F1 0.924734; Mean validation loss 0.114834; Mean validation F1 0.930403; Learning rate 0.000332;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.930403; loss - 0.114834;\n",
    "Group g4: f1 - 0.742269; loss - 0.286648;\n",
    "Group g9: f1 - 0.713303; loss - 0.289775;\n",
    "===========================================================\n",
    "Epoch 039/096 - Mean training loss 0.092230; Mean training F1 0.933844; Mean validation loss 0.100971; Mean validation F1 0.935251; Learning rate 0.000325;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935251; loss - 0.100971;\n",
    "Group g4: f1 - 0.750414; loss - 0.283476;\n",
    "Group g9: f1 - 0.712773; loss - 0.288655;\n",
    "===========================================================\n",
    "Epoch 040/096 - Mean training loss 0.088620; Mean training F1 0.935741; Mean validation loss 0.098142; Mean validation F1 0.935808; Learning rate 0.000317;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935808; loss - 0.098142;\n",
    "Group g4: f1 - 0.763253; loss - 0.282174;\n",
    "Group g9: f1 - 0.738046; loss - 0.285499;\n",
    "===========================================================\n",
    "Epoch 041/096 - Mean training loss 0.088531; Mean training F1 0.935706; Mean validation loss 0.105305; Mean validation F1 0.933238; Learning rate 0.000309;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933238; loss - 0.105305;\n",
    "Group g4: f1 - 0.739755; loss - 0.284278;\n",
    "Group g9: f1 - 0.701439; loss - 0.291406;\n",
    "===========================================================\n",
    "Epoch 042/096 - Mean training loss 0.086889; Mean training F1 0.935887; Mean validation loss 0.096701; Mean validation F1 0.936305; Learning rate 0.000301;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936305; loss - 0.096701;\n",
    "Group g4: f1 - 0.762331; loss - 0.281552;\n",
    "Group g9: f1 - 0.743631; loss - 0.283930;\n",
    "===========================================================\n",
    "Epoch 043/096 - Mean training loss 0.085595; Mean training F1 0.936602; Mean validation loss 0.096782; Mean validation F1 0.935881; Learning rate 0.000293;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935881; loss - 0.096782;\n",
    "Group g4: f1 - 0.763323; loss - 0.281738;\n",
    "Group g9: f1 - 0.742803; loss - 0.284680;\n",
    "===========================================================\n",
    "Epoch 044/096 - Mean training loss 0.085427; Mean training F1 0.936665; Mean validation loss 0.097790; Mean validation F1 0.935892; Learning rate 0.000285;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935892; loss - 0.097790;\n",
    "Group g4: f1 - 0.776576; loss - 0.283062;\n",
    "Group g9: f1 - 0.756507; loss - 0.285691;\n",
    "===========================================================\n",
    "Epoch 045/096 - Mean training loss 0.084774; Mean training F1 0.936892; Mean validation loss 0.095474; Mean validation F1 0.936615; Learning rate 0.000277;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936615; loss - 0.095474;\n",
    "Group g4: f1 - 0.770722; loss - 0.280105;\n",
    "Group g9: f1 - 0.754750; loss - 0.282733;\n",
    "===========================================================\n",
    "Epoch 046/096 - Mean training loss 0.085705; Mean training F1 0.936585; Mean validation loss 0.097180; Mean validation F1 0.935993; Learning rate 0.000269;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935993; loss - 0.097180;\n",
    "Group g4: f1 - 0.764111; loss - 0.282122;\n",
    "Group g9: f1 - 0.750678; loss - 0.284823;\n",
    "===========================================================\n",
    "Epoch 047/096 - Mean training loss 0.085045; Mean training F1 0.936983; Mean validation loss 0.096310; Mean validation F1 0.936431; Learning rate 0.000261;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936431; loss - 0.096310;\n",
    "Group g4: f1 - 0.775605; loss - 0.280968;\n",
    "Group g9: f1 - 0.756802; loss - 0.284030;\n",
    "===========================================================\n",
    "Epoch 048/096 - Mean training loss 0.084926; Mean training F1 0.936753; Mean validation loss 0.097122; Mean validation F1 0.935468; Learning rate 0.000253;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935468; loss - 0.097122;\n",
    "Group g4: f1 - 0.766713; loss - 0.286048;\n",
    "Group g9: f1 - 0.753681; loss - 0.288334;\n",
    "===========================================================\n",
    "Epoch 049/096 - Mean training loss 0.085126; Mean training F1 0.936690; Mean validation loss 0.096083; Mean validation F1 0.936400; Learning rate 0.000245;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936400; loss - 0.096083;\n",
    "Group g4: f1 - 0.758140; loss - 0.279847;\n",
    "Group g9: f1 - 0.730008; loss - 0.283902;\n",
    "===========================================================\n",
    "Epoch 050/096 - Mean training loss 0.084849; Mean training F1 0.936993; Mean validation loss 0.096645; Mean validation F1 0.935704; Learning rate 0.000237;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935704; loss - 0.096645;\n",
    "Group g4: f1 - 0.772152; loss - 0.286617;\n",
    "Group g9: f1 - 0.756273; loss - 0.288881;\n",
    "===========================================================\n",
    "Epoch 051/096 - Mean training loss 0.084320; Mean training F1 0.937139; Mean validation loss 0.095257; Mean validation F1 0.936853; Learning rate 0.000228;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936853; loss - 0.095257;\n",
    "Group g4: f1 - 0.769474; loss - 0.279581;\n",
    "Group g9: f1 - 0.752878; loss - 0.282694;\n",
    "===========================================================\n",
    "Epoch 052/096 - Mean training loss 0.083797; Mean training F1 0.937295; Mean validation loss 0.096883; Mean validation F1 0.935651; Learning rate 0.000220;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935651; loss - 0.096883;\n",
    "Group g4: f1 - 0.761780; loss - 0.280841;\n",
    "Group g9: f1 - 0.747747; loss - 0.284355;\n",
    "===========================================================\n",
    "Epoch 053/096 - Mean training loss 0.084281; Mean training F1 0.937147; Mean validation loss 0.096030; Mean validation F1 0.936517; Learning rate 0.000212;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936517; loss - 0.096030;\n",
    "Group g4: f1 - 0.772774; loss - 0.280722;\n",
    "Group g9: f1 - 0.758853; loss - 0.283415;\n",
    "===========================================================\n",
    "Epoch 054/096 - Mean training loss 0.083617; Mean training F1 0.937510; Mean validation loss 0.095735; Mean validation F1 0.935738; Learning rate 0.000204;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935738; loss - 0.095735;\n",
    "Group g4: f1 - 0.765342; loss - 0.281372;\n",
    "Group g9: f1 - 0.750873; loss - 0.284371;\n",
    "===========================================================\n",
    "Epoch 055/096 - Mean training loss 0.084005; Mean training F1 0.937508; Mean validation loss 0.094728; Mean validation F1 0.936933; Learning rate 0.000197;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936933; loss - 0.094728;\n",
    "Group g4: f1 - 0.767854; loss - 0.278949;\n",
    "Group g9: f1 - 0.748707; loss - 0.282157;\n",
    "===========================================================\n",
    "Epoch 056/096 - Mean training loss 0.084284; Mean training F1 0.937319; Mean validation loss 0.094889; Mean validation F1 0.936785; Learning rate 0.000189;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936785; loss - 0.094889;\n",
    "Group g4: f1 - 0.775214; loss - 0.280824;\n",
    "Group g9: f1 - 0.761044; loss - 0.283404;\n",
    "===========================================================\n",
    "Epoch 057/096 - Mean training loss 0.084083; Mean training F1 0.937464; Mean validation loss 0.095105; Mean validation F1 0.936303; Learning rate 0.000181;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936303; loss - 0.095105;\n",
    "Group g4: f1 - 0.781560; loss - 0.280946;\n",
    "Group g9: f1 - 0.765025; loss - 0.283818;\n",
    "===========================================================\n",
    "Epoch 058/096 - Mean training loss 0.083818; Mean training F1 0.937254; Mean validation loss 0.095519; Mean validation F1 0.936675; Learning rate 0.000173;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936675; loss - 0.095519;\n",
    "Group g4: f1 - 0.778119; loss - 0.279467;\n",
    "Group g9: f1 - 0.765609; loss - 0.281926;\n",
    "===========================================================\n",
    "Epoch 059/096 - Mean training loss 0.083642; Mean training F1 0.937432; Mean validation loss 0.094405; Mean validation F1 0.936711; Learning rate 0.000166;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936711; loss - 0.094405;\n",
    "Group g4: f1 - 0.786547; loss - 0.278870;\n",
    "Group g9: f1 - 0.772766; loss - 0.281638;\n",
    "===========================================================\n",
    "Epoch 060/096 - Mean training loss 0.083810; Mean training F1 0.937408; Mean validation loss 0.094616; Mean validation F1 0.936832; Learning rate 0.000158;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936832; loss - 0.094616;\n",
    "Group g4: f1 - 0.780888; loss - 0.279476;\n",
    "Group g9: f1 - 0.769558; loss - 0.282150;\n",
    "===========================================================\n",
    "Epoch 061/096 - Mean training loss 0.083607; Mean training F1 0.937372; Mean validation loss 0.094698; Mean validation F1 0.936791; Learning rate 0.000151;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936791; loss - 0.094698;\n",
    "Group g4: f1 - 0.781398; loss - 0.280326;\n",
    "Group g9: f1 - 0.762630; loss - 0.283026;\n",
    "===========================================================\n",
    "Epoch 062/096 - Mean training loss 0.083657; Mean training F1 0.937344; Mean validation loss 0.094788; Mean validation F1 0.936596; Learning rate 0.000143;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936596; loss - 0.094788;\n",
    "Group g4: f1 - 0.773113; loss - 0.279317;\n",
    "Group g9: f1 - 0.762279; loss - 0.281974;\n",
    "===========================================================\n",
    "Epoch 063/096 - Mean training loss 0.083876; Mean training F1 0.937623; Mean validation loss 0.095425; Mean validation F1 0.936659; Learning rate 0.000136;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936659; loss - 0.095425;\n",
    "Group g4: f1 - 0.773531; loss - 0.279322;\n",
    "Group g9: f1 - 0.767125; loss - 0.281714;\n",
    "===========================================================\n",
    "Epoch 064/096 - Mean training loss 0.082714; Mean training F1 0.937725; Mean validation loss 0.094102; Mean validation F1 0.937108; Learning rate 0.000129;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937108; loss - 0.094102;\n",
    "Group g4: f1 - 0.785112; loss - 0.278415;\n",
    "Group g9: f1 - 0.772139; loss - 0.281117;\n",
    "===========================================================\n",
    "Epoch 065/096 - Mean training loss 0.083418; Mean training F1 0.937595; Mean validation loss 0.094917; Mean validation F1 0.936542; Learning rate 0.000122;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936542; loss - 0.094917;\n",
    "Group g4: f1 - 0.788158; loss - 0.279533;\n",
    "Group g9: f1 - 0.773232; loss - 0.282104;\n",
    "===========================================================\n",
    "Epoch 066/096 - Mean training loss 0.083197; Mean training F1 0.937524; Mean validation loss 0.094275; Mean validation F1 0.937026; Learning rate 0.000115;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937026; loss - 0.094275;\n",
    "Group g4: f1 - 0.779089; loss - 0.278401;\n",
    "Group g9: f1 - 0.765053; loss - 0.281027;\n",
    "===========================================================\n",
    "Epoch 067/096 - Mean training loss 0.082843; Mean training F1 0.937713; Mean validation loss 0.094205; Mean validation F1 0.937068; Learning rate 0.000109;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937068; loss - 0.094205;\n",
    "Group g4: f1 - 0.777102; loss - 0.278301;\n",
    "Group g9: f1 - 0.762480; loss - 0.281036;\n",
    "===========================================================\n",
    "Epoch 068/096 - Mean training loss 0.082815; Mean training F1 0.937763; Mean validation loss 0.093941; Mean validation F1 0.936980; Learning rate 0.000102;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936980; loss - 0.093941;\n",
    "Group g4: f1 - 0.790123; loss - 0.278332;\n",
    "Group g9: f1 - 0.771024; loss - 0.280991;\n",
    "===========================================================\n",
    "Epoch 069/096 - Mean training loss 0.082724; Mean training F1 0.937846; Mean validation loss 0.094616; Mean validation F1 0.936832; Learning rate 0.000096;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936832; loss - 0.094616;\n",
    "Group g4: f1 - 0.780316; loss - 0.279126;\n",
    "Group g9: f1 - 0.763750; loss - 0.281535;\n",
    "===========================================================\n",
    "Epoch 070/096 - Mean training loss 0.082920; Mean training F1 0.937770; Mean validation loss 0.094418; Mean validation F1 0.936458; Learning rate 0.000090;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936458; loss - 0.094418;\n",
    "Group g4: f1 - 0.772877; loss - 0.279519;\n",
    "Group g9: f1 - 0.758192; loss - 0.282570;\n",
    "===========================================================\n",
    "Epoch 071/096 - Mean training loss 0.082636; Mean training F1 0.937784; Mean validation loss 0.094503; Mean validation F1 0.936871; Learning rate 0.000084;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936871; loss - 0.094503;\n",
    "Group g4: f1 - 0.773129; loss - 0.278685;\n",
    "Group g9: f1 - 0.759908; loss - 0.281257;\n",
    "===========================================================\n",
    "Epoch 072/096 - Mean training loss 0.082409; Mean training F1 0.937967; Mean validation loss 0.093823; Mean validation F1 0.936575; Learning rate 0.000078;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936575; loss - 0.093823;\n",
    "Group g4: f1 - 0.776995; loss - 0.278940;\n",
    "Group g9: f1 - 0.765301; loss - 0.281676;\n",
    "===========================================================\n",
    "Epoch 073/096 - Mean training loss 0.082304; Mean training F1 0.938019; Mean validation loss 0.093935; Mean validation F1 0.937082; Learning rate 0.000072;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937082; loss - 0.093935;\n",
    "Group g4: f1 - 0.782488; loss - 0.278313;\n",
    "Group g9: f1 - 0.772265; loss - 0.281075;\n",
    "===========================================================\n",
    "Epoch 074/096 - Mean training loss 0.082563; Mean training F1 0.937976; Mean validation loss 0.093823; Mean validation F1 0.936915; Learning rate 0.000067;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936915; loss - 0.093823;\n",
    "Group g4: f1 - 0.776109; loss - 0.278330;\n",
    "Group g9: f1 - 0.764209; loss - 0.281058;\n",
    "===========================================================\n",
    "Epoch 075/096 - Mean training loss 0.082440; Mean training F1 0.937953; Mean validation loss 0.093717; Mean validation F1 0.937261; Learning rate 0.000061;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937261; loss - 0.093717;\n",
    "Group g4: f1 - 0.778129; loss - 0.278028;\n",
    "Group g9: f1 - 0.766652; loss - 0.280667;\n",
    "===========================================================\n",
    "Epoch 076/096 - Mean training loss 0.082163; Mean training F1 0.938104; Mean validation loss 0.093766; Mean validation F1 0.937072; Learning rate 0.000056;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937072; loss - 0.093766;\n",
    "Group g4: f1 - 0.778516; loss - 0.278725;\n",
    "Group g9: f1 - 0.764315; loss - 0.281215;\n",
    "===========================================================\n",
    "Epoch 077/096 - Mean training loss 0.082668; Mean training F1 0.938062; Mean validation loss 0.093641; Mean validation F1 0.937036; Learning rate 0.000052;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937036; loss - 0.093641;\n",
    "Group g4: f1 - 0.785516; loss - 0.279068;\n",
    "Group g9: f1 - 0.771383; loss - 0.281642;\n",
    "===========================================================\n",
    "Epoch 078/096 - Mean training loss 0.082133; Mean training F1 0.938158; Mean validation loss 0.093596; Mean validation F1 0.937232; Learning rate 0.000047;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937232; loss - 0.093596;\n",
    "Group g4: f1 - 0.779626; loss - 0.277912;\n",
    "Group g9: f1 - 0.768404; loss - 0.280573;\n",
    "===========================================================\n",
    "Epoch 079/096 - Mean training loss 0.082052; Mean training F1 0.938124; Mean validation loss 0.094021; Mean validation F1 0.936914; Learning rate 0.000043;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936914; loss - 0.094021;\n",
    "Group g4: f1 - 0.786431; loss - 0.278243;\n",
    "Group g9: f1 - 0.772252; loss - 0.280938;\n",
    "===========================================================\n",
    "Epoch 080/096 - Mean training loss 0.082072; Mean training F1 0.938093; Mean validation loss 0.093451; Mean validation F1 0.937366; Learning rate 0.000038;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937366; loss - 0.093451;\n",
    "Group g4: f1 - 0.785429; loss - 0.277833;\n",
    "Group g9: f1 - 0.770293; loss - 0.280555;\n",
    "===========================================================\n",
    "Epoch 081/096 - Mean training loss 0.081896; Mean training F1 0.938147; Mean validation loss 0.093469; Mean validation F1 0.936902; Learning rate 0.000034;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936902; loss - 0.093469;\n",
    "Group g4: f1 - 0.784784; loss - 0.278152;\n",
    "Group g9: f1 - 0.770865; loss - 0.280966;\n",
    "===========================================================\n",
    "Epoch 082/096 - Mean training loss 0.082216; Mean training F1 0.938231; Mean validation loss 0.093677; Mean validation F1 0.936926; Learning rate 0.000031;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936926; loss - 0.093677;\n",
    "Group g4: f1 - 0.783346; loss - 0.278240;\n",
    "Group g9: f1 - 0.767361; loss - 0.281264;\n",
    "===========================================================\n",
    "Epoch 083/096 - Mean training loss 0.082308; Mean training F1 0.938312; Mean validation loss 0.093548; Mean validation F1 0.937267; Learning rate 0.000027;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937267; loss - 0.093548;\n",
    "Group g4: f1 - 0.782591; loss - 0.277780;\n",
    "Group g9: f1 - 0.767342; loss - 0.280558;\n",
    "===========================================================\n",
    "Epoch 084/096 - Mean training loss 0.081863; Mean training F1 0.938279; Mean validation loss 0.093245; Mean validation F1 0.937330; Learning rate 0.000024;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937330; loss - 0.093245;\n",
    "Group g4: f1 - 0.786358; loss - 0.277847;\n",
    "Group g9: f1 - 0.774353; loss - 0.280428;\n",
    "===========================================================\n",
    "Epoch 085/096 - Mean training loss 0.082186; Mean training F1 0.938291; Mean validation loss 0.093488; Mean validation F1 0.936983; Learning rate 0.000021;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936983; loss - 0.093488;\n",
    "Group g4: f1 - 0.783135; loss - 0.277853;\n",
    "Group g9: f1 - 0.768891; loss - 0.280649;\n",
    "===========================================================\n",
    "Epoch 086/096 - Mean training loss 0.082088; Mean training F1 0.938119; Mean validation loss 0.093331; Mean validation F1 0.937082; Learning rate 0.000018;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937082; loss - 0.093331;\n",
    "Group g4: f1 - 0.780842; loss - 0.277787;\n",
    "Group g9: f1 - 0.766310; loss - 0.280600;\n",
    "===========================================================\n",
    "Epoch 087/096 - Mean training loss 0.081906; Mean training F1 0.938251; Mean validation loss 0.093522; Mean validation F1 0.937114; Learning rate 0.000016;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937114; loss - 0.093522;\n",
    "Group g4: f1 - 0.785188; loss - 0.277824;\n",
    "Group g9: f1 - 0.769878; loss - 0.280751;\n",
    "===========================================================\n",
    "Epoch 088/096 - Mean training loss 0.081814; Mean training F1 0.938282; Mean validation loss 0.093209; Mean validation F1 0.937330; Learning rate 0.000014;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937330; loss - 0.093209;\n",
    "Group g4: f1 - 0.784121; loss - 0.277747;\n",
    "Group g9: f1 - 0.772818; loss - 0.280415;\n",
    "===========================================================\n",
    "Epoch 089/096 - Mean training loss 0.082022; Mean training F1 0.938378; Mean validation loss 0.093249; Mean validation F1 0.937191; Learning rate 0.000012;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937191; loss - 0.093249;\n",
    "Group g4: f1 - 0.784276; loss - 0.277725;\n",
    "Group g9: f1 - 0.773646; loss - 0.280348;\n",
    "===========================================================\n",
    "Epoch 090/096 - Mean training loss 0.082106; Mean training F1 0.938261; Mean validation loss 0.093332; Mean validation F1 0.937098; Learning rate 0.000010;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937098; loss - 0.093332;\n",
    "Group g4: f1 - 0.784168; loss - 0.277742;\n",
    "Group g9: f1 - 0.772200; loss - 0.280505;\n",
    "===========================================================\n",
    "Epoch 091/096 - Mean training loss 0.082060; Mean training F1 0.938209; Mean validation loss 0.093271; Mean validation F1 0.937174; Learning rate 0.000008;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937174; loss - 0.093271;\n",
    "Group g4: f1 - 0.787384; loss - 0.277720;\n",
    "Group g9: f1 - 0.773132; loss - 0.280322;\n",
    "===========================================================\n",
    "Epoch 092/096 - Mean training loss 0.081804; Mean training F1 0.938250; Mean validation loss 0.093299; Mean validation F1 0.937183; Learning rate 0.000007;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937183; loss - 0.093299;\n",
    "Group g4: f1 - 0.784592; loss - 0.277646;\n",
    "Group g9: f1 - 0.771839; loss - 0.280345;\n",
    "===========================================================\n",
    "Epoch 093/096 - Mean training loss 0.082024; Mean training F1 0.938258; Mean validation loss 0.093186; Mean validation F1 0.937114; Learning rate 0.000006;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937114; loss - 0.093186;\n",
    "Group g4: f1 - 0.787165; loss - 0.277632;\n",
    "Group g9: f1 - 0.775609; loss - 0.280294;\n",
    "===========================================================\n",
    "Epoch 094/096 - Mean training loss 0.081500; Mean training F1 0.938390; Mean validation loss 0.093232; Mean validation F1 0.937166; Learning rate 0.000006;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937166; loss - 0.093232;\n",
    "Group g4: f1 - 0.785115; loss - 0.277731;\n",
    "Group g9: f1 - 0.772650; loss - 0.280450;\n",
    "===========================================================\n",
    "Epoch 095/096 - Mean training loss 0.082024; Mean training F1 0.938224; Mean validation loss 0.093324; Mean validation F1 0.937077; Learning rate 0.000005;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937077; loss - 0.093324;\n",
    "Group g4: f1 - 0.783672; loss - 0.277665;\n",
    "Group g9: f1 - 0.771715; loss - 0.280457;\n",
    "===========================================================\n",
    "Epoch 096/096 - Mean training loss 0.081671; Mean training F1 0.938488; Mean validation loss 0.093132; Mean validation F1 0.937122; Learning rate 0.000005;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937122; loss - 0.093132;\n",
    "Group g4: f1 - 0.785461; loss - 0.277590;\n",
    "Group g9: f1 - 0.773601; loss - 0.280268;\n",
    "################################################################\n",
    "Training/validation for fold 3/5;\n",
    "===========================================================\n",
    "Epoch 001/096 - Mean training loss 0.763121; Mean training F1 0.651667; Mean validation loss 0.439208; Mean validation F1 0.818756; Learning rate 0.000500;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.818756; loss - 0.439208;\n",
    "Group g4: f1 - 0.368737; loss - 0.873856;\n",
    "Group g9: f1 - 0.367032; loss - 0.893864;\n",
    "===========================================================\n",
    "Epoch 002/096 - Mean training loss 0.282316; Mean training F1 0.865026; Mean validation loss 0.212589; Mean validation F1 0.889604; Learning rate 0.000500;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.889604; loss - 0.212589;\n",
    "Group g4: f1 - 0.452410; loss - 0.543957;\n",
    "Group g9: f1 - 0.448206; loss - 0.568592;\n",
    "===========================================================\n",
    "Epoch 003/096 - Mean training loss 0.187870; Mean training F1 0.899551; Mean validation loss 0.186499; Mean validation F1 0.891912; Learning rate 0.000499;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.891912; loss - 0.186499;\n",
    "Group g4: f1 - 0.539770; loss - 0.420241;\n",
    "Group g9: f1 - 0.533693; loss - 0.438170;\n",
    "===========================================================\n",
    "Epoch 004/096 - Mean training loss 0.168252; Mean training F1 0.906559; Mean validation loss 0.159783; Mean validation F1 0.912169; Learning rate 0.000498;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.912169; loss - 0.159783;\n",
    "Group g4: f1 - 0.598601; loss - 0.321097;\n",
    "Group g9: f1 - 0.598414; loss - 0.325421;\n",
    "===========================================================\n",
    "Epoch 005/096 - Mean training loss 0.161611; Mean training F1 0.907188; Mean validation loss 0.136787; Mean validation F1 0.919610; Learning rate 0.000497;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.919610; loss - 0.136787;\n",
    "Group g4: f1 - 0.566500; loss - 0.397347;\n",
    "Group g9: f1 - 0.561545; loss - 0.413932;\n",
    "===========================================================\n",
    "Epoch 006/096 - Mean training loss 0.139504; Mean training F1 0.915523; Mean validation loss 0.122223; Mean validation F1 0.927004; Learning rate 0.000496;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.927004; loss - 0.122223;\n",
    "Group g4: f1 - 0.589323; loss - 0.356764;\n",
    "Group g9: f1 - 0.585634; loss - 0.367656;\n",
    "===========================================================\n",
    "Epoch 007/096 - Mean training loss 0.129724; Mean training F1 0.920022; Mean validation loss 0.123147; Mean validation F1 0.924263; Learning rate 0.000494;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.924263; loss - 0.123147;\n",
    "Group g4: f1 - 0.624232; loss - 0.320478;\n",
    "Group g9: f1 - 0.622819; loss - 0.324413;\n",
    "===========================================================\n",
    "Epoch 008/096 - Mean training loss 0.126556; Mean training F1 0.921260; Mean validation loss 0.186368; Mean validation F1 0.904181; Learning rate 0.000492;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.904181; loss - 0.186368;\n",
    "Group g4: f1 - 0.610036; loss - 0.333681;\n",
    "Group g9: f1 - 0.606637; loss - 0.340709;\n",
    "===========================================================\n",
    "Epoch 009/096 - Mean training loss 0.129213; Mean training F1 0.920160; Mean validation loss 0.116067; Mean validation F1 0.928616; Learning rate 0.000490;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.928616; loss - 0.116067;\n",
    "Group g4: f1 - 0.636354; loss - 0.315635;\n",
    "Group g9: f1 - 0.634294; loss - 0.321603;\n",
    "===========================================================\n",
    "Epoch 010/096 - Mean training loss 0.127516; Mean training F1 0.921083; Mean validation loss 0.116430; Mean validation F1 0.926868; Learning rate 0.000487;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.926868; loss - 0.116430;\n",
    "Group g4: f1 - 0.617814; loss - 0.339946;\n",
    "Group g9: f1 - 0.612607; loss - 0.348987;\n",
    "===========================================================\n",
    "Epoch 011/096 - Mean training loss 0.119297; Mean training F1 0.924229; Mean validation loss 0.140841; Mean validation F1 0.920519; Learning rate 0.000484;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.920519; loss - 0.140841;\n",
    "Group g4: f1 - 0.628910; loss - 0.318926;\n",
    "Group g9: f1 - 0.626935; loss - 0.323802;\n",
    "===========================================================\n",
    "Epoch 012/096 - Mean training loss 0.119592; Mean training F1 0.924248; Mean validation loss 0.107431; Mean validation F1 0.931392; Learning rate 0.000481;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931392; loss - 0.107431;\n",
    "Group g4: f1 - 0.647982; loss - 0.307665;\n",
    "Group g9: f1 - 0.646025; loss - 0.312555;\n",
    "===========================================================\n",
    "Epoch 013/096 - Mean training loss 0.116346; Mean training F1 0.925138; Mean validation loss 0.115815; Mean validation F1 0.927936; Learning rate 0.000478;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.927936; loss - 0.115815;\n",
    "Group g4: f1 - 0.631011; loss - 0.332561;\n",
    "Group g9: f1 - 0.623329; loss - 0.343833;\n",
    "===========================================================\n",
    "Epoch 014/096 - Mean training loss 0.132605; Mean training F1 0.919430; Mean validation loss 0.107483; Mean validation F1 0.931709; Learning rate 0.000475;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931709; loss - 0.107483;\n",
    "Group g4: f1 - 0.641405; loss - 0.314489;\n",
    "Group g9: f1 - 0.639110; loss - 0.319983;\n",
    "===========================================================\n",
    "Epoch 015/096 - Mean training loss 0.115243; Mean training F1 0.926352; Mean validation loss 0.115345; Mean validation F1 0.927272; Learning rate 0.000471;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.927272; loss - 0.115345;\n",
    "Group g4: f1 - 0.666317; loss - 0.313022;\n",
    "Group g9: f1 - 0.662124; loss - 0.314270;\n",
    "===========================================================\n",
    "Epoch 016/096 - Mean training loss 0.105748; Mean training F1 0.929342; Mean validation loss 0.394229; Mean validation F1 0.802684; Learning rate 0.000467;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.802684; loss - 0.394229;\n",
    "Group g4: f1 - 0.678990; loss - 0.298350;\n",
    "Group g9: f1 - 0.675545; loss - 0.301330;\n",
    "===========================================================\n",
    "Epoch 017/096 - Mean training loss 0.103378; Mean training F1 0.930275; Mean validation loss 0.101326; Mean validation F1 0.932891; Learning rate 0.000463;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.932891; loss - 0.101326;\n",
    "Group g4: f1 - 0.693252; loss - 0.293312;\n",
    "Group g9: f1 - 0.683749; loss - 0.296256;\n",
    "===========================================================\n",
    "Epoch 018/096 - Mean training loss 0.099343; Mean training F1 0.931188; Mean validation loss 0.108995; Mean validation F1 0.930217; Learning rate 0.000459;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.930217; loss - 0.108995;\n",
    "Group g4: f1 - 0.695898; loss - 0.294831;\n",
    "Group g9: f1 - 0.687659; loss - 0.298409;\n",
    "===========================================================\n",
    "Epoch 019/096 - Mean training loss 0.107831; Mean training F1 0.928727; Mean validation loss 0.102767; Mean validation F1 0.931771; Learning rate 0.000454;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931771; loss - 0.102767;\n",
    "Group g4: f1 - 0.687896; loss - 0.296793;\n",
    "Group g9: f1 - 0.679876; loss - 0.300145;\n",
    "===========================================================\n",
    "Epoch 020/096 - Mean training loss 0.096623; Mean training F1 0.932942; Mean validation loss 0.099227; Mean validation F1 0.934775; Learning rate 0.000449;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934775; loss - 0.099227;\n",
    "Group g4: f1 - 0.708594; loss - 0.285521;\n",
    "Group g9: f1 - 0.703271; loss - 0.288325;\n",
    "===========================================================\n",
    "Epoch 021/096 - Mean training loss 0.094730; Mean training F1 0.932642; Mean validation loss 0.100734; Mean validation F1 0.931117; Learning rate 0.000444;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931117; loss - 0.100734;\n",
    "Group g4: f1 - 0.704017; loss - 0.299325;\n",
    "Group g9: f1 - 0.696257; loss - 0.302317;\n",
    "===========================================================\n",
    "Epoch 022/096 - Mean training loss 0.096006; Mean training F1 0.932115; Mean validation loss 0.100226; Mean validation F1 0.931210; Learning rate 0.000439;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931210; loss - 0.100226;\n",
    "Group g4: f1 - 0.704143; loss - 0.294030;\n",
    "Group g9: f1 - 0.699104; loss - 0.297427;\n",
    "===========================================================\n",
    "Epoch 023/096 - Mean training loss 0.094215; Mean training F1 0.933678; Mean validation loss 0.095137; Mean validation F1 0.935016; Learning rate 0.000433;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935016; loss - 0.095137;\n",
    "Group g4: f1 - 0.708215; loss - 0.287446;\n",
    "Group g9: f1 - 0.700964; loss - 0.290268;\n",
    "===========================================================\n",
    "Epoch 024/096 - Mean training loss 0.093915; Mean training F1 0.933854; Mean validation loss 0.097429; Mean validation F1 0.934220; Learning rate 0.000428;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934220; loss - 0.097429;\n",
    "Group g4: f1 - 0.693121; loss - 0.293853;\n",
    "Group g9: f1 - 0.686533; loss - 0.296263;\n",
    "===========================================================\n",
    "Epoch 025/096 - Mean training loss 0.093110; Mean training F1 0.934348; Mean validation loss 0.093093; Mean validation F1 0.935935; Learning rate 0.000422;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935935; loss - 0.093093;\n",
    "Group g4: f1 - 0.710746; loss - 0.283154;\n",
    "Group g9: f1 - 0.707929; loss - 0.285843;\n",
    "===========================================================\n",
    "Epoch 026/096 - Mean training loss 0.092065; Mean training F1 0.934043; Mean validation loss 0.096251; Mean validation F1 0.933936; Learning rate 0.000416;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933936; loss - 0.096251;\n",
    "Group g4: f1 - 0.716212; loss - 0.292726;\n",
    "Group g9: f1 - 0.708154; loss - 0.295684;\n",
    "===========================================================\n",
    "Epoch 027/096 - Mean training loss 0.091340; Mean training F1 0.934554; Mean validation loss 0.093307; Mean validation F1 0.935896; Learning rate 0.000410;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935896; loss - 0.093307;\n",
    "Group g4: f1 - 0.712156; loss - 0.284571;\n",
    "Group g9: f1 - 0.707662; loss - 0.286779;\n",
    "===========================================================\n",
    "Epoch 028/096 - Mean training loss 0.089714; Mean training F1 0.935395; Mean validation loss 0.093174; Mean validation F1 0.935538; Learning rate 0.000403;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935538; loss - 0.093174;\n",
    "Group g4: f1 - 0.710534; loss - 0.285474;\n",
    "Group g9: f1 - 0.708746; loss - 0.287728;\n",
    "===========================================================\n",
    "Epoch 029/096 - Mean training loss 0.090377; Mean training F1 0.934932; Mean validation loss 0.093497; Mean validation F1 0.936005; Learning rate 0.000397;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936005; loss - 0.093497;\n",
    "Group g4: f1 - 0.714713; loss - 0.282062;\n",
    "Group g9: f1 - 0.711131; loss - 0.284769;\n",
    "===========================================================\n",
    "Epoch 030/096 - Mean training loss 0.089126; Mean training F1 0.936015; Mean validation loss 0.092483; Mean validation F1 0.936064; Learning rate 0.000390;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936064; loss - 0.092483;\n",
    "Group g4: f1 - 0.711854; loss - 0.281855;\n",
    "Group g9: f1 - 0.707193; loss - 0.284326;\n",
    "===========================================================\n",
    "Epoch 031/096 - Mean training loss 0.089114; Mean training F1 0.935527; Mean validation loss 0.094139; Mean validation F1 0.934266; Learning rate 0.000383;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934266; loss - 0.094139;\n",
    "Group g4: f1 - 0.727105; loss - 0.284528;\n",
    "Group g9: f1 - 0.725811; loss - 0.287640;\n",
    "===========================================================\n",
    "Epoch 032/096 - Mean training loss 0.088792; Mean training F1 0.935752; Mean validation loss 0.095592; Mean validation F1 0.933836; Learning rate 0.000377;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933836; loss - 0.095592;\n",
    "Group g4: f1 - 0.711615; loss - 0.285606;\n",
    "Group g9: f1 - 0.708254; loss - 0.288770;\n",
    "===========================================================\n",
    "Epoch 033/096 - Mean training loss 0.088127; Mean training F1 0.935746; Mean validation loss 0.092883; Mean validation F1 0.935965; Learning rate 0.000369;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935965; loss - 0.092883;\n",
    "Group g4: f1 - 0.711570; loss - 0.282751;\n",
    "Group g9: f1 - 0.707583; loss - 0.285285;\n",
    "===========================================================\n",
    "Epoch 034/096 - Mean training loss 0.087335; Mean training F1 0.936338; Mean validation loss 0.092473; Mean validation F1 0.936186; Learning rate 0.000362;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936186; loss - 0.092473;\n",
    "Group g4: f1 - 0.717232; loss - 0.281465;\n",
    "Group g9: f1 - 0.712951; loss - 0.284027;\n",
    "===========================================================\n",
    "Epoch 035/096 - Mean training loss 0.088211; Mean training F1 0.935822; Mean validation loss 0.091986; Mean validation F1 0.936235; Learning rate 0.000355;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936235; loss - 0.091986;\n",
    "Group g4: f1 - 0.715165; loss - 0.280801;\n",
    "Group g9: f1 - 0.717951; loss - 0.283225;\n",
    "===========================================================\n",
    "Epoch 036/096 - Mean training loss 0.086668; Mean training F1 0.936531; Mean validation loss 0.091844; Mean validation F1 0.936065; Learning rate 0.000347;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936065; loss - 0.091844;\n",
    "Group g4: f1 - 0.724600; loss - 0.280832;\n",
    "Group g9: f1 - 0.721214; loss - 0.283492;\n",
    "===========================================================\n",
    "Epoch 037/096 - Mean training loss 0.087786; Mean training F1 0.935973; Mean validation loss 0.096714; Mean validation F1 0.934343; Learning rate 0.000340;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934343; loss - 0.096714;\n",
    "Group g4: f1 - 0.751414; loss - 0.289998;\n",
    "Group g9: f1 - 0.746021; loss - 0.292324;\n",
    "===========================================================\n",
    "Epoch 038/096 - Mean training loss 0.089766; Mean training F1 0.934609; Mean validation loss 0.094805; Mean validation F1 0.935155; Learning rate 0.000332;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935155; loss - 0.094805;\n",
    "Group g4: f1 - 0.715719; loss - 0.282764;\n",
    "Group g9: f1 - 0.714403; loss - 0.284958;\n",
    "===========================================================\n",
    "Epoch 039/096 - Mean training loss 0.089015; Mean training F1 0.935102; Mean validation loss 0.091925; Mean validation F1 0.935882; Learning rate 0.000325;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935882; loss - 0.091925;\n",
    "Group g4: f1 - 0.717465; loss - 0.280585;\n",
    "Group g9: f1 - 0.713416; loss - 0.283275;\n",
    "===========================================================\n",
    "Epoch 040/096 - Mean training loss 0.087428; Mean training F1 0.935816; Mean validation loss 0.097656; Mean validation F1 0.934533; Learning rate 0.000317;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934533; loss - 0.097656;\n",
    "Group g4: f1 - 0.714200; loss - 0.286712;\n",
    "Group g9: f1 - 0.702775; loss - 0.290294;\n",
    "===========================================================\n",
    "Epoch 041/096 - Mean training loss 0.086756; Mean training F1 0.936587; Mean validation loss 0.092496; Mean validation F1 0.935253; Learning rate 0.000309;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935253; loss - 0.092496;\n",
    "Group g4: f1 - 0.726321; loss - 0.284118;\n",
    "Group g9: f1 - 0.719890; loss - 0.286743;\n",
    "===========================================================\n",
    "Epoch 042/096 - Mean training loss 0.085489; Mean training F1 0.936924; Mean validation loss 0.092787; Mean validation F1 0.935810; Learning rate 0.000301;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935810; loss - 0.092787;\n",
    "Group g4: f1 - 0.713859; loss - 0.281602;\n",
    "Group g9: f1 - 0.710005; loss - 0.284251;\n",
    "===========================================================\n",
    "Epoch 043/096 - Mean training loss 0.085801; Mean training F1 0.936403; Mean validation loss 0.091789; Mean validation F1 0.935992; Learning rate 0.000293;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935992; loss - 0.091789;\n",
    "Group g4: f1 - 0.725210; loss - 0.281812;\n",
    "Group g9: f1 - 0.719397; loss - 0.284305;\n",
    "===========================================================\n",
    "Epoch 044/096 - Mean training loss 0.085651; Mean training F1 0.937095; Mean validation loss 0.092181; Mean validation F1 0.936086; Learning rate 0.000285;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936086; loss - 0.092181;\n",
    "Group g4: f1 - 0.715989; loss - 0.279924;\n",
    "Group g9: f1 - 0.713401; loss - 0.282530;\n",
    "===========================================================\n",
    "Epoch 045/096 - Mean training loss 0.085003; Mean training F1 0.937093; Mean validation loss 0.092563; Mean validation F1 0.935776; Learning rate 0.000277;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935776; loss - 0.092563;\n",
    "Group g4: f1 - 0.734201; loss - 0.281114;\n",
    "Group g9: f1 - 0.725760; loss - 0.283321;\n",
    "===========================================================\n",
    "Epoch 046/096 - Mean training loss 0.085175; Mean training F1 0.937069; Mean validation loss 0.093085; Mean validation F1 0.935551; Learning rate 0.000269;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935551; loss - 0.093085;\n",
    "Group g4: f1 - 0.742920; loss - 0.281643;\n",
    "Group g9: f1 - 0.732222; loss - 0.283836;\n",
    "===========================================================\n",
    "Epoch 047/096 - Mean training loss 0.085169; Mean training F1 0.937247; Mean validation loss 0.091469; Mean validation F1 0.935343; Learning rate 0.000261;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935343; loss - 0.091469;\n",
    "Group g4: f1 - 0.742591; loss - 0.282281;\n",
    "Group g9: f1 - 0.736273; loss - 0.284987;\n",
    "===========================================================\n",
    "Epoch 048/096 - Mean training loss 0.084743; Mean training F1 0.936985; Mean validation loss 0.091262; Mean validation F1 0.936372; Learning rate 0.000253;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936372; loss - 0.091262;\n",
    "Group g4: f1 - 0.758089; loss - 0.280420;\n",
    "Group g9: f1 - 0.747889; loss - 0.283227;\n",
    "===========================================================\n",
    "Epoch 049/096 - Mean training loss 0.085701; Mean training F1 0.936865; Mean validation loss 0.091528; Mean validation F1 0.936236; Learning rate 0.000245;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936236; loss - 0.091528;\n",
    "Group g4: f1 - 0.723169; loss - 0.281740;\n",
    "Group g9: f1 - 0.725987; loss - 0.284324;\n",
    "===========================================================\n",
    "Epoch 050/096 - Mean training loss 0.084871; Mean training F1 0.937122; Mean validation loss 0.090963; Mean validation F1 0.936594; Learning rate 0.000237;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936594; loss - 0.090963;\n",
    "Group g4: f1 - 0.754515; loss - 0.279256;\n",
    "Group g9: f1 - 0.746345; loss - 0.281676;\n",
    "===========================================================\n",
    "Epoch 051/096 - Mean training loss 0.084332; Mean training F1 0.937440; Mean validation loss 0.090908; Mean validation F1 0.936518; Learning rate 0.000228;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936518; loss - 0.090908;\n",
    "Group g4: f1 - 0.720564; loss - 0.279116;\n",
    "Group g9: f1 - 0.723478; loss - 0.281750;\n",
    "===========================================================\n",
    "Epoch 052/096 - Mean training loss 0.084592; Mean training F1 0.937289; Mean validation loss 0.090956; Mean validation F1 0.935929; Learning rate 0.000220;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935929; loss - 0.090956;\n",
    "Group g4: f1 - 0.743724; loss - 0.280022;\n",
    "Group g9: f1 - 0.731837; loss - 0.282433;\n",
    "===========================================================\n",
    "Epoch 053/096 - Mean training loss 0.084392; Mean training F1 0.937184; Mean validation loss 0.090715; Mean validation F1 0.936647; Learning rate 0.000212;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936647; loss - 0.090715;\n",
    "Group g4: f1 - 0.744029; loss - 0.278989;\n",
    "Group g9: f1 - 0.743503; loss - 0.281347;\n",
    "===========================================================\n",
    "Epoch 054/096 - Mean training loss 0.084835; Mean training F1 0.937524; Mean validation loss 0.091015; Mean validation F1 0.936567; Learning rate 0.000204;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936567; loss - 0.091015;\n",
    "Group g4: f1 - 0.738356; loss - 0.278523;\n",
    "Group g9: f1 - 0.726364; loss - 0.280844;\n",
    "===========================================================\n",
    "Epoch 055/096 - Mean training loss 0.084590; Mean training F1 0.937346; Mean validation loss 0.090732; Mean validation F1 0.936662; Learning rate 0.000197;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936662; loss - 0.090732;\n",
    "Group g4: f1 - 0.751382; loss - 0.280344;\n",
    "Group g9: f1 - 0.739551; loss - 0.282924;\n",
    "===========================================================\n",
    "Epoch 056/096 - Mean training loss 0.084276; Mean training F1 0.937465; Mean validation loss 0.090408; Mean validation F1 0.936439; Learning rate 0.000189;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936439; loss - 0.090408;\n",
    "Group g4: f1 - 0.756075; loss - 0.279476;\n",
    "Group g9: f1 - 0.750214; loss - 0.281789;\n",
    "===========================================================\n",
    "Epoch 057/096 - Mean training loss 0.084223; Mean training F1 0.937370; Mean validation loss 0.091209; Mean validation F1 0.936248; Learning rate 0.000181;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936248; loss - 0.091209;\n",
    "Group g4: f1 - 0.732439; loss - 0.281944;\n",
    "Group g9: f1 - 0.722680; loss - 0.284833;\n",
    "===========================================================\n",
    "Epoch 058/096 - Mean training loss 0.083964; Mean training F1 0.937634; Mean validation loss 0.090156; Mean validation F1 0.936546; Learning rate 0.000173;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936546; loss - 0.090156;\n",
    "Group g4: f1 - 0.730820; loss - 0.278500;\n",
    "Group g9: f1 - 0.729501; loss - 0.281198;\n",
    "===========================================================\n",
    "Epoch 059/096 - Mean training loss 0.083469; Mean training F1 0.937876; Mean validation loss 0.090849; Mean validation F1 0.936709; Learning rate 0.000166;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936709; loss - 0.090849;\n",
    "Group g4: f1 - 0.774300; loss - 0.278499;\n",
    "Group g9: f1 - 0.764758; loss - 0.280805;\n",
    "===========================================================\n",
    "Epoch 060/096 - Mean training loss 0.083261; Mean training F1 0.937955; Mean validation loss 0.090557; Mean validation F1 0.936648; Learning rate 0.000158;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936648; loss - 0.090557;\n",
    "Group g4: f1 - 0.733322; loss - 0.278596;\n",
    "Group g9: f1 - 0.729368; loss - 0.280986;\n",
    "===========================================================\n",
    "Epoch 061/096 - Mean training loss 0.083591; Mean training F1 0.937705; Mean validation loss 0.091256; Mean validation F1 0.935176; Learning rate 0.000151;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935176; loss - 0.091256;\n",
    "Group g4: f1 - 0.768677; loss - 0.282432;\n",
    "Group g9: f1 - 0.761013; loss - 0.285369;\n",
    "===========================================================\n",
    "Epoch 062/096 - Mean training loss 0.083197; Mean training F1 0.937961; Mean validation loss 0.090653; Mean validation F1 0.936640; Learning rate 0.000143;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936640; loss - 0.090653;\n",
    "Group g4: f1 - 0.770380; loss - 0.278204;\n",
    "Group g9: f1 - 0.758133; loss - 0.280378;\n",
    "===========================================================\n",
    "Epoch 063/096 - Mean training loss 0.082801; Mean training F1 0.938076; Mean validation loss 0.091017; Mean validation F1 0.936012; Learning rate 0.000136;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936012; loss - 0.091017;\n",
    "Group g4: f1 - 0.757073; loss - 0.279839;\n",
    "Group g9: f1 - 0.751203; loss - 0.282282;\n",
    "===========================================================\n",
    "Epoch 064/096 - Mean training loss 0.083138; Mean training F1 0.937628; Mean validation loss 0.091344; Mean validation F1 0.934535; Learning rate 0.000129;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934535; loss - 0.091344;\n",
    "Group g4: f1 - 0.752240; loss - 0.282839;\n",
    "Group g9: f1 - 0.749454; loss - 0.285341;\n",
    "===========================================================\n",
    "Epoch 065/096 - Mean training loss 0.083552; Mean training F1 0.937599; Mean validation loss 0.090180; Mean validation F1 0.936556; Learning rate 0.000122;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936556; loss - 0.090180;\n",
    "Group g4: f1 - 0.755304; loss - 0.279544;\n",
    "Group g9: f1 - 0.750759; loss - 0.281826;\n",
    "===========================================================\n",
    "Epoch 066/096 - Mean training loss 0.083203; Mean training F1 0.938064; Mean validation loss 0.089916; Mean validation F1 0.936573; Learning rate 0.000115;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936573; loss - 0.089916;\n",
    "Group g4: f1 - 0.755756; loss - 0.278072;\n",
    "Group g9: f1 - 0.752532; loss - 0.280517;\n",
    "===========================================================\n",
    "Epoch 067/096 - Mean training loss 0.083407; Mean training F1 0.937979; Mean validation loss 0.090944; Mean validation F1 0.936355; Learning rate 0.000109;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936355; loss - 0.090944;\n",
    "Group g4: f1 - 0.771388; loss - 0.279861;\n",
    "Group g9: f1 - 0.755444; loss - 0.281889;\n",
    "===========================================================\n",
    "Epoch 068/096 - Mean training loss 0.082854; Mean training F1 0.938158; Mean validation loss 0.090107; Mean validation F1 0.936771; Learning rate 0.000102;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936771; loss - 0.090107;\n",
    "Group g4: f1 - 0.754373; loss - 0.278021;\n",
    "Group g9: f1 - 0.746628; loss - 0.280334;\n",
    "===========================================================\n",
    "Epoch 069/096 - Mean training loss 0.082858; Mean training F1 0.937930; Mean validation loss 0.090889; Mean validation F1 0.936504; Learning rate 0.000096;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936504; loss - 0.090889;\n",
    "Group g4: f1 - 0.783718; loss - 0.278234;\n",
    "Group g9: f1 - 0.771671; loss - 0.280523;\n",
    "===========================================================\n",
    "Epoch 070/096 - Mean training loss 0.082711; Mean training F1 0.938289; Mean validation loss 0.090374; Mean validation F1 0.936853; Learning rate 0.000090;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936853; loss - 0.090374;\n",
    "Group g4: f1 - 0.752686; loss - 0.279016;\n",
    "Group g9: f1 - 0.748181; loss - 0.280924;\n",
    "===========================================================\n",
    "Epoch 071/096 - Mean training loss 0.082626; Mean training F1 0.938248; Mean validation loss 0.089997; Mean validation F1 0.936952; Learning rate 0.000084;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936952; loss - 0.089997;\n",
    "Group g4: f1 - 0.780429; loss - 0.277730;\n",
    "Group g9: f1 - 0.776273; loss - 0.280067;\n",
    "===========================================================\n",
    "Epoch 072/096 - Mean training loss 0.082625; Mean training F1 0.938292; Mean validation loss 0.089650; Mean validation F1 0.936859; Learning rate 0.000078;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936859; loss - 0.089650;\n",
    "Group g4: f1 - 0.755977; loss - 0.277983;\n",
    "Group g9: f1 - 0.747109; loss - 0.280282;\n",
    "===========================================================\n",
    "Epoch 073/096 - Mean training loss 0.081870; Mean training F1 0.938378; Mean validation loss 0.089480; Mean validation F1 0.936804; Learning rate 0.000072;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936804; loss - 0.089480;\n",
    "Group g4: f1 - 0.766774; loss - 0.277456;\n",
    "Group g9: f1 - 0.754243; loss - 0.279714;\n",
    "===========================================================\n",
    "Epoch 074/096 - Mean training loss 0.082178; Mean training F1 0.938322; Mean validation loss 0.089881; Mean validation F1 0.936714; Learning rate 0.000067;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936714; loss - 0.089881;\n",
    "Group g4: f1 - 0.751721; loss - 0.278111;\n",
    "Group g9: f1 - 0.750363; loss - 0.280579;\n",
    "===========================================================\n",
    "Epoch 075/096 - Mean training loss 0.081955; Mean training F1 0.938359; Mean validation loss 0.089601; Mean validation F1 0.936831; Learning rate 0.000061;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936831; loss - 0.089601;\n",
    "Group g4: f1 - 0.773679; loss - 0.277708;\n",
    "Group g9: f1 - 0.757559; loss - 0.280000;\n",
    "===========================================================\n",
    "Epoch 076/096 - Mean training loss 0.082182; Mean training F1 0.938111; Mean validation loss 0.090243; Mean validation F1 0.936768; Learning rate 0.000056;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936768; loss - 0.090243;\n",
    "Group g4: f1 - 0.754395; loss - 0.278543;\n",
    "Group g9: f1 - 0.750843; loss - 0.280620;\n",
    "===========================================================\n",
    "Epoch 077/096 - Mean training loss 0.082109; Mean training F1 0.938275; Mean validation loss 0.089808; Mean validation F1 0.936839; Learning rate 0.000052;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936839; loss - 0.089808;\n",
    "Group g4: f1 - 0.775652; loss - 0.277568;\n",
    "Group g9: f1 - 0.770004; loss - 0.279808;\n",
    "===========================================================\n",
    "Epoch 078/096 - Mean training loss 0.081843; Mean training F1 0.938506; Mean validation loss 0.089674; Mean validation F1 0.936999; Learning rate 0.000047;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936999; loss - 0.089674;\n",
    "Group g4: f1 - 0.773136; loss - 0.278315;\n",
    "Group g9: f1 - 0.758667; loss - 0.280300;\n",
    "===========================================================\n",
    "Epoch 079/096 - Mean training loss 0.081952; Mean training F1 0.938619; Mean validation loss 0.089442; Mean validation F1 0.937100; Learning rate 0.000043;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937100; loss - 0.089442;\n",
    "Group g4: f1 - 0.764251; loss - 0.277472;\n",
    "Group g9: f1 - 0.752675; loss - 0.279666;\n",
    "===========================================================\n",
    "Epoch 080/096 - Mean training loss 0.081843; Mean training F1 0.938560; Mean validation loss 0.089405; Mean validation F1 0.937219; Learning rate 0.000038;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937219; loss - 0.089405;\n",
    "Group g4: f1 - 0.781267; loss - 0.277192;\n",
    "Group g9: f1 - 0.773821; loss - 0.279453;\n",
    "===========================================================\n",
    "Epoch 081/096 - Mean training loss 0.081932; Mean training F1 0.938442; Mean validation loss 0.089455; Mean validation F1 0.937088; Learning rate 0.000034;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937088; loss - 0.089455;\n",
    "Group g4: f1 - 0.760891; loss - 0.277321;\n",
    "Group g9: f1 - 0.754650; loss - 0.279521;\n",
    "===========================================================\n",
    "Epoch 082/096 - Mean training loss 0.081946; Mean training F1 0.938520; Mean validation loss 0.089686; Mean validation F1 0.936787; Learning rate 0.000031;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936787; loss - 0.089686;\n",
    "Group g4: f1 - 0.768456; loss - 0.277504;\n",
    "Group g9: f1 - 0.754730; loss - 0.279650;\n",
    "===========================================================\n",
    "Epoch 083/096 - Mean training loss 0.081809; Mean training F1 0.938632; Mean validation loss 0.089661; Mean validation F1 0.936767; Learning rate 0.000027;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936767; loss - 0.089661;\n",
    "Group g4: f1 - 0.775076; loss - 0.277264;\n",
    "Group g9: f1 - 0.759358; loss - 0.279510;\n",
    "===========================================================\n",
    "Epoch 084/096 - Mean training loss 0.082025; Mean training F1 0.938617; Mean validation loss 0.089576; Mean validation F1 0.936804; Learning rate 0.000024;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936804; loss - 0.089576;\n",
    "Group g4: f1 - 0.766471; loss - 0.277215;\n",
    "Group g9: f1 - 0.754442; loss - 0.279575;\n",
    "===========================================================\n",
    "Epoch 085/096 - Mean training loss 0.081770; Mean training F1 0.938545; Mean validation loss 0.089482; Mean validation F1 0.937004; Learning rate 0.000021;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937004; loss - 0.089482;\n",
    "Group g4: f1 - 0.768192; loss - 0.277272;\n",
    "Group g9: f1 - 0.756775; loss - 0.279574;\n",
    "===========================================================\n",
    "Epoch 086/096 - Mean training loss 0.082049; Mean training F1 0.938675; Mean validation loss 0.089323; Mean validation F1 0.937247; Learning rate 0.000018;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937247; loss - 0.089323;\n",
    "Group g4: f1 - 0.766870; loss - 0.277343;\n",
    "Group g9: f1 - 0.755098; loss - 0.279549;\n",
    "===========================================================\n",
    "Epoch 087/096 - Mean training loss 0.081720; Mean training F1 0.938628; Mean validation loss 0.089366; Mean validation F1 0.937067; Learning rate 0.000016;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937067; loss - 0.089366;\n",
    "Group g4: f1 - 0.768210; loss - 0.277146;\n",
    "Group g9: f1 - 0.757358; loss - 0.279427;\n",
    "===========================================================\n",
    "Epoch 088/096 - Mean training loss 0.081698; Mean training F1 0.938520; Mean validation loss 0.089337; Mean validation F1 0.937125; Learning rate 0.000014;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937125; loss - 0.089337;\n",
    "Group g4: f1 - 0.777746; loss - 0.277042;\n",
    "Group g9: f1 - 0.765157; loss - 0.279262;\n",
    "===========================================================\n",
    "Epoch 089/096 - Mean training loss 0.081350; Mean training F1 0.938597; Mean validation loss 0.089308; Mean validation F1 0.937154; Learning rate 0.000012;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937154; loss - 0.089308;\n",
    "Group g4: f1 - 0.780909; loss - 0.277053;\n",
    "Group g9: f1 - 0.769567; loss - 0.279251;\n",
    "===========================================================\n",
    "Epoch 090/096 - Mean training loss 0.081429; Mean training F1 0.938712; Mean validation loss 0.089331; Mean validation F1 0.936999; Learning rate 0.000010;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936999; loss - 0.089331;\n",
    "Group g4: f1 - 0.772259; loss - 0.277096;\n",
    "Group g9: f1 - 0.759098; loss - 0.279333;\n",
    "===========================================================\n",
    "Epoch 091/096 - Mean training loss 0.081488; Mean training F1 0.938667; Mean validation loss 0.089301; Mean validation F1 0.937055; Learning rate 0.000008;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937055; loss - 0.089301;\n",
    "Group g4: f1 - 0.775225; loss - 0.277012;\n",
    "Group g9: f1 - 0.762479; loss - 0.279256;\n",
    "===========================================================\n",
    "Epoch 092/096 - Mean training loss 0.081629; Mean training F1 0.938743; Mean validation loss 0.089242; Mean validation F1 0.937133; Learning rate 0.000007;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937133; loss - 0.089242;\n",
    "Group g4: f1 - 0.776288; loss - 0.277087;\n",
    "Group g9: f1 - 0.759885; loss - 0.279289;\n",
    "===========================================================\n",
    "Epoch 093/096 - Mean training loss 0.081478; Mean training F1 0.938664; Mean validation loss 0.089282; Mean validation F1 0.937092; Learning rate 0.000006;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937092; loss - 0.089282;\n",
    "Group g4: f1 - 0.781195; loss - 0.277002;\n",
    "Group g9: f1 - 0.767320; loss - 0.279259;\n",
    "===========================================================\n",
    "Epoch 094/096 - Mean training loss 0.081592; Mean training F1 0.938732; Mean validation loss 0.089270; Mean validation F1 0.937224; Learning rate 0.000006;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937224; loss - 0.089270;\n",
    "Group g4: f1 - 0.777476; loss - 0.277021;\n",
    "Group g9: f1 - 0.762275; loss - 0.279261;\n",
    "===========================================================\n",
    "Epoch 095/096 - Mean training loss 0.081449; Mean training F1 0.938688; Mean validation loss 0.089372; Mean validation F1 0.936938; Learning rate 0.000005;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936938; loss - 0.089372;\n",
    "Group g4: f1 - 0.775657; loss - 0.277110;\n",
    "Group g9: f1 - 0.759711; loss - 0.279339;\n",
    "===========================================================\n",
    "Epoch 096/096 - Mean training loss 0.081612; Mean training F1 0.938587; Mean validation loss 0.089373; Mean validation F1 0.936973; Learning rate 0.000005;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936973; loss - 0.089373;\n",
    "Group g4: f1 - 0.769138; loss - 0.277306;\n",
    "Group g9: f1 - 0.756243; loss - 0.279592;\n",
    "################################################################\n",
    "Training/validation for fold 4/5;\n",
    "===========================================================\n",
    "Epoch 001/096 - Mean training loss 0.828376; Mean training F1 0.608460; Mean validation loss 0.440400; Mean validation F1 0.802206; Learning rate 0.000500;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.802206; loss - 0.440400;\n",
    "Group g4: f1 - 0.343679; loss - 1.084616;\n",
    "Group g9: f1 - 0.341812; loss - 1.108076;\n",
    "===========================================================\n",
    "Epoch 002/096 - Mean training loss 0.373437; Mean training F1 0.820623; Mean validation loss 0.348472; Mean validation F1 0.833253; Learning rate 0.000500;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.833253; loss - 0.348472;\n",
    "Group g4: f1 - 0.412482; loss - 0.884425;\n",
    "Group g9: f1 - 0.409672; loss - 0.927701;\n",
    "===========================================================\n",
    "Epoch 003/096 - Mean training loss 0.199103; Mean training F1 0.898350; Mean validation loss 0.139642; Mean validation F1 0.926736; Learning rate 0.000499;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.926736; loss - 0.139642;\n",
    "Group g4: f1 - 0.541499; loss - 0.358742;\n",
    "Group g9: f1 - 0.541085; loss - 0.363672;\n",
    "===========================================================\n",
    "Epoch 004/096 - Mean training loss 0.162731; Mean training F1 0.906045; Mean validation loss 0.151242; Mean validation F1 0.905035; Learning rate 0.000498;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.905035; loss - 0.151242;\n",
    "Group g4: f1 - 0.599907; loss - 0.361671;\n",
    "Group g9: f1 - 0.599514; loss - 0.364506;\n",
    "===========================================================\n",
    "Epoch 005/096 - Mean training loss 0.142507; Mean training F1 0.914643; Mean validation loss 0.129440; Mean validation F1 0.923343; Learning rate 0.000497;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.923343; loss - 0.129440;\n",
    "Group g4: f1 - 0.620804; loss - 0.320251;\n",
    "Group g9: f1 - 0.619406; loss - 0.323827;\n",
    "===========================================================\n",
    "Epoch 006/096 - Mean training loss 0.127031; Mean training F1 0.921668; Mean validation loss 0.106292; Mean validation F1 0.931646; Learning rate 0.000496;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931646; loss - 0.106292;\n",
    "Group g4: f1 - 0.642163; loss - 0.301685;\n",
    "Group g9: f1 - 0.638474; loss - 0.305116;\n",
    "===========================================================\n",
    "Epoch 007/096 - Mean training loss 0.120549; Mean training F1 0.924268; Mean validation loss 0.102646; Mean validation F1 0.931098; Learning rate 0.000494;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931098; loss - 0.102646;\n",
    "Group g4: f1 - 0.646372; loss - 0.321590;\n",
    "Group g9: f1 - 0.638554; loss - 0.325988;\n",
    "===========================================================\n",
    "Epoch 008/096 - Mean training loss 0.124866; Mean training F1 0.922359; Mean validation loss 0.135330; Mean validation F1 0.926101; Learning rate 0.000492;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.926101; loss - 0.135330;\n",
    "Group g4: f1 - 0.680779; loss - 0.301691;\n",
    "Group g9: f1 - 0.675560; loss - 0.304859;\n",
    "===========================================================\n",
    "Epoch 009/096 - Mean training loss 0.116918; Mean training F1 0.925602; Mean validation loss 0.114802; Mean validation F1 0.928012; Learning rate 0.000490;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.928012; loss - 0.114802;\n",
    "Group g4: f1 - 0.670434; loss - 0.305421;\n",
    "Group g9: f1 - 0.660841; loss - 0.309420;\n",
    "===========================================================\n",
    "Epoch 010/096 - Mean training loss 0.115021; Mean training F1 0.925952; Mean validation loss 2.404871; Mean validation F1 0.489846; Learning rate 0.000487;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.489846; loss - 2.404871;\n",
    "Group g4: f1 - 0.680490; loss - 0.325735;\n",
    "Group g9: f1 - 0.674325; loss - 0.328552;\n",
    "===========================================================\n",
    "Epoch 011/096 - Mean training loss 0.107227; Mean training F1 0.928963; Mean validation loss 0.097242; Mean validation F1 0.934442; Learning rate 0.000484;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934442; loss - 0.097242;\n",
    "Group g4: f1 - 0.713061; loss - 0.290957;\n",
    "Group g9: f1 - 0.707796; loss - 0.294117;\n",
    "===========================================================\n",
    "Epoch 012/096 - Mean training loss 0.109651; Mean training F1 0.928263; Mean validation loss 0.097253; Mean validation F1 0.934621; Learning rate 0.000481;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934621; loss - 0.097253;\n",
    "Group g4: f1 - 0.702873; loss - 0.291976;\n",
    "Group g9: f1 - 0.695107; loss - 0.295204;\n",
    "===========================================================\n",
    "Epoch 013/096 - Mean training loss 0.110779; Mean training F1 0.927550; Mean validation loss 0.102554; Mean validation F1 0.929709; Learning rate 0.000478;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.929709; loss - 0.102554;\n",
    "Group g4: f1 - 0.706475; loss - 0.313570;\n",
    "Group g9: f1 - 0.693699; loss - 0.317047;\n",
    "===========================================================\n",
    "Epoch 014/096 - Mean training loss 0.110215; Mean training F1 0.926437; Mean validation loss 0.170352; Mean validation F1 0.907000; Learning rate 0.000475;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.907000; loss - 0.170352;\n",
    "Group g4: f1 - 0.514842; loss - 0.587897;\n",
    "Group g9: f1 - 0.514606; loss - 0.589411;\n",
    "===========================================================\n",
    "Epoch 015/096 - Mean training loss 0.101766; Mean training F1 0.930120; Mean validation loss 0.091356; Mean validation F1 0.935484; Learning rate 0.000471;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935484; loss - 0.091356;\n",
    "Group g4: f1 - 0.712428; loss - 0.296605;\n",
    "Group g9: f1 - 0.701779; loss - 0.299067;\n",
    "===========================================================\n",
    "Epoch 016/096 - Mean training loss 0.098343; Mean training F1 0.932345; Mean validation loss 0.089654; Mean validation F1 0.936864; Learning rate 0.000467;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936864; loss - 0.089654;\n",
    "Group g4: f1 - 0.711002; loss - 0.289892;\n",
    "Group g9: f1 - 0.702850; loss - 0.292439;\n",
    "===========================================================\n",
    "Epoch 017/096 - Mean training loss 0.099583; Mean training F1 0.931819; Mean validation loss 0.093460; Mean validation F1 0.935579; Learning rate 0.000463;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935579; loss - 0.093460;\n",
    "Group g4: f1 - 0.725490; loss - 0.288695;\n",
    "Group g9: f1 - 0.717856; loss - 0.291942;\n",
    "===========================================================\n",
    "Epoch 018/096 - Mean training loss 0.100859; Mean training F1 0.930947; Mean validation loss 0.117047; Mean validation F1 0.926712; Learning rate 0.000459;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.926712; loss - 0.117047;\n",
    "Group g4: f1 - 0.692249; loss - 0.308851;\n",
    "Group g9: f1 - 0.688536; loss - 0.314350;\n",
    "===========================================================\n",
    "Epoch 019/096 - Mean training loss 0.103416; Mean training F1 0.928335; Mean validation loss 0.093287; Mean validation F1 0.934776; Learning rate 0.000454;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934776; loss - 0.093287;\n",
    "Group g4: f1 - 0.717024; loss - 0.299373;\n",
    "Group g9: f1 - 0.706566; loss - 0.301034;\n",
    "===========================================================\n",
    "Epoch 020/096 - Mean training loss 0.098919; Mean training F1 0.931361; Mean validation loss 0.099526; Mean validation F1 0.933095; Learning rate 0.000449;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933095; loss - 0.099526;\n",
    "Group g4: f1 - 0.718908; loss - 0.293227;\n",
    "Group g9: f1 - 0.712206; loss - 0.295479;\n",
    "===========================================================\n",
    "Epoch 021/096 - Mean training loss 0.097177; Mean training F1 0.932304; Mean validation loss 0.091287; Mean validation F1 0.935421; Learning rate 0.000444;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935421; loss - 0.091287;\n",
    "Group g4: f1 - 0.735125; loss - 0.292373;\n",
    "Group g9: f1 - 0.721373; loss - 0.295048;\n",
    "===========================================================\n",
    "Epoch 022/096 - Mean training loss 0.094180; Mean training F1 0.933789; Mean validation loss 0.094847; Mean validation F1 0.934689; Learning rate 0.000439;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934689; loss - 0.094847;\n",
    "Group g4: f1 - 0.731815; loss - 0.290206;\n",
    "Group g9: f1 - 0.717216; loss - 0.293181;\n",
    "===========================================================\n",
    "Epoch 023/096 - Mean training loss 0.094780; Mean training F1 0.933268; Mean validation loss 0.095626; Mean validation F1 0.932719; Learning rate 0.000433;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.932719; loss - 0.095626;\n",
    "Group g4: f1 - 0.739740; loss - 0.300241;\n",
    "Group g9: f1 - 0.718689; loss - 0.303552;\n",
    "===========================================================\n",
    "Epoch 024/096 - Mean training loss 0.093577; Mean training F1 0.933893; Mean validation loss 0.088495; Mean validation F1 0.937003; Learning rate 0.000428;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937003; loss - 0.088495;\n",
    "Group g4: f1 - 0.737394; loss - 0.284402;\n",
    "Group g9: f1 - 0.719529; loss - 0.287231;\n",
    "===========================================================\n",
    "Epoch 025/096 - Mean training loss 0.093720; Mean training F1 0.933924; Mean validation loss 0.098426; Mean validation F1 0.934389; Learning rate 0.000422;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934389; loss - 0.098426;\n",
    "Group g4: f1 - 0.723612; loss - 0.287197;\n",
    "Group g9: f1 - 0.706482; loss - 0.290484;\n",
    "===========================================================\n",
    "Epoch 026/096 - Mean training loss 0.094228; Mean training F1 0.933200; Mean validation loss 0.137893; Mean validation F1 0.916006; Learning rate 0.000416;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.916006; loss - 0.137893;\n",
    "Group g4: f1 - 0.654074; loss - 0.339767;\n",
    "Group g9: f1 - 0.653633; loss - 0.345256;\n",
    "===========================================================\n",
    "Epoch 027/096 - Mean training loss 0.094479; Mean training F1 0.933297; Mean validation loss 0.087432; Mean validation F1 0.937607; Learning rate 0.000410;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937607; loss - 0.087432;\n",
    "Group g4: f1 - 0.755222; loss - 0.282933;\n",
    "Group g9: f1 - 0.742345; loss - 0.285895;\n",
    "===========================================================\n",
    "Epoch 028/096 - Mean training loss 0.090814; Mean training F1 0.934794; Mean validation loss 0.086897; Mean validation F1 0.938149; Learning rate 0.000403;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938149; loss - 0.086897;\n",
    "Group g4: f1 - 0.756935; loss - 0.282302;\n",
    "Group g9: f1 - 0.738813; loss - 0.284975;\n",
    "===========================================================\n",
    "Epoch 029/096 - Mean training loss 0.089442; Mean training F1 0.935321; Mean validation loss 0.087365; Mean validation F1 0.937725; Learning rate 0.000397;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937725; loss - 0.087365;\n",
    "Group g4: f1 - 0.743678; loss - 0.282739;\n",
    "Group g9: f1 - 0.730569; loss - 0.285794;\n",
    "===========================================================\n",
    "Epoch 030/096 - Mean training loss 0.090245; Mean training F1 0.934920; Mean validation loss 0.088026; Mean validation F1 0.937327; Learning rate 0.000390;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937327; loss - 0.088026;\n",
    "Group g4: f1 - 0.728622; loss - 0.282234;\n",
    "Group g9: f1 - 0.719682; loss - 0.284920;\n",
    "===========================================================\n",
    "Epoch 031/096 - Mean training loss 0.090473; Mean training F1 0.934403; Mean validation loss 0.100122; Mean validation F1 0.932622; Learning rate 0.000383;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.932622; loss - 0.100122;\n",
    "Group g4: f1 - 0.703344; loss - 0.292989;\n",
    "Group g9: f1 - 0.692193; loss - 0.296439;\n",
    "===========================================================\n",
    "Epoch 032/096 - Mean training loss 0.091783; Mean training F1 0.934491; Mean validation loss 0.095310; Mean validation F1 0.934462; Learning rate 0.000377;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934462; loss - 0.095310;\n",
    "Group g4: f1 - 0.733006; loss - 0.291397;\n",
    "Group g9: f1 - 0.717239; loss - 0.293482;\n",
    "===========================================================\n",
    "Epoch 033/096 - Mean training loss 0.092651; Mean training F1 0.934390; Mean validation loss 0.104866; Mean validation F1 0.931324; Learning rate 0.000369;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931324; loss - 0.104866;\n",
    "Group g4: f1 - 0.739362; loss - 0.287242;\n",
    "Group g9: f1 - 0.726360; loss - 0.289947;\n",
    "===========================================================\n",
    "Epoch 034/096 - Mean training loss 0.088995; Mean training F1 0.935152; Mean validation loss 0.088715; Mean validation F1 0.937509; Learning rate 0.000362;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937509; loss - 0.088715;\n",
    "Group g4: f1 - 0.740544; loss - 0.283257;\n",
    "Group g9: f1 - 0.721466; loss - 0.285741;\n",
    "===========================================================\n",
    "Epoch 035/096 - Mean training loss 0.088420; Mean training F1 0.935386; Mean validation loss 0.086983; Mean validation F1 0.937841; Learning rate 0.000355;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937841; loss - 0.086983;\n",
    "Group g4: f1 - 0.762707; loss - 0.282150;\n",
    "Group g9: f1 - 0.748288; loss - 0.284975;\n",
    "===========================================================\n",
    "Epoch 036/096 - Mean training loss 0.087188; Mean training F1 0.936351; Mean validation loss 0.090161; Mean validation F1 0.936892; Learning rate 0.000347;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936892; loss - 0.090161;\n",
    "Group g4: f1 - 0.736244; loss - 0.285868;\n",
    "Group g9: f1 - 0.719937; loss - 0.288863;\n",
    "===========================================================\n",
    "Epoch 037/096 - Mean training loss 0.088649; Mean training F1 0.935136; Mean validation loss 0.087971; Mean validation F1 0.937307; Learning rate 0.000340;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937307; loss - 0.087971;\n",
    "Group g4: f1 - 0.750111; loss - 0.282686;\n",
    "Group g9: f1 - 0.737386; loss - 0.285514;\n",
    "===========================================================\n",
    "Epoch 038/096 - Mean training loss 0.087702; Mean training F1 0.935922; Mean validation loss 0.090684; Mean validation F1 0.936600; Learning rate 0.000332;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936600; loss - 0.090684;\n",
    "Group g4: f1 - 0.746063; loss - 0.287718;\n",
    "Group g9: f1 - 0.735456; loss - 0.290850;\n",
    "===========================================================\n",
    "Epoch 039/096 - Mean training loss 0.088065; Mean training F1 0.935978; Mean validation loss 0.087109; Mean validation F1 0.937678; Learning rate 0.000325;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937678; loss - 0.087109;\n",
    "Group g4: f1 - 0.766433; loss - 0.280920;\n",
    "Group g9: f1 - 0.759310; loss - 0.283913;\n",
    "===========================================================\n",
    "Epoch 040/096 - Mean training loss 0.087166; Mean training F1 0.936266; Mean validation loss 0.086332; Mean validation F1 0.938094; Learning rate 0.000317;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938094; loss - 0.086332;\n",
    "Group g4: f1 - 0.755231; loss - 0.280599;\n",
    "Group g9: f1 - 0.739341; loss - 0.283861;\n",
    "===========================================================\n",
    "Epoch 041/096 - Mean training loss 0.086903; Mean training F1 0.936356; Mean validation loss 0.087416; Mean validation F1 0.937073; Learning rate 0.000309;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937073; loss - 0.087416;\n",
    "Group g4: f1 - 0.750294; loss - 0.281785;\n",
    "Group g9: f1 - 0.740994; loss - 0.284332;\n",
    "===========================================================\n",
    "Epoch 042/096 - Mean training loss 0.087332; Mean training F1 0.935760; Mean validation loss 0.087173; Mean validation F1 0.936812; Learning rate 0.000301;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936812; loss - 0.087173;\n",
    "Group g4: f1 - 0.770723; loss - 0.283496;\n",
    "Group g9: f1 - 0.762861; loss - 0.286455;\n",
    "===========================================================\n",
    "Epoch 043/096 - Mean training loss 0.086717; Mean training F1 0.936469; Mean validation loss 0.085518; Mean validation F1 0.938513; Learning rate 0.000293;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938513; loss - 0.085518;\n",
    "Group g4: f1 - 0.760095; loss - 0.280506;\n",
    "Group g9: f1 - 0.754954; loss - 0.283219;\n",
    "===========================================================\n",
    "Epoch 044/096 - Mean training loss 0.086163; Mean training F1 0.936667; Mean validation loss 0.087563; Mean validation F1 0.937911; Learning rate 0.000285;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937911; loss - 0.087563;\n",
    "Group g4: f1 - 0.753694; loss - 0.281690;\n",
    "Group g9: f1 - 0.741345; loss - 0.284648;\n",
    "===========================================================\n",
    "Epoch 045/096 - Mean training loss 0.087472; Mean training F1 0.935941; Mean validation loss 0.086045; Mean validation F1 0.937937; Learning rate 0.000277;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937937; loss - 0.086045;\n",
    "Group g4: f1 - 0.749625; loss - 0.281642;\n",
    "Group g9: f1 - 0.735262; loss - 0.284616;\n",
    "===========================================================\n",
    "Epoch 046/096 - Mean training loss 0.086613; Mean training F1 0.936322; Mean validation loss 0.087488; Mean validation F1 0.937775; Learning rate 0.000269;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937775; loss - 0.087488;\n",
    "Group g4: f1 - 0.733131; loss - 0.284237;\n",
    "Group g9: f1 - 0.723455; loss - 0.287511;\n",
    "===========================================================\n",
    "Epoch 047/096 - Mean training loss 0.086167; Mean training F1 0.936517; Mean validation loss 0.085623; Mean validation F1 0.938456; Learning rate 0.000261;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938456; loss - 0.085623;\n",
    "Group g4: f1 - 0.769135; loss - 0.279103;\n",
    "Group g9: f1 - 0.762429; loss - 0.282024;\n",
    "===========================================================\n",
    "Epoch 048/096 - Mean training loss 0.086643; Mean training F1 0.936672; Mean validation loss 0.087728; Mean validation F1 0.937762; Learning rate 0.000253;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937762; loss - 0.087728;\n",
    "Group g4: f1 - 0.778670; loss - 0.280579;\n",
    "Group g9: f1 - 0.779678; loss - 0.282919;\n",
    "===========================================================\n",
    "Epoch 049/096 - Mean training loss 0.086075; Mean training F1 0.936532; Mean validation loss 0.086300; Mean validation F1 0.937657; Learning rate 0.000245;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937657; loss - 0.086300;\n",
    "Group g4: f1 - 0.761645; loss - 0.281932;\n",
    "Group g9: f1 - 0.755490; loss - 0.284771;\n",
    "===========================================================\n",
    "Epoch 050/096 - Mean training loss 0.085732; Mean training F1 0.936443; Mean validation loss 0.085411; Mean validation F1 0.938407; Learning rate 0.000237;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938407; loss - 0.085411;\n",
    "Group g4: f1 - 0.760762; loss - 0.279232;\n",
    "Group g9: f1 - 0.751932; loss - 0.282112;\n",
    "===========================================================\n",
    "Epoch 051/096 - Mean training loss 0.085109; Mean training F1 0.937090; Mean validation loss 0.085870; Mean validation F1 0.938157; Learning rate 0.000228;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938157; loss - 0.085870;\n",
    "Group g4: f1 - 0.768599; loss - 0.281529;\n",
    "Group g9: f1 - 0.765603; loss - 0.284592;\n",
    "===========================================================\n",
    "Epoch 052/096 - Mean training loss 0.085128; Mean training F1 0.937066; Mean validation loss 0.086412; Mean validation F1 0.937913; Learning rate 0.000220;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937913; loss - 0.086412;\n",
    "Group g4: f1 - 0.778488; loss - 0.281503;\n",
    "Group g9: f1 - 0.771481; loss - 0.284725;\n",
    "===========================================================\n",
    "Epoch 053/096 - Mean training loss 0.084827; Mean training F1 0.937225; Mean validation loss 0.085234; Mean validation F1 0.938475; Learning rate 0.000212;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938475; loss - 0.085234;\n",
    "Group g4: f1 - 0.775659; loss - 0.278931;\n",
    "Group g9: f1 - 0.777545; loss - 0.281821;\n",
    "===========================================================\n",
    "Epoch 054/096 - Mean training loss 0.085315; Mean training F1 0.936951; Mean validation loss 0.085768; Mean validation F1 0.937992; Learning rate 0.000204;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937992; loss - 0.085768;\n",
    "Group g4: f1 - 0.769022; loss - 0.281596;\n",
    "Group g9: f1 - 0.763662; loss - 0.284633;\n",
    "===========================================================\n",
    "Epoch 055/096 - Mean training loss 0.085617; Mean training F1 0.936820; Mean validation loss 0.086157; Mean validation F1 0.938143; Learning rate 0.000197;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938143; loss - 0.086157;\n",
    "Group g4: f1 - 0.773388; loss - 0.280368;\n",
    "Group g9: f1 - 0.765624; loss - 0.282975;\n",
    "===========================================================\n",
    "Epoch 056/096 - Mean training loss 0.084118; Mean training F1 0.937479; Mean validation loss 0.085094; Mean validation F1 0.938559; Learning rate 0.000189;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938559; loss - 0.085094;\n",
    "Group g4: f1 - 0.778183; loss - 0.280294;\n",
    "Group g9: f1 - 0.779217; loss - 0.282834;\n",
    "===========================================================\n",
    "Epoch 057/096 - Mean training loss 0.085055; Mean training F1 0.937097; Mean validation loss 0.085441; Mean validation F1 0.938512; Learning rate 0.000181;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938512; loss - 0.085441;\n",
    "Group g4: f1 - 0.759269; loss - 0.280303;\n",
    "Group g9: f1 - 0.749727; loss - 0.283076;\n",
    "===========================================================\n",
    "Epoch 058/096 - Mean training loss 0.084277; Mean training F1 0.937339; Mean validation loss 0.085528; Mean validation F1 0.938348; Learning rate 0.000173;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938348; loss - 0.085528;\n",
    "Group g4: f1 - 0.776594; loss - 0.279428;\n",
    "Group g9: f1 - 0.771821; loss - 0.281967;\n",
    "===========================================================\n",
    "Epoch 059/096 - Mean training loss 0.084251; Mean training F1 0.937300; Mean validation loss 0.085153; Mean validation F1 0.938357; Learning rate 0.000166;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938357; loss - 0.085153;\n",
    "Group g4: f1 - 0.781441; loss - 0.279376;\n",
    "Group g9: f1 - 0.781209; loss - 0.282035;\n",
    "===========================================================\n",
    "Epoch 060/096 - Mean training loss 0.083886; Mean training F1 0.937542; Mean validation loss 0.085566; Mean validation F1 0.938544; Learning rate 0.000158;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938544; loss - 0.085566;\n",
    "Group g4: f1 - 0.772280; loss - 0.280207;\n",
    "Group g9: f1 - 0.767989; loss - 0.282795;\n",
    "===========================================================\n",
    "Epoch 061/096 - Mean training loss 0.084108; Mean training F1 0.937602; Mean validation loss 0.086061; Mean validation F1 0.938213; Learning rate 0.000151;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938213; loss - 0.086061;\n",
    "Group g4: f1 - 0.776371; loss - 0.279735;\n",
    "Group g9: f1 - 0.769024; loss - 0.282276;\n",
    "===========================================================\n",
    "Epoch 062/096 - Mean training loss 0.084097; Mean training F1 0.937476; Mean validation loss 0.085517; Mean validation F1 0.938526; Learning rate 0.000143;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938526; loss - 0.085517;\n",
    "Group g4: f1 - 0.775341; loss - 0.278346;\n",
    "Group g9: f1 - 0.774471; loss - 0.281198;\n",
    "===========================================================\n",
    "Epoch 063/096 - Mean training loss 0.084091; Mean training F1 0.937433; Mean validation loss 0.085208; Mean validation F1 0.938806; Learning rate 0.000136;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938806; loss - 0.085208;\n",
    "Group g4: f1 - 0.785944; loss - 0.278450;\n",
    "Group g9: f1 - 0.781310; loss - 0.281249;\n",
    "===========================================================\n",
    "Epoch 064/096 - Mean training loss 0.083447; Mean training F1 0.937755; Mean validation loss 0.084868; Mean validation F1 0.938724; Learning rate 0.000129;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938724; loss - 0.084868;\n",
    "Group g4: f1 - 0.789052; loss - 0.279053;\n",
    "Group g9: f1 - 0.782612; loss - 0.281726;\n",
    "===========================================================\n",
    "Epoch 065/096 - Mean training loss 0.083602; Mean training F1 0.937523; Mean validation loss 0.084810; Mean validation F1 0.938778; Learning rate 0.000122;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938778; loss - 0.084810;\n",
    "Group g4: f1 - 0.784390; loss - 0.278967;\n",
    "Group g9: f1 - 0.782253; loss - 0.281777;\n",
    "===========================================================\n",
    "Epoch 066/096 - Mean training loss 0.084223; Mean training F1 0.937323; Mean validation loss 0.085028; Mean validation F1 0.938272; Learning rate 0.000115;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938272; loss - 0.085028;\n",
    "Group g4: f1 - 0.776178; loss - 0.279587;\n",
    "Group g9: f1 - 0.776761; loss - 0.282265;\n",
    "===========================================================\n",
    "Epoch 067/096 - Mean training loss 0.083848; Mean training F1 0.937526; Mean validation loss 0.084909; Mean validation F1 0.938674; Learning rate 0.000109;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938674; loss - 0.084909;\n",
    "Group g4: f1 - 0.785551; loss - 0.278135;\n",
    "Group g9: f1 - 0.782090; loss - 0.280882;\n",
    "===========================================================\n",
    "Epoch 068/096 - Mean training loss 0.083687; Mean training F1 0.937668; Mean validation loss 0.085199; Mean validation F1 0.938296; Learning rate 0.000102;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938296; loss - 0.085199;\n",
    "Group g4: f1 - 0.785257; loss - 0.280024;\n",
    "Group g9: f1 - 0.781609; loss - 0.282648;\n",
    "===========================================================\n",
    "Epoch 069/096 - Mean training loss 0.083265; Mean training F1 0.937892; Mean validation loss 0.084666; Mean validation F1 0.938777; Learning rate 0.000096;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938777; loss - 0.084666;\n",
    "Group g4: f1 - 0.785877; loss - 0.278664;\n",
    "Group g9: f1 - 0.780476; loss - 0.281448;\n",
    "===========================================================\n",
    "Epoch 070/096 - Mean training loss 0.083358; Mean training F1 0.937690; Mean validation loss 0.084515; Mean validation F1 0.938757; Learning rate 0.000090;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938757; loss - 0.084515;\n",
    "Group g4: f1 - 0.784436; loss - 0.278635;\n",
    "Group g9: f1 - 0.781293; loss - 0.281236;\n",
    "===========================================================\n",
    "Epoch 071/096 - Mean training loss 0.083324; Mean training F1 0.937900; Mean validation loss 0.084495; Mean validation F1 0.938676; Learning rate 0.000084;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938676; loss - 0.084495;\n",
    "Group g4: f1 - 0.784894; loss - 0.277811;\n",
    "Group g9: f1 - 0.782472; loss - 0.280532;\n",
    "===========================================================\n",
    "Epoch 072/096 - Mean training loss 0.083556; Mean training F1 0.937710; Mean validation loss 0.085285; Mean validation F1 0.938390; Learning rate 0.000078;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938390; loss - 0.085285;\n",
    "Group g4: f1 - 0.780280; loss - 0.279706;\n",
    "Group g9: f1 - 0.779551; loss - 0.282252;\n",
    "===========================================================\n",
    "Epoch 073/096 - Mean training loss 0.083376; Mean training F1 0.937684; Mean validation loss 0.084703; Mean validation F1 0.938649; Learning rate 0.000072;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938649; loss - 0.084703;\n",
    "Group g4: f1 - 0.779311; loss - 0.278000;\n",
    "Group g9: f1 - 0.776967; loss - 0.280857;\n",
    "===========================================================\n",
    "Epoch 074/096 - Mean training loss 0.083676; Mean training F1 0.937795; Mean validation loss 0.084381; Mean validation F1 0.938838; Learning rate 0.000067;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938838; loss - 0.084381;\n",
    "Group g4: f1 - 0.781805; loss - 0.277780;\n",
    "Group g9: f1 - 0.781110; loss - 0.280622;\n",
    "===========================================================\n",
    "Epoch 075/096 - Mean training loss 0.082879; Mean training F1 0.938086; Mean validation loss 0.084463; Mean validation F1 0.938432; Learning rate 0.000061;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938432; loss - 0.084463;\n",
    "Group g4: f1 - 0.783683; loss - 0.278319;\n",
    "Group g9: f1 - 0.780469; loss - 0.281143;\n",
    "===========================================================\n",
    "Epoch 076/096 - Mean training loss 0.082735; Mean training F1 0.938079; Mean validation loss 0.084443; Mean validation F1 0.938853; Learning rate 0.000056;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938853; loss - 0.084443;\n",
    "Group g4: f1 - 0.783079; loss - 0.277537;\n",
    "Group g9: f1 - 0.778288; loss - 0.280346;\n",
    "===========================================================\n",
    "Epoch 077/096 - Mean training loss 0.083050; Mean training F1 0.937956; Mean validation loss 0.084424; Mean validation F1 0.938834; Learning rate 0.000052;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938834; loss - 0.084424;\n",
    "Group g4: f1 - 0.786344; loss - 0.277735;\n",
    "Group g9: f1 - 0.781882; loss - 0.280450;\n",
    "===========================================================\n",
    "Epoch 078/096 - Mean training loss 0.082931; Mean training F1 0.938151; Mean validation loss 0.084659; Mean validation F1 0.938501; Learning rate 0.000047;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938501; loss - 0.084659;\n",
    "Group g4: f1 - 0.785237; loss - 0.278455;\n",
    "Group g9: f1 - 0.779484; loss - 0.281354;\n",
    "===========================================================\n",
    "Epoch 079/096 - Mean training loss 0.083704; Mean training F1 0.937950; Mean validation loss 0.084332; Mean validation F1 0.938759; Learning rate 0.000043;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938759; loss - 0.084332;\n",
    "Group g4: f1 - 0.785787; loss - 0.277595;\n",
    "Group g9: f1 - 0.781515; loss - 0.280346;\n",
    "===========================================================\n",
    "Epoch 080/096 - Mean training loss 0.082652; Mean training F1 0.938057; Mean validation loss 0.084257; Mean validation F1 0.938990; Learning rate 0.000038;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938990; loss - 0.084257;\n",
    "Group g4: f1 - 0.787578; loss - 0.277399;\n",
    "Group g9: f1 - 0.782087; loss - 0.280228;\n",
    "===========================================================\n",
    "Epoch 081/096 - Mean training loss 0.082725; Mean training F1 0.938156; Mean validation loss 0.084208; Mean validation F1 0.938835; Learning rate 0.000034;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938835; loss - 0.084208;\n",
    "Group g4: f1 - 0.787273; loss - 0.277531;\n",
    "Group g9: f1 - 0.782497; loss - 0.280220;\n",
    "===========================================================\n",
    "Epoch 082/096 - Mean training loss 0.082534; Mean training F1 0.938348; Mean validation loss 0.084128; Mean validation F1 0.939026; Learning rate 0.000031;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939026; loss - 0.084128;\n",
    "Group g4: f1 - 0.785810; loss - 0.277289;\n",
    "Group g9: f1 - 0.781504; loss - 0.280091;\n",
    "===========================================================\n",
    "Epoch 083/096 - Mean training loss 0.082947; Mean training F1 0.938039; Mean validation loss 0.084173; Mean validation F1 0.938953; Learning rate 0.000027;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938953; loss - 0.084173;\n",
    "Group g4: f1 - 0.785834; loss - 0.277402;\n",
    "Group g9: f1 - 0.780187; loss - 0.280119;\n",
    "===========================================================\n",
    "Epoch 084/096 - Mean training loss 0.082653; Mean training F1 0.938146; Mean validation loss 0.084313; Mean validation F1 0.938890; Learning rate 0.000024;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938890; loss - 0.084313;\n",
    "Group g4: f1 - 0.782721; loss - 0.277708;\n",
    "Group g9: f1 - 0.779235; loss - 0.280502;\n",
    "===========================================================\n",
    "Epoch 085/096 - Mean training loss 0.082315; Mean training F1 0.938281; Mean validation loss 0.084111; Mean validation F1 0.938954; Learning rate 0.000021;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938954; loss - 0.084111;\n",
    "Group g4: f1 - 0.784384; loss - 0.277414;\n",
    "Group g9: f1 - 0.780349; loss - 0.280042;\n",
    "===========================================================\n",
    "Epoch 086/096 - Mean training loss 0.082220; Mean training F1 0.938328; Mean validation loss 0.084181; Mean validation F1 0.938894; Learning rate 0.000018;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938894; loss - 0.084181;\n",
    "Group g4: f1 - 0.785521; loss - 0.277489;\n",
    "Group g9: f1 - 0.781167; loss - 0.280129;\n",
    "===========================================================\n",
    "Epoch 087/096 - Mean training loss 0.082571; Mean training F1 0.938208; Mean validation loss 0.084171; Mean validation F1 0.939015; Learning rate 0.000016;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939015; loss - 0.084171;\n",
    "Group g4: f1 - 0.785547; loss - 0.277296;\n",
    "Group g9: f1 - 0.781538; loss - 0.280064;\n",
    "===========================================================\n",
    "Epoch 088/096 - Mean training loss 0.082506; Mean training F1 0.938316; Mean validation loss 0.084111; Mean validation F1 0.938995; Learning rate 0.000014;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938995; loss - 0.084111;\n",
    "Group g4: f1 - 0.787596; loss - 0.277191;\n",
    "Group g9: f1 - 0.782514; loss - 0.279971;\n",
    "===========================================================\n",
    "Epoch 089/096 - Mean training loss 0.082322; Mean training F1 0.938271; Mean validation loss 0.084097; Mean validation F1 0.938870; Learning rate 0.000012;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938870; loss - 0.084097;\n",
    "Group g4: f1 - 0.786815; loss - 0.277338;\n",
    "Group g9: f1 - 0.781919; loss - 0.280076;\n",
    "===========================================================\n",
    "Epoch 090/096 - Mean training loss 0.082298; Mean training F1 0.938242; Mean validation loss 0.084236; Mean validation F1 0.938933; Learning rate 0.000010;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938933; loss - 0.084236;\n",
    "Group g4: f1 - 0.785724; loss - 0.277398;\n",
    "Group g9: f1 - 0.780982; loss - 0.280179;\n",
    "===========================================================\n",
    "Epoch 091/096 - Mean training loss 0.082510; Mean training F1 0.938259; Mean validation loss 0.084109; Mean validation F1 0.938925; Learning rate 0.000008;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938925; loss - 0.084109;\n",
    "Group g4: f1 - 0.787394; loss - 0.277268;\n",
    "Group g9: f1 - 0.781174; loss - 0.279956;\n",
    "===========================================================\n",
    "Epoch 092/096 - Mean training loss 0.082251; Mean training F1 0.938225; Mean validation loss 0.084135; Mean validation F1 0.938817; Learning rate 0.000007;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938817; loss - 0.084135;\n",
    "Group g4: f1 - 0.786250; loss - 0.277336;\n",
    "Group g9: f1 - 0.780782; loss - 0.280134;\n",
    "===========================================================\n",
    "Epoch 093/096 - Mean training loss 0.082791; Mean training F1 0.938199; Mean validation loss 0.084181; Mean validation F1 0.938910; Learning rate 0.000006;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938910; loss - 0.084181;\n",
    "Group g4: f1 - 0.786771; loss - 0.277564;\n",
    "Group g9: f1 - 0.782277; loss - 0.280171;\n",
    "===========================================================\n",
    "Epoch 094/096 - Mean training loss 0.082220; Mean training F1 0.938203; Mean validation loss 0.084108; Mean validation F1 0.938956; Learning rate 0.000006;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938956; loss - 0.084108;\n",
    "Group g4: f1 - 0.787427; loss - 0.277244;\n",
    "Group g9: f1 - 0.782651; loss - 0.279986;\n",
    "===========================================================\n",
    "Epoch 095/096 - Mean training loss 0.082316; Mean training F1 0.938287; Mean validation loss 0.084085; Mean validation F1 0.939013; Learning rate 0.000005;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939013; loss - 0.084085;\n",
    "Group g4: f1 - 0.787304; loss - 0.277262;\n",
    "Group g9: f1 - 0.781566; loss - 0.279992;\n",
    "===========================================================\n",
    "Epoch 096/096 - Mean training loss 0.082662; Mean training F1 0.938171; Mean validation loss 0.084059; Mean validation F1 0.938969; Learning rate 0.000005;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938969; loss - 0.084059;\n",
    "Group g4: f1 - 0.786394; loss - 0.277261;\n",
    "Group g9: f1 - 0.781229; loss - 0.279963;\n",
    "################################################################\n",
    "Training/validation for fold 5/5;\n",
    "===========================================================\n",
    "Epoch 001/096 - Mean training loss 0.800548; Mean training F1 0.629282; Mean validation loss 0.416050; Mean validation F1 0.818935; Learning rate 0.000500;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.818935; loss - 0.416050;\n",
    "Group g4: f1 - 0.347898; loss - 1.104749;\n",
    "Group g9: f1 - 0.346212; loss - 1.129152;\n",
    "===========================================================\n",
    "Epoch 002/096 - Mean training loss 0.336249; Mean training F1 0.843611; Mean validation loss 0.461732; Mean validation F1 0.745215; Learning rate 0.000500;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.745215; loss - 0.461732;\n",
    "Group g4: f1 - 0.441388; loss - 0.570159;\n",
    "Group g9: f1 - 0.442009; loss - 0.581138;\n",
    "===========================================================\n",
    "Epoch 003/096 - Mean training loss 0.209880; Mean training F1 0.891944; Mean validation loss 0.227745; Mean validation F1 0.879912; Learning rate 0.000499;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.879912; loss - 0.227745;\n",
    "Group g4: f1 - 0.442768; loss - 0.793730;\n",
    "Group g9: f1 - 0.439896; loss - 0.849435;\n",
    "===========================================================\n",
    "Epoch 004/096 - Mean training loss 0.191312; Mean training F1 0.898865; Mean validation loss 0.151676; Mean validation F1 0.910112; Learning rate 0.000498;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.910112; loss - 0.151676;\n",
    "Group g4: f1 - 0.539970; loss - 0.411177;\n",
    "Group g9: f1 - 0.535631; loss - 0.422998;\n",
    "===========================================================\n",
    "Epoch 005/096 - Mean training loss 0.156647; Mean training F1 0.907477; Mean validation loss 0.132471; Mean validation F1 0.920890; Learning rate 0.000497;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.920890; loss - 0.132471;\n",
    "Group g4: f1 - 0.549881; loss - 0.420711;\n",
    "Group g9: f1 - 0.541450; loss - 0.450333;\n",
    "===========================================================\n",
    "Epoch 006/096 - Mean training loss 0.140766; Mean training F1 0.914932; Mean validation loss 0.121113; Mean validation F1 0.925246; Learning rate 0.000496;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.925246; loss - 0.121113;\n",
    "Group g4: f1 - 0.572234; loss - 0.379531;\n",
    "Group g9: f1 - 0.565533; loss - 0.396220;\n",
    "===========================================================\n",
    "Epoch 007/096 - Mean training loss 0.143598; Mean training F1 0.913422; Mean validation loss 0.107893; Mean validation F1 0.930101; Learning rate 0.000494;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.930101; loss - 0.107893;\n",
    "Group g4: f1 - 0.591723; loss - 0.345200;\n",
    "Group g9: f1 - 0.587968; loss - 0.354292;\n",
    "===========================================================\n",
    "Epoch 008/096 - Mean training loss 0.134866; Mean training F1 0.918319; Mean validation loss 0.112854; Mean validation F1 0.925934; Learning rate 0.000492;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.925934; loss - 0.112854;\n",
    "Group g4: f1 - 0.600506; loss - 0.354112;\n",
    "Group g9: f1 - 0.597463; loss - 0.358394;\n",
    "===========================================================\n",
    "Epoch 009/096 - Mean training loss 0.124580; Mean training F1 0.921762; Mean validation loss 0.106995; Mean validation F1 0.928476; Learning rate 0.000490;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.928476; loss - 0.106995;\n",
    "Group g4: f1 - 0.605254; loss - 0.344393;\n",
    "Group g9: f1 - 0.599436; loss - 0.355147;\n",
    "===========================================================\n",
    "Epoch 010/096 - Mean training loss 0.124945; Mean training F1 0.922453; Mean validation loss 0.102129; Mean validation F1 0.931521; Learning rate 0.000487;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931521; loss - 0.102129;\n",
    "Group g4: f1 - 0.624092; loss - 0.327453;\n",
    "Group g9: f1 - 0.618514; loss - 0.334145;\n",
    "===========================================================\n",
    "Epoch 011/096 - Mean training loss 0.114190; Mean training F1 0.927005; Mean validation loss 0.105698; Mean validation F1 0.930404; Learning rate 0.000484;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.930404; loss - 0.105698;\n",
    "Group g4: f1 - 0.619339; loss - 0.326157;\n",
    "Group g9: f1 - 0.614210; loss - 0.335059;\n",
    "===========================================================\n",
    "Epoch 012/096 - Mean training loss 0.123384; Mean training F1 0.922951; Mean validation loss 0.103092; Mean validation F1 0.931897; Learning rate 0.000481;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931897; loss - 0.103092;\n",
    "Group g4: f1 - 0.621288; loss - 0.327764;\n",
    "Group g9: f1 - 0.618245; loss - 0.334565;\n",
    "===========================================================\n",
    "Epoch 013/096 - Mean training loss 0.119744; Mean training F1 0.924037; Mean validation loss 0.131121; Mean validation F1 0.921201; Learning rate 0.000478;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.921201; loss - 0.131121;\n",
    "Group g4: f1 - 0.661750; loss - 0.326583;\n",
    "Group g9: f1 - 0.659221; loss - 0.328510;\n",
    "===========================================================\n",
    "Epoch 014/096 - Mean training loss 0.113512; Mean training F1 0.927194; Mean validation loss 0.109329; Mean validation F1 0.928210; Learning rate 0.000475;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.928210; loss - 0.109329;\n",
    "Group g4: f1 - 0.689399; loss - 0.321243;\n",
    "Group g9: f1 - 0.675798; loss - 0.322300;\n",
    "===========================================================\n",
    "Epoch 015/096 - Mean training loss 0.105409; Mean training F1 0.929806; Mean validation loss 0.096255; Mean validation F1 0.929934; Learning rate 0.000471;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.929934; loss - 0.096255;\n",
    "Group g4: f1 - 0.694096; loss - 0.302041;\n",
    "Group g9: f1 - 0.681685; loss - 0.305160;\n",
    "===========================================================\n",
    "Epoch 016/096 - Mean training loss 0.107943; Mean training F1 0.928241; Mean validation loss 0.101792; Mean validation F1 0.927786; Learning rate 0.000467;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.927786; loss - 0.101792;\n",
    "Group g4: f1 - 0.672433; loss - 0.323068;\n",
    "Group g9: f1 - 0.662042; loss - 0.325977;\n",
    "===========================================================\n",
    "Epoch 017/096 - Mean training loss 0.102597; Mean training F1 0.930506; Mean validation loss 0.113534; Mean validation F1 0.926265; Learning rate 0.000463;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.926265; loss - 0.113534;\n",
    "Group g4: f1 - 0.708720; loss - 0.291317;\n",
    "Group g9: f1 - 0.695952; loss - 0.294361;\n",
    "===========================================================\n",
    "Epoch 018/096 - Mean training loss 0.100749; Mean training F1 0.931695; Mean validation loss 0.090838; Mean validation F1 0.935626; Learning rate 0.000459;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935626; loss - 0.090838;\n",
    "Group g4: f1 - 0.715570; loss - 0.286477;\n",
    "Group g9: f1 - 0.701798; loss - 0.289669;\n",
    "===========================================================\n",
    "Epoch 019/096 - Mean training loss 0.096704; Mean training F1 0.933205; Mean validation loss 0.094211; Mean validation F1 0.931554; Learning rate 0.000454;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931554; loss - 0.094211;\n",
    "Group g4: f1 - 0.730760; loss - 0.300042;\n",
    "Group g9: f1 - 0.709440; loss - 0.303099;\n",
    "===========================================================\n",
    "Epoch 020/096 - Mean training loss 0.099054; Mean training F1 0.932539; Mean validation loss 0.092060; Mean validation F1 0.935024; Learning rate 0.000449;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935024; loss - 0.092060;\n",
    "Group g4: f1 - 0.708770; loss - 0.287484;\n",
    "Group g9: f1 - 0.700735; loss - 0.290326;\n",
    "===========================================================\n",
    "Epoch 021/096 - Mean training loss 0.097327; Mean training F1 0.933024; Mean validation loss 0.092079; Mean validation F1 0.932972; Learning rate 0.000444;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.932972; loss - 0.092079;\n",
    "Group g4: f1 - 0.705210; loss - 0.289867;\n",
    "Group g9: f1 - 0.702544; loss - 0.292758;\n",
    "===========================================================\n",
    "Epoch 022/096 - Mean training loss 0.095770; Mean training F1 0.933361; Mean validation loss 0.088573; Mean validation F1 0.936175; Learning rate 0.000439;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936175; loss - 0.088573;\n",
    "Group g4: f1 - 0.712622; loss - 0.285241;\n",
    "Group g9: f1 - 0.703186; loss - 0.287995;\n",
    "===========================================================\n",
    "Epoch 023/096 - Mean training loss 0.095654; Mean training F1 0.933913; Mean validation loss 0.088354; Mean validation F1 0.936472; Learning rate 0.000433;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936472; loss - 0.088354;\n",
    "Group g4: f1 - 0.735385; loss - 0.284508;\n",
    "Group g9: f1 - 0.713065; loss - 0.287150;\n",
    "===========================================================\n",
    "Epoch 024/096 - Mean training loss 0.094004; Mean training F1 0.934294; Mean validation loss 0.090740; Mean validation F1 0.935953; Learning rate 0.000428;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935953; loss - 0.090740;\n",
    "Group g4: f1 - 0.708596; loss - 0.287230;\n",
    "Group g9: f1 - 0.703546; loss - 0.289806;\n",
    "===========================================================\n",
    "Epoch 025/096 - Mean training loss 0.091645; Mean training F1 0.934904; Mean validation loss 0.087896; Mean validation F1 0.936836; Learning rate 0.000422;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936836; loss - 0.087896;\n",
    "Group g4: f1 - 0.709914; loss - 0.287772;\n",
    "Group g9: f1 - 0.693851; loss - 0.290491;\n",
    "===========================================================\n",
    "Epoch 026/096 - Mean training loss 0.091891; Mean training F1 0.935015; Mean validation loss 0.089669; Mean validation F1 0.936088; Learning rate 0.000416;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936088; loss - 0.089669;\n",
    "Group g4: f1 - 0.744616; loss - 0.286188;\n",
    "Group g9: f1 - 0.728084; loss - 0.288323;\n",
    "===========================================================\n",
    "Epoch 027/096 - Mean training loss 0.091996; Mean training F1 0.934807; Mean validation loss 0.090261; Mean validation F1 0.935714; Learning rate 0.000410;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935714; loss - 0.090261;\n",
    "Group g4: f1 - 0.747598; loss - 0.286326;\n",
    "Group g9: f1 - 0.740744; loss - 0.289195;\n",
    "===========================================================\n",
    "Epoch 028/096 - Mean training loss 0.091376; Mean training F1 0.935158; Mean validation loss 0.087466; Mean validation F1 0.936272; Learning rate 0.000403;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936272; loss - 0.087466;\n",
    "Group g4: f1 - 0.733646; loss - 0.284180;\n",
    "Group g9: f1 - 0.722817; loss - 0.286754;\n",
    "===========================================================\n",
    "Epoch 029/096 - Mean training loss 0.091059; Mean training F1 0.935057; Mean validation loss 0.088725; Mean validation F1 0.935993; Learning rate 0.000397;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935993; loss - 0.088725;\n",
    "Group g4: f1 - 0.733615; loss - 0.285777;\n",
    "Group g9: f1 - 0.710797; loss - 0.288426;\n",
    "===========================================================\n",
    "Epoch 030/096 - Mean training loss 0.090780; Mean training F1 0.935247; Mean validation loss 0.089080; Mean validation F1 0.936178; Learning rate 0.000390;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936178; loss - 0.089080;\n",
    "Group g4: f1 - 0.742949; loss - 0.285766;\n",
    "Group g9: f1 - 0.733612; loss - 0.288060;\n",
    "===========================================================\n",
    "Epoch 031/096 - Mean training loss 0.090412; Mean training F1 0.935427; Mean validation loss 0.086180; Mean validation F1 0.936918; Learning rate 0.000383;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936918; loss - 0.086180;\n",
    "Group g4: f1 - 0.754784; loss - 0.282425;\n",
    "Group g9: f1 - 0.746877; loss - 0.285079;\n",
    "===========================================================\n",
    "Epoch 032/096 - Mean training loss 0.089857; Mean training F1 0.935754; Mean validation loss 0.087389; Mean validation F1 0.936753; Learning rate 0.000377;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936753; loss - 0.087389;\n",
    "Group g4: f1 - 0.747518; loss - 0.282467;\n",
    "Group g9: f1 - 0.741551; loss - 0.285180;\n",
    "===========================================================\n",
    "Epoch 033/096 - Mean training loss 0.090160; Mean training F1 0.935366; Mean validation loss 0.089410; Mean validation F1 0.935809; Learning rate 0.000369;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935809; loss - 0.089410;\n",
    "Group g4: f1 - 0.757127; loss - 0.288866;\n",
    "Group g9: f1 - 0.753141; loss - 0.291688;\n",
    "===========================================================\n",
    "Epoch 034/096 - Mean training loss 0.098253; Mean training F1 0.931858; Mean validation loss 0.118085; Mean validation F1 0.923073; Learning rate 0.000362;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.923073; loss - 0.118085;\n",
    "Group g4: f1 - 0.676173; loss - 0.341056;\n",
    "Group g9: f1 - 0.666395; loss - 0.343120;\n",
    "===========================================================\n",
    "Epoch 035/096 - Mean training loss 0.094484; Mean training F1 0.933248; Mean validation loss 0.094982; Mean validation F1 0.932335; Learning rate 0.000355;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.932335; loss - 0.094982;\n",
    "Group g4: f1 - 0.730818; loss - 0.297284;\n",
    "Group g9: f1 - 0.709172; loss - 0.300829;\n",
    "===========================================================\n",
    "Epoch 036/096 - Mean training loss 0.089826; Mean training F1 0.935134; Mean validation loss 0.087054; Mean validation F1 0.936531; Learning rate 0.000347;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936531; loss - 0.087054;\n",
    "Group g4: f1 - 0.745338; loss - 0.282380;\n",
    "Group g9: f1 - 0.727082; loss - 0.285283;\n",
    "===========================================================\n",
    "Epoch 037/096 - Mean training loss 0.089259; Mean training F1 0.935619; Mean validation loss 0.089138; Mean validation F1 0.935536; Learning rate 0.000340;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935536; loss - 0.089138;\n",
    "Group g4: f1 - 0.763911; loss - 0.285197;\n",
    "Group g9: f1 - 0.759087; loss - 0.288614;\n",
    "===========================================================\n",
    "Epoch 038/096 - Mean training loss 0.088617; Mean training F1 0.936175; Mean validation loss 0.087514; Mean validation F1 0.936336; Learning rate 0.000332;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936336; loss - 0.087514;\n",
    "Group g4: f1 - 0.736120; loss - 0.285554;\n",
    "Group g9: f1 - 0.722535; loss - 0.288068;\n",
    "===========================================================\n",
    "Epoch 039/096 - Mean training loss 0.088434; Mean training F1 0.935908; Mean validation loss 0.088504; Mean validation F1 0.935588; Learning rate 0.000325;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935588; loss - 0.088504;\n",
    "Group g4: f1 - 0.733212; loss - 0.292293;\n",
    "Group g9: f1 - 0.719167; loss - 0.293840;\n",
    "===========================================================\n",
    "Epoch 040/096 - Mean training loss 0.088800; Mean training F1 0.935803; Mean validation loss 0.086611; Mean validation F1 0.937216; Learning rate 0.000317;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937216; loss - 0.086611;\n",
    "Group g4: f1 - 0.748333; loss - 0.283036;\n",
    "Group g9: f1 - 0.732114; loss - 0.285596;\n",
    "===========================================================\n",
    "Epoch 041/096 - Mean training loss 0.087936; Mean training F1 0.936420; Mean validation loss 0.086178; Mean validation F1 0.936856; Learning rate 0.000309;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936856; loss - 0.086178;\n",
    "Group g4: f1 - 0.733311; loss - 0.281506;\n",
    "Group g9: f1 - 0.720323; loss - 0.284326;\n",
    "===========================================================\n",
    "Epoch 042/096 - Mean training loss 0.087751; Mean training F1 0.936195; Mean validation loss 0.086122; Mean validation F1 0.936986; Learning rate 0.000301;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936986; loss - 0.086122;\n",
    "Group g4: f1 - 0.742667; loss - 0.283610;\n",
    "Group g9: f1 - 0.737763; loss - 0.286771;\n",
    "===========================================================\n",
    "Epoch 043/096 - Mean training loss 0.088240; Mean training F1 0.936470; Mean validation loss 0.085572; Mean validation F1 0.937549; Learning rate 0.000293;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937549; loss - 0.085572;\n",
    "Group g4: f1 - 0.760677; loss - 0.280177;\n",
    "Group g9: f1 - 0.755838; loss - 0.282613;\n",
    "===========================================================\n",
    "Epoch 044/096 - Mean training loss 0.086954; Mean training F1 0.936688; Mean validation loss 0.085209; Mean validation F1 0.937514; Learning rate 0.000285;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937514; loss - 0.085209;\n",
    "Group g4: f1 - 0.756655; loss - 0.281206;\n",
    "Group g9: f1 - 0.750262; loss - 0.283811;\n",
    "===========================================================\n",
    "Epoch 045/096 - Mean training loss 0.086866; Mean training F1 0.936816; Mean validation loss 0.085694; Mean validation F1 0.936943; Learning rate 0.000277;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936943; loss - 0.085694;\n",
    "Group g4: f1 - 0.742848; loss - 0.280484;\n",
    "Group g9: f1 - 0.730473; loss - 0.283202;\n",
    "===========================================================\n",
    "Epoch 046/096 - Mean training loss 0.086344; Mean training F1 0.937051; Mean validation loss 0.085557; Mean validation F1 0.937456; Learning rate 0.000269;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937456; loss - 0.085557;\n",
    "Group g4: f1 - 0.764042; loss - 0.280971;\n",
    "Group g9: f1 - 0.764851; loss - 0.283366;\n",
    "===========================================================\n",
    "Epoch 047/096 - Mean training loss 0.086849; Mean training F1 0.936955; Mean validation loss 0.085330; Mean validation F1 0.937604; Learning rate 0.000261;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937604; loss - 0.085330;\n",
    "Group g4: f1 - 0.760802; loss - 0.281024;\n",
    "Group g9: f1 - 0.755792; loss - 0.283414;\n",
    "===========================================================\n",
    "Epoch 048/096 - Mean training loss 0.086039; Mean training F1 0.937183; Mean validation loss 0.084895; Mean validation F1 0.937473; Learning rate 0.000253;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937473; loss - 0.084895;\n",
    "Group g4: f1 - 0.749662; loss - 0.280489;\n",
    "Group g9: f1 - 0.743478; loss - 0.283062;\n",
    "===========================================================\n",
    "Epoch 049/096 - Mean training loss 0.086478; Mean training F1 0.937008; Mean validation loss 0.085430; Mean validation F1 0.936962; Learning rate 0.000245;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936962; loss - 0.085430;\n",
    "Group g4: f1 - 0.763332; loss - 0.281778;\n",
    "Group g9: f1 - 0.757589; loss - 0.284538;\n",
    "===========================================================\n",
    "Epoch 050/096 - Mean training loss 0.085681; Mean training F1 0.937188; Mean validation loss 0.085452; Mean validation F1 0.937629; Learning rate 0.000237;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937629; loss - 0.085452;\n",
    "Group g4: f1 - 0.759659; loss - 0.280808;\n",
    "Group g9: f1 - 0.757836; loss - 0.283068;\n",
    "===========================================================\n",
    "Epoch 051/096 - Mean training loss 0.085741; Mean training F1 0.937254; Mean validation loss 0.086593; Mean validation F1 0.936728; Learning rate 0.000228;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936728; loss - 0.086593;\n",
    "Group g4: f1 - 0.765819; loss - 0.283882;\n",
    "Group g9: f1 - 0.770623; loss - 0.287228;\n",
    "===========================================================\n",
    "Epoch 052/096 - Mean training loss 0.086061; Mean training F1 0.936998; Mean validation loss 0.085692; Mean validation F1 0.937045; Learning rate 0.000220;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937045; loss - 0.085692;\n",
    "Group g4: f1 - 0.765134; loss - 0.281850;\n",
    "Group g9: f1 - 0.760187; loss - 0.284592;\n",
    "===========================================================\n",
    "Epoch 053/096 - Mean training loss 0.085780; Mean training F1 0.937178; Mean validation loss 0.086666; Mean validation F1 0.936727; Learning rate 0.000212;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936727; loss - 0.086666;\n",
    "Group g4: f1 - 0.759624; loss - 0.282986;\n",
    "Group g9: f1 - 0.755014; loss - 0.286017;\n",
    "===========================================================\n",
    "Epoch 054/096 - Mean training loss 0.086070; Mean training F1 0.937009; Mean validation loss 0.085072; Mean validation F1 0.937916; Learning rate 0.000204;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937916; loss - 0.085072;\n",
    "Group g4: f1 - 0.767620; loss - 0.279756;\n",
    "Group g9: f1 - 0.762393; loss - 0.282229;\n",
    "===========================================================\n",
    "Epoch 055/096 - Mean training loss 0.085468; Mean training F1 0.937461; Mean validation loss 0.086067; Mean validation F1 0.937344; Learning rate 0.000197;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937344; loss - 0.086067;\n",
    "Group g4: f1 - 0.770771; loss - 0.280640;\n",
    "Group g9: f1 - 0.774559; loss - 0.282789;\n",
    "===========================================================\n",
    "Epoch 056/096 - Mean training loss 0.085378; Mean training F1 0.937337; Mean validation loss 0.084498; Mean validation F1 0.937963; Learning rate 0.000189;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937963; loss - 0.084498;\n",
    "Group g4: f1 - 0.749836; loss - 0.278979;\n",
    "Group g9: f1 - 0.737581; loss - 0.281521;\n",
    "===========================================================\n",
    "Epoch 057/096 - Mean training loss 0.085540; Mean training F1 0.937503; Mean validation loss 0.085038; Mean validation F1 0.937511; Learning rate 0.000181;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937511; loss - 0.085038;\n",
    "Group g4: f1 - 0.777864; loss - 0.280709;\n",
    "Group g9: f1 - 0.771893; loss - 0.283014;\n",
    "===========================================================\n",
    "Epoch 058/096 - Mean training loss 0.085322; Mean training F1 0.937438; Mean validation loss 0.084474; Mean validation F1 0.937928; Learning rate 0.000173;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937928; loss - 0.084474;\n",
    "Group g4: f1 - 0.762326; loss - 0.278951;\n",
    "Group g9: f1 - 0.759344; loss - 0.281354;\n",
    "===========================================================\n",
    "Epoch 059/096 - Mean training loss 0.085107; Mean training F1 0.937278; Mean validation loss 0.084490; Mean validation F1 0.937841; Learning rate 0.000166;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937841; loss - 0.084490;\n",
    "Group g4: f1 - 0.763615; loss - 0.279380;\n",
    "Group g9: f1 - 0.759680; loss - 0.281880;\n",
    "===========================================================\n",
    "Epoch 060/096 - Mean training loss 0.085009; Mean training F1 0.937609; Mean validation loss 0.085284; Mean validation F1 0.936953; Learning rate 0.000158;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936953; loss - 0.085284;\n",
    "Group g4: f1 - 0.770848; loss - 0.279824;\n",
    "Group g9: f1 - 0.779769; loss - 0.282507;\n",
    "===========================================================\n",
    "Epoch 061/096 - Mean training loss 0.084672; Mean training F1 0.937477; Mean validation loss 0.084689; Mean validation F1 0.937837; Learning rate 0.000151;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937837; loss - 0.084689;\n",
    "Group g4: f1 - 0.775605; loss - 0.279624;\n",
    "Group g9: f1 - 0.773629; loss - 0.282075;\n",
    "===========================================================\n",
    "Epoch 062/096 - Mean training loss 0.085299; Mean training F1 0.937476; Mean validation loss 0.084567; Mean validation F1 0.937738; Learning rate 0.000143;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937738; loss - 0.084567;\n",
    "Group g4: f1 - 0.767689; loss - 0.279455;\n",
    "Group g9: f1 - 0.755026; loss - 0.281975;\n",
    "===========================================================\n",
    "Epoch 063/096 - Mean training loss 0.084430; Mean training F1 0.937734; Mean validation loss 0.084247; Mean validation F1 0.937703; Learning rate 0.000136;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937703; loss - 0.084247;\n",
    "Group g4: f1 - 0.761405; loss - 0.278634;\n",
    "Group g9: f1 - 0.755207; loss - 0.281182;\n",
    "===========================================================\n",
    "Epoch 064/096 - Mean training loss 0.084168; Mean training F1 0.937773; Mean validation loss 0.084460; Mean validation F1 0.937193; Learning rate 0.000129;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937193; loss - 0.084460;\n",
    "Group g4: f1 - 0.764790; loss - 0.279959;\n",
    "Group g9: f1 - 0.755136; loss - 0.282668;\n",
    "===========================================================\n",
    "Epoch 065/096 - Mean training loss 0.084346; Mean training F1 0.937731; Mean validation loss 0.084133; Mean validation F1 0.937970; Learning rate 0.000122;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937970; loss - 0.084133;\n",
    "Group g4: f1 - 0.774972; loss - 0.278835;\n",
    "Group g9: f1 - 0.769199; loss - 0.281438;\n",
    "===========================================================\n",
    "Epoch 066/096 - Mean training loss 0.084152; Mean training F1 0.937974; Mean validation loss 0.084147; Mean validation F1 0.937776; Learning rate 0.000115;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937776; loss - 0.084147;\n",
    "Group g4: f1 - 0.775159; loss - 0.278349;\n",
    "Group g9: f1 - 0.769863; loss - 0.280912;\n",
    "===========================================================\n",
    "Epoch 067/096 - Mean training loss 0.083851; Mean training F1 0.937831; Mean validation loss 0.084050; Mean validation F1 0.938083; Learning rate 0.000109;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938083; loss - 0.084050;\n",
    "Group g4: f1 - 0.757883; loss - 0.278328;\n",
    "Group g9: f1 - 0.754015; loss - 0.280823;\n",
    "===========================================================\n",
    "Epoch 068/096 - Mean training loss 0.083716; Mean training F1 0.937832; Mean validation loss 0.085639; Mean validation F1 0.936936; Learning rate 0.000102;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936936; loss - 0.085639;\n",
    "Group g4: f1 - 0.774135; loss - 0.282469;\n",
    "Group g9: f1 - 0.771537; loss - 0.284752;\n",
    "===========================================================\n",
    "Epoch 069/096 - Mean training loss 0.084130; Mean training F1 0.937634; Mean validation loss 0.084614; Mean validation F1 0.937670; Learning rate 0.000096;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937670; loss - 0.084614;\n",
    "Group g4: f1 - 0.762606; loss - 0.278866;\n",
    "Group g9: f1 - 0.754328; loss - 0.281419;\n",
    "===========================================================\n",
    "Epoch 070/096 - Mean training loss 0.083924; Mean training F1 0.937879; Mean validation loss 0.084334; Mean validation F1 0.937830; Learning rate 0.000090;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937830; loss - 0.084334;\n",
    "Group g4: f1 - 0.772476; loss - 0.279365;\n",
    "Group g9: f1 - 0.767100; loss - 0.281837;\n",
    "===========================================================\n",
    "Epoch 071/096 - Mean training loss 0.084158; Mean training F1 0.937988; Mean validation loss 0.084453; Mean validation F1 0.937971; Learning rate 0.000084;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937971; loss - 0.084453;\n",
    "Group g4: f1 - 0.765206; loss - 0.279647;\n",
    "Group g9: f1 - 0.769791; loss - 0.281862;\n",
    "===========================================================\n",
    "Epoch 072/096 - Mean training loss 0.084256; Mean training F1 0.937774; Mean validation loss 0.084518; Mean validation F1 0.937899; Learning rate 0.000078;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937899; loss - 0.084518;\n",
    "Group g4: f1 - 0.778047; loss - 0.277975;\n",
    "Group g9: f1 - 0.781031; loss - 0.280479;\n",
    "===========================================================\n",
    "Epoch 073/096 - Mean training loss 0.083322; Mean training F1 0.938108; Mean validation loss 0.084028; Mean validation F1 0.937960; Learning rate 0.000072;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937960; loss - 0.084028;\n",
    "Group g4: f1 - 0.761330; loss - 0.278144;\n",
    "Group g9: f1 - 0.753850; loss - 0.280699;\n",
    "===========================================================\n",
    "Epoch 074/096 - Mean training loss 0.083455; Mean training F1 0.938083; Mean validation loss 0.083939; Mean validation F1 0.938187; Learning rate 0.000067;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938187; loss - 0.083939;\n",
    "Group g4: f1 - 0.778865; loss - 0.277970;\n",
    "Group g9: f1 - 0.778065; loss - 0.280350;\n",
    "===========================================================\n",
    "Epoch 075/096 - Mean training loss 0.083642; Mean training F1 0.938003; Mean validation loss 0.083918; Mean validation F1 0.938200; Learning rate 0.000061;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938200; loss - 0.083918;\n",
    "Group g4: f1 - 0.773895; loss - 0.277933;\n",
    "Group g9: f1 - 0.765006; loss - 0.280476;\n",
    "===========================================================\n",
    "Epoch 076/096 - Mean training loss 0.083391; Mean training F1 0.938159; Mean validation loss 0.083968; Mean validation F1 0.938146; Learning rate 0.000056;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938146; loss - 0.083968;\n",
    "Group g4: f1 - 0.774823; loss - 0.277869;\n",
    "Group g9: f1 - 0.774743; loss - 0.280356;\n",
    "===========================================================\n",
    "Epoch 077/096 - Mean training loss 0.084052; Mean training F1 0.938129; Mean validation loss 0.084031; Mean validation F1 0.937683; Learning rate 0.000052;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937683; loss - 0.084031;\n",
    "Group g4: f1 - 0.772532; loss - 0.278596;\n",
    "Group g9: f1 - 0.769564; loss - 0.281243;\n",
    "===========================================================\n",
    "Epoch 078/096 - Mean training loss 0.083375; Mean training F1 0.938123; Mean validation loss 0.083931; Mean validation F1 0.938237; Learning rate 0.000047;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938237; loss - 0.083931;\n",
    "Group g4: f1 - 0.774364; loss - 0.278006;\n",
    "Group g9: f1 - 0.764122; loss - 0.280611;\n",
    "===========================================================\n",
    "Epoch 079/096 - Mean training loss 0.083345; Mean training F1 0.938291; Mean validation loss 0.083806; Mean validation F1 0.938185; Learning rate 0.000043;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938185; loss - 0.083806;\n",
    "Group g4: f1 - 0.779935; loss - 0.277801;\n",
    "Group g9: f1 - 0.776570; loss - 0.280366;\n",
    "===========================================================\n",
    "Epoch 080/096 - Mean training loss 0.083448; Mean training F1 0.938252; Mean validation loss 0.083860; Mean validation F1 0.938138; Learning rate 0.000038;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938138; loss - 0.083860;\n",
    "Group g4: f1 - 0.773959; loss - 0.277854;\n",
    "Group g9: f1 - 0.775799; loss - 0.280359;\n",
    "===========================================================\n",
    "Epoch 081/096 - Mean training loss 0.083128; Mean training F1 0.938287; Mean validation loss 0.083815; Mean validation F1 0.938083; Learning rate 0.000034;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938083; loss - 0.083815;\n",
    "Group g4: f1 - 0.772621; loss - 0.277761;\n",
    "Group g9: f1 - 0.764720; loss - 0.280383;\n",
    "===========================================================\n",
    "Epoch 082/096 - Mean training loss 0.083385; Mean training F1 0.938354; Mean validation loss 0.083832; Mean validation F1 0.937814; Learning rate 0.000031;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937814; loss - 0.083832;\n",
    "Group g4: f1 - 0.773486; loss - 0.277954;\n",
    "Group g9: f1 - 0.766107; loss - 0.280527;\n",
    "===========================================================\n",
    "Epoch 083/096 - Mean training loss 0.083230; Mean training F1 0.938244; Mean validation loss 0.083853; Mean validation F1 0.938284; Learning rate 0.000027;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938284; loss - 0.083853;\n",
    "Group g4: f1 - 0.774659; loss - 0.277769;\n",
    "Group g9: f1 - 0.766798; loss - 0.280299;\n",
    "===========================================================\n",
    "Epoch 084/096 - Mean training loss 0.083093; Mean training F1 0.938326; Mean validation loss 0.083765; Mean validation F1 0.938223; Learning rate 0.000024;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938223; loss - 0.083765;\n",
    "Group g4: f1 - 0.777124; loss - 0.277559;\n",
    "Group g9: f1 - 0.775675; loss - 0.280113;\n",
    "===========================================================\n",
    "Epoch 085/096 - Mean training loss 0.083159; Mean training F1 0.938290; Mean validation loss 0.083768; Mean validation F1 0.938173; Learning rate 0.000021;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938173; loss - 0.083768;\n",
    "Group g4: f1 - 0.771187; loss - 0.277879;\n",
    "Group g9: f1 - 0.767978; loss - 0.280401;\n",
    "===========================================================\n",
    "Epoch 086/096 - Mean training loss 0.083082; Mean training F1 0.938239; Mean validation loss 0.083749; Mean validation F1 0.938148; Learning rate 0.000018;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938148; loss - 0.083749;\n",
    "Group g4: f1 - 0.770377; loss - 0.277869;\n",
    "Group g9: f1 - 0.768392; loss - 0.280374;\n",
    "===========================================================\n",
    "Epoch 087/096 - Mean training loss 0.082825; Mean training F1 0.938301; Mean validation loss 0.083725; Mean validation F1 0.938094; Learning rate 0.000016;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938094; loss - 0.083725;\n",
    "Group g4: f1 - 0.771646; loss - 0.277672;\n",
    "Group g9: f1 - 0.767456; loss - 0.280301;\n",
    "===========================================================\n",
    "Epoch 088/096 - Mean training loss 0.082908; Mean training F1 0.938461; Mean validation loss 0.083798; Mean validation F1 0.938207; Learning rate 0.000014;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938207; loss - 0.083798;\n",
    "Group g4: f1 - 0.773457; loss - 0.277747;\n",
    "Group g9: f1 - 0.769503; loss - 0.280301;\n",
    "===========================================================\n",
    "Epoch 089/096 - Mean training loss 0.083114; Mean training F1 0.938396; Mean validation loss 0.083661; Mean validation F1 0.938274; Learning rate 0.000012;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938274; loss - 0.083661;\n",
    "Group g4: f1 - 0.777599; loss - 0.277600;\n",
    "Group g9: f1 - 0.773491; loss - 0.280161;\n",
    "===========================================================\n",
    "Epoch 090/096 - Mean training loss 0.083209; Mean training F1 0.938382; Mean validation loss 0.083689; Mean validation F1 0.938289; Learning rate 0.000010;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938289; loss - 0.083689;\n",
    "Group g4: f1 - 0.774134; loss - 0.277573;\n",
    "Group g9: f1 - 0.767897; loss - 0.280158;\n",
    "===========================================================\n",
    "Epoch 091/096 - Mean training loss 0.083216; Mean training F1 0.938348; Mean validation loss 0.083714; Mean validation F1 0.938344; Learning rate 0.000008;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938344; loss - 0.083714;\n",
    "Group g4: f1 - 0.771757; loss - 0.277754;\n",
    "Group g9: f1 - 0.764126; loss - 0.280203;\n",
    "===========================================================\n",
    "Epoch 092/096 - Mean training loss 0.082676; Mean training F1 0.938436; Mean validation loss 0.083648; Mean validation F1 0.938266; Learning rate 0.000007;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938266; loss - 0.083648;\n",
    "Group g4: f1 - 0.773130; loss - 0.277530;\n",
    "Group g9: f1 - 0.768257; loss - 0.280151;\n",
    "===========================================================\n",
    "Epoch 093/096 - Mean training loss 0.082799; Mean training F1 0.938479; Mean validation loss 0.083806; Mean validation F1 0.938097; Learning rate 0.000006;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938097; loss - 0.083806;\n",
    "Group g4: f1 - 0.772243; loss - 0.277733;\n",
    "Group g9: f1 - 0.761323; loss - 0.280431;\n",
    "===========================================================\n",
    "Epoch 094/096 - Mean training loss 0.083057; Mean training F1 0.938321; Mean validation loss 0.083670; Mean validation F1 0.938193; Learning rate 0.000006;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938193; loss - 0.083670;\n",
    "Group g4: f1 - 0.773603; loss - 0.277569;\n",
    "Group g9: f1 - 0.767906; loss - 0.280092;\n",
    "===========================================================\n",
    "Epoch 095/096 - Mean training loss 0.083088; Mean training F1 0.938416; Mean validation loss 0.083688; Mean validation F1 0.938158; Learning rate 0.000005;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938158; loss - 0.083688;\n",
    "Group g4: f1 - 0.776612; loss - 0.277528;\n",
    "Group g9: f1 - 0.775687; loss - 0.280014;\n",
    "===========================================================\n",
    "Epoch 096/096 - Mean training loss 0.083092; Mean training F1 0.938408; Mean validation loss 0.083665; Mean validation F1 0.938177; Learning rate 0.000005;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938177; loss - 0.083665;\n",
    "Group g4: f1 - 0.774731; loss - 0.277592;\n",
    "Group g9: f1 - 0.765596; loss - 0.280194;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-------- fold 0 --------\n",
    "model validation loss: 0.095; validation f1: 0.939;\n",
    "-------- fold 1 --------\n",
    "model validation loss: 0.062; validation f1: 0.937;\n",
    "-------- fold 2 --------\n",
    "model validation loss: 0.095; validation f1: 0.937;\n",
    "-------- fold 3 --------\n",
    "model validation loss: 0.061; validation f1: 0.939;\n",
    "-------- fold 4 --------\n",
    "model validation loss: 0.061; validation f1: 0.939;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "################################################################\n",
    "Training/validation for fold 1/5;\n",
    "===========================================================\n",
    "Epoch 001/096 - Mean training loss 0.427053; Mean training F1 0.719997; Mean validation loss 0.157788; Mean validation F1 0.904941; Learning rate 0.000500;\n",
    "===========================================================\n",
    "Epoch 002/096 - Mean training loss 0.159833; Mean training F1 0.882014; Mean validation loss 0.146290; Mean validation F1 0.914156; Learning rate 0.000500;\n",
    "===========================================================\n",
    "Epoch 003/096 - Mean training loss 0.133551; Mean training F1 0.897157; Mean validation loss 0.134820; Mean validation F1 0.924612; Learning rate 0.000499;\n",
    "===========================================================\n",
    "Epoch 004/096 - Mean training loss 0.178729; Mean training F1 0.875723; Mean validation loss 0.163564; Mean validation F1 0.927975; Learning rate 0.000498;\n",
    "===========================================================\n",
    "Epoch 005/096 - Mean training loss 0.113420; Mean training F1 0.916307; Mean validation loss 0.087535; Mean validation F1 0.933290; Learning rate 0.000497;\n",
    "===========================================================\n",
    "Epoch 006/096 - Mean training loss 0.103833; Mean training F1 0.923584; Mean validation loss 0.115553; Mean validation F1 0.929277; Learning rate 0.000496;\n",
    "===========================================================\n",
    "Epoch 007/096 - Mean training loss 0.100111; Mean training F1 0.927184; Mean validation loss 0.089827; Mean validation F1 0.933929; Learning rate 0.000494;\n",
    "===========================================================\n",
    "Epoch 008/096 - Mean training loss 0.097609; Mean training F1 0.927080; Mean validation loss 0.089039; Mean validation F1 0.934180; Learning rate 0.000492;\n",
    "===========================================================\n",
    "Epoch 009/096 - Mean training loss 0.093451; Mean training F1 0.930878; Mean validation loss 0.095206; Mean validation F1 0.934936; Learning rate 0.000490;\n",
    "===========================================================\n",
    "Epoch 010/096 - Mean training loss 0.092379; Mean training F1 0.931282; Mean validation loss 0.070450; Mean validation F1 0.932966; Learning rate 0.000487;\n",
    "===========================================================\n",
    "Epoch 011/096 - Mean training loss 0.092845; Mean training F1 0.929958; Mean validation loss 0.096474; Mean validation F1 0.937538; Learning rate 0.000484;\n",
    "===========================================================\n",
    "Epoch 012/096 - Mean training loss 0.089828; Mean training F1 0.932747; Mean validation loss 0.075376; Mean validation F1 0.936033; Learning rate 0.000481;\n",
    "===========================================================\n",
    "Epoch 013/096 - Mean training loss 0.102658; Mean training F1 0.925116; Mean validation loss 0.102938; Mean validation F1 0.933750; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 014/096 - Mean training loss 0.093856; Mean training F1 0.929904; Mean validation loss 0.106239; Mean validation F1 0.936274; Learning rate 0.000475;\n",
    "===========================================================\n",
    "Epoch 015/096 - Mean training loss 0.088703; Mean training F1 0.933483; Mean validation loss 0.035435; Mean validation F1 0.936063; Learning rate 0.000471;\n",
    "===========================================================\n",
    "Epoch 016/096 - Mean training loss 0.088990; Mean training F1 0.933346; Mean validation loss 0.076228; Mean validation F1 0.935749; Learning rate 0.000467;\n",
    "===========================================================\n",
    "Epoch 017/096 - Mean training loss 0.088518; Mean training F1 0.933790; Mean validation loss 0.054120; Mean validation F1 0.937558; Learning rate 0.000463;\n",
    "===========================================================\n",
    "Epoch 018/096 - Mean training loss 0.087423; Mean training F1 0.933960; Mean validation loss 0.078350; Mean validation F1 0.936952; Learning rate 0.000459;\n",
    "===========================================================\n",
    "Epoch 019/096 - Mean training loss 0.087172; Mean training F1 0.934101; Mean validation loss 0.138057; Mean validation F1 0.937080; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 020/096 - Mean training loss 0.087445; Mean training F1 0.933746; Mean validation loss 0.089963; Mean validation F1 0.936028; Learning rate 0.000449;\n",
    "===========================================================\n",
    "Epoch 021/096 - Mean training loss 0.086702; Mean training F1 0.934803; Mean validation loss 0.076772; Mean validation F1 0.937813; Learning rate 0.000444;\n",
    "===========================================================\n",
    "Epoch 022/096 - Mean training loss 0.086272; Mean training F1 0.935037; Mean validation loss 0.098796; Mean validation F1 0.933390; Learning rate 0.000439;\n",
    "===========================================================\n",
    "Epoch 023/096 - Mean training loss 0.086216; Mean training F1 0.934881; Mean validation loss 0.073814; Mean validation F1 0.934886; Learning rate 0.000433;\n",
    "===========================================================\n",
    "Epoch 024/096 - Mean training loss 0.085960; Mean training F1 0.935237; Mean validation loss 0.057394; Mean validation F1 0.938733; Learning rate 0.000428;\n",
    "===========================================================\n",
    "Epoch 025/096 - Mean training loss 0.085656; Mean training F1 0.935277; Mean validation loss 0.072783; Mean validation F1 0.936911; Learning rate 0.000422;\n",
    "===========================================================\n",
    "Epoch 026/096 - Mean training loss 0.085557; Mean training F1 0.935096; Mean validation loss 0.066365; Mean validation F1 0.938019; Learning rate 0.000416;\n",
    "===========================================================\n",
    "Epoch 027/096 - Mean training loss 0.085018; Mean training F1 0.935841; Mean validation loss 0.104756; Mean validation F1 0.938541; Learning rate 0.000410;\n",
    "===========================================================\n",
    "Epoch 028/096 - Mean training loss 0.084766; Mean training F1 0.936099; Mean validation loss 0.100022; Mean validation F1 0.937945; Learning rate 0.000403;\n",
    "===========================================================\n",
    "Epoch 029/096 - Mean training loss 0.084439; Mean training F1 0.935783; Mean validation loss 0.079025; Mean validation F1 0.938278; Learning rate 0.000397;\n",
    "===========================================================\n",
    "Epoch 030/096 - Mean training loss 0.084524; Mean training F1 0.935966; Mean validation loss 0.073444; Mean validation F1 0.938573; Learning rate 0.000390;\n",
    "===========================================================\n",
    "Epoch 031/096 - Mean training loss 0.140982; Mean training F1 0.913847; Mean validation loss 0.102051; Mean validation F1 0.933927; Learning rate 0.000383;\n",
    "===========================================================\n",
    "Epoch 032/096 - Mean training loss 0.092145; Mean training F1 0.932633; Mean validation loss 0.060174; Mean validation F1 0.937985; Learning rate 0.000377;\n",
    "===========================================================\n",
    "Epoch 033/096 - Mean training loss 0.088860; Mean training F1 0.934066; Mean validation loss 0.078800; Mean validation F1 0.937688; Learning rate 0.000369;\n",
    "===========================================================\n",
    "Epoch 034/096 - Mean training loss 0.086768; Mean training F1 0.935209; Mean validation loss 0.106463; Mean validation F1 0.938499; Learning rate 0.000362;\n",
    "===========================================================\n",
    "Epoch 035/096 - Mean training loss 0.085537; Mean training F1 0.935786; Mean validation loss 0.059723; Mean validation F1 0.937111; Learning rate 0.000355;\n",
    "===========================================================\n",
    "Epoch 036/096 - Mean training loss 0.085092; Mean training F1 0.935989; Mean validation loss 0.124292; Mean validation F1 0.938608; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 037/096 - Mean training loss 0.084409; Mean training F1 0.936276; Mean validation loss 0.062715; Mean validation F1 0.936547; Learning rate 0.000340;\n",
    "===========================================================\n",
    "Epoch 038/096 - Mean training loss 0.084186; Mean training F1 0.936331; Mean validation loss 0.114687; Mean validation F1 0.937705; Learning rate 0.000332;\n",
    "===========================================================\n",
    "Epoch 039/096 - Mean training loss 0.083773; Mean training F1 0.936739; Mean validation loss 0.085199; Mean validation F1 0.938155; Learning rate 0.000325;\n",
    "===========================================================\n",
    "Epoch 040/096 - Mean training loss 0.083843; Mean training F1 0.936492; Mean validation loss 0.100507; Mean validation F1 0.938745; Learning rate 0.000317;\n",
    "===========================================================\n",
    "Epoch 041/096 - Mean training loss 0.083590; Mean training F1 0.936474; Mean validation loss 0.079642; Mean validation F1 0.937720; Learning rate 0.000309;\n",
    "===========================================================\n",
    "Epoch 042/096 - Mean training loss 0.083267; Mean training F1 0.937112; Mean validation loss 0.071169; Mean validation F1 0.939145; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 043/096 - Mean training loss 0.083049; Mean training F1 0.937181; Mean validation loss 0.064106; Mean validation F1 0.938129; Learning rate 0.000293;\n",
    "===========================================================\n",
    "Epoch 044/096 - Mean training loss 0.083053; Mean training F1 0.936971; Mean validation loss 0.036235; Mean validation F1 0.937409; Learning rate 0.000285;\n",
    "===========================================================\n",
    "Epoch 045/096 - Mean training loss 0.082816; Mean training F1 0.937394; Mean validation loss 0.097111; Mean validation F1 0.939006; Learning rate 0.000277;\n",
    "===========================================================\n",
    "Epoch 046/096 - Mean training loss 0.082792; Mean training F1 0.937166; Mean validation loss 0.052730; Mean validation F1 0.938573; Learning rate 0.000269;\n",
    "===========================================================\n",
    "Epoch 047/096 - Mean training loss 0.082568; Mean training F1 0.937257; Mean validation loss 0.073013; Mean validation F1 0.939228; Learning rate 0.000261;\n",
    "===========================================================\n",
    "Epoch 048/096 - Mean training loss 0.082373; Mean training F1 0.937369; Mean validation loss 0.064467; Mean validation F1 0.938997; Learning rate 0.000253;\n",
    "===========================================================\n",
    "Epoch 049/096 - Mean training loss 0.082196; Mean training F1 0.937192; Mean validation loss 0.091947; Mean validation F1 0.938309; Learning rate 0.000245;\n",
    "===========================================================\n",
    "Epoch 050/096 - Mean training loss 0.082383; Mean training F1 0.937407; Mean validation loss 0.085980; Mean validation F1 0.938829; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 051/096 - Mean training loss 0.082000; Mean training F1 0.937640; Mean validation loss 0.062079; Mean validation F1 0.938568; Learning rate 0.000228;\n",
    "===========================================================\n",
    "Epoch 052/096 - Mean training loss 0.082181; Mean training F1 0.937411; Mean validation loss 0.103885; Mean validation F1 0.939069; Learning rate 0.000220;\n",
    "===========================================================\n",
    "Epoch 053/096 - Mean training loss 0.081724; Mean training F1 0.937835; Mean validation loss 0.078203; Mean validation F1 0.936569; Learning rate 0.000212;\n",
    "===========================================================\n",
    "Epoch 054/096 - Mean training loss 0.081705; Mean training F1 0.937742; Mean validation loss 0.082344; Mean validation F1 0.939143; Learning rate 0.000204;\n",
    "===========================================================\n",
    "Epoch 055/096 - Mean training loss 0.081430; Mean training F1 0.937836; Mean validation loss 0.071595; Mean validation F1 0.938641; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 056/096 - Mean training loss 0.081252; Mean training F1 0.938185; Mean validation loss 0.091750; Mean validation F1 0.939077; Learning rate 0.000189;\n",
    "===========================================================\n",
    "Epoch 057/096 - Mean training loss 0.081271; Mean training F1 0.938033; Mean validation loss 0.101835; Mean validation F1 0.938982; Learning rate 0.000181;\n",
    "===========================================================\n",
    "Epoch 058/096 - Mean training loss 0.081336; Mean training F1 0.937800; Mean validation loss 0.073870; Mean validation F1 0.938589; Learning rate 0.000173;\n",
    "===========================================================\n",
    "Epoch 059/096 - Mean training loss 0.080945; Mean training F1 0.938287; Mean validation loss 0.104467; Mean validation F1 0.938332; Learning rate 0.000166;\n",
    "===========================================================\n",
    "Epoch 060/096 - Mean training loss 0.080587; Mean training F1 0.938380; Mean validation loss 0.094439; Mean validation F1 0.939167; Learning rate 0.000158;\n",
    "===========================================================\n",
    "Epoch 061/096 - Mean training loss 0.080563; Mean training F1 0.938343; Mean validation loss 0.100542; Mean validation F1 0.939267; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 062/096 - Mean training loss 0.080689; Mean training F1 0.938280; Mean validation loss 0.091423; Mean validation F1 0.938577; Learning rate 0.000143;\n",
    "===========================================================\n",
    "Epoch 063/096 - Mean training loss 0.080386; Mean training F1 0.938559; Mean validation loss 0.064779; Mean validation F1 0.937854; Learning rate 0.000136;\n",
    "===========================================================\n",
    "Epoch 064/096 - Mean training loss 0.080038; Mean training F1 0.938737; Mean validation loss 0.062872; Mean validation F1 0.938968; Learning rate 0.000129;\n",
    "===========================================================\n",
    "Epoch 065/096 - Mean training loss 0.079928; Mean training F1 0.938700; Mean validation loss 0.086492; Mean validation F1 0.938900; Learning rate 0.000122;\n",
    "===========================================================\n",
    "Epoch 066/096 - Mean training loss 0.079768; Mean training F1 0.938822; Mean validation loss 0.064734; Mean validation F1 0.938078; Learning rate 0.000115;\n",
    "===========================================================\n",
    "Epoch 067/096 - Mean training loss 0.079658; Mean training F1 0.938908; Mean validation loss 0.094464; Mean validation F1 0.939153; Learning rate 0.000109;\n",
    "===========================================================\n",
    "Epoch 068/096 - Mean training loss 0.079413; Mean training F1 0.939119; Mean validation loss 0.087999; Mean validation F1 0.938944; Learning rate 0.000102;\n",
    "===========================================================\n",
    "Epoch 069/096 - Mean training loss 0.079194; Mean training F1 0.939229; Mean validation loss 0.077751; Mean validation F1 0.937806; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 070/096 - Mean training loss 0.079150; Mean training F1 0.939050; Mean validation loss 0.086330; Mean validation F1 0.937580; Learning rate 0.000090;\n",
    "===========================================================\n",
    "Epoch 071/096 - Mean training loss 0.078945; Mean training F1 0.939189; Mean validation loss 0.068755; Mean validation F1 0.938088; Learning rate 0.000084;\n",
    "===========================================================\n",
    "Epoch 072/096 - Mean training loss 0.078783; Mean training F1 0.939353; Mean validation loss 0.097753; Mean validation F1 0.938867; Learning rate 0.000078;\n",
    "===========================================================\n",
    "Epoch 073/096 - Mean training loss 0.078493; Mean training F1 0.939647; Mean validation loss 0.095341; Mean validation F1 0.939313; Learning rate 0.000072;\n",
    "===========================================================\n",
    "Epoch 074/096 - Mean training loss 0.078424; Mean training F1 0.939519; Mean validation loss 0.087711; Mean validation F1 0.938544; Learning rate 0.000067;\n",
    "===========================================================\n",
    "Epoch 075/096 - Mean training loss 0.078302; Mean training F1 0.939767; Mean validation loss 0.102267; Mean validation F1 0.939069; Learning rate 0.000061;\n",
    "===========================================================\n",
    "Epoch 076/096 - Mean training loss 0.078059; Mean training F1 0.939793; Mean validation loss 0.097352; Mean validation F1 0.939130; Learning rate 0.000056;\n",
    "===========================================================\n",
    "Epoch 077/096 - Mean training loss 0.077920; Mean training F1 0.939886; Mean validation loss 0.065793; Mean validation F1 0.938948; Learning rate 0.000052;\n",
    "===========================================================\n",
    "Epoch 078/096 - Mean training loss 0.077786; Mean training F1 0.939878; Mean validation loss 0.077632; Mean validation F1 0.938600; Learning rate 0.000047;\n",
    "===========================================================\n",
    "Epoch 079/096 - Mean training loss 0.077649; Mean training F1 0.939812; Mean validation loss 0.099055; Mean validation F1 0.939241; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 080/096 - Mean training loss 0.077464; Mean training F1 0.939970; Mean validation loss 0.061416; Mean validation F1 0.938914; Learning rate 0.000038;\n",
    "===========================================================\n",
    "Epoch 081/096 - Mean training loss 0.077311; Mean training F1 0.940158; Mean validation loss 0.037914; Mean validation F1 0.939046; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 082/096 - Mean training loss 0.077134; Mean training F1 0.940301; Mean validation loss 0.079193; Mean validation F1 0.938498; Learning rate 0.000031;\n",
    "===========================================================\n",
    "Epoch 083/096 - Mean training loss 0.077121; Mean training F1 0.940207; Mean validation loss 0.067838; Mean validation F1 0.938606; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 084/096 - Mean training loss 0.076957; Mean training F1 0.940244; Mean validation loss 0.092256; Mean validation F1 0.938543; Learning rate 0.000024;\n",
    "===========================================================\n",
    "Epoch 085/096 - Mean training loss 0.076814; Mean training F1 0.940351; Mean validation loss 0.082783; Mean validation F1 0.938892; Learning rate 0.000021;\n",
    "===========================================================\n",
    "Epoch 086/096 - Mean training loss 0.076797; Mean training F1 0.940323; Mean validation loss 0.132158; Mean validation F1 0.938965; Learning rate 0.000018;\n",
    "===========================================================\n",
    "Epoch 087/096 - Mean training loss 0.076689; Mean training F1 0.940489; Mean validation loss 0.067002; Mean validation F1 0.939108; Learning rate 0.000016;\n",
    "===========================================================\n",
    "Epoch 088/096 - Mean training loss 0.076573; Mean training F1 0.940598; Mean validation loss 0.087865; Mean validation F1 0.939129; Learning rate 0.000014;\n",
    "===========================================================\n",
    "Epoch 089/096 - Mean training loss 0.076520; Mean training F1 0.940560; Mean validation loss 0.033237; Mean validation F1 0.939008; Learning rate 0.000012;\n",
    "===========================================================\n",
    "Epoch 090/096 - Mean training loss 0.076405; Mean training F1 0.940549; Mean validation loss 0.075173; Mean validation F1 0.938916; Learning rate 0.000010;\n",
    "===========================================================\n",
    "Epoch 091/096 - Mean training loss 0.076427; Mean training F1 0.940589; Mean validation loss 0.116932; Mean validation F1 0.938898; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 092/096 - Mean training loss 0.076372; Mean training F1 0.940665; Mean validation loss 0.060591; Mean validation F1 0.939045; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 093/096 - Mean training loss 0.076287; Mean training F1 0.940701; Mean validation loss 0.056117; Mean validation F1 0.939090; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 094/096 - Mean training loss 0.076316; Mean training F1 0.940691; Mean validation loss 0.093555; Mean validation F1 0.938944; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 095/096 - Mean training loss 0.076290; Mean training F1 0.940723; Mean validation loss 0.095410; Mean validation F1 0.939016; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 096/096 - Mean training loss 0.076241; Mean training F1 0.940822; Mean validation loss 0.084339; Mean validation F1 0.938990; Learning rate 0.000005;\n",
    "################################################################\n",
    "Training/validation for fold 2/5;\n",
    "===========================================================\n",
    "Epoch 001/096 - Mean training loss 0.447238; Mean training F1 0.703941; Mean validation loss 0.226672; Mean validation F1 0.903899; Learning rate 0.000500;\n",
    "===========================================================\n",
    "Epoch 002/096 - Mean training loss 0.188791; Mean training F1 0.866313; Mean validation loss 0.142585; Mean validation F1 0.908550; Learning rate 0.000500;\n",
    "===========================================================\n",
    "Epoch 003/096 - Mean training loss 0.141775; Mean training F1 0.900405; Mean validation loss 0.127600; Mean validation F1 0.923941; Learning rate 0.000499;\n",
    "===========================================================\n",
    "Epoch 004/096 - Mean training loss 0.117152; Mean training F1 0.912546; Mean validation loss 0.119064; Mean validation F1 0.901711; Learning rate 0.000498;\n",
    "===========================================================\n",
    "Epoch 005/096 - Mean training loss 0.122020; Mean training F1 0.912916; Mean validation loss 0.124747; Mean validation F1 0.925980; Learning rate 0.000497;\n",
    "===========================================================\n",
    "Epoch 006/096 - Mean training loss 0.103119; Mean training F1 0.922138; Mean validation loss 0.106640; Mean validation F1 0.909917; Learning rate 0.000496;\n",
    "===========================================================\n",
    "Epoch 007/096 - Mean training loss 0.097523; Mean training F1 0.926290; Mean validation loss 0.108097; Mean validation F1 0.900425; Learning rate 0.000494;\n",
    "===========================================================\n",
    "Epoch 008/096 - Mean training loss 0.093031; Mean training F1 0.929270; Mean validation loss 0.082286; Mean validation F1 0.923465; Learning rate 0.000492;\n",
    "===========================================================\n",
    "Epoch 009/096 - Mean training loss 0.101458; Mean training F1 0.924438; Mean validation loss 0.105697; Mean validation F1 0.932299; Learning rate 0.000490;\n",
    "===========================================================\n",
    "Epoch 010/096 - Mean training loss 0.091094; Mean training F1 0.931042; Mean validation loss 0.082979; Mean validation F1 0.931369; Learning rate 0.000487;\n",
    "===========================================================\n",
    "Epoch 011/096 - Mean training loss 0.089671; Mean training F1 0.931983; Mean validation loss 0.109314; Mean validation F1 0.932828; Learning rate 0.000484;\n",
    "===========================================================\n",
    "Epoch 012/096 - Mean training loss 0.088955; Mean training F1 0.932331; Mean validation loss 0.063286; Mean validation F1 0.931966; Learning rate 0.000481;\n",
    "===========================================================\n",
    "Epoch 013/096 - Mean training loss 0.088572; Mean training F1 0.932156; Mean validation loss 0.101764; Mean validation F1 0.932465; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 014/096 - Mean training loss 0.087665; Mean training F1 0.932890; Mean validation loss 0.085685; Mean validation F1 0.933209; Learning rate 0.000475;\n",
    "===========================================================\n",
    "Epoch 015/096 - Mean training loss 0.087389; Mean training F1 0.933152; Mean validation loss 0.112142; Mean validation F1 0.932909; Learning rate 0.000471;\n",
    "===========================================================\n",
    "Epoch 016/096 - Mean training loss 0.086112; Mean training F1 0.934355; Mean validation loss 0.088221; Mean validation F1 0.932576; Learning rate 0.000467;\n",
    "===========================================================\n",
    "Epoch 017/096 - Mean training loss 0.087107; Mean training F1 0.933515; Mean validation loss 0.095407; Mean validation F1 0.932008; Learning rate 0.000463;\n",
    "===========================================================\n",
    "Epoch 018/096 - Mean training loss 0.088312; Mean training F1 0.932106; Mean validation loss 0.095500; Mean validation F1 0.934943; Learning rate 0.000459;\n",
    "===========================================================\n",
    "Epoch 019/096 - Mean training loss 0.087562; Mean training F1 0.932979; Mean validation loss 0.069770; Mean validation F1 0.935518; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 020/096 - Mean training loss 0.085155; Mean training F1 0.935097; Mean validation loss 0.092726; Mean validation F1 0.933120; Learning rate 0.000449;\n",
    "===========================================================\n",
    "Epoch 021/096 - Mean training loss 0.086912; Mean training F1 0.933644; Mean validation loss 0.091351; Mean validation F1 0.934052; Learning rate 0.000444;\n",
    "===========================================================\n",
    "Epoch 022/096 - Mean training loss 0.084936; Mean training F1 0.935221; Mean validation loss 0.054688; Mean validation F1 0.935185; Learning rate 0.000439;\n",
    "===========================================================\n",
    "Epoch 023/096 - Mean training loss 0.085977; Mean training F1 0.933377; Mean validation loss 0.081577; Mean validation F1 0.934360; Learning rate 0.000433;\n",
    "===========================================================\n",
    "Epoch 024/096 - Mean training loss 0.084307; Mean training F1 0.936028; Mean validation loss 0.092105; Mean validation F1 0.935900; Learning rate 0.000428;\n",
    "===========================================================\n",
    "Epoch 025/096 - Mean training loss 0.084407; Mean training F1 0.935525; Mean validation loss 0.062688; Mean validation F1 0.935435; Learning rate 0.000422;\n",
    "===========================================================\n",
    "Epoch 026/096 - Mean training loss 0.084478; Mean training F1 0.935339; Mean validation loss 0.085214; Mean validation F1 0.925770; Learning rate 0.000416;\n",
    "===========================================================\n",
    "Epoch 027/096 - Mean training loss 0.204767; Mean training F1 0.884674; Mean validation loss 0.098937; Mean validation F1 0.931841; Learning rate 0.000410;\n",
    "===========================================================\n",
    "Epoch 028/096 - Mean training loss 0.092571; Mean training F1 0.931827; Mean validation loss 0.121501; Mean validation F1 0.932730; Learning rate 0.000403;\n",
    "===========================================================\n",
    "Epoch 029/096 - Mean training loss 0.090339; Mean training F1 0.932750; Mean validation loss 0.085485; Mean validation F1 0.935119; Learning rate 0.000397;\n",
    "===========================================================\n",
    "Epoch 030/096 - Mean training loss 0.087645; Mean training F1 0.934171; Mean validation loss 0.089760; Mean validation F1 0.935378; Learning rate 0.000390;\n",
    "===========================================================\n",
    "Epoch 031/096 - Mean training loss 0.087147; Mean training F1 0.934164; Mean validation loss 0.061809; Mean validation F1 0.931797; Learning rate 0.000383;\n",
    "===========================================================\n",
    "Epoch 032/096 - Mean training loss 0.086092; Mean training F1 0.934770; Mean validation loss 0.098906; Mean validation F1 0.935870; Learning rate 0.000377;\n",
    "===========================================================\n",
    "Epoch 033/096 - Mean training loss 0.084880; Mean training F1 0.935655; Mean validation loss 0.106161; Mean validation F1 0.933484; Learning rate 0.000369;\n",
    "===========================================================\n",
    "Epoch 034/096 - Mean training loss 0.084787; Mean training F1 0.935562; Mean validation loss 0.081289; Mean validation F1 0.935658; Learning rate 0.000362;\n",
    "===========================================================\n",
    "Epoch 035/096 - Mean training loss 0.086431; Mean training F1 0.935159; Mean validation loss 0.080151; Mean validation F1 0.929606; Learning rate 0.000355;\n",
    "===========================================================\n",
    "Epoch 036/096 - Mean training loss 0.084078; Mean training F1 0.935801; Mean validation loss 0.070599; Mean validation F1 0.935246; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 037/096 - Mean training loss 0.083559; Mean training F1 0.936190; Mean validation loss 0.089681; Mean validation F1 0.935851; Learning rate 0.000340;\n",
    "===========================================================\n",
    "Epoch 038/096 - Mean training loss 0.083026; Mean training F1 0.936657; Mean validation loss 0.087491; Mean validation F1 0.935755; Learning rate 0.000332;\n",
    "===========================================================\n",
    "Epoch 039/096 - Mean training loss 0.082916; Mean training F1 0.936597; Mean validation loss 0.077491; Mean validation F1 0.935752; Learning rate 0.000325;\n",
    "===========================================================\n",
    "Epoch 040/096 - Mean training loss 0.082692; Mean training F1 0.936952; Mean validation loss 0.091577; Mean validation F1 0.936321; Learning rate 0.000317;\n",
    "===========================================================\n",
    "Epoch 041/096 - Mean training loss 0.082542; Mean training F1 0.937006; Mean validation loss 0.085207; Mean validation F1 0.935471; Learning rate 0.000309;\n",
    "===========================================================\n",
    "Epoch 042/096 - Mean training loss 0.082881; Mean training F1 0.936428; Mean validation loss 0.102303; Mean validation F1 0.936241; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 043/096 - Mean training loss 0.082126; Mean training F1 0.937049; Mean validation loss 0.061887; Mean validation F1 0.935962; Learning rate 0.000293;\n",
    "===========================================================\n",
    "Epoch 044/096 - Mean training loss 0.082489; Mean training F1 0.936670; Mean validation loss 0.091209; Mean validation F1 0.936800; Learning rate 0.000285;\n",
    "===========================================================\n",
    "Epoch 045/096 - Mean training loss 0.081909; Mean training F1 0.937288; Mean validation loss 0.068194; Mean validation F1 0.936523; Learning rate 0.000277;\n",
    "===========================================================\n",
    "Epoch 046/096 - Mean training loss 0.081980; Mean training F1 0.937293; Mean validation loss 0.074694; Mean validation F1 0.936680; Learning rate 0.000269;\n",
    "===========================================================\n",
    "Epoch 047/096 - Mean training loss 0.081775; Mean training F1 0.937092; Mean validation loss 0.069949; Mean validation F1 0.936111; Learning rate 0.000261;\n",
    "===========================================================\n",
    "Epoch 048/096 - Mean training loss 0.081644; Mean training F1 0.937254; Mean validation loss 0.069965; Mean validation F1 0.936795; Learning rate 0.000253;\n",
    "===========================================================\n",
    "Epoch 049/096 - Mean training loss 0.081376; Mean training F1 0.937467; Mean validation loss 0.068728; Mean validation F1 0.936365; Learning rate 0.000245;\n",
    "===========================================================\n",
    "Epoch 050/096 - Mean training loss 0.081104; Mean training F1 0.937775; Mean validation loss 0.103270; Mean validation F1 0.936227; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 051/096 - Mean training loss 0.081303; Mean training F1 0.937410; Mean validation loss 0.084964; Mean validation F1 0.936125; Learning rate 0.000228;\n",
    "===========================================================\n",
    "Epoch 052/096 - Mean training loss 0.080975; Mean training F1 0.937474; Mean validation loss 0.092626; Mean validation F1 0.932641; Learning rate 0.000220;\n",
    "===========================================================\n",
    "Epoch 053/096 - Mean training loss 0.081294; Mean training F1 0.937584; Mean validation loss 0.051567; Mean validation F1 0.936628; Learning rate 0.000212;\n",
    "===========================================================\n",
    "Epoch 054/096 - Mean training loss 0.080627; Mean training F1 0.937975; Mean validation loss 0.071407; Mean validation F1 0.937140; Learning rate 0.000204;\n",
    "===========================================================\n",
    "Epoch 055/096 - Mean training loss 0.080581; Mean training F1 0.937976; Mean validation loss 0.054307; Mean validation F1 0.935930; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 056/096 - Mean training loss 0.080420; Mean training F1 0.937983; Mean validation loss 0.056378; Mean validation F1 0.937192; Learning rate 0.000189;\n",
    "===========================================================\n",
    "Epoch 057/096 - Mean training loss 0.080181; Mean training F1 0.938324; Mean validation loss 0.084305; Mean validation F1 0.936992; Learning rate 0.000181;\n",
    "===========================================================\n",
    "Epoch 058/096 - Mean training loss 0.080268; Mean training F1 0.938054; Mean validation loss 0.086820; Mean validation F1 0.936260; Learning rate 0.000173;\n",
    "===========================================================\n",
    "Epoch 059/096 - Mean training loss 0.080730; Mean training F1 0.937944; Mean validation loss 0.062478; Mean validation F1 0.937489; Learning rate 0.000166;\n",
    "===========================================================\n",
    "Epoch 060/096 - Mean training loss 0.079605; Mean training F1 0.938598; Mean validation loss 0.100206; Mean validation F1 0.935960; Learning rate 0.000158;\n",
    "===========================================================\n",
    "Epoch 061/096 - Mean training loss 0.079594; Mean training F1 0.938593; Mean validation loss 0.051889; Mean validation F1 0.936914; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 062/096 - Mean training loss 0.079777; Mean training F1 0.938684; Mean validation loss 0.099512; Mean validation F1 0.936839; Learning rate 0.000143;\n",
    "===========================================================\n",
    "Epoch 063/096 - Mean training loss 0.079307; Mean training F1 0.938930; Mean validation loss 0.047814; Mean validation F1 0.936629; Learning rate 0.000136;\n",
    "===========================================================\n",
    "Epoch 064/096 - Mean training loss 0.079092; Mean training F1 0.938972; Mean validation loss 0.055922; Mean validation F1 0.937470; Learning rate 0.000129;\n",
    "===========================================================\n",
    "Epoch 065/096 - Mean training loss 0.079078; Mean training F1 0.938922; Mean validation loss 0.078243; Mean validation F1 0.936831; Learning rate 0.000122;\n",
    "===========================================================\n",
    "Epoch 066/096 - Mean training loss 0.079067; Mean training F1 0.938911; Mean validation loss 0.080439; Mean validation F1 0.936678; Learning rate 0.000115;\n",
    "===========================================================\n",
    "Epoch 067/096 - Mean training loss 0.078703; Mean training F1 0.939153; Mean validation loss 0.052012; Mean validation F1 0.937065; Learning rate 0.000109;\n",
    "===========================================================\n",
    "Epoch 068/096 - Mean training loss 0.078665; Mean training F1 0.939128; Mean validation loss 0.107762; Mean validation F1 0.937165; Learning rate 0.000102;\n",
    "===========================================================\n",
    "Epoch 069/096 - Mean training loss 0.078450; Mean training F1 0.939219; Mean validation loss 0.089202; Mean validation F1 0.937081; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 070/096 - Mean training loss 0.078171; Mean training F1 0.939499; Mean validation loss 0.074147; Mean validation F1 0.936061; Learning rate 0.000090;\n",
    "===========================================================\n",
    "Epoch 071/096 - Mean training loss 0.078106; Mean training F1 0.939351; Mean validation loss 0.123576; Mean validation F1 0.936876; Learning rate 0.000084;\n",
    "===========================================================\n",
    "Epoch 072/096 - Mean training loss 0.077986; Mean training F1 0.939490; Mean validation loss 0.114138; Mean validation F1 0.937175; Learning rate 0.000078;\n",
    "===========================================================\n",
    "Epoch 073/096 - Mean training loss 0.078021; Mean training F1 0.939418; Mean validation loss 0.075832; Mean validation F1 0.937100; Learning rate 0.000072;\n",
    "===========================================================\n",
    "Epoch 074/096 - Mean training loss 0.077627; Mean training F1 0.939886; Mean validation loss 0.089303; Mean validation F1 0.936812; Learning rate 0.000067;\n",
    "===========================================================\n",
    "Epoch 075/096 - Mean training loss 0.077602; Mean training F1 0.939699; Mean validation loss 0.056519; Mean validation F1 0.937195; Learning rate 0.000061;\n",
    "===========================================================\n",
    "Epoch 076/096 - Mean training loss 0.077421; Mean training F1 0.939830; Mean validation loss 0.078585; Mean validation F1 0.937303; Learning rate 0.000056;\n",
    "===========================================================\n",
    "Epoch 077/096 - Mean training loss 0.077193; Mean training F1 0.940026; Mean validation loss 0.043926; Mean validation F1 0.937175; Learning rate 0.000052;\n",
    "===========================================================\n",
    "Epoch 078/096 - Mean training loss 0.077145; Mean training F1 0.939934; Mean validation loss 0.074533; Mean validation F1 0.937176; Learning rate 0.000047;\n",
    "===========================================================\n",
    "Epoch 079/096 - Mean training loss 0.076951; Mean training F1 0.940083; Mean validation loss 0.076999; Mean validation F1 0.936838; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 080/096 - Mean training loss 0.076904; Mean training F1 0.940118; Mean validation loss 0.062151; Mean validation F1 0.936609; Learning rate 0.000038;\n",
    "===========================================================\n",
    "Epoch 081/096 - Mean training loss 0.076785; Mean training F1 0.940105; Mean validation loss 0.055443; Mean validation F1 0.937253; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 082/096 - Mean training loss 0.076637; Mean training F1 0.940294; Mean validation loss 0.087298; Mean validation F1 0.937110; Learning rate 0.000031;\n",
    "===========================================================\n",
    "Epoch 083/096 - Mean training loss 0.076503; Mean training F1 0.940373; Mean validation loss 0.077609; Mean validation F1 0.937071; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 084/096 - Mean training loss 0.076548; Mean training F1 0.940267; Mean validation loss 0.087293; Mean validation F1 0.937073; Learning rate 0.000024;\n",
    "===========================================================\n",
    "Epoch 085/096 - Mean training loss 0.076292; Mean training F1 0.940507; Mean validation loss 0.046334; Mean validation F1 0.936598; Learning rate 0.000021;\n",
    "################################################################\n",
    "Training/validation for fold 3/5;\n",
    "===========================================================\n",
    "Epoch 001/096 - Mean training loss 0.386741; Mean training F1 0.736764; Mean validation loss 0.118273; Mean validation F1 0.816454; Learning rate 0.000500;\n",
    "===========================================================\n",
    "Epoch 002/096 - Mean training loss 0.188411; Mean training F1 0.866210; Mean validation loss 0.222886; Mean validation F1 0.884324; Learning rate 0.000500;\n",
    "===========================================================\n",
    "Epoch 003/096 - Mean training loss 0.131499; Mean training F1 0.903157; Mean validation loss 0.102930; Mean validation F1 0.925685; Learning rate 0.000499;\n",
    "===========================================================\n",
    "Epoch 004/096 - Mean training loss 0.113387; Mean training F1 0.917142; Mean validation loss 0.103496; Mean validation F1 0.930899; Learning rate 0.000498;\n",
    "===========================================================\n",
    "Epoch 005/096 - Mean training loss 0.106419; Mean training F1 0.920815; Mean validation loss 0.145311; Mean validation F1 0.914454; Learning rate 0.000497;\n",
    "===========================================================\n",
    "Epoch 006/096 - Mean training loss 0.100427; Mean training F1 0.924775; Mean validation loss 0.099799; Mean validation F1 0.933429; Learning rate 0.000496;\n",
    "===========================================================\n",
    "Epoch 007/096 - Mean training loss 0.095311; Mean training F1 0.929032; Mean validation loss 0.138243; Mean validation F1 0.929763; Learning rate 0.000494;\n",
    "===========================================================\n",
    "Epoch 008/096 - Mean training loss 0.093026; Mean training F1 0.930453; Mean validation loss 0.130162; Mean validation F1 0.934509; Learning rate 0.000492;\n",
    "===========================================================\n",
    "Epoch 009/096 - Mean training loss 0.090907; Mean training F1 0.932021; Mean validation loss 0.109671; Mean validation F1 0.933612; Learning rate 0.000490;\n",
    "===========================================================\n",
    "Epoch 010/096 - Mean training loss 0.091396; Mean training F1 0.930911; Mean validation loss 0.090825; Mean validation F1 0.932833; Learning rate 0.000487;\n",
    "===========================================================\n",
    "Epoch 011/096 - Mean training loss 0.090690; Mean training F1 0.931915; Mean validation loss 0.076071; Mean validation F1 0.934728; Learning rate 0.000484;\n",
    "===========================================================\n",
    "Epoch 012/096 - Mean training loss 0.090415; Mean training F1 0.932128; Mean validation loss 0.068898; Mean validation F1 0.933748; Learning rate 0.000481;\n",
    "===========================================================\n",
    "Epoch 013/096 - Mean training loss 0.087703; Mean training F1 0.934003; Mean validation loss 0.145958; Mean validation F1 0.933824; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 014/096 - Mean training loss 0.090090; Mean training F1 0.932977; Mean validation loss 0.088726; Mean validation F1 0.934383; Learning rate 0.000475;\n",
    "===========================================================\n",
    "Epoch 015/096 - Mean training loss 0.090013; Mean training F1 0.932448; Mean validation loss 0.066544; Mean validation F1 0.919194; Learning rate 0.000471;\n",
    "===========================================================\n",
    "Epoch 016/096 - Mean training loss 0.087776; Mean training F1 0.933601; Mean validation loss 0.090740; Mean validation F1 0.932882; Learning rate 0.000467;\n",
    "===========================================================\n",
    "Epoch 017/096 - Mean training loss 0.086535; Mean training F1 0.935152; Mean validation loss 0.085349; Mean validation F1 0.934282; Learning rate 0.000463;\n",
    "===========================================================\n",
    "Epoch 018/096 - Mean training loss 0.086589; Mean training F1 0.934735; Mean validation loss 0.117302; Mean validation F1 0.934961; Learning rate 0.000459;\n",
    "===========================================================\n",
    "Epoch 019/096 - Mean training loss 0.087578; Mean training F1 0.933971; Mean validation loss 0.100979; Mean validation F1 0.935826; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 020/096 - Mean training loss 0.085588; Mean training F1 0.935513; Mean validation loss 0.079383; Mean validation F1 0.933476; Learning rate 0.000449;\n",
    "===========================================================\n",
    "Epoch 021/096 - Mean training loss 0.085224; Mean training F1 0.935718; Mean validation loss 0.092992; Mean validation F1 0.936811; Learning rate 0.000444;\n",
    "===========================================================\n",
    "Epoch 022/096 - Mean training loss 0.084786; Mean training F1 0.935974; Mean validation loss 0.057754; Mean validation F1 0.932338; Learning rate 0.000439;\n",
    "===========================================================\n",
    "Epoch 023/096 - Mean training loss 0.084913; Mean training F1 0.935591; Mean validation loss 0.072394; Mean validation F1 0.935425; Learning rate 0.000433;\n",
    "===========================================================\n",
    "Epoch 024/096 - Mean training loss 0.085918; Mean training F1 0.934871; Mean validation loss 0.061548; Mean validation F1 0.934320; Learning rate 0.000428;\n",
    "===========================================================\n",
    "Epoch 025/096 - Mean training loss 0.084411; Mean training F1 0.936206; Mean validation loss 0.045827; Mean validation F1 0.935977; Learning rate 0.000422;\n",
    "===========================================================\n",
    "Epoch 026/096 - Mean training loss 0.084914; Mean training F1 0.935659; Mean validation loss 0.130147; Mean validation F1 0.936351; Learning rate 0.000416;\n",
    "===========================================================\n",
    "Epoch 027/096 - Mean training loss 0.083570; Mean training F1 0.936716; Mean validation loss 0.060627; Mean validation F1 0.934802; Learning rate 0.000410;\n",
    "===========================================================\n",
    "Epoch 028/096 - Mean training loss 0.083608; Mean training F1 0.936587; Mean validation loss 0.078445; Mean validation F1 0.932646; Learning rate 0.000403;\n",
    "===========================================================\n",
    "Epoch 029/096 - Mean training loss 0.083905; Mean training F1 0.936101; Mean validation loss 0.087578; Mean validation F1 0.935871; Learning rate 0.000397;\n",
    "===========================================================\n",
    "Epoch 030/096 - Mean training loss 0.083017; Mean training F1 0.937324; Mean validation loss 0.094818; Mean validation F1 0.935404; Learning rate 0.000390;\n",
    "===========================================================\n",
    "Epoch 031/096 - Mean training loss 0.083334; Mean training F1 0.936878; Mean validation loss 0.083195; Mean validation F1 0.936709; Learning rate 0.000383;\n",
    "===========================================================\n",
    "Epoch 032/096 - Mean training loss 0.082910; Mean training F1 0.937129; Mean validation loss 0.061211; Mean validation F1 0.935534; Learning rate 0.000377;\n",
    "===========================================================\n",
    "Epoch 033/096 - Mean training loss 0.083542; Mean training F1 0.936212; Mean validation loss 0.101371; Mean validation F1 0.937067; Learning rate 0.000369;\n",
    "===========================================================\n",
    "Epoch 034/096 - Mean training loss 0.082352; Mean training F1 0.937451; Mean validation loss 0.091002; Mean validation F1 0.935939; Learning rate 0.000362;\n",
    "===========================================================\n",
    "Epoch 035/096 - Mean training loss 0.082026; Mean training F1 0.937902; Mean validation loss 0.064401; Mean validation F1 0.935856; Learning rate 0.000355;\n",
    "===========================================================\n",
    "Epoch 036/096 - Mean training loss 0.082083; Mean training F1 0.937524; Mean validation loss 0.072726; Mean validation F1 0.935239; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 037/096 - Mean training loss 0.081739; Mean training F1 0.937798; Mean validation loss 0.058031; Mean validation F1 0.935871; Learning rate 0.000340;\n",
    "===========================================================\n",
    "Epoch 038/096 - Mean training loss 0.081605; Mean training F1 0.938057; Mean validation loss 0.085712; Mean validation F1 0.936704; Learning rate 0.000332;\n",
    "===========================================================\n",
    "Epoch 039/096 - Mean training loss 0.081500; Mean training F1 0.938096; Mean validation loss 0.093674; Mean validation F1 0.936554; Learning rate 0.000325;\n",
    "===========================================================\n",
    "Epoch 040/096 - Mean training loss 0.081275; Mean training F1 0.938076; Mean validation loss 0.106722; Mean validation F1 0.936853; Learning rate 0.000317;\n",
    "===========================================================\n",
    "Epoch 041/096 - Mean training loss 0.084725; Mean training F1 0.936998; Mean validation loss 0.095913; Mean validation F1 0.928812; Learning rate 0.000309;\n",
    "===========================================================\n",
    "Epoch 042/096 - Mean training loss 0.089112; Mean training F1 0.933256; Mean validation loss 0.083344; Mean validation F1 0.936829; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 043/096 - Mean training loss 0.081969; Mean training F1 0.937955; Mean validation loss 0.071107; Mean validation F1 0.937203; Learning rate 0.000293;\n",
    "===========================================================\n",
    "Epoch 044/096 - Mean training loss 0.080951; Mean training F1 0.938349; Mean validation loss 0.066768; Mean validation F1 0.937092; Learning rate 0.000285;\n",
    "===========================================================\n",
    "Epoch 045/096 - Mean training loss 0.080788; Mean training F1 0.938600; Mean validation loss 0.075408; Mean validation F1 0.935834; Learning rate 0.000277;\n",
    "===========================================================\n",
    "Epoch 046/096 - Mean training loss 0.080582; Mean training F1 0.938629; Mean validation loss 0.094911; Mean validation F1 0.937450; Learning rate 0.000269;\n",
    "===========================================================\n",
    "Epoch 047/096 - Mean training loss 0.080181; Mean training F1 0.938706; Mean validation loss 0.068942; Mean validation F1 0.937115; Learning rate 0.000261;\n",
    "===========================================================\n",
    "Epoch 048/096 - Mean training loss 0.080045; Mean training F1 0.938915; Mean validation loss 0.082657; Mean validation F1 0.937323; Learning rate 0.000253;\n",
    "===========================================================\n",
    "Epoch 049/096 - Mean training loss 0.079770; Mean training F1 0.939163; Mean validation loss 0.082774; Mean validation F1 0.936741; Learning rate 0.000245;\n",
    "===========================================================\n",
    "Epoch 050/096 - Mean training loss 0.079616; Mean training F1 0.938994; Mean validation loss 0.056779; Mean validation F1 0.937293; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 051/096 - Mean training loss 0.079480; Mean training F1 0.939103; Mean validation loss 0.059870; Mean validation F1 0.936919; Learning rate 0.000228;\n",
    "===========================================================\n",
    "Epoch 052/096 - Mean training loss 0.079338; Mean training F1 0.938977; Mean validation loss 0.052876; Mean validation F1 0.936884; Learning rate 0.000220;\n",
    "===========================================================\n",
    "Epoch 053/096 - Mean training loss 0.079089; Mean training F1 0.939189; Mean validation loss 0.066937; Mean validation F1 0.937180; Learning rate 0.000212;\n",
    "===========================================================\n",
    "Epoch 054/096 - Mean training loss 0.078843; Mean training F1 0.939362; Mean validation loss 0.076504; Mean validation F1 0.937288; Learning rate 0.000204;\n",
    "===========================================================\n",
    "Epoch 055/096 - Mean training loss 0.078458; Mean training F1 0.939694; Mean validation loss 0.072863; Mean validation F1 0.937039; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 056/096 - Mean training loss 0.078392; Mean training F1 0.939690; Mean validation loss 0.099493; Mean validation F1 0.936954; Learning rate 0.000189;\n",
    "===========================================================\n",
    "Epoch 057/096 - Mean training loss 0.078076; Mean training F1 0.939807; Mean validation loss 0.075798; Mean validation F1 0.937394; Learning rate 0.000181;\n",
    "===========================================================\n",
    "Epoch 058/096 - Mean training loss 0.077700; Mean training F1 0.940240; Mean validation loss 0.111666; Mean validation F1 0.937041; Learning rate 0.000173;\n",
    "===========================================================\n",
    "Epoch 059/096 - Mean training loss 0.077352; Mean training F1 0.940160; Mean validation loss 0.093771; Mean validation F1 0.937181; Learning rate 0.000166;\n",
    "===========================================================\n",
    "Epoch 060/096 - Mean training loss 0.077166; Mean training F1 0.940314; Mean validation loss 0.090949; Mean validation F1 0.937077; Learning rate 0.000158;\n",
    "===========================================================\n",
    "Epoch 061/096 - Mean training loss 0.076553; Mean training F1 0.940682; Mean validation loss 0.115603; Mean validation F1 0.936791; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 062/096 - Mean training loss 0.076215; Mean training F1 0.940631; Mean validation loss 0.053371; Mean validation F1 0.936946; Learning rate 0.000143;\n",
    "===========================================================\n",
    "Epoch 063/096 - Mean training loss 0.075775; Mean training F1 0.941024; Mean validation loss 0.087847; Mean validation F1 0.936977; Learning rate 0.000136;\n",
    "===========================================================\n",
    "Epoch 064/096 - Mean training loss 0.075268; Mean training F1 0.941349; Mean validation loss 0.069507; Mean validation F1 0.936481; Learning rate 0.000129;\n",
    "===========================================================\n",
    "Epoch 065/096 - Mean training loss 0.074862; Mean training F1 0.941355; Mean validation loss 0.064998; Mean validation F1 0.936190; Learning rate 0.000122;\n",
    "===========================================================\n",
    "Epoch 066/096 - Mean training loss 0.074394; Mean training F1 0.941739; Mean validation loss 0.112326; Mean validation F1 0.936386; Learning rate 0.000115;\n",
    "===========================================================\n",
    "Epoch 067/096 - Mean training loss 0.074057; Mean training F1 0.941894; Mean validation loss 0.087862; Mean validation F1 0.936734; Learning rate 0.000109;\n",
    "===========================================================\n",
    "Epoch 068/096 - Mean training loss 0.073466; Mean training F1 0.942150; Mean validation loss 0.088765; Mean validation F1 0.936653; Learning rate 0.000102;\n",
    "===========================================================\n",
    "Epoch 069/096 - Mean training loss 0.072891; Mean training F1 0.942505; Mean validation loss 0.064257; Mean validation F1 0.936523; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 070/096 - Mean training loss 0.072985; Mean training F1 0.942476; Mean validation loss 0.078676; Mean validation F1 0.936328; Learning rate 0.000090;\n",
    "===========================================================\n",
    "Epoch 071/096 - Mean training loss 0.072313; Mean training F1 0.942802; Mean validation loss 0.100130; Mean validation F1 0.936472; Learning rate 0.000084;\n",
    "===========================================================\n",
    "Epoch 072/096 - Mean training loss 0.071439; Mean training F1 0.943227; Mean validation loss 0.082740; Mean validation F1 0.936385; Learning rate 0.000078;\n",
    "################################################################\n",
    "Training/validation for fold 4/5;\n",
    "===========================================================\n",
    "Epoch 001/096 - Mean training loss 0.468247; Mean training F1 0.695626; Mean validation loss 0.148862; Mean validation F1 0.878318; Learning rate 0.000500;\n",
    "===========================================================\n",
    "Epoch 002/096 - Mean training loss 0.154216; Mean training F1 0.884165; Mean validation loss 0.166866; Mean validation F1 0.923247; Learning rate 0.000500;\n",
    "===========================================================\n",
    "Epoch 003/096 - Mean training loss 0.163407; Mean training F1 0.880759; Mean validation loss 0.182524; Mean validation F1 0.926844; Learning rate 0.000499;\n",
    "===========================================================\n",
    "Epoch 004/096 - Mean training loss 0.122262; Mean training F1 0.908862; Mean validation loss 0.071858; Mean validation F1 0.930002; Learning rate 0.000498;\n",
    "===========================================================\n",
    "Epoch 005/096 - Mean training loss 0.124608; Mean training F1 0.909490; Mean validation loss 0.128145; Mean validation F1 0.910437; Learning rate 0.000497;\n",
    "===========================================================\n",
    "Epoch 006/096 - Mean training loss 0.105042; Mean training F1 0.922395; Mean validation loss 0.064732; Mean validation F1 0.929936; Learning rate 0.000496;\n",
    "===========================================================\n",
    "Epoch 007/096 - Mean training loss 0.098456; Mean training F1 0.926693; Mean validation loss 0.112110; Mean validation F1 0.932937; Learning rate 0.000494;\n",
    "===========================================================\n",
    "Epoch 008/096 - Mean training loss 0.144435; Mean training F1 0.901713; Mean validation loss 0.115783; Mean validation F1 0.907063; Learning rate 0.000492;\n",
    "===========================================================\n",
    "Epoch 009/096 - Mean training loss 0.112347; Mean training F1 0.917595; Mean validation loss 0.083614; Mean validation F1 0.935280; Learning rate 0.000490;\n",
    "===========================================================\n",
    "Epoch 010/096 - Mean training loss 0.099399; Mean training F1 0.926243; Mean validation loss 0.103708; Mean validation F1 0.931922; Learning rate 0.000487;\n",
    "===========================================================\n",
    "Epoch 011/096 - Mean training loss 0.093184; Mean training F1 0.930873; Mean validation loss 0.093006; Mean validation F1 0.935858; Learning rate 0.000484;\n",
    "===========================================================\n",
    "Epoch 012/096 - Mean training loss 0.092070; Mean training F1 0.931946; Mean validation loss 0.072437; Mean validation F1 0.930672; Learning rate 0.000481;\n",
    "===========================================================\n",
    "Epoch 013/096 - Mean training loss 0.090356; Mean training F1 0.932490; Mean validation loss 0.097022; Mean validation F1 0.935351; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 014/096 - Mean training loss 0.090580; Mean training F1 0.932196; Mean validation loss 0.082745; Mean validation F1 0.934821; Learning rate 0.000475;\n",
    "===========================================================\n",
    "Epoch 015/096 - Mean training loss 0.089961; Mean training F1 0.932998; Mean validation loss 0.086287; Mean validation F1 0.929596; Learning rate 0.000471;\n",
    "===========================================================\n",
    "Epoch 016/096 - Mean training loss 0.088905; Mean training F1 0.933454; Mean validation loss 0.089752; Mean validation F1 0.936202; Learning rate 0.000467;\n",
    "===========================================================\n",
    "Epoch 017/096 - Mean training loss 0.087987; Mean training F1 0.934289; Mean validation loss 0.082151; Mean validation F1 0.936151; Learning rate 0.000463;\n",
    "===========================================================\n",
    "Epoch 018/096 - Mean training loss 0.224467; Mean training F1 0.873526; Mean validation loss 0.079244; Mean validation F1 0.920186; Learning rate 0.000459;\n",
    "===========================================================\n",
    "Epoch 019/096 - Mean training loss 0.112394; Mean training F1 0.917209; Mean validation loss 0.143339; Mean validation F1 0.934580; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 020/096 - Mean training loss 0.100308; Mean training F1 0.926798; Mean validation loss 0.127285; Mean validation F1 0.934023; Learning rate 0.000449;\n",
    "===========================================================\n",
    "Epoch 021/096 - Mean training loss 0.094181; Mean training F1 0.930750; Mean validation loss 0.083397; Mean validation F1 0.936212; Learning rate 0.000444;\n",
    "===========================================================\n",
    "Epoch 022/096 - Mean training loss 0.092305; Mean training F1 0.931701; Mean validation loss 0.081337; Mean validation F1 0.936807; Learning rate 0.000439;\n",
    "===========================================================\n",
    "Epoch 023/096 - Mean training loss 0.090205; Mean training F1 0.933134; Mean validation loss 0.086724; Mean validation F1 0.937531; Learning rate 0.000433;\n",
    "===========================================================\n",
    "Epoch 024/096 - Mean training loss 0.089272; Mean training F1 0.934031; Mean validation loss 0.072074; Mean validation F1 0.937209; Learning rate 0.000428;\n",
    "===========================================================\n",
    "Epoch 025/096 - Mean training loss 0.091899; Mean training F1 0.932383; Mean validation loss 0.176115; Mean validation F1 0.935158; Learning rate 0.000422;\n",
    "===========================================================\n",
    "Epoch 026/096 - Mean training loss 0.089180; Mean training F1 0.933829; Mean validation loss 0.091414; Mean validation F1 0.937017; Learning rate 0.000416;\n",
    "===========================================================\n",
    "Epoch 027/096 - Mean training loss 0.087755; Mean training F1 0.934956; Mean validation loss 0.050236; Mean validation F1 0.932113; Learning rate 0.000410;\n",
    "===========================================================\n",
    "Epoch 028/096 - Mean training loss 0.087690; Mean training F1 0.934547; Mean validation loss 0.067214; Mean validation F1 0.936565; Learning rate 0.000403;\n",
    "===========================================================\n",
    "Epoch 029/096 - Mean training loss 0.087848; Mean training F1 0.934801; Mean validation loss 0.108922; Mean validation F1 0.935772; Learning rate 0.000397;\n",
    "===========================================================\n",
    "Epoch 030/096 - Mean training loss 0.086607; Mean training F1 0.935651; Mean validation loss 0.077772; Mean validation F1 0.937859; Learning rate 0.000390;\n",
    "===========================================================\n",
    "Epoch 031/096 - Mean training loss 0.132557; Mean training F1 0.912650; Mean validation loss 0.138219; Mean validation F1 0.904174; Learning rate 0.000383;\n",
    "===========================================================\n",
    "Epoch 032/096 - Mean training loss 0.100125; Mean training F1 0.925124; Mean validation loss 0.089982; Mean validation F1 0.936051; Learning rate 0.000377;\n",
    "===========================================================\n",
    "Epoch 033/096 - Mean training loss 0.092271; Mean training F1 0.930931; Mean validation loss 0.143568; Mean validation F1 0.937000; Learning rate 0.000369;\n",
    "===========================================================\n",
    "Epoch 034/096 - Mean training loss 0.089250; Mean training F1 0.933993; Mean validation loss 0.067623; Mean validation F1 0.937494; Learning rate 0.000362;\n",
    "===========================================================\n",
    "Epoch 035/096 - Mean training loss 0.087965; Mean training F1 0.934994; Mean validation loss 0.063228; Mean validation F1 0.937587; Learning rate 0.000355;\n",
    "===========================================================\n",
    "Epoch 036/096 - Mean training loss 0.087150; Mean training F1 0.935213; Mean validation loss 0.063169; Mean validation F1 0.936813; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 037/096 - Mean training loss 0.086775; Mean training F1 0.935148; Mean validation loss 0.066981; Mean validation F1 0.937336; Learning rate 0.000340;\n",
    "===========================================================\n",
    "Epoch 038/096 - Mean training loss 0.086479; Mean training F1 0.935394; Mean validation loss 0.088013; Mean validation F1 0.937750; Learning rate 0.000332;\n",
    "===========================================================\n",
    "Epoch 039/096 - Mean training loss 0.086380; Mean training F1 0.935849; Mean validation loss 0.079139; Mean validation F1 0.937982; Learning rate 0.000325;\n",
    "===========================================================\n",
    "Epoch 040/096 - Mean training loss 0.086005; Mean training F1 0.935908; Mean validation loss 0.084300; Mean validation F1 0.936325; Learning rate 0.000317;\n",
    "===========================================================\n",
    "Epoch 041/096 - Mean training loss 0.086000; Mean training F1 0.935865; Mean validation loss 0.121064; Mean validation F1 0.937439; Learning rate 0.000309;\n",
    "===========================================================\n",
    "Epoch 042/096 - Mean training loss 0.085510; Mean training F1 0.936062; Mean validation loss 0.060799; Mean validation F1 0.937323; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 043/096 - Mean training loss 0.085069; Mean training F1 0.936477; Mean validation loss 0.069724; Mean validation F1 0.934288; Learning rate 0.000293;\n",
    "===========================================================\n",
    "Epoch 044/096 - Mean training loss 0.085069; Mean training F1 0.936446; Mean validation loss 0.108287; Mean validation F1 0.934868; Learning rate 0.000285;\n",
    "===========================================================\n",
    "Epoch 045/096 - Mean training loss 0.084875; Mean training F1 0.936419; Mean validation loss 0.093401; Mean validation F1 0.938201; Learning rate 0.000277;\n",
    "===========================================================\n",
    "Epoch 046/096 - Mean training loss 0.084551; Mean training F1 0.936865; Mean validation loss 0.067599; Mean validation F1 0.938036; Learning rate 0.000269;\n",
    "===========================================================\n",
    "Epoch 047/096 - Mean training loss 0.084370; Mean training F1 0.936576; Mean validation loss 0.062899; Mean validation F1 0.936764; Learning rate 0.000261;\n",
    "===========================================================\n",
    "Epoch 048/096 - Mean training loss 0.084408; Mean training F1 0.936683; Mean validation loss 0.056256; Mean validation F1 0.938350; Learning rate 0.000253;\n",
    "===========================================================\n",
    "Epoch 049/096 - Mean training loss 0.084184; Mean training F1 0.936653; Mean validation loss 0.087441; Mean validation F1 0.937790; Learning rate 0.000245;\n",
    "===========================================================\n",
    "Epoch 050/096 - Mean training loss 0.083865; Mean training F1 0.937206; Mean validation loss 0.066268; Mean validation F1 0.937628; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 051/096 - Mean training loss 0.083604; Mean training F1 0.937274; Mean validation loss 0.098379; Mean validation F1 0.937401; Learning rate 0.000228;\n",
    "===========================================================\n",
    "Epoch 052/096 - Mean training loss 0.083545; Mean training F1 0.937234; Mean validation loss 0.096024; Mean validation F1 0.938340; Learning rate 0.000220;\n",
    "===========================================================\n",
    "Epoch 053/096 - Mean training loss 0.083610; Mean training F1 0.937002; Mean validation loss 0.024589; Mean validation F1 0.938447; Learning rate 0.000212;\n",
    "===========================================================\n",
    "Epoch 054/096 - Mean training loss 0.083151; Mean training F1 0.937244; Mean validation loss 0.102062; Mean validation F1 0.938119; Learning rate 0.000204;\n",
    "===========================================================\n",
    "Epoch 055/096 - Mean training loss 0.083214; Mean training F1 0.937285; Mean validation loss 0.067166; Mean validation F1 0.938239; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 056/096 - Mean training loss 0.082818; Mean training F1 0.937720; Mean validation loss 0.090207; Mean validation F1 0.938273; Learning rate 0.000189;\n",
    "===========================================================\n",
    "Epoch 057/096 - Mean training loss 0.082648; Mean training F1 0.937811; Mean validation loss 0.093418; Mean validation F1 0.938217; Learning rate 0.000181;\n",
    "===========================================================\n",
    "Epoch 058/096 - Mean training loss 0.082728; Mean training F1 0.937558; Mean validation loss 0.070299; Mean validation F1 0.938508; Learning rate 0.000173;\n",
    "===========================================================\n",
    "Epoch 059/096 - Mean training loss 0.082385; Mean training F1 0.937872; Mean validation loss 0.089938; Mean validation F1 0.936796; Learning rate 0.000166;\n",
    "===========================================================\n",
    "Epoch 060/096 - Mean training loss 0.082225; Mean training F1 0.937927; Mean validation loss 0.074861; Mean validation F1 0.937790; Learning rate 0.000158;\n",
    "===========================================================\n",
    "Epoch 061/096 - Mean training loss 0.082218; Mean training F1 0.937972; Mean validation loss 0.040343; Mean validation F1 0.938527; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 062/096 - Mean training loss 0.081964; Mean training F1 0.938122; Mean validation loss 0.073448; Mean validation F1 0.938326; Learning rate 0.000143;\n",
    "===========================================================\n",
    "Epoch 063/096 - Mean training loss 0.081771; Mean training F1 0.938238; Mean validation loss 0.103909; Mean validation F1 0.938520; Learning rate 0.000136;\n",
    "===========================================================\n",
    "Epoch 064/096 - Mean training loss 0.081600; Mean training F1 0.938349; Mean validation loss 0.075131; Mean validation F1 0.937480; Learning rate 0.000129;\n",
    "===========================================================\n",
    "Epoch 065/096 - Mean training loss 0.081558; Mean training F1 0.938171; Mean validation loss 0.071703; Mean validation F1 0.938577; Learning rate 0.000122;\n",
    "===========================================================\n",
    "Epoch 066/096 - Mean training loss 0.081373; Mean training F1 0.938564; Mean validation loss 0.088940; Mean validation F1 0.938449; Learning rate 0.000115;\n",
    "===========================================================\n",
    "Epoch 067/096 - Mean training loss 0.081235; Mean training F1 0.938427; Mean validation loss 0.076877; Mean validation F1 0.938442; Learning rate 0.000109;\n",
    "===========================================================\n",
    "Epoch 068/096 - Mean training loss 0.081072; Mean training F1 0.938665; Mean validation loss 0.060540; Mean validation F1 0.938954; Learning rate 0.000102;\n",
    "===========================================================\n",
    "Epoch 069/096 - Mean training loss 0.081001; Mean training F1 0.938727; Mean validation loss 0.055466; Mean validation F1 0.938918; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 070/096 - Mean training loss 0.080812; Mean training F1 0.938746; Mean validation loss 0.083094; Mean validation F1 0.938754; Learning rate 0.000090;\n",
    "===========================================================\n",
    "Epoch 071/096 - Mean training loss 0.080734; Mean training F1 0.938886; Mean validation loss 0.059881; Mean validation F1 0.938455; Learning rate 0.000084;\n",
    "===========================================================\n",
    "Epoch 072/096 - Mean training loss 0.080638; Mean training F1 0.938833; Mean validation loss 0.061259; Mean validation F1 0.938763; Learning rate 0.000078;\n",
    "===========================================================\n",
    "Epoch 073/096 - Mean training loss 0.080458; Mean training F1 0.938860; Mean validation loss 0.088120; Mean validation F1 0.938765; Learning rate 0.000072;\n",
    "===========================================================\n",
    "Epoch 074/096 - Mean training loss 0.080435; Mean training F1 0.938821; Mean validation loss 0.061832; Mean validation F1 0.938528; Learning rate 0.000067;\n",
    "===========================================================\n",
    "Epoch 075/096 - Mean training loss 0.080263; Mean training F1 0.939122; Mean validation loss 0.058044; Mean validation F1 0.938719; Learning rate 0.000061;\n",
    "===========================================================\n",
    "Epoch 076/096 - Mean training loss 0.080128; Mean training F1 0.939105; Mean validation loss 0.107880; Mean validation F1 0.938901; Learning rate 0.000056;\n",
    "===========================================================\n",
    "Epoch 077/096 - Mean training loss 0.079979; Mean training F1 0.939121; Mean validation loss 0.065004; Mean validation F1 0.938777; Learning rate 0.000052;\n",
    "===========================================================\n",
    "Epoch 078/096 - Mean training loss 0.079904; Mean training F1 0.939211; Mean validation loss 0.072946; Mean validation F1 0.938707; Learning rate 0.000047;\n",
    "===========================================================\n",
    "Epoch 079/096 - Mean training loss 0.079767; Mean training F1 0.939227; Mean validation loss 0.088512; Mean validation F1 0.938618; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 080/096 - Mean training loss 0.079728; Mean training F1 0.939418; Mean validation loss 0.111239; Mean validation F1 0.938820; Learning rate 0.000038;\n",
    "===========================================================\n",
    "Epoch 081/096 - Mean training loss 0.079675; Mean training F1 0.939305; Mean validation loss 0.097376; Mean validation F1 0.938578; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 082/096 - Mean training loss 0.079571; Mean training F1 0.939410; Mean validation loss 0.066402; Mean validation F1 0.938619; Learning rate 0.000031;\n",
    "===========================================================\n",
    "Epoch 083/096 - Mean training loss 0.079447; Mean training F1 0.939525; Mean validation loss 0.060601; Mean validation F1 0.938783; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 084/096 - Mean training loss 0.079349; Mean training F1 0.939518; Mean validation loss 0.103994; Mean validation F1 0.938879; Learning rate 0.000024;\n",
    "===========================================================\n",
    "Epoch 085/096 - Mean training loss 0.079331; Mean training F1 0.939495; Mean validation loss 0.093670; Mean validation F1 0.938798; Learning rate 0.000021;\n",
    "===========================================================\n",
    "Epoch 086/096 - Mean training loss 0.079228; Mean training F1 0.939608; Mean validation loss 0.073624; Mean validation F1 0.938612; Learning rate 0.000018;\n",
    "===========================================================\n",
    "Epoch 087/096 - Mean training loss 0.079163; Mean training F1 0.939673; Mean validation loss 0.097390; Mean validation F1 0.938700; Learning rate 0.000016;\n",
    "===========================================================\n",
    "Epoch 088/096 - Mean training loss 0.079116; Mean training F1 0.939746; Mean validation loss 0.068161; Mean validation F1 0.938897; Learning rate 0.000014;\n",
    "===========================================================\n",
    "Epoch 089/096 - Mean training loss 0.079125; Mean training F1 0.939729; Mean validation loss 0.098399; Mean validation F1 0.938831; Learning rate 0.000012;\n",
    "===========================================================\n",
    "Epoch 090/096 - Mean training loss 0.078988; Mean training F1 0.939872; Mean validation loss 0.077353; Mean validation F1 0.938756; Learning rate 0.000010;\n",
    "===========================================================\n",
    "Epoch 091/096 - Mean training loss 0.078972; Mean training F1 0.939748; Mean validation loss 0.076436; Mean validation F1 0.938684; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 092/096 - Mean training loss 0.078973; Mean training F1 0.939759; Mean validation loss 0.063999; Mean validation F1 0.938857; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 093/096 - Mean training loss 0.078927; Mean training F1 0.939676; Mean validation loss 0.085634; Mean validation F1 0.938737; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 094/096 - Mean training loss 0.078878; Mean training F1 0.939791; Mean validation loss 0.056370; Mean validation F1 0.938809; Learning rate 0.000006;\n",
    "################################################################\n",
    "Training/validation for fold 5/5;\n",
    "===========================================================\n",
    "Epoch 001/096 - Mean training loss 0.403289; Mean training F1 0.728635; Mean validation loss 0.182789; Mean validation F1 0.841891; Learning rate 0.000500;\n",
    "===========================================================\n",
    "Epoch 002/096 - Mean training loss 0.153397; Mean training F1 0.888508; Mean validation loss 0.099083; Mean validation F1 0.920793; Learning rate 0.000500;\n",
    "===========================================================\n",
    "Epoch 003/096 - Mean training loss 0.126706; Mean training F1 0.905005; Mean validation loss 0.082065; Mean validation F1 0.907120; Learning rate 0.000499;\n",
    "===========================================================\n",
    "Epoch 004/096 - Mean training loss 0.189652; Mean training F1 0.877120; Mean validation loss 0.132715; Mean validation F1 0.920028; Learning rate 0.000498;\n",
    "===========================================================\n",
    "Epoch 005/096 - Mean training loss 0.118515; Mean training F1 0.913921; Mean validation loss 0.132710; Mean validation F1 0.932225; Learning rate 0.000497;\n",
    "===========================================================\n",
    "Epoch 006/096 - Mean training loss 0.108855; Mean training F1 0.919712; Mean validation loss 0.108250; Mean validation F1 0.933738; Learning rate 0.000496;\n",
    "===========================================================\n",
    "Epoch 007/096 - Mean training loss 0.102039; Mean training F1 0.924265; Mean validation loss 0.079190; Mean validation F1 0.933867; Learning rate 0.000494;\n",
    "===========================================================\n",
    "Epoch 008/096 - Mean training loss 0.170327; Mean training F1 0.887061; Mean validation loss 0.134430; Mean validation F1 0.925545; Learning rate 0.000492;\n",
    "===========================================================\n",
    "Epoch 009/096 - Mean training loss 0.122283; Mean training F1 0.909557; Mean validation loss 0.114469; Mean validation F1 0.931941; Learning rate 0.000490;\n",
    "===========================================================\n",
    "Epoch 010/096 - Mean training loss 0.105728; Mean training F1 0.923373; Mean validation loss 0.112680; Mean validation F1 0.932990; Learning rate 0.000487;\n",
    "===========================================================\n",
    "Epoch 011/096 - Mean training loss 0.097721; Mean training F1 0.928269; Mean validation loss 0.074055; Mean validation F1 0.936415; Learning rate 0.000484;\n",
    "===========================================================\n",
    "Epoch 012/096 - Mean training loss 0.095549; Mean training F1 0.929017; Mean validation loss 0.057172; Mean validation F1 0.932068; Learning rate 0.000481;\n",
    "===========================================================\n",
    "Epoch 013/096 - Mean training loss 0.093732; Mean training F1 0.930587; Mean validation loss 0.126646; Mean validation F1 0.936865; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 014/096 - Mean training loss 0.093008; Mean training F1 0.930593; Mean validation loss 0.121231; Mean validation F1 0.935523; Learning rate 0.000475;\n",
    "===========================================================\n",
    "Epoch 015/096 - Mean training loss 0.124921; Mean training F1 0.917638; Mean validation loss 0.092577; Mean validation F1 0.936678; Learning rate 0.000471;\n",
    "===========================================================\n",
    "Epoch 016/096 - Mean training loss 0.095800; Mean training F1 0.928625; Mean validation loss 0.046008; Mean validation F1 0.932759; Learning rate 0.000467;\n",
    "===========================================================\n",
    "Epoch 017/096 - Mean training loss 0.091840; Mean training F1 0.932043; Mean validation loss 0.062049; Mean validation F1 0.936405; Learning rate 0.000463;\n",
    "===========================================================\n",
    "Epoch 018/096 - Mean training loss 0.090488; Mean training F1 0.932595; Mean validation loss 0.072554; Mean validation F1 0.937326; Learning rate 0.000459;\n",
    "===========================================================\n",
    "Epoch 019/096 - Mean training loss 0.089439; Mean training F1 0.933628; Mean validation loss 0.100985; Mean validation F1 0.935657; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 020/096 - Mean training loss 0.090376; Mean training F1 0.932365; Mean validation loss 0.085422; Mean validation F1 0.935725; Learning rate 0.000449;\n",
    "===========================================================\n",
    "Epoch 021/096 - Mean training loss 0.094421; Mean training F1 0.930879; Mean validation loss 0.082558; Mean validation F1 0.936663; Learning rate 0.000444;\n",
    "===========================================================\n",
    "Epoch 022/096 - Mean training loss 0.091042; Mean training F1 0.932525; Mean validation loss 0.125101; Mean validation F1 0.936739; Learning rate 0.000439;\n",
    "===========================================================\n",
    "Epoch 023/096 - Mean training loss 0.088138; Mean training F1 0.934401; Mean validation loss 0.096564; Mean validation F1 0.936659; Learning rate 0.000433;\n",
    "===========================================================\n",
    "Epoch 024/096 - Mean training loss 0.087889; Mean training F1 0.934595; Mean validation loss 0.104145; Mean validation F1 0.934741; Learning rate 0.000428;\n",
    "===========================================================\n",
    "Epoch 025/096 - Mean training loss 0.088213; Mean training F1 0.933849; Mean validation loss 0.078123; Mean validation F1 0.928905; Learning rate 0.000422;\n",
    "===========================================================\n",
    "Epoch 026/096 - Mean training loss 0.087530; Mean training F1 0.934522; Mean validation loss 0.099645; Mean validation F1 0.936772; Learning rate 0.000416;\n",
    "===========================================================\n",
    "Epoch 027/096 - Mean training loss 0.088356; Mean training F1 0.934241; Mean validation loss 0.102125; Mean validation F1 0.937658; Learning rate 0.000410;\n",
    "===========================================================\n",
    "Epoch 028/096 - Mean training loss 0.087135; Mean training F1 0.934699; Mean validation loss 0.096726; Mean validation F1 0.922936; Learning rate 0.000403;\n",
    "===========================================================\n",
    "Epoch 029/096 - Mean training loss 0.087001; Mean training F1 0.935112; Mean validation loss 0.088309; Mean validation F1 0.936602; Learning rate 0.000397;\n",
    "===========================================================\n",
    "Epoch 030/096 - Mean training loss 0.103108; Mean training F1 0.925724; Mean validation loss 0.127312; Mean validation F1 0.928475; Learning rate 0.000390;\n",
    "===========================================================\n",
    "Epoch 031/096 - Mean training loss 0.092777; Mean training F1 0.931604; Mean validation loss 0.076712; Mean validation F1 0.933764; Learning rate 0.000383;\n",
    "===========================================================\n",
    "Epoch 032/096 - Mean training loss 0.088037; Mean training F1 0.934089; Mean validation loss 0.099781; Mean validation F1 0.936835; Learning rate 0.000377;\n",
    "===========================================================\n",
    "Epoch 033/096 - Mean training loss 0.128099; Mean training F1 0.913590; Mean validation loss 0.186934; Mean validation F1 0.920729; Learning rate 0.000369;\n",
    "===========================================================\n",
    "Epoch 034/096 - Mean training loss 0.107335; Mean training F1 0.920731; Mean validation loss 0.090630; Mean validation F1 0.933732; Learning rate 0.000362;\n",
    "===========================================================\n",
    "Epoch 035/096 - Mean training loss 0.103342; Mean training F1 0.924097; Mean validation loss 0.084266; Mean validation F1 0.936554; Learning rate 0.000355;\n",
    "===========================================================\n",
    "Epoch 036/096 - Mean training loss 0.090179; Mean training F1 0.932446; Mean validation loss 0.083200; Mean validation F1 0.936052; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 037/096 - Mean training loss 0.088725; Mean training F1 0.933515; Mean validation loss 0.088710; Mean validation F1 0.937914; Learning rate 0.000340;\n",
    "===========================================================\n",
    "Epoch 038/096 - Mean training loss 0.087537; Mean training F1 0.934544; Mean validation loss 0.076579; Mean validation F1 0.937759; Learning rate 0.000332;\n",
    "===========================================================\n",
    "Epoch 039/096 - Mean training loss 0.086807; Mean training F1 0.935308; Mean validation loss 0.088426; Mean validation F1 0.936659; Learning rate 0.000325;\n",
    "===========================================================\n",
    "Epoch 040/096 - Mean training loss 0.086399; Mean training F1 0.935513; Mean validation loss 0.045925; Mean validation F1 0.938137; Learning rate 0.000317;\n",
    "===========================================================\n",
    "Epoch 041/096 - Mean training loss 0.086194; Mean training F1 0.935664; Mean validation loss 0.086938; Mean validation F1 0.938062; Learning rate 0.000309;\n",
    "===========================================================\n",
    "Epoch 042/096 - Mean training loss 0.086005; Mean training F1 0.935676; Mean validation loss 0.108081; Mean validation F1 0.937202; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 043/096 - Mean training loss 0.085550; Mean training F1 0.936071; Mean validation loss 0.062914; Mean validation F1 0.937233; Learning rate 0.000293;\n",
    "===========================================================\n",
    "Epoch 044/096 - Mean training loss 0.085910; Mean training F1 0.935859; Mean validation loss 0.056322; Mean validation F1 0.937755; Learning rate 0.000285;\n",
    "===========================================================\n",
    "Epoch 045/096 - Mean training loss 0.085190; Mean training F1 0.936404; Mean validation loss 0.089039; Mean validation F1 0.936934; Learning rate 0.000277;\n",
    "===========================================================\n",
    "Epoch 046/096 - Mean training loss 0.085846; Mean training F1 0.935716; Mean validation loss 0.087558; Mean validation F1 0.938315; Learning rate 0.000269;\n",
    "===========================================================\n",
    "Epoch 047/096 - Mean training loss 0.085013; Mean training F1 0.936184; Mean validation loss 0.092824; Mean validation F1 0.937118; Learning rate 0.000261;\n",
    "===========================================================\n",
    "Epoch 048/096 - Mean training loss 0.084828; Mean training F1 0.936446; Mean validation loss 0.109956; Mean validation F1 0.938237; Learning rate 0.000253;\n",
    "===========================================================\n",
    "Epoch 049/096 - Mean training loss 0.084333; Mean training F1 0.936895; Mean validation loss 0.053222; Mean validation F1 0.938484; Learning rate 0.000245;\n",
    "===========================================================\n",
    "Epoch 050/096 - Mean training loss 0.084341; Mean training F1 0.936928; Mean validation loss 0.073815; Mean validation F1 0.937163; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 051/096 - Mean training loss 0.084392; Mean training F1 0.936571; Mean validation loss 0.091626; Mean validation F1 0.937526; Learning rate 0.000228;\n",
    "===========================================================\n",
    "Epoch 052/096 - Mean training loss 0.084163; Mean training F1 0.936861; Mean validation loss 0.089541; Mean validation F1 0.938296; Learning rate 0.000220;\n",
    "===========================================================\n",
    "Epoch 053/096 - Mean training loss 0.084115; Mean training F1 0.936756; Mean validation loss 0.085697; Mean validation F1 0.937912; Learning rate 0.000212;\n",
    "===========================================================\n",
    "Epoch 054/096 - Mean training loss 0.083661; Mean training F1 0.937223; Mean validation loss 0.099795; Mean validation F1 0.938266; Learning rate 0.000204;\n",
    "===========================================================\n",
    "Epoch 055/096 - Mean training loss 0.083835; Mean training F1 0.936968; Mean validation loss 0.111670; Mean validation F1 0.937375; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 056/096 - Mean training loss 0.083465; Mean training F1 0.937338; Mean validation loss 0.072594; Mean validation F1 0.938131; Learning rate 0.000189;\n",
    "===========================================================\n",
    "Epoch 057/096 - Mean training loss 0.083517; Mean training F1 0.937134; Mean validation loss 0.114835; Mean validation F1 0.938063; Learning rate 0.000181;\n",
    "===========================================================\n",
    "Epoch 058/096 - Mean training loss 0.089697; Mean training F1 0.931760; Mean validation loss 0.086797; Mean validation F1 0.937012; Learning rate 0.000173;\n",
    "===========================================================\n",
    "Epoch 059/096 - Mean training loss 0.084059; Mean training F1 0.936726; Mean validation loss 0.034449; Mean validation F1 0.938677; Learning rate 0.000166;\n",
    "===========================================================\n",
    "Epoch 060/096 - Mean training loss 0.083408; Mean training F1 0.937385; Mean validation loss 0.098053; Mean validation F1 0.937788; Learning rate 0.000158;\n",
    "===========================================================\n",
    "Epoch 061/096 - Mean training loss 0.083237; Mean training F1 0.937335; Mean validation loss 0.059769; Mean validation F1 0.938231; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 062/096 - Mean training loss 0.082874; Mean training F1 0.937670; Mean validation loss 0.071147; Mean validation F1 0.938114; Learning rate 0.000143;\n",
    "===========================================================\n",
    "Epoch 063/096 - Mean training loss 0.082713; Mean training F1 0.937793; Mean validation loss 0.078543; Mean validation F1 0.938836; Learning rate 0.000136;\n",
    "===========================================================\n",
    "Epoch 064/096 - Mean training loss 0.082556; Mean training F1 0.937838; Mean validation loss 0.066737; Mean validation F1 0.938766; Learning rate 0.000129;\n",
    "===========================================================\n",
    "Epoch 065/096 - Mean training loss 0.082360; Mean training F1 0.938078; Mean validation loss 0.059624; Mean validation F1 0.938647; Learning rate 0.000122;\n",
    "===========================================================\n",
    "Epoch 066/096 - Mean training loss 0.082457; Mean training F1 0.937949; Mean validation loss 0.041977; Mean validation F1 0.938808; Learning rate 0.000115;\n",
    "===========================================================\n",
    "Epoch 067/096 - Mean training loss 0.082300; Mean training F1 0.937879; Mean validation loss 0.088944; Mean validation F1 0.938367; Learning rate 0.000109;\n",
    "===========================================================\n",
    "Epoch 068/096 - Mean training loss 0.082195; Mean training F1 0.937925; Mean validation loss 0.075779; Mean validation F1 0.938676; Learning rate 0.000102;\n",
    "===========================================================\n",
    "Epoch 069/096 - Mean training loss 0.081941; Mean training F1 0.938394; Mean validation loss 0.104990; Mean validation F1 0.938939; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 070/096 - Mean training loss 0.081924; Mean training F1 0.938236; Mean validation loss 0.120648; Mean validation F1 0.938647; Learning rate 0.000090;\n",
    "===========================================================\n",
    "Epoch 071/096 - Mean training loss 0.081812; Mean training F1 0.938186; Mean validation loss 0.087816; Mean validation F1 0.938892; Learning rate 0.000084;\n",
    "===========================================================\n",
    "Epoch 072/096 - Mean training loss 0.081694; Mean training F1 0.938365; Mean validation loss 0.132233; Mean validation F1 0.938459; Learning rate 0.000078;\n",
    "===========================================================\n",
    "Epoch 073/096 - Mean training loss 0.081434; Mean training F1 0.938516; Mean validation loss 0.049486; Mean validation F1 0.938325; Learning rate 0.000072;\n",
    "===========================================================\n",
    "Epoch 074/096 - Mean training loss 0.081405; Mean training F1 0.938369; Mean validation loss 0.043687; Mean validation F1 0.938893; Learning rate 0.000067;\n",
    "===========================================================\n",
    "Epoch 075/096 - Mean training loss 0.081265; Mean training F1 0.938607; Mean validation loss 0.088706; Mean validation F1 0.938786; Learning rate 0.000061;\n",
    "===========================================================\n",
    "Epoch 076/096 - Mean training loss 0.081189; Mean training F1 0.938564; Mean validation loss 0.065307; Mean validation F1 0.938616; Learning rate 0.000056;\n",
    "===========================================================\n",
    "Epoch 077/096 - Mean training loss 0.081065; Mean training F1 0.938779; Mean validation loss 0.078908; Mean validation F1 0.938880; Learning rate 0.000052;\n",
    "===========================================================\n",
    "Epoch 078/096 - Mean training loss 0.081375; Mean training F1 0.938375; Mean validation loss 0.059555; Mean validation F1 0.938847; Learning rate 0.000047;\n",
    "===========================================================\n",
    "Epoch 079/096 - Mean training loss 0.080865; Mean training F1 0.938701; Mean validation loss 0.074071; Mean validation F1 0.938760; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 080/096 - Mean training loss 0.080764; Mean training F1 0.938870; Mean validation loss 0.070719; Mean validation F1 0.938913; Learning rate 0.000038;\n",
    "===========================================================\n",
    "Epoch 081/096 - Mean training loss 0.080693; Mean training F1 0.939000; Mean validation loss 0.060973; Mean validation F1 0.938936; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 082/096 - Mean training loss 0.080627; Mean training F1 0.938894; Mean validation loss 0.070682; Mean validation F1 0.939013; Learning rate 0.000031;\n",
    "===========================================================\n",
    "Epoch 083/096 - Mean training loss 0.080578; Mean training F1 0.939045; Mean validation loss 0.113393; Mean validation F1 0.939005; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 084/096 - Mean training loss 0.080465; Mean training F1 0.939149; Mean validation loss 0.061118; Mean validation F1 0.939136; Learning rate 0.000024;\n",
    "===========================================================\n",
    "Epoch 085/096 - Mean training loss 0.080501; Mean training F1 0.939097; Mean validation loss 0.114638; Mean validation F1 0.939045; Learning rate 0.000021;\n",
    "===========================================================\n",
    "Epoch 086/096 - Mean training loss 0.080329; Mean training F1 0.939020; Mean validation loss 0.089038; Mean validation F1 0.938909; Learning rate 0.000018;\n",
    "===========================================================\n",
    "Epoch 087/096 - Mean training loss 0.080279; Mean training F1 0.939148; Mean validation loss 0.090417; Mean validation F1 0.938985; Learning rate 0.000016;\n",
    "===========================================================\n",
    "Epoch 088/096 - Mean training loss 0.080237; Mean training F1 0.939113; Mean validation loss 0.089974; Mean validation F1 0.938832; Learning rate 0.000014;\n",
    "===========================================================\n",
    "Epoch 089/096 - Mean training loss 0.080184; Mean training F1 0.939252; Mean validation loss 0.092096; Mean validation F1 0.939001; Learning rate 0.000012;\n",
    "===========================================================\n",
    "Epoch 090/096 - Mean training loss 0.080206; Mean training F1 0.939216; Mean validation loss 0.098374; Mean validation F1 0.938885; Learning rate 0.000010;\n",
    "===========================================================\n",
    "Epoch 091/096 - Mean training loss 0.080129; Mean training F1 0.939132; Mean validation loss 0.052961; Mean validation F1 0.939053; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 092/096 - Mean training loss 0.080131; Mean training F1 0.939273; Mean validation loss 0.050002; Mean validation F1 0.938929; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 093/096 - Mean training loss 0.080111; Mean training F1 0.939168; Mean validation loss 0.101090; Mean validation F1 0.938803; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 094/096 - Mean training loss 0.080058; Mean training F1 0.939310; Mean validation loss 0.083516; Mean validation F1 0.938850; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 095/096 - Mean training loss 0.080162; Mean training F1 0.939163; Mean validation loss 0.068058; Mean validation F1 0.938939; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 096/096 - Mean training loss 0.080062; Mean training F1 0.939180; Mean validation loss 0.076037; Mean validation F1 0.939021; Learning rate 0.000005;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
