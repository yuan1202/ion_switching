{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import math\n",
    "import warnings\n",
    "import gc\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import bloscpack as bp\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold, train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn import metrics\n",
    "\n",
    "pd.set_option('display.max_columns', 10000)\n",
    "pd.set_option('display.max_rows', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../input/batch_ids_trn.pkl', 'rb') as f:\n",
    "    batch_id_trn = pickle.load(f)\n",
    "with open('../input/batch_ids_tst.pkl', 'rb') as f:\n",
    "    batch_id_tst = pickle.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dat_files = [f for f in os.listdir('../input/feats_tblr') if ('_dat_' in f) and ('srs' not in f)]\n",
    "lbl_files = [f for f in os.listdir('../input/feats_tblr') if ('_lbl_' in f) and ('srs' not in f)]\n",
    "# feat_files = [f for f in os.listdir('../input') if '_feat_' in f]\n",
    "\n",
    "def load_group_data(group, tag, mode='train'):\n",
    "    assert isinstance(group, str)\n",
    "    \n",
    "    if not isinstance(tag, list): tag = [tag]\n",
    "    m = 'trn' if mode == 'train' else 'tst'\n",
    "    \n",
    "    dat_to_load = [f for f in dat_files if (group in f) and any(v in f for v in tag) and (m in f)]\n",
    "    print(dat_to_load)\n",
    "    lbl_to_load = [f for f in lbl_files if (group in f) and any(v in f for v in tag) and (m in f)]\n",
    "    print(lbl_to_load)\n",
    "    \n",
    "    dat = np.concatenate([bp.unpack_ndarray_from_file(os.path.join('../input/feats_tblr', f)) for f in dat_to_load], axis=1)\n",
    "    if m == 'trn':\n",
    "        lbl = [bp.unpack_ndarray_from_file(os.path.join('../input/feats_tblr', f)) for f in lbl_to_load]\n",
    "        assert np.all([np.all(a==b) for a, b in zip(lbl[:-1], lbl[1:])])\n",
    "        return dat, lbl[0]\n",
    "    else:\n",
    "        return dat"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tst_fs = sorted([f for f in os.listdir('../input/feats_tblr/') if ('tst' in f) and ('dat' in f) and ('w200' in f)])\n",
    "tst_fs = tst_fs[:1] + tst_fs[11:] + tst_fs[1:11]\n",
    "tst_dat = np.concatenate([bp.unpack_ndarray_from_file(os.path.join('../input/feats_tblr', f)) for f in tst_fs], 0)\n",
    "bp.pack_ndarray_to_file(tst_dat, '../input/feats_tblr/tst_dat_all_w200.bp')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "g0_dat, g0_lbl = load_group_data('g0', ['w200'])\n",
    "g1_dat, g1_lbl = load_group_data('g1', ['w200'])\n",
    "g2_dat, g2_lbl = load_group_data('g2', ['w200'])\n",
    "g3_dat, g3_lbl = load_group_data('g3', ['w200'])\n",
    "g4_dat, g4_lbl = load_group_data('g4', ['w200'])\n",
    "g5_dat, g5_lbl = load_group_data('g5', ['w200'])\n",
    "g6_dat, g6_lbl = load_group_data('g6', ['w200'])\n",
    "g7_dat, g7_lbl = load_group_data('g7', ['w200'])\n",
    "g8_dat, g8_lbl = load_group_data('g8', ['w200'])\n",
    "g9_dat, g9_lbl = load_group_data('g9', ['w200'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dat = np.concatenate([g0_dat, g1_dat, g2_dat, g3_dat, g4_dat, g5_dat, g6_dat, g7_dat, g8_dat, g9_dat], axis=0)\n",
    "lbl = np.concatenate([g0_lbl, g1_lbl, g2_lbl, g3_lbl, g4_lbl, g5_lbl, g6_lbl, g7_lbl, g8_lbl, g9_lbl], axis=0)\n",
    "# dat = np.concatenate([g0_dat, g1_dat, g2_dat, g3_dat, g6_dat, g7_dat], axis=0)\n",
    "# lbl = np.concatenate([g0_lbl, g1_lbl, g2_lbl, g3_lbl, g6_lbl, g7_lbl], axis=0)\n",
    "# dat = np.concatenate([g3_dat, g4_dat, g5_dat, g7_dat, g8_dat, g9_dat], axis=0)\n",
    "# lbl = np.concatenate([g3_lbl, g4_lbl, g5_lbl, g7_lbl, g8_lbl, g9_lbl], axis=0)\n",
    "# dat = np.concatenate([g4_dat, g5_dat, g8_dat, g9_dat], axis=0)\n",
    "# lbl = np.concatenate([g4_lbl, g5_lbl, g8_lbl, g9_lbl], axis=0)\n",
    "# dat = g9_dat\n",
    "# lbl = g9_lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_w200 = bp.unpack_ndarray_from_file('../input/feats_tblr/trn_dat_all_w200.bp')\n",
    "lbl_w200 = bp.unpack_ndarray_from_file('../input/feats_tblr/trn_lbl_all_w200.bp')\n",
    "\n",
    "dat_orig = pd.read_pickle('../input/feats_tblr/trn_dat_orig_v2_all.pkl')\n",
    "lbl_orig = pd.read_pickle('../input/feats_tblr/trn_lbl_orig_v2_all.pkl')\n",
    "\n",
    "dat_orig = dat_orig.loc[:, [c for c in dat_orig.columns if c not in ('time', 'signal', 'batch', 'open_channels')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = np.concatenate([dat_orig.values, dat_w200], axis=-1)\n",
    "lbl = lbl_w200\n",
    "del dat_w200, tst_w200, dat_orig, tst_orig, lbl_orig"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# del g0_dat, g1_dat, g2_dat, g3_dat, g4_dat, g5_dat, g6_dat, g7_dat, g8_dat, g9_dat\n",
    "# del g0_lbl, g1_lbl, g2_lbl, g3_lbl, g4_lbl, g5_lbl, g6_lbl, g7_lbl, g8_lbl, g9_lbl\n",
    "# del g0_dat, g1_dat, g2_dat\n",
    "# del g0_lbl, g1_lbl, g2_lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lbl = [str(a) + '_' + str(b) for a, b in zip(lbl.astype('uint32'), np.concatenate([np.ones(500000).astype('uint32') * i for i in range(10)]))]\n",
    "unq_l = np.unique(new_lbl)\n",
    "lbl_map = {str_l: i for str_l, i in zip(unq_l, np.arange(len(unq_l)))}\n",
    "new_lbl = [lbl_map[s] for s in new_lbl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del x_trn, x_vld, y_trn, y_vld\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (trn_ndcs, vld_ndcs) in enumerate(kf.split(dat, new_lbl)):\n",
    "    if fold == 4:\n",
    "        x_trn, x_vld = dat[trn_ndcs], dat[vld_ndcs]\n",
    "        y_trn, y_vld = lbl[trn_ndcs], lbl[vld_ndcs]\n",
    "        break\n",
    "    #trn_set = lgb.Dataset(x_trn, y_trn)\n",
    "    #vld_set = lgb.Dataset(x_vld, y_vld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \"metric\": 'rmse',\n",
    "    'objective': 'regression',\n",
    "    'random_state': 236,\n",
    "    'num_leaves': 280,\n",
    "    'learning_rate': 0.026623466966581126,\n",
    "    'max_depth': 80,\n",
    "    'reg_alpha': 2.959759088169741, # L1\n",
    "    'reg_lambda': 1.331172832164913, # L2\n",
    "    \"bagging_fraction\": 0.9655406551472153,\n",
    "    \"bagging_freq\": 9,\n",
    "    'colsample_bytree': 0.6867118652742716\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's rmse: 0.708458\n",
      "[100]\tvalid_0's rmse: 0.237957\n",
      "[150]\tvalid_0's rmse: 0.162392\n",
      "[200]\tvalid_0's rmse: 0.155546\n",
      "[250]\tvalid_0's rmse: 0.154789\n",
      "[300]\tvalid_0's rmse: 0.154534\n",
      "[350]\tvalid_0's rmse: 0.154353\n",
      "[400]\tvalid_0's rmse: 0.154238\n",
      "[450]\tvalid_0's rmse: 0.154132\n",
      "[500]\tvalid_0's rmse: 0.154063\n",
      "[550]\tvalid_0's rmse: 0.153996\n",
      "[600]\tvalid_0's rmse: 0.153939\n",
      "[650]\tvalid_0's rmse: 0.153877\n",
      "[700]\tvalid_0's rmse: 0.153824\n",
      "[750]\tvalid_0's rmse: 0.153768\n",
      "[800]\tvalid_0's rmse: 0.153726\n",
      "[850]\tvalid_0's rmse: 0.153691\n",
      "[900]\tvalid_0's rmse: 0.153649\n",
      "[950]\tvalid_0's rmse: 0.153623\n",
      "[1000]\tvalid_0's rmse: 0.153597\n",
      "[1050]\tvalid_0's rmse: 0.153572\n",
      "[1100]\tvalid_0's rmse: 0.153549\n",
      "[1150]\tvalid_0's rmse: 0.153527\n",
      "[1200]\tvalid_0's rmse: 0.153508\n",
      "[1250]\tvalid_0's rmse: 0.153487\n",
      "[1300]\tvalid_0's rmse: 0.153464\n",
      "[1350]\tvalid_0's rmse: 0.15345\n",
      "[1400]\tvalid_0's rmse: 0.153427\n",
      "[1450]\tvalid_0's rmse: 0.153413\n",
      "[1500]\tvalid_0's rmse: 0.153402\n",
      "[1550]\tvalid_0's rmse: 0.153389\n",
      "[1600]\tvalid_0's rmse: 0.153383\n",
      "[1650]\tvalid_0's rmse: 0.153369\n",
      "[1700]\tvalid_0's rmse: 0.153359\n",
      "[1750]\tvalid_0's rmse: 0.15335\n",
      "[1800]\tvalid_0's rmse: 0.153345\n",
      "[1850]\tvalid_0's rmse: 0.153335\n",
      "[1900]\tvalid_0's rmse: 0.153321\n",
      "[1950]\tvalid_0's rmse: 0.153316\n",
      "[2000]\tvalid_0's rmse: 0.153309\n",
      "[2050]\tvalid_0's rmse: 0.153302\n",
      "[2100]\tvalid_0's rmse: 0.153294\n",
      "[2150]\tvalid_0's rmse: 0.153285\n",
      "[2200]\tvalid_0's rmse: 0.153285\n",
      "[2250]\tvalid_0's rmse: 0.153283\n",
      "[2300]\tvalid_0's rmse: 0.153275\n",
      "[2350]\tvalid_0's rmse: 0.153269\n",
      "[2400]\tvalid_0's rmse: 0.153265\n",
      "[2450]\tvalid_0's rmse: 0.153263\n",
      "[2500]\tvalid_0's rmse: 0.153259\n",
      "[2550]\tvalid_0's rmse: 0.15326\n",
      "[2600]\tvalid_0's rmse: 0.153257\n",
      "[2650]\tvalid_0's rmse: 0.153254\n",
      "[2700]\tvalid_0's rmse: 0.15325\n",
      "[2750]\tvalid_0's rmse: 0.153251\n",
      "[2800]\tvalid_0's rmse: 0.153253\n",
      "[2850]\tvalid_0's rmse: 0.153241\n",
      "[2900]\tvalid_0's rmse: 0.153243\n",
      "[2950]\tvalid_0's rmse: 0.153241\n",
      "Early stopping, best iteration is:\n",
      "[2861]\tvalid_0's rmse: 0.15324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.9655406551472153, bagging_freq=9,\n",
       "              boosting='gbdt', boosting_type='gbdt', class_weight=None,\n",
       "              colsample_bytree=0.6867118652742716, importance_type='split',\n",
       "              learning_rate=0.026623466966581126, max_depth=80, metric='rmse',\n",
       "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "              n_estimators=10000, n_jobs=12, num_leaves=280,\n",
       "              objective='regression', random_state=236,\n",
       "              reg_alpha=2.959759088169741, reg_lambda=1.331172832164913,\n",
       "              silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "              subsample_freq=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lgb.LGBMRegressor(**params, n_estimators=10000, n_jobs=12)\n",
    "model.fit(X=x_trn, y=y_trn, eval_set=[(x_vld, y_vld)], eval_metric='rmse', verbose=50, early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./saved_models/lgbm_feats_origv2_myw200_fld4.pkl']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, './saved_models/lgbm_feats_origv2_myw200_fld{:d}.pkl'.format(fold))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# model = lgb.train(params, trn_set, num_boost_round=10000, early_stopping_rounds=100, valid_sets=[vld_set], verbose_eval=50)\n",
    "model = lgb.LGBMRegressor(**params, n_estimators=10000, n_jobs=12)\n",
    "model.fit(X=g4_feats, y=g4_lbls, eval_set=[(g9_feats, g9_lbls)], eval_metric='rmse', verbose=50, early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9386508905001126\n"
     ]
    }
   ],
   "source": [
    "vld_pred = model.predict(x_vld, num_iteration=model.best_iteration_)\n",
    "vld_pred = np.round(np.clip(vld_pred, 0, 10)).astype(int)\n",
    "f1 = metrics.f1_score(y_vld.astype(int), vld_pred, average = 'macro')\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.9386508905001126 fold 4\n",
    "0.9398466657512052 fold 3\n",
    "0.9401051411632334 fold 2\n",
    "0.9393302920554323 fold 1\n",
    "0.9396574201993828 fold 0\n",
    "0.9396419066068368\n",
    "0.9394454786488392\n",
    "0.934983763304277"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9968903682469297\n"
     ]
    }
   ],
   "source": [
    "vld_pred_g0= model.predict(g0_dat, num_iteration=model.best_iteration_)\n",
    "vld_pred_g0 = np.round(np.clip(vld_pred_g0, 0, 10)).astype(int)\n",
    "f1_g0 = metrics.f1_score(g0_lbl.astype(int), vld_pred_g0, average = 'macro')\n",
    "print(f1_g0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.9968903682469297\n",
    "0.6649385280200172\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9968424553280641\n"
     ]
    }
   ],
   "source": [
    "vld_pred_g1= model.predict(g1_dat, num_iteration=model.best_iteration_)\n",
    "vld_pred_g1 = np.round(np.clip(vld_pred_g1, 0, 10)).astype(int)\n",
    "f1_g1 = metrics.f1_score(g1_lbl.astype(int), vld_pred_g1, average = 'macro')\n",
    "print(f1_g1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.9968424553280641\n",
    "0.9968829962401913\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6646538107371066\n"
     ]
    }
   ],
   "source": [
    "vld_pred_g2= model.predict(g2_dat, num_iteration=model.best_iteration_)\n",
    "vld_pred_g2 = np.round(np.clip(vld_pred_g2, 0, 10)).astype(int)\n",
    "f1_g2 = metrics.f1_score(g2_lbl.astype(int), vld_pred_g2, average = 'macro')\n",
    "print(f1_g2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.6646538107371066\n",
    "0.9969891438044296\n",
    "0.6647126573075317"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9868084651120028\n"
     ]
    }
   ],
   "source": [
    "vld_pred_g3= model.predict(g3_dat, num_iteration=model.best_iteration_)\n",
    "vld_pred_g3 = np.round(np.clip(vld_pred_g3, 0, 10)).astype(int)\n",
    "f1_g3 = metrics.f1_score(g3_lbl.astype(int), vld_pred_g3, average = 'macro')\n",
    "print(f1_g3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.9868084651120028\n",
    "0.9870350237200967\n",
    "0.986656035463432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8212875579648767\n"
     ]
    }
   ],
   "source": [
    "vld_pred_g4= model.predict(g4_dat, num_iteration=model.best_iteration_)\n",
    "vld_pred_g4 = np.round(np.clip(vld_pred_g4, 0, 10)).astype(int)\n",
    "f1_g4 = metrics.f1_score(g4_lbl.astype(int), vld_pred_g4, average = 'macro')\n",
    "print(f1_g4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.8212875579648767\n",
    "0.8260337236356086\n",
    "0.8942446664286391"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736932581052553\n"
     ]
    }
   ],
   "source": [
    "vld_pred_g5= model.predict(g5_dat, num_iteration=model.best_iteration_)\n",
    "vld_pred_g5 = np.round(np.clip(vld_pred_g5, 0, 10)).astype(int)\n",
    "f1_g5 = metrics.f1_score(g5_lbl.astype(int), vld_pred_g5, average = 'macro')\n",
    "print(f1_g5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.9736932581052553\n",
    "0.973730327589147\n",
    "0.9732927691543368"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9966063601403695\n"
     ]
    }
   ],
   "source": [
    "vld_pred_g6= model.predict(g6_dat, num_iteration=model.best_iteration_)\n",
    "vld_pred_g6 = np.round(np.clip(vld_pred_g6, 0, 10)).astype(int)\n",
    "f1_g6 = metrics.f1_score(g6_lbl.astype(int), vld_pred_g6, average = 'macro')\n",
    "print(f1_g6)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.9966063601403695\n",
    "0.6645403771422551\n",
    "0.6646888239380492"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7780210018430778\n"
     ]
    }
   ],
   "source": [
    "vld_pred_g7 = model.predict(g7_dat, num_iteration=model.best_iteration_)\n",
    "vld_pred_g7 = np.round(np.clip(vld_pred_g7, 0, 10)).astype(int)\n",
    "f1_g7 = metrics.f1_score(g7_lbl.astype(int), vld_pred_g7, average = 'macro')\n",
    "print(f1_g7)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.7780210018430778\n",
    "0.9726543249924238\n",
    "0.9729210756681197"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9749084848835565\n"
     ]
    }
   ],
   "source": [
    "vld_pred_g8 = model.predict(g8_dat, num_iteration=model.best_iteration_)\n",
    "vld_pred_g8 = np.round(np.clip(vld_pred_g8, 0, 10)).astype(int)\n",
    "f1_g8 = metrics.f1_score(g8_lbl.astype(int), vld_pred_g8, average = 'macro')\n",
    "print(f1_g8)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.9749084848835565\n",
    "0.9737512339455049\n",
    "0.9756024481983628"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8977718030245324\n"
     ]
    }
   ],
   "source": [
    "vld_pred_g9 = model.predict(g9_dat, num_iteration=model.best_iteration_)\n",
    "vld_pred_g9 = np.round(np.clip(vld_pred_g9, 0, 10)).astype(int)\n",
    "f1_g9 = metrics.f1_score(g9_lbl.astype(int), vld_pred_g9, average = 'macro')\n",
    "print(f1_g9)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.8977718030245324\n",
    "0.9068700614535483\n",
    "0.9147493146748186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_w200 = bp.unpack_ndarray_from_file('../input/feats_tblr/tst_dat_all_w200.bp')\n",
    "tst_orig = pd.read_pickle('../input/feats_tblr/tst_dat_orig_v2_all.pkl')\n",
    "tst_orig = tst_orig.loc[:, [c for c in tst_orig.columns if c not in ('time', 'signal', 'batch', 'open_channels')]]\n",
    "tst = np.concatenate([tst_orig.values, tst_w200], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv', dtype={'time': str, 'open_channels': 'Int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(5):\n",
    "    mdl = joblib.load('./saved_models/lgbm_feats_origv2_myw200_fld{:d}.pkl'.format(fold))\n",
    "    if fold == 0:\n",
    "        predictions = mdl.predict(tst, num_iteration=mdl.best_iteration_)\n",
    "    else:\n",
    "        predictions += mdl.predict(tst, num_iteration=mdl.best_iteration_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_sub = np.round(np.clip(predictions/5, 0, 10)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['open_channels'] = predictions_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"../submissions/sub_lgbm_origv2_w200feats_cvbygroupandclass.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
