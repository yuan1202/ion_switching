{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import bloscpack as bp\n",
    "\n",
    "from tsfresh.feature_extraction import feature_calculators\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold, GroupKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from NNs import WaveTRSFM_Classifier, Wave_Classifier, WaveRNN_Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe381b3dcd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda:0'\n",
    "EPOCHS = 128\n",
    "BATCHSIZE = 32\n",
    "SEED = 19550423\n",
    "LR = 0.0005\n",
    "SPLITS = 5\n",
    "\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_tag = 's500'\n",
    "wndw_tag = 'w500'\n",
    "vers_tag = 'final'\n",
    "trn_fs = sorted([f for f in os.listdir('../input/feats_srs') if (('trn_srs_dat' in f) and (step_tag in f) and (wndw_tag in f) and (vers_tag in f))])\n",
    "lbl_fs = sorted([f for f in os.listdir('../input/feats_srs') if ('trn_srs_lbl' in f) and (step_tag in f) and (wndw_tag in f) and (vers_tag in f)])\n",
    "\n",
    "tst_fs = sorted([f for f in os.listdir('../input/feats_srs') if (('tst_srs_dat' in f) and (step_tag in f) and (wndw_tag in f) and (vers_tag in f))])\n",
    "tst_fs = [tst_fs[i] for i in [0, 11, 12, 13, 14, 15, 16, 17, 18, 19]] + tst_fs[1:11]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tst_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_dat_all = np.concatenate(\n",
    "    [bp.unpack_ndarray_from_file(os.path.join('../input/feats_srs', f)) for f in trn_fs],\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "series_lbl_all = [bp.unpack_ndarray_from_file(os.path.join('../input/feats_srs', f)) for f in lbl_fs]\n",
    "\n",
    "series_bch_all = np.concatenate(\n",
    "    [np.ones(shape=(arr.shape[0],)) * i for i, arr in zip([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], series_lbl_all)],\n",
    "    axis=0\n",
    ").astype(int)\n",
    "\n",
    "series_lbl_all = np.concatenate(\n",
    "    series_lbl_all,\n",
    "    axis=0\n",
    ")[:, :, None]\n",
    "\n",
    "series_dat_tst = np.concatenate(\n",
    "    [bp.unpack_ndarray_from_file(os.path.join('../input/feats_srs', f)) for f in tst_fs],\n",
    "    axis=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 30 / 30; \r"
     ]
    }
   ],
   "source": [
    "for i in range(series_dat_all.shape[-1]):\n",
    "\n",
    "    avg = series_dat_all[:, :, i].mean()\n",
    "    std = series_dat_all[:, :, i].std()\n",
    "    series_dat_all[:, :, i] = (series_dat_all[:, :, i] - avg) / std\n",
    "#     series_dat_tst[:, :, i] = (series_dat_tst[:, :, i] - avg) / std\n",
    "    \n",
    "    #print('---------')\n",
    "    #print('{:d} - max {:.3f}; min {:.3f};'.format(i, series_dat_all[:, :, i].max(), series_dat_all[:, :, i].min()))\n",
    "    #print('{:d} - max {:.3f}; min {:.3f};'.format(i, series_dat_tst[:, :, i].max(), series_dat_tst[:, :, i].min()))\n",
    "    print('progress: {:02d} / {:02d}; '.format(i+1, series_dat_all.shape[-1]), end='\\r')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "unit = 500\n",
    "series_dat_all = np.concatenate([series_dat_all[4*unit:5*unit], series_dat_all[9*unit:10*unit]], 0)\n",
    "series_lbl_all = np.concatenate([series_lbl_all[4*unit:5*unit], series_lbl_all[9*unit:10*unit]], 0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "series_dat_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_ent = [feature_calculators.binned_entropy(lst, max_bins=20) for lst in series_dat_all[:, :, 0].tolist()]\n",
    "bin_ent = pd.qcut(pd.Series(bin_ent), q=10, duplicates='drop')\n",
    "\n",
    "skf_trgt = [str(a) + '_' + str(b) for a, b in zip(series_bch_all, bin_ent)]\n",
    "us = np.unique(skf_trgt)\n",
    "umap = {u: i for u, i in zip(us, range(len(us)))}\n",
    "skf_trgt = [umap[u] for u in skf_trgt]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "us, cs = np.unique(skf_trgt, return_counts=True)\n",
    "for u, c in zip(us, cs):\n",
    "    print(u, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Waveset(Dataset):\n",
    "    def __init__(self, data, labels=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "        \n",
    "        if self.labels is None:\n",
    "            return data.astype(np.float32)\n",
    "        else:\n",
    "            labels = self.labels[idx]\n",
    "            return (data.astype(np.float32), labels.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_train_validate(\n",
    "    model, optimizer, criterion, scheduler,\n",
    "    training_loader, validation_loaders, fold_number,\n",
    "    save_path='./saved_models/wavenet_model_fold{:03d}_checkpoint.pth',\n",
    "    early_stopping=15,\n",
    "):\n",
    "    assert isinstance(validation_loaders, dict)\n",
    "\n",
    "    trn_losses = [np.nan]\n",
    "    vld_losses = [np.nan]\n",
    "    vld_f1s = [np.nan]\n",
    "    \n",
    "    last_best = 0\n",
    "\n",
    "    for epc in range(EPOCHS):\n",
    "        print('===========================================================')\n",
    "\n",
    "        epoch_trn_losses = []\n",
    "        epoch_trn_lbls = []\n",
    "        epoch_trn_prds = []\n",
    "        \n",
    "        # ------ training ------\n",
    "        model.train()\n",
    "        for i, (trn_batch_dat, trn_batch_lbl) in enumerate(training_loader):\n",
    "            trn_batch_dat, trn_batch_lbl = trn_batch_dat.to(DEVICE), trn_batch_lbl.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            trn_batch_prd = model(trn_batch_dat)\n",
    "            trn_batch_prd = trn_batch_prd.view(-1, trn_batch_prd.size(-1))\n",
    "            trn_batch_lbl = trn_batch_lbl.view(-1)\n",
    "            loss = criterion(trn_batch_prd, trn_batch_lbl)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_trn_losses.append(loss.item())\n",
    "            epoch_trn_lbls.append(trn_batch_lbl.detach().cpu().numpy())\n",
    "            epoch_trn_prds.append(trn_batch_prd.detach().cpu().numpy())\n",
    "\n",
    "            #print(\n",
    "            #    'Epoch {:03d}/{:03d} - Training batch {:04d}/{:04d}: Training loss {:.6f};'.format(\n",
    "            #        epc + 1, EPOCHS, i + 1, len(training_loader), epoch_trn_losses[-1],\n",
    "            #    ), \n",
    "            #    end='\\r'\n",
    "            #)\n",
    "\n",
    "        # ------ validation ------\n",
    "        model.eval()\n",
    "        \n",
    "        grp_vld_metrics = {}\n",
    "        epoch_vld_losses = []\n",
    "        epoch_vld_lbls = []\n",
    "        epoch_vld_prds = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (grp, ldr) in enumerate(validation_loaders.items()):\n",
    "                \n",
    "                epoch_grp_vld_losses = []\n",
    "                epoch_grp_vld_lbls = []\n",
    "                epoch_grp_vld_prds = []\n",
    "\n",
    "                for j, (vld_batch_dat, vld_batch_lbl) in enumerate(ldr):\n",
    "                    vld_batch_dat, vld_batch_lbl = vld_batch_dat.to(DEVICE), vld_batch_lbl.to(DEVICE)\n",
    "\n",
    "                    vld_batch_prd = model(vld_batch_dat)\n",
    "                    vld_batch_prd = vld_batch_prd.view(-1, vld_batch_prd.size(-1))\n",
    "                    vld_batch_lbl = vld_batch_lbl.view(-1)\n",
    "                    loss = criterion(vld_batch_prd, vld_batch_lbl)\n",
    "\n",
    "                    epoch_grp_vld_losses.append(loss.item())\n",
    "                    epoch_grp_vld_lbls.append(vld_batch_lbl.detach().cpu().numpy())\n",
    "                    epoch_grp_vld_prds.append(vld_batch_prd.detach().cpu().numpy())\n",
    "                    if grp == 'vld':\n",
    "                        epoch_vld_losses.append(epoch_grp_vld_losses[-1])\n",
    "                        epoch_vld_lbls.append(epoch_grp_vld_lbls[-1])\n",
    "                        epoch_vld_prds.append(epoch_grp_vld_prds[-1])\n",
    "                    \n",
    "                epoch_grp_vld_lbls = np.concatenate(epoch_grp_vld_lbls, axis=0)\n",
    "                epoch_grp_vld_prds = np.concatenate(epoch_grp_vld_prds, axis=0).argmax(1)\n",
    "                \n",
    "                grp_f1_vld = f1_score(\n",
    "                    epoch_grp_vld_lbls, \n",
    "                    epoch_grp_vld_prds,\n",
    "                    #labels=list(range(11)), \n",
    "                    average='macro'\n",
    "                )\n",
    "                \n",
    "                grp_vld_metrics.update({grp: {'f1': grp_f1_vld, 'loss': np.mean(epoch_grp_vld_losses)}})\n",
    "\n",
    "                #print('Validation progress: {:03d}/{:03d} group done;'.format(i + 1, len(validation_loaders)), end='\\r')\n",
    "\n",
    "        # ------ epoch end ------\n",
    "        epoch_trn_lbls = np.concatenate(epoch_trn_lbls, axis=0)\n",
    "        epoch_trn_prds = np.concatenate(epoch_trn_prds, axis=0).argmax(1)\n",
    "\n",
    "        f1_trn = f1_score(\n",
    "            epoch_trn_lbls, \n",
    "            epoch_trn_prds,\n",
    "            #labels=list(range(11)), \n",
    "            average='macro'\n",
    "        )\n",
    "        \n",
    "        epoch_vld_lbls = np.concatenate(epoch_vld_lbls, axis=0)\n",
    "        epoch_vld_prds = np.concatenate(epoch_vld_prds, axis=0).argmax(1)\n",
    "\n",
    "        f1_vld = f1_score(\n",
    "            epoch_vld_lbls, \n",
    "            epoch_vld_prds,\n",
    "            #labels=list(range(11)), \n",
    "            average='macro'\n",
    "        )\n",
    "\n",
    "\n",
    "        print(\n",
    "            'Epoch {:03d}/{:03d} - Mean training loss {:.6f}; Mean training F1 {:.6f}; Mean validation loss {:.6f}; Mean validation F1 {:.6f}; Learning rate {:.6f};'.format(\n",
    "                epc + 1, EPOCHS, np.mean(epoch_trn_losses), f1_trn, np.mean(epoch_vld_losses), f1_vld, scheduler.get_lr()[0],\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        print('Validation metrics:')\n",
    "        for g, m in grp_vld_metrics.items():\n",
    "            print('Group {}: f1 - {:.6f}; loss - {:.6f};'.format(g, m['f1'], m['loss']))\n",
    "        \n",
    "        if f1_vld > np.nanmax(vld_f1s):\n",
    "            torch.save(\n",
    "                {\n",
    "                    'epoch': epc + 1,\n",
    "                    'model': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'f1': f1_vld,\n",
    "                    'loss': np.mean(epoch_vld_losses),\n",
    "                }, \n",
    "                save_path.format(fold_number)\n",
    "            )\n",
    "            \n",
    "            last_best = epc\n",
    "            \n",
    "        if epc - last_best > early_stopping:\n",
    "            continue\n",
    "\n",
    "        vld_f1s.append(f1_vld)\n",
    "\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FOLDS = 5\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################\n",
      "Training/validation for fold 1/5;\n",
      "===========================================================\n",
      "Epoch 001/128 - Mean training loss 0.390097; Mean training F1 0.739592; Mean validation loss 0.221473; Mean validation F1 0.742415; Learning rate 0.000500;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.742415; loss - 0.221473;\n",
      "Group g4: f1 - 0.995540; loss - 0.014508;\n",
      "Group g9: f1 - 0.426581; loss - 0.826582;\n",
      "===========================================================\n",
      "Epoch 002/128 - Mean training loss 0.179598; Mean training F1 0.866523; Mean validation loss 0.142939; Mean validation F1 0.850568; Learning rate 0.000500;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.850568; loss - 0.142939;\n",
      "Group g4: f1 - 0.995105; loss - 0.014998;\n",
      "Group g9: f1 - 0.550291; loss - 0.440505;\n",
      "===========================================================\n",
      "Epoch 003/128 - Mean training loss 0.140204; Mean training F1 0.892625; Mean validation loss 0.112570; Mean validation F1 0.900464; Learning rate 0.000499;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.900464; loss - 0.112570;\n",
      "Group g4: f1 - 0.996252; loss - 0.009510;\n",
      "Group g9: f1 - 0.598086; loss - 0.366455;\n",
      "===========================================================\n",
      "Epoch 004/128 - Mean training loss 0.118307; Mean training F1 0.909726; Mean validation loss 0.100500; Mean validation F1 0.926309; Learning rate 0.000499;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.926309; loss - 0.100500;\n",
      "Group g4: f1 - 0.996188; loss - 0.008888;\n",
      "Group g9: f1 - 0.696751; loss - 0.336823;\n",
      "===========================================================\n",
      "Epoch 005/128 - Mean training loss 0.137893; Mean training F1 0.903460; Mean validation loss 0.114414; Mean validation F1 0.916864; Learning rate 0.000498;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.916864; loss - 0.114414;\n",
      "Group g4: f1 - 0.995692; loss - 0.010536;\n",
      "Group g9: f1 - 0.682175; loss - 0.375699;\n",
      "===========================================================\n",
      "Epoch 006/128 - Mean training loss 0.111431; Mean training F1 0.917395; Mean validation loss 0.100468; Mean validation F1 0.927433; Learning rate 0.000497;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.927433; loss - 0.100468;\n",
      "Group g4: f1 - 0.996347; loss - 0.008119;\n",
      "Group g9: f1 - 0.699640; loss - 0.320074;\n",
      "===========================================================\n",
      "Epoch 007/128 - Mean training loss 0.101874; Mean training F1 0.924309; Mean validation loss 0.099349; Mean validation F1 0.930757; Learning rate 0.000497;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.930757; loss - 0.099349;\n",
      "Group g4: f1 - 0.989032; loss - 0.024793;\n",
      "Group g9: f1 - 0.678080; loss - 0.302963;\n",
      "===========================================================\n",
      "Epoch 008/128 - Mean training loss 0.101156; Mean training F1 0.922981; Mean validation loss 0.091698; Mean validation F1 0.934548; Learning rate 0.000495;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.934548; loss - 0.091698;\n",
      "Group g4: f1 - 0.996346; loss - 0.007968;\n",
      "Group g9: f1 - 0.710191; loss - 0.297638;\n",
      "===========================================================\n",
      "Epoch 009/128 - Mean training loss 0.271858; Mean training F1 0.833981; Mean validation loss 0.117489; Mean validation F1 0.888462; Learning rate 0.000494;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.888462; loss - 0.117489;\n",
      "Group g4: f1 - 0.996178; loss - 0.010941;\n",
      "Group g9: f1 - 0.579214; loss - 0.377004;\n",
      "===========================================================\n",
      "Epoch 010/128 - Mean training loss 0.137800; Mean training F1 0.898819; Mean validation loss 0.108463; Mean validation F1 0.922589; Learning rate 0.000493;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.922589; loss - 0.108463;\n",
      "Group g4: f1 - 0.996144; loss - 0.010999;\n",
      "Group g9: f1 - 0.639223; loss - 0.349300;\n",
      "===========================================================\n",
      "Epoch 011/128 - Mean training loss 0.123828; Mean training F1 0.910467; Mean validation loss 0.113191; Mean validation F1 0.919133; Learning rate 0.000491;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.919133; loss - 0.113191;\n",
      "Group g4: f1 - 0.996153; loss - 0.009180;\n",
      "Group g9: f1 - 0.647536; loss - 0.372010;\n",
      "===========================================================\n",
      "Epoch 012/128 - Mean training loss 0.108705; Mean training F1 0.919823; Mean validation loss 0.092776; Mean validation F1 0.933012; Learning rate 0.000489;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.933012; loss - 0.092776;\n",
      "Group g4: f1 - 0.996277; loss - 0.008396;\n",
      "Group g9: f1 - 0.702499; loss - 0.302337;\n",
      "===========================================================\n",
      "Epoch 013/128 - Mean training loss 0.101418; Mean training F1 0.924385; Mean validation loss 0.091596; Mean validation F1 0.931246; Learning rate 0.000488;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.931246; loss - 0.091596;\n",
      "Group g4: f1 - 0.996264; loss - 0.008499;\n",
      "Group g9: f1 - 0.703646; loss - 0.303782;\n",
      "===========================================================\n",
      "Epoch 014/128 - Mean training loss 0.097774; Mean training F1 0.927021; Mean validation loss 0.088904; Mean validation F1 0.936004; Learning rate 0.000486;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.936004; loss - 0.088904;\n",
      "Group g4: f1 - 0.996416; loss - 0.007951;\n",
      "Group g9: f1 - 0.712813; loss - 0.288357;\n",
      "===========================================================\n",
      "Epoch 015/128 - Mean training loss 0.094541; Mean training F1 0.929656; Mean validation loss 0.090847; Mean validation F1 0.936272; Learning rate 0.000484;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.936272; loss - 0.090847;\n",
      "Group g4: f1 - 0.996438; loss - 0.007930;\n",
      "Group g9: f1 - 0.708011; loss - 0.286518;\n",
      "===========================================================\n",
      "Epoch 016/128 - Mean training loss 0.093475; Mean training F1 0.929942; Mean validation loss 0.089270; Mean validation F1 0.935803; Learning rate 0.000481;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.935803; loss - 0.089270;\n",
      "Group g4: f1 - 0.996166; loss - 0.008550;\n",
      "Group g9: f1 - 0.705795; loss - 0.294763;\n",
      "===========================================================\n",
      "Epoch 017/128 - Mean training loss 0.091990; Mean training F1 0.931219; Mean validation loss 0.089090; Mean validation F1 0.935412; Learning rate 0.000479;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.935412; loss - 0.089090;\n",
      "Group g4: f1 - 0.996201; loss - 0.008432;\n",
      "Group g9: f1 - 0.701948; loss - 0.286520;\n",
      "===========================================================\n",
      "Epoch 018/128 - Mean training loss 0.091787; Mean training F1 0.931644; Mean validation loss 0.093090; Mean validation F1 0.933641; Learning rate 0.000476;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.933641; loss - 0.093090;\n",
      "Group g4: f1 - 0.996417; loss - 0.007952;\n",
      "Group g9: f1 - 0.710494; loss - 0.299165;\n",
      "===========================================================\n",
      "Epoch 019/128 - Mean training loss 0.090507; Mean training F1 0.932138; Mean validation loss 0.089562; Mean validation F1 0.935451; Learning rate 0.000474;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.935451; loss - 0.089562;\n",
      "Group g4: f1 - 0.996480; loss - 0.007617;\n",
      "Group g9: f1 - 0.709609; loss - 0.286009;\n",
      "===========================================================\n",
      "Epoch 020/128 - Mean training loss 0.090435; Mean training F1 0.932436; Mean validation loss 0.086562; Mean validation F1 0.936114; Learning rate 0.000471;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.936114; loss - 0.086562;\n",
      "Group g4: f1 - 0.996472; loss - 0.007795;\n",
      "Group g9: f1 - 0.715454; loss - 0.283774;\n",
      "===========================================================\n",
      "Epoch 021/128 - Mean training loss 0.089331; Mean training F1 0.933092; Mean validation loss 0.089920; Mean validation F1 0.933611; Learning rate 0.000468;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.933611; loss - 0.089920;\n",
      "Group g4: f1 - 0.996403; loss - 0.007878;\n",
      "Group g9: f1 - 0.708811; loss - 0.292932;\n",
      "===========================================================\n",
      "Epoch 022/128 - Mean training loss 0.090912; Mean training F1 0.931566; Mean validation loss 0.086929; Mean validation F1 0.936463; Learning rate 0.000465;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.936463; loss - 0.086929;\n",
      "Group g4: f1 - 0.996290; loss - 0.007878;\n",
      "Group g9: f1 - 0.714846; loss - 0.282238;\n",
      "===========================================================\n",
      "Epoch 023/128 - Mean training loss 0.088763; Mean training F1 0.933619; Mean validation loss 0.089181; Mean validation F1 0.934355; Learning rate 0.000462;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.934355; loss - 0.089181;\n",
      "Group g4: f1 - 0.996511; loss - 0.007975;\n",
      "Group g9: f1 - 0.774748; loss - 0.284380;\n",
      "===========================================================\n",
      "Epoch 024/128 - Mean training loss 0.089611; Mean training F1 0.932958; Mean validation loss 0.089127; Mean validation F1 0.936706; Learning rate 0.000458;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.936706; loss - 0.089127;\n",
      "Group g4: f1 - 0.996260; loss - 0.008196;\n",
      "Group g9: f1 - 0.758621; loss - 0.284295;\n",
      "===========================================================\n",
      "Epoch 025/128 - Mean training loss 0.088391; Mean training F1 0.933632; Mean validation loss 0.086428; Mean validation F1 0.937440; Learning rate 0.000455;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.937440; loss - 0.086428;\n",
      "Group g4: f1 - 0.996440; loss - 0.007712;\n",
      "Group g9: f1 - 0.785632; loss - 0.282591;\n",
      "===========================================================\n",
      "Epoch 026/128 - Mean training loss 0.089508; Mean training F1 0.932217; Mean validation loss 0.086703; Mean validation F1 0.932737; Learning rate 0.000451;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.932737; loss - 0.086703;\n",
      "Group g4: f1 - 0.996532; loss - 0.007354;\n",
      "Group g9: f1 - 0.743199; loss - 0.290419;\n",
      "===========================================================\n",
      "Epoch 027/128 - Mean training loss 0.087482; Mean training F1 0.934148; Mean validation loss 0.086880; Mean validation F1 0.936676; Learning rate 0.000448;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.936676; loss - 0.086880;\n",
      "Group g4: f1 - 0.996632; loss - 0.007484;\n",
      "Group g9: f1 - 0.749185; loss - 0.286342;\n",
      "===========================================================\n",
      "Epoch 028/128 - Mean training loss 0.086492; Mean training F1 0.935341; Mean validation loss 0.085351; Mean validation F1 0.937835; Learning rate 0.000444;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.937835; loss - 0.085351;\n",
      "Group g4: f1 - 0.996503; loss - 0.007393;\n",
      "Group g9: f1 - 0.791806; loss - 0.283199;\n",
      "===========================================================\n",
      "Epoch 029/128 - Mean training loss 0.087418; Mean training F1 0.934281; Mean validation loss 0.088083; Mean validation F1 0.935707; Learning rate 0.000440;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.935707; loss - 0.088083;\n",
      "Group g4: f1 - 0.996621; loss - 0.007241;\n",
      "Group g9: f1 - 0.767583; loss - 0.287355;\n",
      "===========================================================\n",
      "Epoch 030/128 - Mean training loss 0.086970; Mean training F1 0.934970; Mean validation loss 0.085638; Mean validation F1 0.938381; Learning rate 0.000436;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938381; loss - 0.085638;\n",
      "Group g4: f1 - 0.996659; loss - 0.007347;\n",
      "Group g9: f1 - 0.791900; loss - 0.280735;\n",
      "===========================================================\n",
      "Epoch 031/128 - Mean training loss 0.086910; Mean training F1 0.935184; Mean validation loss 0.085901; Mean validation F1 0.936208; Learning rate 0.000432;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.936208; loss - 0.085901;\n",
      "Group g4: f1 - 0.996487; loss - 0.007315;\n",
      "Group g9: f1 - 0.713744; loss - 0.285197;\n",
      "===========================================================\n",
      "Epoch 032/128 - Mean training loss 0.087679; Mean training F1 0.934045; Mean validation loss 0.084873; Mean validation F1 0.938184; Learning rate 0.000428;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938184; loss - 0.084873;\n",
      "Group g4: f1 - 0.996625; loss - 0.007295;\n",
      "Group g9: f1 - 0.773225; loss - 0.282629;\n",
      "===========================================================\n",
      "Epoch 033/128 - Mean training loss 0.093338; Mean training F1 0.932635; Mean validation loss 0.090393; Mean validation F1 0.936280; Learning rate 0.000423;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.936280; loss - 0.090393;\n",
      "Group g4: f1 - 0.995997; loss - 0.008298;\n",
      "Group g9: f1 - 0.744560; loss - 0.288039;\n",
      "===========================================================\n",
      "Epoch 034/128 - Mean training loss 0.093536; Mean training F1 0.930782; Mean validation loss 0.086764; Mean validation F1 0.937572; Learning rate 0.000419;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.937572; loss - 0.086764;\n",
      "Group g4: f1 - 0.996559; loss - 0.007518;\n",
      "Group g9: f1 - 0.715555; loss - 0.288042;\n",
      "===========================================================\n",
      "Epoch 035/128 - Mean training loss 0.086196; Mean training F1 0.935552; Mean validation loss 0.084746; Mean validation F1 0.937835; Learning rate 0.000414;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.937835; loss - 0.084746;\n",
      "Group g4: f1 - 0.996527; loss - 0.007331;\n",
      "Group g9: f1 - 0.765945; loss - 0.280019;\n",
      "===========================================================\n",
      "Epoch 036/128 - Mean training loss 0.085916; Mean training F1 0.935440; Mean validation loss 0.085119; Mean validation F1 0.937548; Learning rate 0.000410;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.937548; loss - 0.085119;\n",
      "Group g4: f1 - 0.996520; loss - 0.007214;\n",
      "Group g9: f1 - 0.792061; loss - 0.282945;\n",
      "===========================================================\n",
      "Epoch 037/128 - Mean training loss 0.085700; Mean training F1 0.935641; Mean validation loss 0.084371; Mean validation F1 0.937785; Learning rate 0.000405;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.937785; loss - 0.084371;\n",
      "Group g4: f1 - 0.996664; loss - 0.007117;\n",
      "Group g9: f1 - 0.761199; loss - 0.279344;\n",
      "===========================================================\n",
      "Epoch 038/128 - Mean training loss 0.085298; Mean training F1 0.935776; Mean validation loss 0.083941; Mean validation F1 0.938536; Learning rate 0.000400;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938536; loss - 0.083941;\n",
      "Group g4: f1 - 0.996607; loss - 0.007238;\n",
      "Group g9: f1 - 0.782634; loss - 0.279134;\n",
      "===========================================================\n",
      "Epoch 039/128 - Mean training loss 0.167636; Mean training F1 0.896640; Mean validation loss 0.094477; Mean validation F1 0.931786; Learning rate 0.000395;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.931786; loss - 0.094477;\n",
      "Group g4: f1 - 0.996242; loss - 0.008348;\n",
      "Group g9: f1 - 0.703374; loss - 0.301430;\n",
      "===========================================================\n",
      "Epoch 040/128 - Mean training loss 0.098094; Mean training F1 0.927384; Mean validation loss 0.088455; Mean validation F1 0.935839; Learning rate 0.000390;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.935839; loss - 0.088455;\n",
      "Group g4: f1 - 0.996217; loss - 0.008198;\n",
      "Group g9: f1 - 0.769676; loss - 0.290740;\n",
      "===========================================================\n",
      "Epoch 041/128 - Mean training loss 0.092091; Mean training F1 0.931827; Mean validation loss 0.087017; Mean validation F1 0.937545; Learning rate 0.000385;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.937545; loss - 0.087017;\n",
      "Group g4: f1 - 0.996543; loss - 0.007553;\n",
      "Group g9: f1 - 0.759233; loss - 0.285892;\n",
      "===========================================================\n",
      "Epoch 042/128 - Mean training loss 0.089696; Mean training F1 0.933002; Mean validation loss 0.085342; Mean validation F1 0.937978; Learning rate 0.000380;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.937978; loss - 0.085342;\n",
      "Group g4: f1 - 0.996420; loss - 0.007557;\n",
      "Group g9: f1 - 0.784580; loss - 0.283185;\n",
      "===========================================================\n",
      "Epoch 043/128 - Mean training loss 0.088477; Mean training F1 0.934111; Mean validation loss 0.085837; Mean validation F1 0.937380; Learning rate 0.000375;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.937380; loss - 0.085837;\n",
      "Group g4: f1 - 0.996482; loss - 0.008130;\n",
      "Group g9: f1 - 0.781264; loss - 0.282916;\n",
      "===========================================================\n",
      "Epoch 044/128 - Mean training loss 0.087344; Mean training F1 0.934548; Mean validation loss 0.084601; Mean validation F1 0.938057; Learning rate 0.000369;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938057; loss - 0.084601;\n",
      "Group g4: f1 - 0.996547; loss - 0.007375;\n",
      "Group g9: f1 - 0.778112; loss - 0.280278;\n",
      "===========================================================\n",
      "Epoch 045/128 - Mean training loss 0.087043; Mean training F1 0.934720; Mean validation loss 0.084806; Mean validation F1 0.937209; Learning rate 0.000364;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.937209; loss - 0.084806;\n",
      "Group g4: f1 - 0.996228; loss - 0.008205;\n",
      "Group g9: f1 - 0.779349; loss - 0.281651;\n",
      "===========================================================\n",
      "Epoch 046/128 - Mean training loss 0.086158; Mean training F1 0.935150; Mean validation loss 0.084900; Mean validation F1 0.937761; Learning rate 0.000358;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.937761; loss - 0.084900;\n",
      "Group g4: f1 - 0.996016; loss - 0.009070;\n",
      "Group g9: f1 - 0.791395; loss - 0.281515;\n",
      "===========================================================\n",
      "Epoch 047/128 - Mean training loss 0.085710; Mean training F1 0.935768; Mean validation loss 0.084916; Mean validation F1 0.936509; Learning rate 0.000353;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.936509; loss - 0.084916;\n",
      "Group g4: f1 - 0.996473; loss - 0.007749;\n",
      "Group g9: f1 - 0.796464; loss - 0.280249;\n",
      "===========================================================\n",
      "Epoch 048/128 - Mean training loss 0.085432; Mean training F1 0.935621; Mean validation loss 0.084757; Mean validation F1 0.937050; Learning rate 0.000347;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.937050; loss - 0.084757;\n",
      "Group g4: f1 - 0.996539; loss - 0.007461;\n",
      "Group g9: f1 - 0.787354; loss - 0.284180;\n",
      "===========================================================\n",
      "Epoch 049/128 - Mean training loss 0.085050; Mean training F1 0.935959; Mean validation loss 0.084464; Mean validation F1 0.938469; Learning rate 0.000342;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938469; loss - 0.084464;\n",
      "Group g4: f1 - 0.996408; loss - 0.007494;\n",
      "Group g9: f1 - 0.802065; loss - 0.279482;\n",
      "===========================================================\n",
      "Epoch 050/128 - Mean training loss 0.085002; Mean training F1 0.936069; Mean validation loss 0.085402; Mean validation F1 0.935753; Learning rate 0.000336;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.935753; loss - 0.085402;\n",
      "Group g4: f1 - 0.996467; loss - 0.007675;\n",
      "Group g9: f1 - 0.800773; loss - 0.281144;\n",
      "===========================================================\n",
      "Epoch 051/128 - Mean training loss 0.084735; Mean training F1 0.936281; Mean validation loss 0.083629; Mean validation F1 0.938650; Learning rate 0.000330;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938650; loss - 0.083629;\n",
      "Group g4: f1 - 0.996608; loss - 0.007426;\n",
      "Group g9: f1 - 0.802034; loss - 0.279457;\n",
      "===========================================================\n",
      "Epoch 052/128 - Mean training loss 0.084488; Mean training F1 0.936419; Mean validation loss 0.083595; Mean validation F1 0.939070; Learning rate 0.000324;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939070; loss - 0.083595;\n",
      "Group g4: f1 - 0.996431; loss - 0.007623;\n",
      "Group g9: f1 - 0.803663; loss - 0.277527;\n",
      "===========================================================\n",
      "Epoch 053/128 - Mean training loss 0.084307; Mean training F1 0.936282; Mean validation loss 0.084968; Mean validation F1 0.936463; Learning rate 0.000319;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.936463; loss - 0.084968;\n",
      "Group g4: f1 - 0.996609; loss - 0.007103;\n",
      "Group g9: f1 - 0.788864; loss - 0.281468;\n",
      "===========================================================\n",
      "Epoch 054/128 - Mean training loss 0.084760; Mean training F1 0.936000; Mean validation loss 0.085149; Mean validation F1 0.937989; Learning rate 0.000313;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.937989; loss - 0.085149;\n",
      "Group g4: f1 - 0.996648; loss - 0.007280;\n",
      "Group g9: f1 - 0.770593; loss - 0.282564;\n",
      "===========================================================\n",
      "Epoch 055/128 - Mean training loss 0.084334; Mean training F1 0.936460; Mean validation loss 0.084403; Mean validation F1 0.938187; Learning rate 0.000307;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938187; loss - 0.084403;\n",
      "Group g4: f1 - 0.996347; loss - 0.007664;\n",
      "Group g9: f1 - 0.795889; loss - 0.281752;\n",
      "===========================================================\n",
      "Epoch 056/128 - Mean training loss 0.084047; Mean training F1 0.936565; Mean validation loss 0.084064; Mean validation F1 0.938540; Learning rate 0.000301;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938540; loss - 0.084064;\n",
      "Group g4: f1 - 0.996524; loss - 0.007558;\n",
      "Group g9: f1 - 0.768361; loss - 0.279777;\n",
      "===========================================================\n",
      "Epoch 057/128 - Mean training loss 0.084151; Mean training F1 0.936321; Mean validation loss 0.083558; Mean validation F1 0.937588; Learning rate 0.000295;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.937588; loss - 0.083558;\n",
      "Group g4: f1 - 0.996734; loss - 0.007145;\n",
      "Group g9: f1 - 0.786040; loss - 0.278102;\n",
      "===========================================================\n",
      "Epoch 058/128 - Mean training loss 0.083896; Mean training F1 0.936467; Mean validation loss 0.083409; Mean validation F1 0.938635; Learning rate 0.000289;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938635; loss - 0.083409;\n",
      "Group g4: f1 - 0.996711; loss - 0.007058;\n",
      "Group g9: f1 - 0.802619; loss - 0.277602;\n",
      "===========================================================\n",
      "Epoch 059/128 - Mean training loss 0.083525; Mean training F1 0.936914; Mean validation loss 0.082953; Mean validation F1 0.938965; Learning rate 0.000283;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938965; loss - 0.082953;\n",
      "Group g4: f1 - 0.996587; loss - 0.007130;\n",
      "Group g9: f1 - 0.793778; loss - 0.276656;\n",
      "===========================================================\n",
      "Epoch 060/128 - Mean training loss 0.083864; Mean training F1 0.936612; Mean validation loss 0.083335; Mean validation F1 0.938428; Learning rate 0.000277;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938428; loss - 0.083335;\n",
      "Group g4: f1 - 0.996688; loss - 0.006951;\n",
      "Group g9: f1 - 0.793238; loss - 0.277896;\n",
      "===========================================================\n",
      "Epoch 061/128 - Mean training loss 0.083540; Mean training F1 0.936815; Mean validation loss 0.084000; Mean validation F1 0.938498; Learning rate 0.000271;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938498; loss - 0.084000;\n",
      "Group g4: f1 - 0.996780; loss - 0.006921;\n",
      "Group g9: f1 - 0.795095; loss - 0.280440;\n",
      "===========================================================\n",
      "Epoch 062/128 - Mean training loss 0.083416; Mean training F1 0.936992; Mean validation loss 0.083215; Mean validation F1 0.938260; Learning rate 0.000265;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938260; loss - 0.083215;\n",
      "Group g4: f1 - 0.996587; loss - 0.007296;\n",
      "Group g9: f1 - 0.801153; loss - 0.278748;\n",
      "===========================================================\n",
      "Epoch 063/128 - Mean training loss 0.083145; Mean training F1 0.937079; Mean validation loss 0.083450; Mean validation F1 0.938978; Learning rate 0.000259;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938978; loss - 0.083450;\n",
      "Group g4: f1 - 0.996411; loss - 0.007782;\n",
      "Group g9: f1 - 0.801653; loss - 0.276731;\n",
      "===========================================================\n",
      "Epoch 064/128 - Mean training loss 0.082720; Mean training F1 0.937369; Mean validation loss 0.083239; Mean validation F1 0.938496; Learning rate 0.000253;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938496; loss - 0.083239;\n",
      "Group g4: f1 - 0.996721; loss - 0.006902;\n",
      "Group g9: f1 - 0.800786; loss - 0.278009;\n",
      "===========================================================\n",
      "Epoch 065/128 - Mean training loss 0.082851; Mean training F1 0.937422; Mean validation loss 0.083045; Mean validation F1 0.938693; Learning rate 0.000247;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938693; loss - 0.083045;\n",
      "Group g4: f1 - 0.996797; loss - 0.006907;\n",
      "Group g9: f1 - 0.805201; loss - 0.277121;\n",
      "===========================================================\n",
      "Epoch 066/128 - Mean training loss 0.082950; Mean training F1 0.937225; Mean validation loss 0.084124; Mean validation F1 0.936728; Learning rate 0.000241;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.936728; loss - 0.084124;\n",
      "Group g4: f1 - 0.996719; loss - 0.006876;\n",
      "Group g9: f1 - 0.777405; loss - 0.280810;\n",
      "===========================================================\n",
      "Epoch 067/128 - Mean training loss 0.082701; Mean training F1 0.937309; Mean validation loss 0.083624; Mean validation F1 0.939059; Learning rate 0.000234;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939059; loss - 0.083624;\n",
      "Group g4: f1 - 0.996652; loss - 0.007303;\n",
      "Group g9: f1 - 0.800916; loss - 0.277828;\n",
      "===========================================================\n",
      "Epoch 068/128 - Mean training loss 0.082574; Mean training F1 0.937427; Mean validation loss 0.083002; Mean validation F1 0.939223; Learning rate 0.000228;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939223; loss - 0.083002;\n",
      "Group g4: f1 - 0.996698; loss - 0.006737;\n",
      "Group g9: f1 - 0.788764; loss - 0.276929;\n",
      "===========================================================\n",
      "Epoch 069/128 - Mean training loss 0.082362; Mean training F1 0.937556; Mean validation loss 0.083189; Mean validation F1 0.938933; Learning rate 0.000222;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938933; loss - 0.083189;\n",
      "Group g4: f1 - 0.996636; loss - 0.007463;\n",
      "Group g9: f1 - 0.802236; loss - 0.276072;\n",
      "===========================================================\n",
      "Epoch 070/128 - Mean training loss 0.082362; Mean training F1 0.937581; Mean validation loss 0.083670; Mean validation F1 0.937497; Learning rate 0.000216;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.937497; loss - 0.083670;\n",
      "Group g4: f1 - 0.996586; loss - 0.007383;\n",
      "Group g9: f1 - 0.802411; loss - 0.279524;\n",
      "===========================================================\n",
      "Epoch 071/128 - Mean training loss 0.082272; Mean training F1 0.937481; Mean validation loss 0.082733; Mean validation F1 0.938955; Learning rate 0.000210;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938955; loss - 0.082733;\n",
      "Group g4: f1 - 0.996725; loss - 0.006735;\n",
      "Group g9: f1 - 0.802159; loss - 0.275497;\n",
      "===========================================================\n",
      "Epoch 072/128 - Mean training loss 0.082481; Mean training F1 0.937424; Mean validation loss 0.084365; Mean validation F1 0.937426; Learning rate 0.000204;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.937426; loss - 0.084365;\n",
      "Group g4: f1 - 0.996757; loss - 0.006793;\n",
      "Group g9: f1 - 0.796625; loss - 0.282712;\n",
      "===========================================================\n",
      "Epoch 073/128 - Mean training loss 0.082105; Mean training F1 0.937931; Mean validation loss 0.082850; Mean validation F1 0.939329; Learning rate 0.000198;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939329; loss - 0.082850;\n",
      "Group g4: f1 - 0.996566; loss - 0.007183;\n",
      "Group g9: f1 - 0.802662; loss - 0.275498;\n",
      "===========================================================\n",
      "Epoch 074/128 - Mean training loss 0.081827; Mean training F1 0.937881; Mean validation loss 0.082832; Mean validation F1 0.938543; Learning rate 0.000193;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938543; loss - 0.082832;\n",
      "Group g4: f1 - 0.996750; loss - 0.006919;\n",
      "Group g9: f1 - 0.797364; loss - 0.276137;\n",
      "===========================================================\n",
      "Epoch 075/128 - Mean training loss 0.081884; Mean training F1 0.937827; Mean validation loss 0.083048; Mean validation F1 0.938663; Learning rate 0.000187;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938663; loss - 0.083048;\n",
      "Group g4: f1 - 0.996780; loss - 0.006952;\n",
      "Group g9: f1 - 0.803473; loss - 0.277606;\n",
      "===========================================================\n",
      "Epoch 076/128 - Mean training loss 0.081549; Mean training F1 0.938003; Mean validation loss 0.082921; Mean validation F1 0.939017; Learning rate 0.000181;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939017; loss - 0.082921;\n",
      "Group g4: f1 - 0.996819; loss - 0.006920;\n",
      "Group g9: f1 - 0.803178; loss - 0.275476;\n",
      "===========================================================\n",
      "Epoch 077/128 - Mean training loss 0.081579; Mean training F1 0.937963; Mean validation loss 0.083262; Mean validation F1 0.938709; Learning rate 0.000175;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938709; loss - 0.083262;\n",
      "Group g4: f1 - 0.996801; loss - 0.006916;\n",
      "Group g9: f1 - 0.802115; loss - 0.276793;\n",
      "===========================================================\n",
      "Epoch 078/128 - Mean training loss 0.081541; Mean training F1 0.938111; Mean validation loss 0.082449; Mean validation F1 0.939094; Learning rate 0.000169;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939094; loss - 0.082449;\n",
      "Group g4: f1 - 0.996853; loss - 0.006673;\n",
      "Group g9: f1 - 0.803587; loss - 0.275202;\n",
      "===========================================================\n",
      "Epoch 079/128 - Mean training loss 0.081276; Mean training F1 0.938241; Mean validation loss 0.082993; Mean validation F1 0.938852; Learning rate 0.000164;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938852; loss - 0.082993;\n",
      "Group g4: f1 - 0.996767; loss - 0.006710;\n",
      "Group g9: f1 - 0.803306; loss - 0.275177;\n",
      "===========================================================\n",
      "Epoch 080/128 - Mean training loss 0.081290; Mean training F1 0.938114; Mean validation loss 0.082640; Mean validation F1 0.938609; Learning rate 0.000158;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938609; loss - 0.082640;\n",
      "Group g4: f1 - 0.996759; loss - 0.006997;\n",
      "Group g9: f1 - 0.798902; loss - 0.275476;\n",
      "===========================================================\n",
      "Epoch 081/128 - Mean training loss 0.081088; Mean training F1 0.938153; Mean validation loss 0.082437; Mean validation F1 0.939417; Learning rate 0.000152;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939417; loss - 0.082437;\n",
      "Group g4: f1 - 0.996921; loss - 0.006614;\n",
      "Group g9: f1 - 0.806046; loss - 0.275206;\n",
      "===========================================================\n",
      "Epoch 082/128 - Mean training loss 0.080971; Mean training F1 0.938385; Mean validation loss 0.082467; Mean validation F1 0.939065; Learning rate 0.000147;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939065; loss - 0.082467;\n",
      "Group g4: f1 - 0.996853; loss - 0.006839;\n",
      "Group g9: f1 - 0.800505; loss - 0.274854;\n",
      "===========================================================\n",
      "Epoch 083/128 - Mean training loss 0.081052; Mean training F1 0.938064; Mean validation loss 0.082354; Mean validation F1 0.939162; Learning rate 0.000141;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939162; loss - 0.082354;\n",
      "Group g4: f1 - 0.996868; loss - 0.006636;\n",
      "Group g9: f1 - 0.804724; loss - 0.274156;\n",
      "===========================================================\n",
      "Epoch 084/128 - Mean training loss 0.080888; Mean training F1 0.938331; Mean validation loss 0.082304; Mean validation F1 0.939416; Learning rate 0.000136;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939416; loss - 0.082304;\n",
      "Group g4: f1 - 0.996819; loss - 0.006693;\n",
      "Group g9: f1 - 0.803171; loss - 0.273480;\n",
      "===========================================================\n",
      "Epoch 085/128 - Mean training loss 0.080703; Mean training F1 0.938557; Mean validation loss 0.082734; Mean validation F1 0.938804; Learning rate 0.000131;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938804; loss - 0.082734;\n",
      "Group g4: f1 - 0.996837; loss - 0.006593;\n",
      "Group g9: f1 - 0.803952; loss - 0.274289;\n",
      "===========================================================\n",
      "Epoch 086/128 - Mean training loss 0.080670; Mean training F1 0.938442; Mean validation loss 0.082514; Mean validation F1 0.939348; Learning rate 0.000125;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939348; loss - 0.082514;\n",
      "Group g4: f1 - 0.996771; loss - 0.006684;\n",
      "Group g9: f1 - 0.802912; loss - 0.273649;\n",
      "===========================================================\n",
      "Epoch 087/128 - Mean training loss 0.080561; Mean training F1 0.938389; Mean validation loss 0.082879; Mean validation F1 0.938960; Learning rate 0.000120;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938960; loss - 0.082879;\n",
      "Group g4: f1 - 0.996730; loss - 0.006673;\n",
      "Group g9: f1 - 0.804064; loss - 0.276454;\n",
      "===========================================================\n",
      "Epoch 088/128 - Mean training loss 0.080393; Mean training F1 0.938764; Mean validation loss 0.082168; Mean validation F1 0.939266; Learning rate 0.000115;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939266; loss - 0.082168;\n",
      "Group g4: f1 - 0.996787; loss - 0.006721;\n",
      "Group g9: f1 - 0.802320; loss - 0.273224;\n",
      "===========================================================\n",
      "Epoch 089/128 - Mean training loss 0.080369; Mean training F1 0.938654; Mean validation loss 0.082440; Mean validation F1 0.939235; Learning rate 0.000110;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939235; loss - 0.082440;\n",
      "Group g4: f1 - 0.996865; loss - 0.006897;\n",
      "Group g9: f1 - 0.807277; loss - 0.273338;\n",
      "===========================================================\n",
      "Epoch 090/128 - Mean training loss 0.080214; Mean training F1 0.938673; Mean validation loss 0.082387; Mean validation F1 0.938940; Learning rate 0.000105;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938940; loss - 0.082387;\n",
      "Group g4: f1 - 0.996948; loss - 0.006583;\n",
      "Group g9: f1 - 0.805605; loss - 0.273647;\n",
      "===========================================================\n",
      "Epoch 092/128 - Mean training loss 0.080018; Mean training F1 0.938709; Mean validation loss 0.082266; Mean validation F1 0.939435; Learning rate 0.000096;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939435; loss - 0.082266;\n",
      "Group g4: f1 - 0.996844; loss - 0.006723;\n",
      "Group g9: f1 - 0.804882; loss - 0.272530;\n",
      "===========================================================\n",
      "Epoch 093/128 - Mean training loss 0.079907; Mean training F1 0.938942; Mean validation loss 0.082412; Mean validation F1 0.939333; Learning rate 0.000091;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939333; loss - 0.082412;\n",
      "Group g4: f1 - 0.996756; loss - 0.006994;\n",
      "Group g9: f1 - 0.806851; loss - 0.272287;\n",
      "===========================================================\n",
      "Epoch 094/128 - Mean training loss 0.079815; Mean training F1 0.938931; Mean validation loss 0.082276; Mean validation F1 0.939254; Learning rate 0.000086;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939254; loss - 0.082276;\n",
      "Group g4: f1 - 0.996862; loss - 0.006578;\n",
      "Group g9: f1 - 0.809141; loss - 0.272385;\n",
      "===========================================================\n",
      "Epoch 095/128 - Mean training loss 0.079806; Mean training F1 0.938867; Mean validation loss 0.082435; Mean validation F1 0.938978; Learning rate 0.000082;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938978; loss - 0.082435;\n",
      "Group g4: f1 - 0.996911; loss - 0.006608;\n",
      "Group g9: f1 - 0.807794; loss - 0.272022;\n",
      "===========================================================\n",
      "Epoch 096/128 - Mean training loss 0.079676; Mean training F1 0.938978; Mean validation loss 0.082465; Mean validation F1 0.939220; Learning rate 0.000078;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939220; loss - 0.082465;\n",
      "Group g4: f1 - 0.996906; loss - 0.006666;\n",
      "Group g9: f1 - 0.808028; loss - 0.272892;\n",
      "===========================================================\n",
      "Epoch 097/128 - Mean training loss 0.079538; Mean training F1 0.938917; Mean validation loss 0.082362; Mean validation F1 0.939390; Learning rate 0.000073;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939390; loss - 0.082362;\n",
      "Group g4: f1 - 0.996829; loss - 0.006911;\n",
      "Group g9: f1 - 0.806741; loss - 0.271724;\n",
      "===========================================================\n",
      "Epoch 098/128 - Mean training loss 0.079420; Mean training F1 0.939196; Mean validation loss 0.082661; Mean validation F1 0.938985; Learning rate 0.000069;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938985; loss - 0.082661;\n",
      "Group g4: f1 - 0.996942; loss - 0.006654;\n",
      "Group g9: f1 - 0.808554; loss - 0.271953;\n",
      "===========================================================\n",
      "Epoch 099/128 - Mean training loss 0.079383; Mean training F1 0.939233; Mean validation loss 0.082547; Mean validation F1 0.938555; Learning rate 0.000065;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938555; loss - 0.082547;\n",
      "Group g4: f1 - 0.996942; loss - 0.006555;\n",
      "Group g9: f1 - 0.808089; loss - 0.272544;\n",
      "===========================================================\n",
      "Epoch 100/128 - Mean training loss 0.079426; Mean training F1 0.938935; Mean validation loss 0.082259; Mean validation F1 0.939027; Learning rate 0.000061;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939027; loss - 0.082259;\n",
      "Group g4: f1 - 0.996864; loss - 0.006659;\n",
      "Group g9: f1 - 0.809045; loss - 0.271378;\n",
      "===========================================================\n",
      "Epoch 101/128 - Mean training loss 0.079209; Mean training F1 0.939253; Mean validation loss 0.082384; Mean validation F1 0.939358; Learning rate 0.000058;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939358; loss - 0.082384;\n",
      "Group g4: f1 - 0.996980; loss - 0.006614;\n",
      "Group g9: f1 - 0.808790; loss - 0.271631;\n",
      "===========================================================\n",
      "Epoch 102/128 - Mean training loss 0.079129; Mean training F1 0.939224; Mean validation loss 0.082326; Mean validation F1 0.939314; Learning rate 0.000054;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939314; loss - 0.082326;\n",
      "Group g4: f1 - 0.996829; loss - 0.006712;\n",
      "Group g9: f1 - 0.806593; loss - 0.271344;\n",
      "===========================================================\n",
      "Epoch 103/128 - Mean training loss 0.079033; Mean training F1 0.939394; Mean validation loss 0.082425; Mean validation F1 0.939399; Learning rate 0.000050;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939399; loss - 0.082425;\n",
      "Group g4: f1 - 0.996948; loss - 0.006546;\n",
      "Group g9: f1 - 0.810180; loss - 0.270458;\n",
      "===========================================================\n",
      "Epoch 104/128 - Mean training loss 0.078937; Mean training F1 0.939301; Mean validation loss 0.082254; Mean validation F1 0.938709; Learning rate 0.000047;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938709; loss - 0.082254;\n",
      "Group g4: f1 - 0.996910; loss - 0.006486;\n",
      "Group g9: f1 - 0.809832; loss - 0.270972;\n",
      "===========================================================\n",
      "Epoch 105/128 - Mean training loss 0.078981; Mean training F1 0.939414; Mean validation loss 0.082253; Mean validation F1 0.938952; Learning rate 0.000044;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938952; loss - 0.082253;\n",
      "Group g4: f1 - 0.996895; loss - 0.006544;\n",
      "Group g9: f1 - 0.805629; loss - 0.270610;\n",
      "===========================================================\n",
      "Epoch 106/128 - Mean training loss 0.078744; Mean training F1 0.939395; Mean validation loss 0.082338; Mean validation F1 0.939409; Learning rate 0.000040;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939409; loss - 0.082338;\n",
      "Group g4: f1 - 0.996937; loss - 0.006543;\n",
      "Group g9: f1 - 0.810326; loss - 0.270305;\n",
      "===========================================================\n",
      "Epoch 107/128 - Mean training loss 0.078751; Mean training F1 0.939538; Mean validation loss 0.082314; Mean validation F1 0.939471; Learning rate 0.000037;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939471; loss - 0.082314;\n",
      "Group g4: f1 - 0.996927; loss - 0.006504;\n",
      "Group g9: f1 - 0.810765; loss - 0.270483;\n",
      "===========================================================\n",
      "Epoch 108/128 - Mean training loss 0.078699; Mean training F1 0.939508; Mean validation loss 0.082251; Mean validation F1 0.939421; Learning rate 0.000034;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939421; loss - 0.082251;\n",
      "Group g4: f1 - 0.996881; loss - 0.006617;\n",
      "Group g9: f1 - 0.809772; loss - 0.270213;\n",
      "===========================================================\n",
      "Epoch 109/128 - Mean training loss 0.078607; Mean training F1 0.939523; Mean validation loss 0.082359; Mean validation F1 0.939239; Learning rate 0.000032;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939239; loss - 0.082359;\n",
      "Group g4: f1 - 0.996953; loss - 0.006485;\n",
      "Group g9: f1 - 0.808374; loss - 0.270257;\n",
      "===========================================================\n",
      "Epoch 110/128 - Mean training loss 0.078526; Mean training F1 0.939654; Mean validation loss 0.082306; Mean validation F1 0.939257; Learning rate 0.000029;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939257; loss - 0.082306;\n",
      "Group g4: f1 - 0.996953; loss - 0.006557;\n",
      "Group g9: f1 - 0.807688; loss - 0.270085;\n",
      "===========================================================\n",
      "Epoch 111/128 - Mean training loss 0.078572; Mean training F1 0.939510; Mean validation loss 0.082416; Mean validation F1 0.938723; Learning rate 0.000026;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938723; loss - 0.082416;\n",
      "Group g4: f1 - 0.996912; loss - 0.006629;\n",
      "Group g9: f1 - 0.808776; loss - 0.270282;\n",
      "===========================================================\n",
      "Epoch 112/128 - Mean training loss 0.078431; Mean training F1 0.939486; Mean validation loss 0.082371; Mean validation F1 0.939263; Learning rate 0.000024;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939263; loss - 0.082371;\n",
      "Group g4: f1 - 0.996953; loss - 0.006507;\n",
      "Group g9: f1 - 0.809010; loss - 0.269870;\n",
      "===========================================================\n",
      "Epoch 113/128 - Mean training loss 0.078423; Mean training F1 0.939490; Mean validation loss 0.082353; Mean validation F1 0.938970; Learning rate 0.000022;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.938970; loss - 0.082353;\n",
      "Group g4: f1 - 0.996958; loss - 0.006513;\n",
      "Group g9: f1 - 0.810667; loss - 0.269617;\n",
      "===========================================================\n",
      "Epoch 114/128 - Mean training loss 0.078373; Mean training F1 0.939683; Mean validation loss 0.082368; Mean validation F1 0.939494; Learning rate 0.000020;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939494; loss - 0.082368;\n",
      "Group g4: f1 - 0.996957; loss - 0.006455;\n",
      "Group g9: f1 - 0.810908; loss - 0.269466;\n",
      "===========================================================\n",
      "Epoch 115/128 - Mean training loss 0.078308; Mean training F1 0.939595; Mean validation loss 0.082396; Mean validation F1 0.939158; Learning rate 0.000018;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939158; loss - 0.082396;\n",
      "Group g4: f1 - 0.996953; loss - 0.006502;\n",
      "Group g9: f1 - 0.810754; loss - 0.269774;\n",
      "===========================================================\n",
      "Epoch 116/128 - Mean training loss 0.078234; Mean training F1 0.939667; Mean validation loss 0.082455; Mean validation F1 0.939245; Learning rate 0.000016;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939245; loss - 0.082455;\n",
      "Group g4: f1 - 0.996948; loss - 0.006536;\n",
      "Group g9: f1 - 0.810423; loss - 0.269668;\n",
      "===========================================================\n",
      "Epoch 117/128 - Mean training loss 0.078169; Mean training F1 0.939785; Mean validation loss 0.082358; Mean validation F1 0.939303; Learning rate 0.000014;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939303; loss - 0.082358;\n",
      "Group g4: f1 - 0.996979; loss - 0.006467;\n",
      "Group g9: f1 - 0.811100; loss - 0.269415;\n",
      "===========================================================\n",
      "Epoch 118/128 - Mean training loss 0.078175; Mean training F1 0.939721; Mean validation loss 0.082431; Mean validation F1 0.939266; Learning rate 0.000013;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939266; loss - 0.082431;\n",
      "Group g4: f1 - 0.996905; loss - 0.006488;\n",
      "Group g9: f1 - 0.811957; loss - 0.269291;\n",
      "===========================================================\n",
      "Epoch 119/128 - Mean training loss 0.078134; Mean training F1 0.939705; Mean validation loss 0.082389; Mean validation F1 0.939255; Learning rate 0.000011;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939255; loss - 0.082389;\n",
      "Group g4: f1 - 0.996958; loss - 0.006490;\n",
      "Group g9: f1 - 0.812213; loss - 0.269048;\n",
      "===========================================================\n",
      "Epoch 120/128 - Mean training loss 0.078115; Mean training F1 0.939746; Mean validation loss 0.082407; Mean validation F1 0.939244; Learning rate 0.000010;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939244; loss - 0.082407;\n",
      "Group g4: f1 - 0.996922; loss - 0.006513;\n",
      "Group g9: f1 - 0.811972; loss - 0.269097;\n",
      "===========================================================\n",
      "Epoch 121/128 - Mean training loss 0.078047; Mean training F1 0.939697; Mean validation loss 0.082390; Mean validation F1 0.939390; Learning rate 0.000009;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939390; loss - 0.082390;\n",
      "Group g4: f1 - 0.996973; loss - 0.006458;\n",
      "Group g9: f1 - 0.812275; loss - 0.269041;\n",
      "===========================================================\n",
      "Epoch 122/128 - Mean training loss 0.078060; Mean training F1 0.939819; Mean validation loss 0.082394; Mean validation F1 0.939511; Learning rate 0.000008;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939511; loss - 0.082394;\n",
      "Group g4: f1 - 0.996958; loss - 0.006507;\n",
      "Group g9: f1 - 0.812263; loss - 0.269050;\n",
      "===========================================================\n",
      "Epoch 123/128 - Mean training loss 0.077996; Mean training F1 0.939659; Mean validation loss 0.082484; Mean validation F1 0.939186; Learning rate 0.000007;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939186; loss - 0.082484;\n",
      "Group g4: f1 - 0.996917; loss - 0.006559;\n",
      "Group g9: f1 - 0.810919; loss - 0.269030;\n",
      "===========================================================\n",
      "Epoch 124/128 - Mean training loss 0.078037; Mean training F1 0.939736; Mean validation loss 0.082458; Mean validation F1 0.939102; Learning rate 0.000006;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939102; loss - 0.082458;\n",
      "Group g4: f1 - 0.996969; loss - 0.006490;\n",
      "Group g9: f1 - 0.812260; loss - 0.269100;\n",
      "===========================================================\n",
      "Epoch 125/128 - Mean training loss 0.077966; Mean training F1 0.939746; Mean validation loss 0.082401; Mean validation F1 0.939468; Learning rate 0.000006;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939468; loss - 0.082401;\n",
      "Group g4: f1 - 0.996948; loss - 0.006508;\n",
      "Group g9: f1 - 0.812637; loss - 0.268841;\n",
      "===========================================================\n",
      "Epoch 126/128 - Mean training loss 0.077944; Mean training F1 0.939829; Mean validation loss 0.082423; Mean validation F1 0.939481; Learning rate 0.000005;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939481; loss - 0.082423;\n",
      "Group g4: f1 - 0.996948; loss - 0.006498;\n",
      "Group g9: f1 - 0.812544; loss - 0.268786;\n",
      "===========================================================\n",
      "Epoch 127/128 - Mean training loss 0.077925; Mean training F1 0.939820; Mean validation loss 0.082457; Mean validation F1 0.939281; Learning rate 0.000005;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939281; loss - 0.082457;\n",
      "Group g4: f1 - 0.996995; loss - 0.006498;\n",
      "Group g9: f1 - 0.811090; loss - 0.268864;\n",
      "===========================================================\n",
      "Epoch 128/128 - Mean training loss 0.077923; Mean training F1 0.939862; Mean validation loss 0.082412; Mean validation F1 0.939282; Learning rate 0.000005;\n",
      "Validation metrics:\n",
      "Group vld: f1 - 0.939282; loss - 0.082412;\n",
      "Group g4: f1 - 0.996932; loss - 0.006478;\n",
      "Group g9: f1 - 0.810149; loss - 0.268882;\n"
     ]
    }
   ],
   "source": [
    "unit = 1000\n",
    "\n",
    "for fld, (ndcs_trn, ndcs_vld) in enumerate(skf.split(series_dat_all, skf_trgt)):\n",
    "    #if fld < 3:\n",
    "    #    continue\n",
    "        \n",
    "    print('################################################################')\n",
    "    print('Training/validation for fold {:d}/{:d};'.format(fld+1, N_FOLDS))\n",
    "    \n",
    "    # setup fold data\n",
    "    dat_trn, lbl_trn = series_dat_all[ndcs_trn], series_lbl_all[ndcs_trn]\n",
    "    dat_vld, lbl_vld = series_dat_all[ndcs_vld], series_lbl_all[ndcs_vld]\n",
    "    \n",
    "    waveset_trn = Waveset(dat_trn, lbl_trn)\n",
    "    waveset_vld = Waveset(dat_vld, lbl_vld)\n",
    "\n",
    "    loader_trn = DataLoader(waveset_trn, BATCHSIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    loader_vld = DataLoader(waveset_vld, BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    \n",
    "    unit = 500\n",
    "    vld_loaders = {\n",
    "        'vld': loader_vld,\n",
    "        #'g0': DataLoader(Waveset(series_dat_all[0*unit:1*unit], series_lbl_all[0*unit:1*unit]), BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True),\n",
    "        #'g1': DataLoader(Waveset(series_dat_all[1*unit:2*unit], series_lbl_all[1*unit:2*unit]), BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True),\n",
    "        #'g2': DataLoader(Waveset(series_dat_all[2*unit:3*unit], series_lbl_all[2*unit:3*unit]), BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True),\n",
    "        #'g3': DataLoader(Waveset(series_dat_all[3*unit:4*unit], series_lbl_all[3*unit:4*unit]), BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True),\n",
    "        'g4': DataLoader(Waveset(series_dat_all[4*unit:5*unit], series_lbl_all[4*unit:5*unit]), BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True),\n",
    "        #'g5': DataLoader(Waveset(series_dat_all[5*unit:6*unit], series_lbl_all[5*unit:6*unit]), BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True),\n",
    "        #'g6': DataLoader(Waveset(series_dat_all[6*unit:7*unit], series_lbl_all[6*unit:7*unit]), BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True),\n",
    "        #'g7': DataLoader(Waveset(series_dat_all[7*unit:8*unit], series_lbl_all[7*unit:8*unit]), BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True),\n",
    "        #'g8': DataLoader(Waveset(series_dat_all[8*unit:9*unit], series_lbl_all[8*unit:9*unit]), BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True),\n",
    "        'g9': DataLoader(Waveset(series_dat_all[9*unit:10*unit], series_lbl_all[9*unit:10*unit]), BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True),\n",
    "    }\n",
    "    \n",
    "    # setup fold model\n",
    "    mdl = WaveTRSFM_Classifier(series_dat_all.shape[-1]).to(DEVICE)\n",
    "    critrn = nn.CrossEntropyLoss()\n",
    "    optimzr = torch.optim.AdamW(mdl.parameters(), lr=LR)\n",
    "    schdlr = torch.optim.lr_scheduler.CosineAnnealingLR(optimzr, T_max=EPOCHS, eta_min=LR/100)\n",
    "    \n",
    "    # run\n",
    "    fold_train_validate(\n",
    "        model=mdl, optimizer=optimzr, criterion=critrn,\n",
    "        scheduler=schdlr, training_loader=loader_trn, validation_loaders=vld_loaders,\n",
    "        fold_number=fld,\n",
    "        save_path='./saved_models/wave_transformer_model_final_feats_w500_fold{:03d}_checkpoint.pth',\n",
    "        early_stopping=50\n",
    "    )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv', dtype={'time': str, 'open_channels': 'Int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- fold 0 --------\n",
      "model validation loss: 0.082; validation f1: 0.940;\n",
      "-------- fold 1 --------\n",
      "model validation loss: 0.091; validation f1: 0.937;\n",
      "-------- fold 2 --------\n",
      "model validation loss: 0.085; validation f1: 0.938;\n",
      "-------- fold 3 --------\n",
      "model validation loss: 0.082; validation f1: 0.939;\n",
      "-------- fold 4 --------\n",
      "model validation loss: 0.080; validation f1: 0.939;\n"
     ]
    }
   ],
   "source": [
    "submission_pred = np.zeros(shape=(submission.shape[0], 11))\n",
    "\n",
    "# waveset_tst = Waveset(series_tst)\n",
    "# loader_tst = DataLoader(waveset_tst, BATCHSIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "for fld in range(5):\n",
    "    print('-------- fold {:d} --------'.format(fld))\n",
    "    fld_weight = torch.load('./saved_models/wave_transformer_model_final_feats_w500_fold{:03d}_checkpoint.pth'.format(fld))\n",
    "    print('model validation loss: {:.3f}; validation f1: {:.3f};'.format(fld_weight['loss'], fld_weight['f1']))\n",
    "#     mdl = WaveTRSFM_Classifier(series_trn.shape[-1]).to(DEVICE)\n",
    "#     mdl.load_state_dict(fld_weight['model'])\n",
    "#     mdl.eval()\n",
    "#     with torch.no_grad():\n",
    "#         tst_fold_prd = []\n",
    "#         for tst_batch_dat in loader_tst:\n",
    "#             tst_batch_prd = mdl(tst_batch_dat.to(DEVICE))\n",
    "#             tst_batch_prd = tst_batch_prd.view(-1, tst_batch_prd.size(-1)).detach().cpu().numpy()\n",
    "#             tst_fold_prd.append(tst_batch_prd)\n",
    "            \n",
    "#         submission_pred += np.concatenate(tst_fold_prd, 0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "submission['open_channels'] = submission_pred.argmax(1)\n",
    "submission.to_csv(\"../submissions/sub0_waveTRSFM_basicwithnew2_cvbyentropy_meanstdnorm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "wavenet + rnn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "################################################################\n",
    "Training/validation for fold 1/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.351473; Mean training F1 0.804234; Mean validation loss 0.135117; Mean validation F1 0.921385; Learning rate 0.001000;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.921385; loss - 0.135117;\n",
    "Group g4: f1 - 0.663113; loss - 0.015070;\n",
    "Group g9: f1 - 0.555232; loss - 0.370326;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.136749; Mean training F1 0.910633; Mean validation loss 0.099721; Mean validation F1 0.930866; Learning rate 0.001000;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.930866; loss - 0.099721;\n",
    "Group g4: f1 - 0.663458; loss - 0.011258;\n",
    "Group g9: f1 - 0.623255; loss - 0.314354;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.108366; Mean training F1 0.923583; Mean validation loss 0.099147; Mean validation F1 0.932575; Learning rate 0.000999;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.932575; loss - 0.099147;\n",
    "Group g4: f1 - 0.996144; loss - 0.009008;\n",
    "Group g9: f1 - 0.644066; loss - 0.305396;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.096138; Mean training F1 0.930831; Mean validation loss 0.089431; Mean validation F1 0.936048; Learning rate 0.000998;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936048; loss - 0.089431;\n",
    "Group g4: f1 - 0.996579; loss - 0.008103;\n",
    "Group g9: f1 - 0.665800; loss - 0.294721;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.092489; Mean training F1 0.932416; Mean validation loss 0.089876; Mean validation F1 0.934841; Learning rate 0.000997;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934841; loss - 0.089876;\n",
    "Group g4: f1 - 0.996486; loss - 0.007661;\n",
    "Group g9: f1 - 0.678308; loss - 0.293611;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.092332; Mean training F1 0.931863; Mean validation loss 0.088293; Mean validation F1 0.936516; Learning rate 0.000995;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936516; loss - 0.088293;\n",
    "Group g4: f1 - 0.996370; loss - 0.008015;\n",
    "Group g9: f1 - 0.689535; loss - 0.289971;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.088666; Mean training F1 0.934327; Mean validation loss 0.092959; Mean validation F1 0.933645; Learning rate 0.000993;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933645; loss - 0.092959;\n",
    "Group g4: f1 - 0.996557; loss - 0.007524;\n",
    "Group g9: f1 - 0.695169; loss - 0.302811;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.087076; Mean training F1 0.935084; Mean validation loss 0.085657; Mean validation F1 0.937396; Learning rate 0.000991;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937396; loss - 0.085657;\n",
    "Group g4: f1 - 0.996781; loss - 0.007159;\n",
    "Group g9: f1 - 0.706567; loss - 0.285390;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.086439; Mean training F1 0.934893; Mean validation loss 0.087053; Mean validation F1 0.930232; Learning rate 0.000988;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.930232; loss - 0.087053;\n",
    "Group g4: f1 - 0.996841; loss - 0.006912;\n",
    "Group g9: f1 - 0.704288; loss - 0.293991;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.086606; Mean training F1 0.935163; Mean validation loss 0.086835; Mean validation F1 0.934473; Learning rate 0.000985;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934473; loss - 0.086835;\n",
    "Group g4: f1 - 0.996352; loss - 0.007909;\n",
    "Group g9: f1 - 0.702608; loss - 0.288027;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.086163; Mean training F1 0.935122; Mean validation loss 0.085340; Mean validation F1 0.936957; Learning rate 0.000982;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936957; loss - 0.085340;\n",
    "Group g4: f1 - 0.996381; loss - 0.007913;\n",
    "Group g9: f1 - 0.715836; loss - 0.281897;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.085489; Mean training F1 0.935411; Mean validation loss 0.083813; Mean validation F1 0.938423; Learning rate 0.000979;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938423; loss - 0.083813;\n",
    "Group g4: f1 - 0.996827; loss - 0.007040;\n",
    "Group g9: f1 - 0.727752; loss - 0.280916;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.084374; Mean training F1 0.936260; Mean validation loss 0.084304; Mean validation F1 0.938199; Learning rate 0.000975;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938199; loss - 0.084304;\n",
    "Group g4: f1 - 0.996870; loss - 0.006925;\n",
    "Group g9: f1 - 0.713397; loss - 0.280843;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.083803; Mean training F1 0.936765; Mean validation loss 0.084429; Mean validation F1 0.937989; Learning rate 0.000971;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937989; loss - 0.084429;\n",
    "Group g4: f1 - 0.996761; loss - 0.007092;\n",
    "Group g9: f1 - 0.731410; loss - 0.280498;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.084112; Mean training F1 0.936446; Mean validation loss 0.083871; Mean validation F1 0.938643; Learning rate 0.000967;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938643; loss - 0.083871;\n",
    "Group g4: f1 - 0.996489; loss - 0.007816;\n",
    "Group g9: f1 - 0.743258; loss - 0.278347;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.083583; Mean training F1 0.936675; Mean validation loss 0.083932; Mean validation F1 0.938210; Learning rate 0.000963;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938210; loss - 0.083932;\n",
    "Group g4: f1 - 0.996937; loss - 0.006803;\n",
    "Group g9: f1 - 0.738341; loss - 0.279793;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.083440; Mean training F1 0.936902; Mean validation loss 0.084885; Mean validation F1 0.937718; Learning rate 0.000958;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937718; loss - 0.084885;\n",
    "Group g4: f1 - 0.996867; loss - 0.006873;\n",
    "Group g9: f1 - 0.728930; loss - 0.281779;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.082919; Mean training F1 0.936942; Mean validation loss 0.084274; Mean validation F1 0.937180; Learning rate 0.000953;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937180; loss - 0.084274;\n",
    "Group g4: f1 - 0.996839; loss - 0.007002;\n",
    "Group g9: f1 - 0.740018; loss - 0.280863;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.082919; Mean training F1 0.936625; Mean validation loss 0.085487; Mean validation F1 0.936665; Learning rate 0.000947;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936665; loss - 0.085487;\n",
    "Group g4: f1 - 0.996773; loss - 0.007373;\n",
    "Group g9: f1 - 0.754386; loss - 0.281218;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.082879; Mean training F1 0.936677; Mean validation loss 0.083573; Mean validation F1 0.938778; Learning rate 0.000942;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938778; loss - 0.083573;\n",
    "Group g4: f1 - 0.996925; loss - 0.006713;\n",
    "Group g9: f1 - 0.774948; loss - 0.277473;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.082357; Mean training F1 0.937255; Mean validation loss 0.084685; Mean validation F1 0.931406; Learning rate 0.000936;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931406; loss - 0.084685;\n",
    "Group g4: f1 - 0.996915; loss - 0.006651;\n",
    "Group g9: f1 - 0.740839; loss - 0.284551;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.083759; Mean training F1 0.936551; Mean validation loss 0.084324; Mean validation F1 0.938091; Learning rate 0.000930;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938091; loss - 0.084324;\n",
    "Group g4: f1 - 0.996850; loss - 0.006953;\n",
    "Group g9: f1 - 0.759271; loss - 0.283190;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.081686; Mean training F1 0.937695; Mean validation loss 0.083909; Mean validation F1 0.938248; Learning rate 0.000923;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938248; loss - 0.083909;\n",
    "Group g4: f1 - 0.996921; loss - 0.006751;\n",
    "Group g9: f1 - 0.772499; loss - 0.278071;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.081156; Mean training F1 0.937926; Mean validation loss 0.083279; Mean validation F1 0.938604; Learning rate 0.000917;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938604; loss - 0.083279;\n",
    "Group g4: f1 - 0.996866; loss - 0.006871;\n",
    "Group g9: f1 - 0.778527; loss - 0.275844;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.081189; Mean training F1 0.938002; Mean validation loss 0.083948; Mean validation F1 0.938667; Learning rate 0.000910;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938667; loss - 0.083948;\n",
    "Group g4: f1 - 0.996644; loss - 0.007126;\n",
    "Group g9: f1 - 0.787508; loss - 0.276351;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.080763; Mean training F1 0.938191; Mean validation loss 0.083814; Mean validation F1 0.938308; Learning rate 0.000903;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938308; loss - 0.083814;\n",
    "Group g4: f1 - 0.996611; loss - 0.007229;\n",
    "Group g9: f1 - 0.786703; loss - 0.277090;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.080961; Mean training F1 0.938196; Mean validation loss 0.084181; Mean validation F1 0.938128; Learning rate 0.000896;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938128; loss - 0.084181;\n",
    "Group g4: f1 - 0.996756; loss - 0.006946;\n",
    "Group g9: f1 - 0.769310; loss - 0.277119;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.080358; Mean training F1 0.938545; Mean validation loss 0.084094; Mean validation F1 0.938260; Learning rate 0.000888;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938260; loss - 0.084094;\n",
    "Group g4: f1 - 0.996926; loss - 0.006622;\n",
    "Group g9: f1 - 0.782389; loss - 0.278597;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.080739; Mean training F1 0.938146; Mean validation loss 0.085466; Mean validation F1 0.938034; Learning rate 0.000880;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938034; loss - 0.085466;\n",
    "Group g4: f1 - 0.996936; loss - 0.006535;\n",
    "Group g9: f1 - 0.796699; loss - 0.274237;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.080071; Mean training F1 0.938696; Mean validation loss 0.083020; Mean validation F1 0.938987; Learning rate 0.000872;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938987; loss - 0.083020;\n",
    "Group g4: f1 - 0.996948; loss - 0.006623;\n",
    "Group g9: f1 - 0.790057; loss - 0.273307;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.080046; Mean training F1 0.938679; Mean validation loss 0.083329; Mean validation F1 0.938492; Learning rate 0.000864;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938492; loss - 0.083329;\n",
    "Group g4: f1 - 0.996901; loss - 0.006727;\n",
    "Group g9: f1 - 0.798062; loss - 0.273765;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.079694; Mean training F1 0.939130; Mean validation loss 0.083455; Mean validation F1 0.938796; Learning rate 0.000855;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938796; loss - 0.083455;\n",
    "Group g4: f1 - 0.996888; loss - 0.006619;\n",
    "Group g9: f1 - 0.800613; loss - 0.274145;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.079394; Mean training F1 0.939112; Mean validation loss 0.084430; Mean validation F1 0.937000; Learning rate 0.000847;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937000; loss - 0.084430;\n",
    "Group g4: f1 - 0.996968; loss - 0.006521;\n",
    "Group g9: f1 - 0.793798; loss - 0.280037;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.079160; Mean training F1 0.939366; Mean validation loss 0.083621; Mean validation F1 0.937080; Learning rate 0.000838;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937080; loss - 0.083621;\n",
    "Group g4: f1 - 0.996908; loss - 0.006682;\n",
    "Group g9: f1 - 0.789240; loss - 0.273666;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.078904; Mean training F1 0.939351; Mean validation loss 0.086581; Mean validation F1 0.937854; Learning rate 0.000829;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937854; loss - 0.086581;\n",
    "Group g4: f1 - 0.996761; loss - 0.006959;\n",
    "Group g9: f1 - 0.791815; loss - 0.274556;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.078655; Mean training F1 0.939625; Mean validation loss 0.084738; Mean validation F1 0.935804; Learning rate 0.000819;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935804; loss - 0.084738;\n",
    "Group g4: f1 - 0.996018; loss - 0.008758;\n",
    "Group g9: f1 - 0.791699; loss - 0.275891;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.078955; Mean training F1 0.939031; Mean validation loss 0.083672; Mean validation F1 0.938830; Learning rate 0.000810;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938830; loss - 0.083672;\n",
    "Group g4: f1 - 0.996967; loss - 0.006462;\n",
    "Group g9: f1 - 0.798613; loss - 0.272101;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.078200; Mean training F1 0.939781; Mean validation loss 0.084730; Mean validation F1 0.938433; Learning rate 0.000800;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938433; loss - 0.084730;\n",
    "Group g4: f1 - 0.996993; loss - 0.006367;\n",
    "Group g9: f1 - 0.798651; loss - 0.272901;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.078358; Mean training F1 0.939745; Mean validation loss 0.084193; Mean validation F1 0.938147; Learning rate 0.000790;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938147; loss - 0.084193;\n",
    "Group g4: f1 - 0.996872; loss - 0.006651;\n",
    "Group g9: f1 - 0.791486; loss - 0.269837;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.077729; Mean training F1 0.940204; Mean validation loss 0.084315; Mean validation F1 0.937559; Learning rate 0.000780;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937559; loss - 0.084315;\n",
    "Group g4: f1 - 0.997062; loss - 0.006312;\n",
    "Group g9: f1 - 0.793386; loss - 0.270893;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.077531; Mean training F1 0.940302; Mean validation loss 0.086004; Mean validation F1 0.936704; Learning rate 0.000770;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936704; loss - 0.086004;\n",
    "Group g4: f1 - 0.997016; loss - 0.006409;\n",
    "Group g9: f1 - 0.802762; loss - 0.272606;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.077021; Mean training F1 0.940524; Mean validation loss 0.083975; Mean validation F1 0.938477; Learning rate 0.000760;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938477; loss - 0.083975;\n",
    "Group g4: f1 - 0.997042; loss - 0.006407;\n",
    "Group g9: f1 - 0.802257; loss - 0.268621;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.076972; Mean training F1 0.940588; Mean validation loss 0.083844; Mean validation F1 0.938301; Learning rate 0.000749;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938301; loss - 0.083844;\n",
    "Group g4: f1 - 0.996860; loss - 0.006510;\n",
    "Group g9: f1 - 0.805894; loss - 0.267440;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.084021; Mean training F1 0.936927; Mean validation loss 0.084032; Mean validation F1 0.938611; Learning rate 0.000739;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938611; loss - 0.084032;\n",
    "Group g4: f1 - 0.996860; loss - 0.006715;\n",
    "Group g9: f1 - 0.800621; loss - 0.272311;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.077967; Mean training F1 0.940055; Mean validation loss 0.083563; Mean validation F1 0.938521; Learning rate 0.000728;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938521; loss - 0.083563;\n",
    "Group g4: f1 - 0.996815; loss - 0.006627;\n",
    "Group g9: f1 - 0.801304; loss - 0.268602;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.076758; Mean training F1 0.940746; Mean validation loss 0.083775; Mean validation F1 0.938574; Learning rate 0.000717;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938574; loss - 0.083775;\n",
    "Group g4: f1 - 0.996992; loss - 0.006413;\n",
    "Group g9: f1 - 0.802474; loss - 0.267777;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.076289; Mean training F1 0.940988; Mean validation loss 0.084568; Mean validation F1 0.937975; Learning rate 0.000706;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937975; loss - 0.084568;\n",
    "Group g4: f1 - 0.997035; loss - 0.006270;\n",
    "Group g9: f1 - 0.807525; loss - 0.268030;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.075921; Mean training F1 0.941155; Mean validation loss 0.085032; Mean validation F1 0.937765; Learning rate 0.000695;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937765; loss - 0.085032;\n",
    "Group g4: f1 - 0.996882; loss - 0.006403;\n",
    "Group g9: f1 - 0.796061; loss - 0.269516;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.075926; Mean training F1 0.941249; Mean validation loss 0.084091; Mean validation F1 0.938741; Learning rate 0.000683;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938741; loss - 0.084091;\n",
    "Group g4: f1 - 0.996768; loss - 0.006816;\n",
    "Group g9: f1 - 0.808579; loss - 0.264769;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.075626; Mean training F1 0.941375; Mean validation loss 0.084039; Mean validation F1 0.938569; Learning rate 0.000672;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938569; loss - 0.084039;\n",
    "Group g4: f1 - 0.997047; loss - 0.006263;\n",
    "Group g9: f1 - 0.806779; loss - 0.263114;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.075313; Mean training F1 0.941600; Mean validation loss 0.084341; Mean validation F1 0.938630; Learning rate 0.000661;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938630; loss - 0.084341;\n",
    "Group g4: f1 - 0.997034; loss - 0.006333;\n",
    "Group g9: f1 - 0.804684; loss - 0.263620;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.075093; Mean training F1 0.941728; Mean validation loss 0.084464; Mean validation F1 0.937798; Learning rate 0.000649;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937798; loss - 0.084464;\n",
    "Group g4: f1 - 0.997140; loss - 0.006186;\n",
    "Group g9: f1 - 0.811224; loss - 0.263284;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.074714; Mean training F1 0.941932; Mean validation loss 0.084522; Mean validation F1 0.938093; Learning rate 0.000637;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938093; loss - 0.084522;\n",
    "Group g4: f1 - 0.997166; loss - 0.006154;\n",
    "Group g9: f1 - 0.809491; loss - 0.261994;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.074562; Mean training F1 0.942129; Mean validation loss 0.086020; Mean validation F1 0.937382; Learning rate 0.000626;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937382; loss - 0.086020;\n",
    "Group g4: f1 - 0.997096; loss - 0.006366;\n",
    "Group g9: f1 - 0.810065; loss - 0.262611;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.074294; Mean training F1 0.942311; Mean validation loss 0.085221; Mean validation F1 0.937866; Learning rate 0.000614;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937866; loss - 0.085221;\n",
    "Group g4: f1 - 0.997087; loss - 0.006203;\n",
    "Group g9: f1 - 0.812918; loss - 0.263023;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.074050; Mean training F1 0.942434; Mean validation loss 0.085066; Mean validation F1 0.938286; Learning rate 0.000602;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938286; loss - 0.085066;\n",
    "Group g4: f1 - 0.996820; loss - 0.006940;\n",
    "Group g9: f1 - 0.815699; loss - 0.258747;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.073943; Mean training F1 0.942499; Mean validation loss 0.086629; Mean validation F1 0.936304; Learning rate 0.000590;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936304; loss - 0.086629;\n",
    "Group g4: f1 - 0.997110; loss - 0.006283;\n",
    "Group g9: f1 - 0.810687; loss - 0.264009;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.073462; Mean training F1 0.942938; Mean validation loss 0.085805; Mean validation F1 0.937591; Learning rate 0.000578;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937591; loss - 0.085805;\n",
    "Group g4: f1 - 0.997188; loss - 0.006093;\n",
    "Group g9: f1 - 0.813369; loss - 0.259627;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.073207; Mean training F1 0.943001; Mean validation loss 0.085575; Mean validation F1 0.938094; Learning rate 0.000566;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938094; loss - 0.085575;\n",
    "Group g4: f1 - 0.996996; loss - 0.006475;\n",
    "Group g9: f1 - 0.817233; loss - 0.257920;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.072979; Mean training F1 0.942982; Mean validation loss 0.086379; Mean validation F1 0.936621; Learning rate 0.000554;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936621; loss - 0.086379;\n",
    "Group g4: f1 - 0.997219; loss - 0.006104;\n",
    "Group g9: f1 - 0.814231; loss - 0.258898;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.072786; Mean training F1 0.943371; Mean validation loss 0.086890; Mean validation F1 0.935808; Learning rate 0.000542;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935808; loss - 0.086890;\n",
    "Group g4: f1 - 0.997213; loss - 0.006111;\n",
    "Group g9: f1 - 0.812931; loss - 0.260749;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.072503; Mean training F1 0.943525; Mean validation loss 0.086660; Mean validation F1 0.937672; Learning rate 0.000530;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937672; loss - 0.086660;\n",
    "Group g4: f1 - 0.996955; loss - 0.006526;\n",
    "Group g9: f1 - 0.817170; loss - 0.255878;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.072099; Mean training F1 0.943937; Mean validation loss 0.086702; Mean validation F1 0.937440; Learning rate 0.000517;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937440; loss - 0.086702;\n",
    "Group g4: f1 - 0.997155; loss - 0.006142;\n",
    "Group g9: f1 - 0.817408; loss - 0.254582;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.071818; Mean training F1 0.943992; Mean validation loss 0.086732; Mean validation F1 0.937252; Learning rate 0.000505;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937252; loss - 0.086732;\n",
    "Group g4: f1 - 0.997153; loss - 0.006232;\n",
    "Group g9: f1 - 0.819514; loss - 0.254341;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.071492; Mean training F1 0.944240; Mean validation loss 0.086999; Mean validation F1 0.937168; Learning rate 0.000493;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937168; loss - 0.086999;\n",
    "Group g4: f1 - 0.997266; loss - 0.006007;\n",
    "Group g9: f1 - 0.816735; loss - 0.253800;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.071238; Mean training F1 0.944375; Mean validation loss 0.087260; Mean validation F1 0.936570; Learning rate 0.000481;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936570; loss - 0.087260;\n",
    "Group g4: f1 - 0.997230; loss - 0.006039;\n",
    "Group g9: f1 - 0.820362; loss - 0.254383;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.070837; Mean training F1 0.944641; Mean validation loss 0.087505; Mean validation F1 0.937140; Learning rate 0.000469;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937140; loss - 0.087505;\n",
    "Group g4: f1 - 0.997186; loss - 0.006229;\n",
    "Group g9: f1 - 0.822891; loss - 0.251026;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.070548; Mean training F1 0.944993; Mean validation loss 0.087820; Mean validation F1 0.936877; Learning rate 0.000457;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936877; loss - 0.087820;\n",
    "Group g4: f1 - 0.997165; loss - 0.006159;\n",
    "Group g9: f1 - 0.823527; loss - 0.250573;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.070211; Mean training F1 0.945135; Mean validation loss 0.088060; Mean validation F1 0.936745; Learning rate 0.000445;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936745; loss - 0.088060;\n",
    "Group g4: f1 - 0.997213; loss - 0.006047;\n",
    "Group g9: f1 - 0.825054; loss - 0.250387;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.069914; Mean training F1 0.945259; Mean validation loss 0.088782; Mean validation F1 0.935346; Learning rate 0.000433;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935346; loss - 0.088782;\n",
    "Group g4: f1 - 0.997293; loss - 0.006021;\n",
    "Group g9: f1 - 0.819961; loss - 0.251604;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.069575; Mean training F1 0.945479; Mean validation loss 0.088270; Mean validation F1 0.936635; Learning rate 0.000421;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936635; loss - 0.088270;\n",
    "Group g4: f1 - 0.997308; loss - 0.005890;\n",
    "Group g9: f1 - 0.828042; loss - 0.249120;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.069293; Mean training F1 0.945851; Mean validation loss 0.088834; Mean validation F1 0.936550; Learning rate 0.000409;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936550; loss - 0.088834;\n",
    "Group g4: f1 - 0.997257; loss - 0.005996;\n",
    "Group g9: f1 - 0.825217; loss - 0.247091;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.068872; Mean training F1 0.946042; Mean validation loss 0.088930; Mean validation F1 0.936723; Learning rate 0.000397;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936723; loss - 0.088930;\n",
    "Group g4: f1 - 0.997222; loss - 0.006151;\n",
    "Group g9: f1 - 0.825774; loss - 0.246337;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.068604; Mean training F1 0.946503; Mean validation loss 0.089093; Mean validation F1 0.936498; Learning rate 0.000385;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936498; loss - 0.089093;\n",
    "Group g4: f1 - 0.997255; loss - 0.005951;\n",
    "Group g9: f1 - 0.828200; loss - 0.244848;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.068386; Mean training F1 0.946481; Mean validation loss 0.089360; Mean validation F1 0.936379; Learning rate 0.000373;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936379; loss - 0.089360;\n",
    "Group g4: f1 - 0.997258; loss - 0.006071;\n",
    "Group g9: f1 - 0.827014; loss - 0.244989;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.068209; Mean training F1 0.946502; Mean validation loss 0.089275; Mean validation F1 0.936283; Learning rate 0.000362;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936283; loss - 0.089275;\n",
    "Group g4: f1 - 0.997304; loss - 0.005998;\n",
    "Group g9: f1 - 0.823418; loss - 0.243474;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.067756; Mean training F1 0.947020; Mean validation loss 0.089863; Mean validation F1 0.936033; Learning rate 0.000350;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936033; loss - 0.089863;\n",
    "Group g4: f1 - 0.997350; loss - 0.005957;\n",
    "Group g9: f1 - 0.827509; loss - 0.242744;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.067444; Mean training F1 0.947379; Mean validation loss 0.089976; Mean validation F1 0.935985; Learning rate 0.000339;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935985; loss - 0.089976;\n",
    "Group g4: f1 - 0.997329; loss - 0.005945;\n",
    "Group g9: f1 - 0.825587; loss - 0.242030;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.067111; Mean training F1 0.947374; Mean validation loss 0.090312; Mean validation F1 0.935606; Learning rate 0.000327;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935606; loss - 0.090312;\n",
    "Group g4: f1 - 0.997356; loss - 0.005858;\n",
    "Group g9: f1 - 0.827763; loss - 0.241489;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.066896; Mean training F1 0.947555; Mean validation loss 0.090636; Mean validation F1 0.935679; Learning rate 0.000316;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935679; loss - 0.090636;\n",
    "Group g4: f1 - 0.997391; loss - 0.005902;\n",
    "Group g9: f1 - 0.827901; loss - 0.240446;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.066634; Mean training F1 0.947811; Mean validation loss 0.091141; Mean validation F1 0.935411; Learning rate 0.000305;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935411; loss - 0.091141;\n",
    "Group g4: f1 - 0.997386; loss - 0.005927;\n",
    "Group g9: f1 - 0.827509; loss - 0.240071;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "wavenet"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "################################################################\n",
    "Training/validation for fold 1/5;\n",
    "===========================================================\n",
    "Epoch 001/128 - Mean training loss 0.492604; Mean training F1 0.749163; Mean validation loss 0.194567; Mean validation F1 0.892978; Learning rate 0.001000;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.892978; loss - 0.194567;\n",
    "Group g4: f1 - 0.662407; loss - 0.029555;\n",
    "Group g9: f1 - 0.453813; loss - 0.651341;\n",
    "===========================================================\n",
    "Epoch 002/128 - Mean training loss 0.193040; Mean training F1 0.888699; Mean validation loss 0.126198; Mean validation F1 0.919435; Learning rate 0.001000;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.919435; loss - 0.126198;\n",
    "Group g4: f1 - 0.663826; loss - 0.013426;\n",
    "Group g9: f1 - 0.570537; loss - 0.403935;\n",
    "===========================================================\n",
    "Epoch 003/128 - Mean training loss 0.162064; Mean training F1 0.901505; Mean validation loss 0.129793; Mean validation F1 0.923296; Learning rate 0.000999;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.923296; loss - 0.129793;\n",
    "Group g4: f1 - 0.664002; loss - 0.013898;\n",
    "Group g9: f1 - 0.600791; loss - 0.359086;\n",
    "===========================================================\n",
    "Epoch 004/128 - Mean training loss 0.134553; Mean training F1 0.914121; Mean validation loss 0.117813; Mean validation F1 0.928152; Learning rate 0.000998;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.928152; loss - 0.117813;\n",
    "Group g4: f1 - 0.664078; loss - 0.010840;\n",
    "Group g9: f1 - 0.638440; loss - 0.313264;\n",
    "===========================================================\n",
    "Epoch 005/128 - Mean training loss 0.121607; Mean training F1 0.920090; Mean validation loss 0.103768; Mean validation F1 0.930082; Learning rate 0.000997;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.930082; loss - 0.103768;\n",
    "Group g4: f1 - 0.663864; loss - 0.010482;\n",
    "Group g9: f1 - 0.626848; loss - 0.330721;\n",
    "===========================================================\n",
    "Epoch 006/128 - Mean training loss 0.113810; Mean training F1 0.924232; Mean validation loss 0.105532; Mean validation F1 0.932015; Learning rate 0.000995;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.932015; loss - 0.105532;\n",
    "Group g4: f1 - 0.498128; loss - 0.009882;\n",
    "Group g9: f1 - 0.630475; loss - 0.309220;\n",
    "===========================================================\n",
    "Epoch 007/128 - Mean training loss 0.111103; Mean training F1 0.924856; Mean validation loss 0.103761; Mean validation F1 0.932705; Learning rate 0.000993;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.932705; loss - 0.103761;\n",
    "Group g4: f1 - 0.663874; loss - 0.015797;\n",
    "Group g9: f1 - 0.645183; loss - 0.314123;\n",
    "===========================================================\n",
    "Epoch 008/128 - Mean training loss 0.117301; Mean training F1 0.921964; Mean validation loss 0.097106; Mean validation F1 0.932434; Learning rate 0.000991;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.932434; loss - 0.097106;\n",
    "Group g4: f1 - 0.664152; loss - 0.008836;\n",
    "Group g9: f1 - 0.633282; loss - 0.316701;\n",
    "===========================================================\n",
    "Epoch 009/128 - Mean training loss 0.104740; Mean training F1 0.928069; Mean validation loss 0.097540; Mean validation F1 0.930908; Learning rate 0.000988;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.930908; loss - 0.097540;\n",
    "Group g4: f1 - 0.664021; loss - 0.009116;\n",
    "Group g9: f1 - 0.646714; loss - 0.317190;\n",
    "===========================================================\n",
    "Epoch 010/128 - Mean training loss 0.103684; Mean training F1 0.928551; Mean validation loss 0.096664; Mean validation F1 0.934799; Learning rate 0.000985;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934799; loss - 0.096664;\n",
    "Group g4: f1 - 0.664288; loss - 0.008521;\n",
    "Group g9: f1 - 0.645511; loss - 0.307522;\n",
    "===========================================================\n",
    "Epoch 011/128 - Mean training loss 0.102799; Mean training F1 0.929028; Mean validation loss 0.099096; Mean validation F1 0.932302; Learning rate 0.000982;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.932302; loss - 0.099096;\n",
    "Group g4: f1 - 0.664286; loss - 0.008304;\n",
    "Group g9: f1 - 0.674376; loss - 0.316139;\n",
    "===========================================================\n",
    "Epoch 012/128 - Mean training loss 0.100748; Mean training F1 0.929697; Mean validation loss 1.116199; Mean validation F1 0.629411; Learning rate 0.000979;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.629411; loss - 1.116199;\n",
    "Group g4: f1 - 0.393869; loss - 0.098319;\n",
    "Group g9: f1 - 0.681910; loss - 0.329274;\n",
    "===========================================================\n",
    "Epoch 013/128 - Mean training loss 0.096804; Mean training F1 0.931233; Mean validation loss 0.093902; Mean validation F1 0.933230; Learning rate 0.000975;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933230; loss - 0.093902;\n",
    "Group g4: f1 - 0.664057; loss - 0.009005;\n",
    "Group g9: f1 - 0.687928; loss - 0.293813;\n",
    "===========================================================\n",
    "Epoch 014/128 - Mean training loss 0.094396; Mean training F1 0.932496; Mean validation loss 0.090922; Mean validation F1 0.931332; Learning rate 0.000971;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931332; loss - 0.090922;\n",
    "Group g4: f1 - 0.996538; loss - 0.007516;\n",
    "Group g9: f1 - 0.695773; loss - 0.295489;\n",
    "===========================================================\n",
    "Epoch 015/128 - Mean training loss 0.092820; Mean training F1 0.932814; Mean validation loss 0.089813; Mean validation F1 0.936583; Learning rate 0.000967;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936583; loss - 0.089813;\n",
    "Group g4: f1 - 0.664114; loss - 0.009020;\n",
    "Group g9: f1 - 0.699689; loss - 0.287308;\n",
    "===========================================================\n",
    "Epoch 016/128 - Mean training loss 0.093443; Mean training F1 0.931594; Mean validation loss 0.087714; Mean validation F1 0.937591; Learning rate 0.000963;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937591; loss - 0.087714;\n",
    "Group g4: f1 - 0.664414; loss - 0.007585;\n",
    "Group g9: f1 - 0.710690; loss - 0.283028;\n",
    "===========================================================\n",
    "Epoch 017/128 - Mean training loss 0.091656; Mean training F1 0.932763; Mean validation loss 0.089667; Mean validation F1 0.936062; Learning rate 0.000958;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936062; loss - 0.089667;\n",
    "Group g4: f1 - 0.664218; loss - 0.008318;\n",
    "Group g9: f1 - 0.712277; loss - 0.285708;\n",
    "===========================================================\n",
    "Epoch 018/128 - Mean training loss 0.094704; Mean training F1 0.930776; Mean validation loss 0.090687; Mean validation F1 0.934934; Learning rate 0.000953;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934934; loss - 0.090687;\n",
    "Group g4: f1 - 0.664340; loss - 0.008081;\n",
    "Group g9: f1 - 0.757574; loss - 0.283043;\n",
    "===========================================================\n",
    "Epoch 019/128 - Mean training loss 0.095100; Mean training F1 0.930618; Mean validation loss 0.087590; Mean validation F1 0.937172; Learning rate 0.000947;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937172; loss - 0.087590;\n",
    "Group g4: f1 - 0.664416; loss - 0.007462;\n",
    "Group g9: f1 - 0.731577; loss - 0.284151;\n",
    "===========================================================\n",
    "Epoch 020/128 - Mean training loss 0.089004; Mean training F1 0.934440; Mean validation loss 0.088971; Mean validation F1 0.935474; Learning rate 0.000942;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935474; loss - 0.088971;\n",
    "Group g4: f1 - 0.996285; loss - 0.008350;\n",
    "Group g9: f1 - 0.709957; loss - 0.283849;\n",
    "===========================================================\n",
    "Epoch 021/128 - Mean training loss 0.087691; Mean training F1 0.935200; Mean validation loss 0.087762; Mean validation F1 0.936661; Learning rate 0.000936;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936661; loss - 0.087762;\n",
    "Group g4: f1 - 0.664483; loss - 0.007416;\n",
    "Group g9: f1 - 0.754239; loss - 0.282251;\n",
    "===========================================================\n",
    "Epoch 022/128 - Mean training loss 0.089759; Mean training F1 0.934026; Mean validation loss 0.089146; Mean validation F1 0.935212; Learning rate 0.000930;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935212; loss - 0.089146;\n",
    "Group g4: f1 - 0.664418; loss - 0.007516;\n",
    "Group g9: f1 - 0.723362; loss - 0.291217;\n",
    "===========================================================\n",
    "Epoch 023/128 - Mean training loss 0.087967; Mean training F1 0.934945; Mean validation loss 0.087715; Mean validation F1 0.936415; Learning rate 0.000923;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936415; loss - 0.087715;\n",
    "Group g4: f1 - 0.664211; loss - 0.008264;\n",
    "Group g9: f1 - 0.713583; loss - 0.285907;\n",
    "===========================================================\n",
    "Epoch 024/128 - Mean training loss 0.088100; Mean training F1 0.934121; Mean validation loss 0.088301; Mean validation F1 0.937516; Learning rate 0.000917;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937516; loss - 0.088301;\n",
    "Group g4: f1 - 0.664374; loss - 0.007794;\n",
    "Group g9: f1 - 0.718880; loss - 0.288870;\n",
    "===========================================================\n",
    "Epoch 025/128 - Mean training loss 0.088207; Mean training F1 0.934740; Mean validation loss 0.085785; Mean validation F1 0.937810; Learning rate 0.000910;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937810; loss - 0.085785;\n",
    "Group g4: f1 - 0.664491; loss - 0.007362;\n",
    "Group g9: f1 - 0.748266; loss - 0.279227;\n",
    "===========================================================\n",
    "Epoch 026/128 - Mean training loss 0.086774; Mean training F1 0.935555; Mean validation loss 0.086051; Mean validation F1 0.937691; Learning rate 0.000903;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937691; loss - 0.086051;\n",
    "Group g4: f1 - 0.664065; loss - 0.008455;\n",
    "Group g9: f1 - 0.754009; loss - 0.281815;\n",
    "===========================================================\n",
    "Epoch 027/128 - Mean training loss 0.086500; Mean training F1 0.935505; Mean validation loss 0.086241; Mean validation F1 0.937806; Learning rate 0.000896;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937806; loss - 0.086241;\n",
    "Group g4: f1 - 0.664428; loss - 0.007388;\n",
    "Group g9: f1 - 0.791382; loss - 0.280170;\n",
    "===========================================================\n",
    "Epoch 028/128 - Mean training loss 0.086900; Mean training F1 0.935351; Mean validation loss 0.088881; Mean validation F1 0.935574; Learning rate 0.000888;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935574; loss - 0.088881;\n",
    "Group g4: f1 - 0.664471; loss - 0.007413;\n",
    "Group g9: f1 - 0.747156; loss - 0.285000;\n",
    "===========================================================\n",
    "Epoch 029/128 - Mean training loss 0.092634; Mean training F1 0.932506; Mean validation loss 0.086354; Mean validation F1 0.938099; Learning rate 0.000880;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938099; loss - 0.086354;\n",
    "Group g4: f1 - 0.664443; loss - 0.007715;\n",
    "Group g9: f1 - 0.757942; loss - 0.282112;\n",
    "===========================================================\n",
    "Epoch 030/128 - Mean training loss 0.087045; Mean training F1 0.935349; Mean validation loss 0.085960; Mean validation F1 0.938127; Learning rate 0.000872;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938127; loss - 0.085960;\n",
    "Group g4: f1 - 0.664456; loss - 0.007234;\n",
    "Group g9: f1 - 0.790929; loss - 0.282125;\n",
    "===========================================================\n",
    "Epoch 031/128 - Mean training loss 0.085935; Mean training F1 0.935809; Mean validation loss 0.089179; Mean validation F1 0.936297; Learning rate 0.000864;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936297; loss - 0.089179;\n",
    "Group g4: f1 - 0.664216; loss - 0.008504;\n",
    "Group g9: f1 - 0.750274; loss - 0.286263;\n",
    "===========================================================\n",
    "Epoch 032/128 - Mean training loss 0.085616; Mean training F1 0.935973; Mean validation loss 0.085333; Mean validation F1 0.937930; Learning rate 0.000855;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937930; loss - 0.085333;\n",
    "Group g4: f1 - 0.664479; loss - 0.007117;\n",
    "Group g9: f1 - 0.784305; loss - 0.281449;\n",
    "===========================================================\n",
    "Epoch 033/128 - Mean training loss 0.085303; Mean training F1 0.936321; Mean validation loss 0.086644; Mean validation F1 0.936003; Learning rate 0.000847;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936003; loss - 0.086644;\n",
    "Group g4: f1 - 0.664422; loss - 0.007342;\n",
    "Group g9: f1 - 0.756050; loss - 0.280311;\n",
    "===========================================================\n",
    "Epoch 034/128 - Mean training loss 0.084827; Mean training F1 0.936468; Mean validation loss 0.085349; Mean validation F1 0.938106; Learning rate 0.000838;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938106; loss - 0.085349;\n",
    "Group g4: f1 - 0.664398; loss - 0.007271;\n",
    "Group g9: f1 - 0.796427; loss - 0.279404;\n",
    "===========================================================\n",
    "Epoch 035/128 - Mean training loss 0.084981; Mean training F1 0.936041; Mean validation loss 0.084862; Mean validation F1 0.938482; Learning rate 0.000829;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938482; loss - 0.084862;\n",
    "Group g4: f1 - 0.664484; loss - 0.007045;\n",
    "Group g9: f1 - 0.787093; loss - 0.279010;\n",
    "===========================================================\n",
    "Epoch 036/128 - Mean training loss 0.084668; Mean training F1 0.936733; Mean validation loss 0.085102; Mean validation F1 0.938194; Learning rate 0.000819;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938194; loss - 0.085102;\n",
    "Group g4: f1 - 0.664509; loss - 0.007011;\n",
    "Group g9: f1 - 0.786894; loss - 0.279442;\n",
    "===========================================================\n",
    "Epoch 037/128 - Mean training loss 0.084972; Mean training F1 0.936078; Mean validation loss 0.084578; Mean validation F1 0.938580; Learning rate 0.000810;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938580; loss - 0.084578;\n",
    "Group g4: f1 - 0.664435; loss - 0.007243;\n",
    "Group g9: f1 - 0.801033; loss - 0.278665;\n",
    "===========================================================\n",
    "Epoch 038/128 - Mean training loss 0.099261; Mean training F1 0.928870; Mean validation loss 0.094419; Mean validation F1 0.934616; Learning rate 0.000800;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934616; loss - 0.094419;\n",
    "Group g4: f1 - 0.663659; loss - 0.010192;\n",
    "Group g9: f1 - 0.726964; loss - 0.299263;\n",
    "===========================================================\n",
    "Epoch 039/128 - Mean training loss 0.090087; Mean training F1 0.933877; Mean validation loss 0.087228; Mean validation F1 0.937616; Learning rate 0.000790;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937616; loss - 0.087228;\n",
    "Group g4: f1 - 0.664172; loss - 0.008180;\n",
    "Group g9: f1 - 0.752303; loss - 0.281150;\n",
    "===========================================================\n",
    "Epoch 040/128 - Mean training loss 0.085403; Mean training F1 0.935989; Mean validation loss 0.085818; Mean validation F1 0.936522; Learning rate 0.000780;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936522; loss - 0.085818;\n",
    "Group g4: f1 - 0.664484; loss - 0.007221;\n",
    "Group g9: f1 - 0.792474; loss - 0.284379;\n",
    "===========================================================\n",
    "Epoch 041/128 - Mean training loss 0.084946; Mean training F1 0.936439; Mean validation loss 0.086262; Mean validation F1 0.936306; Learning rate 0.000770;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936306; loss - 0.086262;\n",
    "Group g4: f1 - 0.664490; loss - 0.007238;\n",
    "Group g9: f1 - 0.789204; loss - 0.283531;\n",
    "===========================================================\n",
    "Epoch 042/128 - Mean training loss 0.084112; Mean training F1 0.936878; Mean validation loss 0.084136; Mean validation F1 0.939201; Learning rate 0.000760;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939201; loss - 0.084136;\n",
    "Group g4: f1 - 0.664490; loss - 0.007190;\n",
    "Group g9: f1 - 0.781617; loss - 0.277164;\n",
    "===========================================================\n",
    "Epoch 043/128 - Mean training loss 0.084481; Mean training F1 0.936411; Mean validation loss 0.085097; Mean validation F1 0.936498; Learning rate 0.000749;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936498; loss - 0.085097;\n",
    "Group g4: f1 - 0.664475; loss - 0.007150;\n",
    "Group g9: f1 - 0.742067; loss - 0.280956;\n",
    "===========================================================\n",
    "Epoch 044/128 - Mean training loss 0.086794; Mean training F1 0.935207; Mean validation loss 0.090833; Mean validation F1 0.936431; Learning rate 0.000739;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936431; loss - 0.090833;\n",
    "Group g4: f1 - 0.664345; loss - 0.007495;\n",
    "Group g9: f1 - 0.776377; loss - 0.282522;\n",
    "===========================================================\n",
    "Epoch 045/128 - Mean training loss 0.084658; Mean training F1 0.936502; Mean validation loss 0.086415; Mean validation F1 0.937761; Learning rate 0.000728;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937761; loss - 0.086415;\n",
    "Group g4: f1 - 0.664457; loss - 0.007008;\n",
    "Group g9: f1 - 0.804424; loss - 0.278934;\n",
    "===========================================================\n",
    "Epoch 046/128 - Mean training loss 0.083593; Mean training F1 0.936842; Mean validation loss 0.084662; Mean validation F1 0.936809; Learning rate 0.000717;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936809; loss - 0.084662;\n",
    "Group g4: f1 - 0.664477; loss - 0.007136;\n",
    "Group g9: f1 - 0.794755; loss - 0.278490;\n",
    "===========================================================\n",
    "Epoch 047/128 - Mean training loss 0.083495; Mean training F1 0.936979; Mean validation loss 0.084388; Mean validation F1 0.938420; Learning rate 0.000706;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938420; loss - 0.084388;\n",
    "Group g4: f1 - 0.664557; loss - 0.006920;\n",
    "Group g9: f1 - 0.780848; loss - 0.278383;\n",
    "===========================================================\n",
    "Epoch 048/128 - Mean training loss 0.083624; Mean training F1 0.936957; Mean validation loss 0.084538; Mean validation F1 0.937756; Learning rate 0.000695;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937756; loss - 0.084538;\n",
    "Group g4: f1 - 0.664447; loss - 0.007114;\n",
    "Group g9: f1 - 0.798341; loss - 0.277288;\n",
    "===========================================================\n",
    "Epoch 049/128 - Mean training loss 0.083861; Mean training F1 0.936652; Mean validation loss 0.085218; Mean validation F1 0.938232; Learning rate 0.000683;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938232; loss - 0.085218;\n",
    "Group g4: f1 - 0.664536; loss - 0.006935;\n",
    "Group g9: f1 - 0.800223; loss - 0.280277;\n",
    "===========================================================\n",
    "Epoch 050/128 - Mean training loss 0.083309; Mean training F1 0.937167; Mean validation loss 0.083936; Mean validation F1 0.938830; Learning rate 0.000672;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938830; loss - 0.083936;\n",
    "Group g4: f1 - 0.664443; loss - 0.007113;\n",
    "Group g9: f1 - 0.763350; loss - 0.278151;\n",
    "===========================================================\n",
    "Epoch 051/128 - Mean training loss 0.083525; Mean training F1 0.937034; Mean validation loss 0.084525; Mean validation F1 0.938529; Learning rate 0.000661;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938529; loss - 0.084525;\n",
    "Group g4: f1 - 0.664525; loss - 0.007138;\n",
    "Group g9: f1 - 0.787839; loss - 0.277422;\n",
    "===========================================================\n",
    "Epoch 052/128 - Mean training loss 0.083198; Mean training F1 0.937210; Mean validation loss 0.084439; Mean validation F1 0.938255; Learning rate 0.000649;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938255; loss - 0.084439;\n",
    "Group g4: f1 - 0.664560; loss - 0.006858;\n",
    "Group g9: f1 - 0.803048; loss - 0.279925;\n",
    "===========================================================\n",
    "Epoch 053/128 - Mean training loss 0.083423; Mean training F1 0.936644; Mean validation loss 0.083720; Mean validation F1 0.938733; Learning rate 0.000637;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938733; loss - 0.083720;\n",
    "Group g4: f1 - 0.664546; loss - 0.006823;\n",
    "Group g9: f1 - 0.799051; loss - 0.278325;\n",
    "===========================================================\n",
    "Epoch 054/128 - Mean training loss 0.082713; Mean training F1 0.937278; Mean validation loss 0.083526; Mean validation F1 0.938425; Learning rate 0.000626;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938425; loss - 0.083526;\n",
    "Group g4: f1 - 0.664528; loss - 0.007022;\n",
    "Group g9: f1 - 0.802441; loss - 0.276335;\n",
    "===========================================================\n",
    "Epoch 055/128 - Mean training loss 0.082755; Mean training F1 0.937280; Mean validation loss 0.083648; Mean validation F1 0.938472; Learning rate 0.000614;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938472; loss - 0.083648;\n",
    "Group g4: f1 - 0.664432; loss - 0.007123;\n",
    "Group g9: f1 - 0.804949; loss - 0.277418;\n",
    "===========================================================\n",
    "Epoch 056/128 - Mean training loss 0.082588; Mean training F1 0.937379; Mean validation loss 0.083986; Mean validation F1 0.938945; Learning rate 0.000602;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938945; loss - 0.083986;\n",
    "Group g4: f1 - 0.664489; loss - 0.007007;\n",
    "Group g9: f1 - 0.798892; loss - 0.275997;\n",
    "===========================================================\n",
    "Epoch 057/128 - Mean training loss 0.082569; Mean training F1 0.937299; Mean validation loss 0.083693; Mean validation F1 0.938679; Learning rate 0.000590;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938679; loss - 0.083693;\n",
    "Group g4: f1 - 0.664561; loss - 0.006920;\n",
    "Group g9: f1 - 0.793362; loss - 0.276320;\n",
    "===========================================================\n",
    "Epoch 058/128 - Mean training loss 0.082469; Mean training F1 0.937544; Mean validation loss 0.083283; Mean validation F1 0.938960; Learning rate 0.000578;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938960; loss - 0.083283;\n",
    "Group g4: f1 - 0.996745; loss - 0.006918;\n",
    "Group g9: f1 - 0.804160; loss - 0.276061;\n",
    "===========================================================\n",
    "Epoch 059/128 - Mean training loss 0.082331; Mean training F1 0.937667; Mean validation loss 0.083530; Mean validation F1 0.939207; Learning rate 0.000566;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939207; loss - 0.083530;\n",
    "Group g4: f1 - 0.664496; loss - 0.007041;\n",
    "Group g9: f1 - 0.794691; loss - 0.275849;\n",
    "===========================================================\n",
    "Epoch 060/128 - Mean training loss 0.082207; Mean training F1 0.937661; Mean validation loss 0.083339; Mean validation F1 0.938123; Learning rate 0.000554;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938123; loss - 0.083339;\n",
    "Group g4: f1 - 0.664540; loss - 0.006831;\n",
    "Group g9: f1 - 0.800941; loss - 0.276826;\n",
    "===========================================================\n",
    "Epoch 061/128 - Mean training loss 0.081967; Mean training F1 0.937719; Mean validation loss 0.083310; Mean validation F1 0.938226; Learning rate 0.000542;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938226; loss - 0.083310;\n",
    "Group g4: f1 - 0.664560; loss - 0.006798;\n",
    "Group g9: f1 - 0.803255; loss - 0.276201;\n",
    "===========================================================\n",
    "Epoch 062/128 - Mean training loss 0.082050; Mean training F1 0.937708; Mean validation loss 0.083404; Mean validation F1 0.938708; Learning rate 0.000530;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938708; loss - 0.083404;\n",
    "Group g4: f1 - 0.664578; loss - 0.006706;\n",
    "Group g9: f1 - 0.798248; loss - 0.275733;\n",
    "===========================================================\n",
    "Epoch 063/128 - Mean training loss 0.081893; Mean training F1 0.937710; Mean validation loss 0.083151; Mean validation F1 0.938751; Learning rate 0.000517;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938751; loss - 0.083151;\n",
    "Group g4: f1 - 0.664522; loss - 0.006905;\n",
    "Group g9: f1 - 0.803543; loss - 0.276697;\n",
    "===========================================================\n",
    "Epoch 064/128 - Mean training loss 0.082064; Mean training F1 0.937574; Mean validation loss 0.084381; Mean validation F1 0.936937; Learning rate 0.000505;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936937; loss - 0.084381;\n",
    "Group g4: f1 - 0.664462; loss - 0.007049;\n",
    "Group g9: f1 - 0.799204; loss - 0.279292;\n",
    "===========================================================\n",
    "Epoch 065/128 - Mean training loss 0.081978; Mean training F1 0.937874; Mean validation loss 0.083074; Mean validation F1 0.939034; Learning rate 0.000493;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939034; loss - 0.083074;\n",
    "Group g4: f1 - 0.664532; loss - 0.006905;\n",
    "Group g9: f1 - 0.803885; loss - 0.275606;\n",
    "===========================================================\n",
    "Epoch 066/128 - Mean training loss 0.081729; Mean training F1 0.937946; Mean validation loss 0.083597; Mean validation F1 0.938959; Learning rate 0.000481;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938959; loss - 0.083597;\n",
    "Group g4: f1 - 0.664558; loss - 0.006916;\n",
    "Group g9: f1 - 0.797158; loss - 0.275513;\n",
    "===========================================================\n",
    "Epoch 067/128 - Mean training loss 0.081683; Mean training F1 0.937908; Mean validation loss 0.083203; Mean validation F1 0.939166; Learning rate 0.000469;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939166; loss - 0.083203;\n",
    "Group g4: f1 - 0.664560; loss - 0.006723;\n",
    "Group g9: f1 - 0.803304; loss - 0.274514;\n",
    "===========================================================\n",
    "Epoch 068/128 - Mean training loss 0.081543; Mean training F1 0.938049; Mean validation loss 0.083333; Mean validation F1 0.937818; Learning rate 0.000457;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937818; loss - 0.083333;\n",
    "Group g4: f1 - 0.664485; loss - 0.006984;\n",
    "Group g9: f1 - 0.800251; loss - 0.277192;\n",
    "===========================================================\n",
    "Epoch 069/128 - Mean training loss 0.081264; Mean training F1 0.938144; Mean validation loss 0.083497; Mean validation F1 0.938915; Learning rate 0.000445;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938915; loss - 0.083497;\n",
    "Group g4: f1 - 0.664478; loss - 0.006977;\n",
    "Group g9: f1 - 0.864974; loss - 0.276553;\n",
    "===========================================================\n",
    "Epoch 070/128 - Mean training loss 0.081711; Mean training F1 0.937946; Mean validation loss 0.082807; Mean validation F1 0.938574; Learning rate 0.000433;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938574; loss - 0.082807;\n",
    "Group g4: f1 - 0.996791; loss - 0.006886;\n",
    "Group g9: f1 - 0.804262; loss - 0.274929;\n",
    "===========================================================\n",
    "Epoch 071/128 - Mean training loss 0.081085; Mean training F1 0.938233; Mean validation loss 0.082633; Mean validation F1 0.939503; Learning rate 0.000421;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939503; loss - 0.082633;\n",
    "Group g4: f1 - 0.664568; loss - 0.006702;\n",
    "Group g9: f1 - 0.804720; loss - 0.274761;\n",
    "===========================================================\n",
    "Epoch 072/128 - Mean training loss 0.081231; Mean training F1 0.938075; Mean validation loss 0.082733; Mean validation F1 0.939102; Learning rate 0.000409;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939102; loss - 0.082733;\n",
    "Group g4: f1 - 0.664581; loss - 0.006690;\n",
    "Group g9: f1 - 0.805321; loss - 0.275139;\n",
    "===========================================================\n",
    "Epoch 073/128 - Mean training loss 0.081137; Mean training F1 0.938106; Mean validation loss 0.083174; Mean validation F1 0.938577; Learning rate 0.000397;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938577; loss - 0.083174;\n",
    "Group g4: f1 - 0.664559; loss - 0.006819;\n",
    "Group g9: f1 - 0.801690; loss - 0.275463;\n",
    "===========================================================\n",
    "Epoch 074/128 - Mean training loss 0.080896; Mean training F1 0.938319; Mean validation loss 0.082521; Mean validation F1 0.939334; Learning rate 0.000385;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939334; loss - 0.082521;\n",
    "Group g4: f1 - 0.664595; loss - 0.006646;\n",
    "Group g9: f1 - 0.803391; loss - 0.274185;\n",
    "===========================================================\n",
    "Epoch 075/128 - Mean training loss 0.080865; Mean training F1 0.938280; Mean validation loss 0.083040; Mean validation F1 0.938192; Learning rate 0.000373;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938192; loss - 0.083040;\n",
    "Group g4: f1 - 0.664570; loss - 0.006719;\n",
    "Group g9: f1 - 0.802836; loss - 0.276042;\n",
    "===========================================================\n",
    "Epoch 076/128 - Mean training loss 0.080642; Mean training F1 0.938394; Mean validation loss 0.083556; Mean validation F1 0.937775; Learning rate 0.000362;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937775; loss - 0.083556;\n",
    "Group g4: f1 - 0.996863; loss - 0.006710;\n",
    "Group g9: f1 - 0.803352; loss - 0.277932;\n",
    "===========================================================\n",
    "Epoch 077/128 - Mean training loss 0.080706; Mean training F1 0.938310; Mean validation loss 0.083020; Mean validation F1 0.938235; Learning rate 0.000350;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938235; loss - 0.083020;\n",
    "Group g4: f1 - 0.664566; loss - 0.006717;\n",
    "Group g9: f1 - 0.801250; loss - 0.275415;\n",
    "===========================================================\n",
    "Epoch 078/128 - Mean training loss 0.080788; Mean training F1 0.938229; Mean validation loss 0.082720; Mean validation F1 0.939291; Learning rate 0.000339;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939291; loss - 0.082720;\n",
    "Group g4: f1 - 0.664536; loss - 0.006651;\n",
    "Group g9: f1 - 0.801721; loss - 0.274254;\n",
    "===========================================================\n",
    "Epoch 079/128 - Mean training loss 0.080524; Mean training F1 0.938744; Mean validation loss 0.082871; Mean validation F1 0.938826; Learning rate 0.000327;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938826; loss - 0.082871;\n",
    "Group g4: f1 - 0.664475; loss - 0.006993;\n",
    "Group g9: f1 - 0.803767; loss - 0.274757;\n",
    "===========================================================\n",
    "Epoch 080/128 - Mean training loss 0.080553; Mean training F1 0.938674; Mean validation loss 0.083400; Mean validation F1 0.938210; Learning rate 0.000316;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938210; loss - 0.083400;\n",
    "Group g4: f1 - 0.664538; loss - 0.006660;\n",
    "Group g9: f1 - 0.863086; loss - 0.276971;\n",
    "===========================================================\n",
    "Epoch 081/128 - Mean training loss 0.080381; Mean training F1 0.938529; Mean validation loss 0.082623; Mean validation F1 0.938843; Learning rate 0.000305;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938843; loss - 0.082623;\n",
    "Group g4: f1 - 0.664557; loss - 0.006806;\n",
    "Group g9: f1 - 0.803297; loss - 0.274187;\n",
    "===========================================================\n",
    "Epoch 082/128 - Mean training loss 0.080275; Mean training F1 0.938669; Mean validation loss 0.082778; Mean validation F1 0.938838; Learning rate 0.000294;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938838; loss - 0.082778;\n",
    "Group g4: f1 - 0.664570; loss - 0.006675;\n",
    "Group g9: f1 - 0.867413; loss - 0.274666;\n",
    "===========================================================\n",
    "Epoch 083/128 - Mean training loss 0.080180; Mean training F1 0.938723; Mean validation loss 0.083193; Mean validation F1 0.938382; Learning rate 0.000283;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938382; loss - 0.083193;\n",
    "Group g4: f1 - 0.664509; loss - 0.006783;\n",
    "Group g9: f1 - 0.804704; loss - 0.275011;\n",
    "===========================================================\n",
    "Epoch 084/128 - Mean training loss 0.080874; Mean training F1 0.938400; Mean validation loss 0.082889; Mean validation F1 0.938955; Learning rate 0.000272;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938955; loss - 0.082889;\n",
    "Group g4: f1 - 0.664520; loss - 0.006841;\n",
    "Group g9: f1 - 0.802950; loss - 0.275401;\n",
    "===========================================================\n",
    "Epoch 085/128 - Mean training loss 0.080593; Mean training F1 0.938521; Mean validation loss 0.082921; Mean validation F1 0.938550; Learning rate 0.000261;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938550; loss - 0.082921;\n",
    "Group g4: f1 - 0.664594; loss - 0.006653;\n",
    "Group g9: f1 - 0.802604; loss - 0.275681;\n",
    "===========================================================\n",
    "Epoch 086/128 - Mean training loss 0.080157; Mean training F1 0.938747; Mean validation loss 0.082610; Mean validation F1 0.939278; Learning rate 0.000251;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939278; loss - 0.082610;\n",
    "Group g4: f1 - 0.664541; loss - 0.006737;\n",
    "Group g9: f1 - 0.802852; loss - 0.273553;\n",
    "===========================================================\n",
    "Epoch 087/128 - Mean training loss 0.080015; Mean training F1 0.938814; Mean validation loss 0.082886; Mean validation F1 0.939095; Learning rate 0.000240;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939095; loss - 0.082886;\n",
    "Group g4: f1 - 0.664554; loss - 0.006698;\n",
    "Group g9: f1 - 0.863908; loss - 0.274000;\n",
    "===========================================================\n",
    "Epoch 088/128 - Mean training loss 0.080017; Mean training F1 0.938742; Mean validation loss 0.082762; Mean validation F1 0.939078; Learning rate 0.000230;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939078; loss - 0.082762;\n",
    "Group g4: f1 - 0.664568; loss - 0.006666;\n",
    "Group g9: f1 - 0.868498; loss - 0.273360;\n",
    "===========================================================\n",
    "Epoch 089/128 - Mean training loss 0.080045; Mean training F1 0.938763; Mean validation loss 0.082636; Mean validation F1 0.938174; Learning rate 0.000220;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938174; loss - 0.082636;\n",
    "Group g4: f1 - 0.664561; loss - 0.006603;\n",
    "Group g9: f1 - 0.804283; loss - 0.274328;\n",
    "===========================================================\n",
    "Epoch 090/128 - Mean training loss 0.079887; Mean training F1 0.938898; Mean validation loss 0.082646; Mean validation F1 0.939086; Learning rate 0.000210;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939086; loss - 0.082646;\n",
    "Group g4: f1 - 0.664596; loss - 0.006630;\n",
    "Group g9: f1 - 0.806242; loss - 0.273800;\n",
    "===========================================================\n",
    "Epoch 091/128 - Mean training loss 0.079724; Mean training F1 0.938854; Mean validation loss 0.082773; Mean validation F1 0.938694; Learning rate 0.000201;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938694; loss - 0.082773;\n",
    "Group g4: f1 - 0.664492; loss - 0.006780;\n",
    "Group g9: f1 - 0.802883; loss - 0.274244;\n",
    "===========================================================\n",
    "Epoch 092/128 - Mean training loss 0.079744; Mean training F1 0.938919; Mean validation loss 0.082559; Mean validation F1 0.939533; Learning rate 0.000191;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939533; loss - 0.082559;\n",
    "Group g4: f1 - 0.664605; loss - 0.006586;\n",
    "Group g9: f1 - 0.867748; loss - 0.273705;\n",
    "===========================================================\n",
    "Epoch 093/128 - Mean training loss 0.079549; Mean training F1 0.939133; Mean validation loss 0.082515; Mean validation F1 0.939144; Learning rate 0.000182;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939144; loss - 0.082515;\n",
    "Group g4: f1 - 0.664603; loss - 0.006610;\n",
    "Group g9: f1 - 0.866694; loss - 0.273237;\n",
    "===========================================================\n",
    "Epoch 094/128 - Mean training loss 0.079557; Mean training F1 0.939126; Mean validation loss 0.082593; Mean validation F1 0.939230; Learning rate 0.000173;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939230; loss - 0.082593;\n",
    "Group g4: f1 - 0.664602; loss - 0.006583;\n",
    "Group g9: f1 - 0.866864; loss - 0.273489;\n",
    "===========================================================\n",
    "Epoch 095/128 - Mean training loss 0.079537; Mean training F1 0.939049; Mean validation loss 0.082602; Mean validation F1 0.938252; Learning rate 0.000164;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938252; loss - 0.082602;\n",
    "Group g4: f1 - 0.664630; loss - 0.006531;\n",
    "Group g9: f1 - 0.865088; loss - 0.274114;\n",
    "===========================================================\n",
    "Epoch 096/128 - Mean training loss 0.079528; Mean training F1 0.939045; Mean validation loss 0.082970; Mean validation F1 0.939407; Learning rate 0.000155;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939407; loss - 0.082970;\n",
    "Group g4: f1 - 0.996806; loss - 0.006808;\n",
    "Group g9: f1 - 0.804744; loss - 0.273172;\n",
    "===========================================================\n",
    "Epoch 097/128 - Mean training loss 0.079472; Mean training F1 0.939116; Mean validation loss 0.082550; Mean validation F1 0.938579; Learning rate 0.000147;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938579; loss - 0.082550;\n",
    "Group g4: f1 - 0.664606; loss - 0.006562;\n",
    "Group g9: f1 - 0.807916; loss - 0.273381;\n",
    "===========================================================\n",
    "Epoch 098/128 - Mean training loss 0.079342; Mean training F1 0.939208; Mean validation loss 0.082455; Mean validation F1 0.939249; Learning rate 0.000139;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939249; loss - 0.082455;\n",
    "Group g4: f1 - 0.664615; loss - 0.006629;\n",
    "Group g9: f1 - 0.867856; loss - 0.273299;\n",
    "===========================================================\n",
    "Epoch 099/128 - Mean training loss 0.079294; Mean training F1 0.939159; Mean validation loss 0.082332; Mean validation F1 0.939078; Learning rate 0.000130;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939078; loss - 0.082332;\n",
    "Group g4: f1 - 0.664616; loss - 0.006567;\n",
    "Group g9: f1 - 0.867388; loss - 0.273105;\n",
    "===========================================================\n",
    "Epoch 100/128 - Mean training loss 0.079269; Mean training F1 0.939173; Mean validation loss 0.082381; Mean validation F1 0.939371; Learning rate 0.000123;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939371; loss - 0.082381;\n",
    "Group g4: f1 - 0.664520; loss - 0.006729;\n",
    "Group g9: f1 - 0.868250; loss - 0.272539;\n",
    "===========================================================\n",
    "Epoch 101/128 - Mean training loss 0.079189; Mean training F1 0.939264; Mean validation loss 0.082459; Mean validation F1 0.939359; Learning rate 0.000115;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939359; loss - 0.082459;\n",
    "Group g4: f1 - 0.664610; loss - 0.006563;\n",
    "Group g9: f1 - 0.867294; loss - 0.273390;\n",
    "===========================================================\n",
    "Epoch 102/128 - Mean training loss 0.079252; Mean training F1 0.939139; Mean validation loss 0.082451; Mean validation F1 0.939504; Learning rate 0.000108;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939504; loss - 0.082451;\n",
    "Group g4: f1 - 0.664557; loss - 0.006710;\n",
    "Group g9: f1 - 0.869181; loss - 0.272604;\n",
    "===========================================================\n",
    "Epoch 103/128 - Mean training loss 0.079203; Mean training F1 0.939274; Mean validation loss 0.082490; Mean validation F1 0.939297; Learning rate 0.000101;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939297; loss - 0.082490;\n",
    "Group g4: f1 - 0.664591; loss - 0.006564;\n",
    "Group g9: f1 - 0.865741; loss - 0.273096;\n",
    "===========================================================\n",
    "Epoch 104/128 - Mean training loss 0.079111; Mean training F1 0.939364; Mean validation loss 0.082343; Mean validation F1 0.939291; Learning rate 0.000094;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939291; loss - 0.082343;\n",
    "Group g4: f1 - 0.664602; loss - 0.006529;\n",
    "Group g9: f1 - 0.869171; loss - 0.272698;\n",
    "===========================================================\n",
    "Epoch 105/128 - Mean training loss 0.079059; Mean training F1 0.939232; Mean validation loss 0.082554; Mean validation F1 0.938475; Learning rate 0.000087;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938475; loss - 0.082554;\n",
    "Group g4: f1 - 0.664527; loss - 0.006638;\n",
    "Group g9: f1 - 0.869184; loss - 0.273162;\n",
    "===========================================================\n",
    "Epoch 106/128 - Mean training loss 0.078998; Mean training F1 0.939393; Mean validation loss 0.082434; Mean validation F1 0.939094; Learning rate 0.000081;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939094; loss - 0.082434;\n",
    "Group g4: f1 - 0.664603; loss - 0.006574;\n",
    "Group g9: f1 - 0.869584; loss - 0.272798;\n",
    "===========================================================\n",
    "Epoch 107/128 - Mean training loss 0.078991; Mean training F1 0.939422; Mean validation loss 0.082359; Mean validation F1 0.939379; Learning rate 0.000075;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939379; loss - 0.082359;\n",
    "Group g4: f1 - 0.664608; loss - 0.006527;\n",
    "Group g9: f1 - 0.868918; loss - 0.272308;\n",
    "===========================================================\n",
    "Epoch 108/128 - Mean training loss 0.078932; Mean training F1 0.939382; Mean validation loss 0.082302; Mean validation F1 0.939432; Learning rate 0.000069;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939432; loss - 0.082302;\n",
    "Group g4: f1 - 0.664599; loss - 0.006529;\n",
    "Group g9: f1 - 0.870542; loss - 0.272411;\n",
    "===========================================================\n",
    "Epoch 109/128 - Mean training loss 0.078948; Mean training F1 0.939437; Mean validation loss 0.082363; Mean validation F1 0.939420; Learning rate 0.000063;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939420; loss - 0.082363;\n",
    "Group g4: f1 - 0.664630; loss - 0.006516;\n",
    "Group g9: f1 - 0.870941; loss - 0.272581;\n",
    "===========================================================\n",
    "Epoch 110/128 - Mean training loss 0.078908; Mean training F1 0.939386; Mean validation loss 0.082324; Mean validation F1 0.939561; Learning rate 0.000058;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939561; loss - 0.082324;\n",
    "Group g4: f1 - 0.664575; loss - 0.006529;\n",
    "Group g9: f1 - 0.870233; loss - 0.272791;\n",
    "===========================================================\n",
    "Epoch 111/128 - Mean training loss 0.078885; Mean training F1 0.939345; Mean validation loss 0.082328; Mean validation F1 0.939564; Learning rate 0.000053;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939564; loss - 0.082328;\n",
    "Group g4: f1 - 0.664587; loss - 0.006530;\n",
    "Group g9: f1 - 0.865964; loss - 0.272343;\n",
    "===========================================================\n",
    "Epoch 112/128 - Mean training loss 0.078870; Mean training F1 0.939455; Mean validation loss 0.082300; Mean validation F1 0.939310; Learning rate 0.000048;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939310; loss - 0.082300;\n",
    "Group g4: f1 - 0.664602; loss - 0.006509;\n",
    "Group g9: f1 - 0.807562; loss - 0.272291;\n",
    "===========================================================\n",
    "Epoch 113/128 - Mean training loss 0.078800; Mean training F1 0.939514; Mean validation loss 0.082299; Mean validation F1 0.939499; Learning rate 0.000043;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939499; loss - 0.082299;\n",
    "Group g4: f1 - 0.664616; loss - 0.006539;\n",
    "Group g9: f1 - 0.870553; loss - 0.272295;\n",
    "===========================================================\n",
    "Epoch 114/128 - Mean training loss 0.078838; Mean training F1 0.939624; Mean validation loss 0.082276; Mean validation F1 0.939450; Learning rate 0.000039;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939450; loss - 0.082276;\n",
    "Group g4: f1 - 0.664585; loss - 0.006512;\n",
    "Group g9: f1 - 0.868628; loss - 0.272164;\n",
    "===========================================================\n",
    "Epoch 115/128 - Mean training loss 0.078726; Mean training F1 0.939459; Mean validation loss 0.082365; Mean validation F1 0.939010; Learning rate 0.000035;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939010; loss - 0.082365;\n",
    "Group g4: f1 - 0.664613; loss - 0.006494;\n",
    "Group g9: f1 - 0.806079; loss - 0.272549;\n",
    "===========================================================\n",
    "Epoch 116/128 - Mean training loss 0.078754; Mean training F1 0.939480; Mean validation loss 0.082386; Mean validation F1 0.939010; Learning rate 0.000032;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939010; loss - 0.082386;\n",
    "Group g4: f1 - 0.664616; loss - 0.006478;\n",
    "Group g9: f1 - 0.867535; loss - 0.272669;\n",
    "===========================================================\n",
    "Epoch 117/128 - Mean training loss 0.078708; Mean training F1 0.939537; Mean validation loss 0.082394; Mean validation F1 0.938950; Learning rate 0.000028;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938950; loss - 0.082394;\n",
    "Group g4: f1 - 0.664626; loss - 0.006506;\n",
    "Group g9: f1 - 0.870476; loss - 0.272722;\n",
    "===========================================================\n",
    "Epoch 118/128 - Mean training loss 0.078680; Mean training F1 0.939615; Mean validation loss 0.082307; Mean validation F1 0.939189; Learning rate 0.000025;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939189; loss - 0.082307;\n",
    "Group g4: f1 - 0.664626; loss - 0.006480;\n",
    "Group g9: f1 - 0.870602; loss - 0.272282;\n",
    "===========================================================\n",
    "Epoch 119/128 - Mean training loss 0.078647; Mean training F1 0.939589; Mean validation loss 0.082322; Mean validation F1 0.939165; Learning rate 0.000022;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939165; loss - 0.082322;\n",
    "Group g4: f1 - 0.664599; loss - 0.006512;\n",
    "Group g9: f1 - 0.868786; loss - 0.272365;\n",
    "===========================================================\n",
    "Epoch 120/128 - Mean training loss 0.078675; Mean training F1 0.939604; Mean validation loss 0.082286; Mean validation F1 0.939391; Learning rate 0.000020;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939391; loss - 0.082286;\n",
    "Group g4: f1 - 0.664620; loss - 0.006490;\n",
    "Group g9: f1 - 0.870443; loss - 0.272146;\n",
    "===========================================================\n",
    "Epoch 121/128 - Mean training loss 0.078674; Mean training F1 0.939564; Mean validation loss 0.082246; Mean validation F1 0.939619; Learning rate 0.000018;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939619; loss - 0.082246;\n",
    "Group g4: f1 - 0.664606; loss - 0.006491;\n",
    "Group g9: f1 - 0.869700; loss - 0.271949;\n",
    "===========================================================\n",
    "Epoch 122/128 - Mean training loss 0.078666; Mean training F1 0.939614; Mean validation loss 0.082320; Mean validation F1 0.939283; Learning rate 0.000016;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939283; loss - 0.082320;\n",
    "Group g4: f1 - 0.664616; loss - 0.006481;\n",
    "Group g9: f1 - 0.869721; loss - 0.272351;\n",
    "===========================================================\n",
    "Epoch 123/128 - Mean training loss 0.078668; Mean training F1 0.939586; Mean validation loss 0.082289; Mean validation F1 0.939568; Learning rate 0.000014;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939568; loss - 0.082289;\n",
    "Group g4: f1 - 0.664616; loss - 0.006503;\n",
    "Group g9: f1 - 0.868106; loss - 0.272142;\n",
    "===========================================================\n",
    "Epoch 124/128 - Mean training loss 0.078627; Mean training F1 0.939480; Mean validation loss 0.082306; Mean validation F1 0.939272; Learning rate 0.000013;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939272; loss - 0.082306;\n",
    "Group g4: f1 - 0.664634; loss - 0.006477;\n",
    "Group g9: f1 - 0.869433; loss - 0.272051;\n",
    "===========================================================\n",
    "Epoch 125/128 - Mean training loss 0.078612; Mean training F1 0.939563; Mean validation loss 0.082341; Mean validation F1 0.939388; Learning rate 0.000012;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939388; loss - 0.082341;\n",
    "Group g4: f1 - 0.664598; loss - 0.006474;\n",
    "Group g9: f1 - 0.869619; loss - 0.272315;\n",
    "===========================================================\n",
    "Epoch 126/128 - Mean training loss 0.078609; Mean training F1 0.939555; Mean validation loss 0.082383; Mean validation F1 0.939205; Learning rate 0.000011;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939205; loss - 0.082383;\n",
    "Group g4: f1 - 0.664637; loss - 0.006498;\n",
    "Group g9: f1 - 0.868701; loss - 0.272385;\n",
    "===========================================================\n",
    "Epoch 127/128 - Mean training loss 0.078619; Mean training F1 0.939574; Mean validation loss 0.082295; Mean validation F1 0.939264; Learning rate 0.000010;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939264; loss - 0.082295;\n",
    "Group g4: f1 - 0.664595; loss - 0.006484;\n",
    "Group g9: f1 - 0.869523; loss - 0.272202;\n",
    "===========================================================\n",
    "Epoch 128/128 - Mean training loss 0.078679; Mean training F1 0.939657; Mean validation loss 0.082423; Mean validation F1 0.938661; Learning rate 0.000010;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938661; loss - 0.082423;\n",
    "Group g4: f1 - 0.664602; loss - 0.006494;\n",
    "Group g9: f1 - 0.869273; loss - 0.272729;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train all full data, lr 0.0005"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-------- fold 0 --------\n",
    "model validation loss: 0.095; validation f1: 0.939;\n",
    "-------- fold 1 --------\n",
    "model validation loss: 0.062; validation f1: 0.937;\n",
    "-------- fold 2 --------\n",
    "model validation loss: 0.095; validation f1: 0.937;\n",
    "-------- fold 3 --------\n",
    "model validation loss: 0.061; validation f1: 0.939;\n",
    "-------- fold 4 --------\n",
    "model validation loss: 0.061; validation f1: 0.939;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "################################################################\n",
    "Training/validation for fold 1/5;\n",
    "===========================================================\n",
    "Epoch 001/096 - Mean training loss 0.830562; Mean training F1 0.606319; Mean validation loss 0.462108; Mean validation F1 0.781263; Learning rate 0.000500;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.781263; loss - 0.462108;\n",
    "Group g4: f1 - 0.344227; loss - 1.057367;\n",
    "Group g9: f1 - 0.342235; loss - 1.081927;\n",
    "===========================================================\n",
    "Epoch 002/096 - Mean training loss 0.350422; Mean training F1 0.833843; Mean validation loss 0.212503; Mean validation F1 0.900474; Learning rate 0.000500;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.900474; loss - 0.212503;\n",
    "Group g4: f1 - 0.445994; loss - 0.612860;\n",
    "Group g9: f1 - 0.442408; loss - 0.639302;\n",
    "===========================================================\n",
    "Epoch 003/096 - Mean training loss 0.202482; Mean training F1 0.897108; Mean validation loss 0.148787; Mean validation F1 0.918353; Learning rate 0.000499;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.918353; loss - 0.148787;\n",
    "Group g4: f1 - 0.519896; loss - 0.451263;\n",
    "Group g9: f1 - 0.514248; loss - 0.472359;\n",
    "===========================================================\n",
    "Epoch 004/096 - Mean training loss 0.169083; Mean training F1 0.905481; Mean validation loss 0.150327; Mean validation F1 0.918189; Learning rate 0.000498;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.918189; loss - 0.150327;\n",
    "Group g4: f1 - 0.575655; loss - 0.359367;\n",
    "Group g9: f1 - 0.575915; loss - 0.363197;\n",
    "===========================================================\n",
    "Epoch 005/096 - Mean training loss 0.166904; Mean training F1 0.905946; Mean validation loss 0.161927; Mean validation F1 0.904244; Learning rate 0.000497;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.904244; loss - 0.161927;\n",
    "Group g4: f1 - 0.600310; loss - 0.328800;\n",
    "Group g9: f1 - 0.598651; loss - 0.331456;\n",
    "===========================================================\n",
    "Epoch 006/096 - Mean training loss 0.147829; Mean training F1 0.913963; Mean validation loss 0.128067; Mean validation F1 0.923470; Learning rate 0.000496;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.923470; loss - 0.128067;\n",
    "Group g4: f1 - 0.569160; loss - 0.390062;\n",
    "Group g9: f1 - 0.560858; loss - 0.413006;\n",
    "===========================================================\n",
    "Epoch 007/096 - Mean training loss 0.138881; Mean training F1 0.915441; Mean validation loss 0.850137; Mean validation F1 0.696577; Learning rate 0.000494;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.696577; loss - 0.850137;\n",
    "Group g4: f1 - 0.638195; loss - 0.335757;\n",
    "Group g9: f1 - 0.634826; loss - 0.337943;\n",
    "===========================================================\n",
    "Epoch 008/096 - Mean training loss 0.129698; Mean training F1 0.918908; Mean validation loss 0.109220; Mean validation F1 0.930193; Learning rate 0.000492;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.930193; loss - 0.109220;\n",
    "Group g4: f1 - 0.641093; loss - 0.304612;\n",
    "Group g9: f1 - 0.636097; loss - 0.307770;\n",
    "===========================================================\n",
    "Epoch 009/096 - Mean training loss 0.114419; Mean training F1 0.925138; Mean validation loss 0.102281; Mean validation F1 0.933137; Learning rate 0.000490;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933137; loss - 0.102281;\n",
    "Group g4: f1 - 0.675238; loss - 0.304954;\n",
    "Group g9: f1 - 0.668482; loss - 0.307276;\n",
    "===========================================================\n",
    "Epoch 010/096 - Mean training loss 0.115284; Mean training F1 0.925267; Mean validation loss 0.101006; Mean validation F1 0.934222; Learning rate 0.000487;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934222; loss - 0.101006;\n",
    "Group g4: f1 - 0.681036; loss - 0.298594;\n",
    "Group g9: f1 - 0.674487; loss - 0.301250;\n",
    "===========================================================\n",
    "Epoch 011/096 - Mean training loss 0.109573; Mean training F1 0.926961; Mean validation loss 0.100741; Mean validation F1 0.933885; Learning rate 0.000484;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933885; loss - 0.100741;\n",
    "Group g4: f1 - 0.688030; loss - 0.299403;\n",
    "Group g9: f1 - 0.680201; loss - 0.302364;\n",
    "===========================================================\n",
    "Epoch 012/096 - Mean training loss 0.104599; Mean training F1 0.930421; Mean validation loss 0.097662; Mean validation F1 0.935180; Learning rate 0.000481;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935180; loss - 0.097662;\n",
    "Group g4: f1 - 0.690829; loss - 0.295147;\n",
    "Group g9: f1 - 0.682851; loss - 0.298043;\n",
    "===========================================================\n",
    "Epoch 013/096 - Mean training loss 0.103047; Mean training F1 0.929793; Mean validation loss 0.102800; Mean validation F1 0.933838; Learning rate 0.000478;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933838; loss - 0.102800;\n",
    "Group g4: f1 - 0.687861; loss - 0.300709;\n",
    "Group g9: f1 - 0.677496; loss - 0.303616;\n",
    "===========================================================\n",
    "Epoch 014/096 - Mean training loss 0.104952; Mean training F1 0.929573; Mean validation loss 0.099761; Mean validation F1 0.933968; Learning rate 0.000475;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933968; loss - 0.099761;\n",
    "Group g4: f1 - 0.698181; loss - 0.301800;\n",
    "Group g9: f1 - 0.690878; loss - 0.304824;\n",
    "===========================================================\n",
    "Epoch 015/096 - Mean training loss 0.100720; Mean training F1 0.930767; Mean validation loss 0.097231; Mean validation F1 0.935804; Learning rate 0.000471;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935804; loss - 0.097231;\n",
    "Group g4: f1 - 0.705458; loss - 0.287784;\n",
    "Group g9: f1 - 0.694843; loss - 0.290714;\n",
    "===========================================================\n",
    "Epoch 016/096 - Mean training loss 0.101923; Mean training F1 0.930661; Mean validation loss 0.096926; Mean validation F1 0.936068; Learning rate 0.000467;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936068; loss - 0.096926;\n",
    "Group g4: f1 - 0.706983; loss - 0.285948;\n",
    "Group g9: f1 - 0.702938; loss - 0.288483;\n",
    "===========================================================\n",
    "Epoch 017/096 - Mean training loss 0.102572; Mean training F1 0.929821; Mean validation loss 0.095443; Mean validation F1 0.935946; Learning rate 0.000463;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935946; loss - 0.095443;\n",
    "Group g4: f1 - 0.718414; loss - 0.286405;\n",
    "Group g9: f1 - 0.702182; loss - 0.288853;\n",
    "===========================================================\n",
    "Epoch 018/096 - Mean training loss 0.101511; Mean training F1 0.930346; Mean validation loss 0.106998; Mean validation F1 0.931290; Learning rate 0.000459;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931290; loss - 0.106998;\n",
    "Group g4: f1 - 0.712480; loss - 0.289621;\n",
    "Group g9: f1 - 0.699610; loss - 0.292354;\n",
    "===========================================================\n",
    "Epoch 019/096 - Mean training loss 0.101479; Mean training F1 0.930414; Mean validation loss 0.104684; Mean validation F1 0.933501; Learning rate 0.000454;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933501; loss - 0.104684;\n",
    "Group g4: f1 - 0.708233; loss - 0.289263;\n",
    "Group g9: f1 - 0.702975; loss - 0.291914;\n",
    "===========================================================\n",
    "Epoch 020/096 - Mean training loss 0.095944; Mean training F1 0.933072; Mean validation loss 0.094448; Mean validation F1 0.936287; Learning rate 0.000449;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936287; loss - 0.094448;\n",
    "Group g4: f1 - 0.713276; loss - 0.286869;\n",
    "Group g9: f1 - 0.703445; loss - 0.289743;\n",
    "===========================================================\n",
    "Epoch 021/096 - Mean training loss 0.093186; Mean training F1 0.933692; Mean validation loss 0.097383; Mean validation F1 0.934946; Learning rate 0.000444;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934946; loss - 0.097383;\n",
    "Group g4: f1 - 0.729155; loss - 0.297345;\n",
    "Group g9: f1 - 0.718263; loss - 0.298961;\n",
    "===========================================================\n",
    "Epoch 022/096 - Mean training loss 0.094396; Mean training F1 0.932745; Mean validation loss 0.095980; Mean validation F1 0.934382; Learning rate 0.000439;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934382; loss - 0.095980;\n",
    "Group g4: f1 - 0.717237; loss - 0.298149;\n",
    "Group g9: f1 - 0.708094; loss - 0.301315;\n",
    "===========================================================\n",
    "Epoch 023/096 - Mean training loss 0.095295; Mean training F1 0.932077; Mean validation loss 0.106946; Mean validation F1 0.930624; Learning rate 0.000433;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.930624; loss - 0.106946;\n",
    "Group g4: f1 - 0.714962; loss - 0.300788;\n",
    "Group g9: f1 - 0.702665; loss - 0.303870;\n",
    "===========================================================\n",
    "Epoch 024/096 - Mean training loss 0.093724; Mean training F1 0.933591; Mean validation loss 0.093695; Mean validation F1 0.936225; Learning rate 0.000428;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936225; loss - 0.093695;\n",
    "Group g4: f1 - 0.729764; loss - 0.283905;\n",
    "Group g9: f1 - 0.729722; loss - 0.286707;\n",
    "===========================================================\n",
    "Epoch 025/096 - Mean training loss 0.092636; Mean training F1 0.934347; Mean validation loss 0.093654; Mean validation F1 0.936765; Learning rate 0.000422;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936765; loss - 0.093654;\n",
    "Group g4: f1 - 0.720047; loss - 0.284046;\n",
    "Group g9: f1 - 0.710709; loss - 0.286383;\n",
    "===========================================================\n",
    "Epoch 026/096 - Mean training loss 0.090670; Mean training F1 0.934868; Mean validation loss 0.092079; Mean validation F1 0.937469; Learning rate 0.000416;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937469; loss - 0.092079;\n",
    "Group g4: f1 - 0.725020; loss - 0.283272;\n",
    "Group g9: f1 - 0.721288; loss - 0.285652;\n",
    "===========================================================\n",
    "Epoch 027/096 - Mean training loss 0.090516; Mean training F1 0.934966; Mean validation loss 0.093402; Mean validation F1 0.936705; Learning rate 0.000410;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936705; loss - 0.093402;\n",
    "Group g4: f1 - 0.744916; loss - 0.283197;\n",
    "Group g9: f1 - 0.738250; loss - 0.285814;\n",
    "===========================================================\n",
    "Epoch 028/096 - Mean training loss 0.089673; Mean training F1 0.935282; Mean validation loss 0.092780; Mean validation F1 0.937192; Learning rate 0.000403;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937192; loss - 0.092780;\n",
    "Group g4: f1 - 0.736283; loss - 0.282683;\n",
    "Group g9: f1 - 0.721760; loss - 0.285036;\n",
    "===========================================================\n",
    "Epoch 029/096 - Mean training loss 0.091163; Mean training F1 0.934763; Mean validation loss 0.091549; Mean validation F1 0.937119; Learning rate 0.000397;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937119; loss - 0.091549;\n",
    "Group g4: f1 - 0.723932; loss - 0.283547;\n",
    "Group g9: f1 - 0.718801; loss - 0.285963;\n",
    "===========================================================\n",
    "Epoch 030/096 - Mean training loss 0.089873; Mean training F1 0.935332; Mean validation loss 0.093051; Mean validation F1 0.936570; Learning rate 0.000390;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936570; loss - 0.093051;\n",
    "Group g4: f1 - 0.717221; loss - 0.286743;\n",
    "Group g9: f1 - 0.714246; loss - 0.289664;\n",
    "===========================================================\n",
    "Epoch 031/096 - Mean training loss 0.089762; Mean training F1 0.935210; Mean validation loss 0.093289; Mean validation F1 0.936367; Learning rate 0.000383;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936367; loss - 0.093289;\n",
    "Group g4: f1 - 0.710087; loss - 0.282891;\n",
    "Group g9: f1 - 0.706888; loss - 0.285561;\n",
    "===========================================================\n",
    "Epoch 032/096 - Mean training loss 0.088390; Mean training F1 0.935985; Mean validation loss 0.094867; Mean validation F1 0.936039; Learning rate 0.000377;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936039; loss - 0.094867;\n",
    "Group g4: f1 - 0.730986; loss - 0.290018;\n",
    "Group g9: f1 - 0.723610; loss - 0.292022;\n",
    "===========================================================\n",
    "Epoch 033/096 - Mean training loss 0.088553; Mean training F1 0.935327; Mean validation loss 0.090830; Mean validation F1 0.937862; Learning rate 0.000369;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937862; loss - 0.090830;\n",
    "Group g4: f1 - 0.751252; loss - 0.281181;\n",
    "Group g9: f1 - 0.730355; loss - 0.283593;\n",
    "===========================================================\n",
    "Epoch 034/096 - Mean training loss 0.088544; Mean training F1 0.935325; Mean validation loss 0.094175; Mean validation F1 0.936309; Learning rate 0.000362;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936309; loss - 0.094175;\n",
    "Group g4: f1 - 0.745929; loss - 0.286986;\n",
    "Group g9: f1 - 0.727857; loss - 0.288743;\n",
    "===========================================================\n",
    "Epoch 035/096 - Mean training loss 0.088501; Mean training F1 0.935838; Mean validation loss 0.090686; Mean validation F1 0.937677; Learning rate 0.000355;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937677; loss - 0.090686;\n",
    "Group g4: f1 - 0.767259; loss - 0.280776;\n",
    "Group g9: f1 - 0.762277; loss - 0.283472;\n",
    "===========================================================\n",
    "Epoch 036/096 - Mean training loss 0.088418; Mean training F1 0.935470; Mean validation loss 0.092804; Mean validation F1 0.936711; Learning rate 0.000347;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936711; loss - 0.092804;\n",
    "Group g4: f1 - 0.750576; loss - 0.281886;\n",
    "Group g9: f1 - 0.741085; loss - 0.284496;\n",
    "===========================================================\n",
    "Epoch 037/096 - Mean training loss 0.087578; Mean training F1 0.935756; Mean validation loss 0.093343; Mean validation F1 0.936696; Learning rate 0.000340;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936696; loss - 0.093343;\n",
    "Group g4: f1 - 0.751518; loss - 0.286728;\n",
    "Group g9: f1 - 0.741554; loss - 0.288527;\n",
    "===========================================================\n",
    "Epoch 038/096 - Mean training loss 0.087474; Mean training F1 0.936095; Mean validation loss 0.094886; Mean validation F1 0.936015; Learning rate 0.000332;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936015; loss - 0.094886;\n",
    "Group g4: f1 - 0.765720; loss - 0.287382;\n",
    "Group g9: f1 - 0.759299; loss - 0.289141;\n",
    "===========================================================\n",
    "Epoch 039/096 - Mean training loss 0.087558; Mean training F1 0.935826; Mean validation loss 0.096199; Mean validation F1 0.935413; Learning rate 0.000325;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935413; loss - 0.096199;\n",
    "Group g4: f1 - 0.712841; loss - 0.284103;\n",
    "Group g9: f1 - 0.712250; loss - 0.286431;\n",
    "===========================================================\n",
    "Epoch 040/096 - Mean training loss 0.086798; Mean training F1 0.936336; Mean validation loss 0.091205; Mean validation F1 0.936423; Learning rate 0.000317;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936423; loss - 0.091205;\n",
    "Group g4: f1 - 0.759494; loss - 0.282940;\n",
    "Group g9: f1 - 0.737078; loss - 0.285513;\n",
    "===========================================================\n",
    "Epoch 041/096 - Mean training loss 0.086605; Mean training F1 0.936010; Mean validation loss 0.092449; Mean validation F1 0.937003; Learning rate 0.000309;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937003; loss - 0.092449;\n",
    "Group g4: f1 - 0.736473; loss - 0.281919;\n",
    "Group g9: f1 - 0.728548; loss - 0.283959;\n",
    "===========================================================\n",
    "Epoch 042/096 - Mean training loss 0.085956; Mean training F1 0.936731; Mean validation loss 0.091078; Mean validation F1 0.935898; Learning rate 0.000301;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935898; loss - 0.091078;\n",
    "Group g4: f1 - 0.750062; loss - 0.283207;\n",
    "Group g9: f1 - 0.742055; loss - 0.285888;\n",
    "===========================================================\n",
    "Epoch 043/096 - Mean training loss 0.085532; Mean training F1 0.936685; Mean validation loss 0.091927; Mean validation F1 0.937064; Learning rate 0.000293;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937064; loss - 0.091927;\n",
    "Group g4: f1 - 0.749058; loss - 0.281945;\n",
    "Group g9: f1 - 0.732909; loss - 0.284692;\n",
    "===========================================================\n",
    "Epoch 044/096 - Mean training loss 0.086148; Mean training F1 0.936541; Mean validation loss 0.091093; Mean validation F1 0.937663; Learning rate 0.000285;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937663; loss - 0.091093;\n",
    "Group g4: f1 - 0.762838; loss - 0.279508;\n",
    "Group g9: f1 - 0.750297; loss - 0.281983;\n",
    "===========================================================\n",
    "Epoch 045/096 - Mean training loss 0.087166; Mean training F1 0.935890; Mean validation loss 0.091357; Mean validation F1 0.937007; Learning rate 0.000277;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937007; loss - 0.091357;\n",
    "Group g4: f1 - 0.761117; loss - 0.283112;\n",
    "Group g9: f1 - 0.740573; loss - 0.285956;\n",
    "===========================================================\n",
    "Epoch 046/096 - Mean training loss 0.086740; Mean training F1 0.936320; Mean validation loss 0.090687; Mean validation F1 0.937790; Learning rate 0.000269;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937790; loss - 0.090687;\n",
    "Group g4: f1 - 0.768957; loss - 0.279771;\n",
    "Group g9: f1 - 0.764601; loss - 0.282129;\n",
    "===========================================================\n",
    "Epoch 047/096 - Mean training loss 0.085352; Mean training F1 0.936748; Mean validation loss 0.089849; Mean validation F1 0.938119; Learning rate 0.000261;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938119; loss - 0.089849;\n",
    "Group g4: f1 - 0.761174; loss - 0.280769;\n",
    "Group g9: f1 - 0.741777; loss - 0.282871;\n",
    "===========================================================\n",
    "Epoch 048/096 - Mean training loss 0.084731; Mean training F1 0.937003; Mean validation loss 0.090420; Mean validation F1 0.936740; Learning rate 0.000253;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936740; loss - 0.090420;\n",
    "Group g4: f1 - 0.775092; loss - 0.284480;\n",
    "Group g9: f1 - 0.760656; loss - 0.286448;\n",
    "===========================================================\n",
    "Epoch 049/096 - Mean training loss 0.084798; Mean training F1 0.936932; Mean validation loss 0.090152; Mean validation F1 0.936816; Learning rate 0.000245;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936816; loss - 0.090152;\n",
    "Group g4: f1 - 0.777838; loss - 0.281004;\n",
    "Group g9: f1 - 0.767441; loss - 0.283182;\n",
    "===========================================================\n",
    "Epoch 050/096 - Mean training loss 0.084762; Mean training F1 0.936986; Mean validation loss 0.091356; Mean validation F1 0.936931; Learning rate 0.000237;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936931; loss - 0.091356;\n",
    "Group g4: f1 - 0.775414; loss - 0.283988;\n",
    "Group g9: f1 - 0.767525; loss - 0.286456;\n",
    "===========================================================\n",
    "Epoch 051/096 - Mean training loss 0.084497; Mean training F1 0.937107; Mean validation loss 0.091262; Mean validation F1 0.937295; Learning rate 0.000228;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937295; loss - 0.091262;\n",
    "Group g4: f1 - 0.765131; loss - 0.279470;\n",
    "Group g9: f1 - 0.746798; loss - 0.281879;\n",
    "===========================================================\n",
    "Epoch 052/096 - Mean training loss 0.084184; Mean training F1 0.937118; Mean validation loss 0.089597; Mean validation F1 0.938322; Learning rate 0.000220;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938322; loss - 0.089597;\n",
    "Group g4: f1 - 0.781838; loss - 0.279418;\n",
    "Group g9: f1 - 0.775545; loss - 0.281456;\n",
    "===========================================================\n",
    "Epoch 053/096 - Mean training loss 0.084468; Mean training F1 0.937221; Mean validation loss 0.089195; Mean validation F1 0.937938; Learning rate 0.000212;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937938; loss - 0.089195;\n",
    "Group g4: f1 - 0.770300; loss - 0.279183;\n",
    "Group g9: f1 - 0.763088; loss - 0.281303;\n",
    "===========================================================\n",
    "Epoch 054/096 - Mean training loss 0.084449; Mean training F1 0.937260; Mean validation loss 0.089323; Mean validation F1 0.937838; Learning rate 0.000204;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937838; loss - 0.089323;\n",
    "Group g4: f1 - 0.790064; loss - 0.280279;\n",
    "Group g9: f1 - 0.782984; loss - 0.282487;\n",
    "===========================================================\n",
    "Epoch 055/096 - Mean training loss 0.084639; Mean training F1 0.937180; Mean validation loss 0.090443; Mean validation F1 0.937665; Learning rate 0.000197;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937665; loss - 0.090443;\n",
    "Group g4: f1 - 0.769236; loss - 0.282219;\n",
    "Group g9: f1 - 0.759062; loss - 0.283993;\n",
    "===========================================================\n",
    "Epoch 056/096 - Mean training loss 0.084193; Mean training F1 0.937216; Mean validation loss 0.090132; Mean validation F1 0.938086; Learning rate 0.000189;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938086; loss - 0.090132;\n",
    "Group g4: f1 - 0.772997; loss - 0.281123;\n",
    "Group g9: f1 - 0.764634; loss - 0.283009;\n",
    "===========================================================\n",
    "Epoch 057/096 - Mean training loss 0.083626; Mean training F1 0.937555; Mean validation loss 0.089340; Mean validation F1 0.938236; Learning rate 0.000181;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938236; loss - 0.089340;\n",
    "Group g4: f1 - 0.784354; loss - 0.279698;\n",
    "Group g9: f1 - 0.781167; loss - 0.281563;\n",
    "===========================================================\n",
    "Epoch 058/096 - Mean training loss 0.083778; Mean training F1 0.937454; Mean validation loss 0.089767; Mean validation F1 0.938268; Learning rate 0.000173;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938268; loss - 0.089767;\n",
    "Group g4: f1 - 0.778654; loss - 0.279375;\n",
    "Group g9: f1 - 0.771856; loss - 0.281588;\n",
    "===========================================================\n",
    "Epoch 059/096 - Mean training loss 0.084023; Mean training F1 0.937368; Mean validation loss 0.089747; Mean validation F1 0.938280; Learning rate 0.000166;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938280; loss - 0.089747;\n",
    "Group g4: f1 - 0.778631; loss - 0.279544;\n",
    "Group g9: f1 - 0.774148; loss - 0.281595;\n",
    "===========================================================\n",
    "Epoch 060/096 - Mean training loss 0.083379; Mean training F1 0.937762; Mean validation loss 0.088726; Mean validation F1 0.938429; Learning rate 0.000158;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938429; loss - 0.088726;\n",
    "Group g4: f1 - 0.775500; loss - 0.279151;\n",
    "Group g9: f1 - 0.770927; loss - 0.281136;\n",
    "===========================================================\n",
    "Epoch 061/096 - Mean training loss 0.083209; Mean training F1 0.937746; Mean validation loss 0.091675; Mean validation F1 0.937232; Learning rate 0.000151;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937232; loss - 0.091675;\n",
    "Group g4: f1 - 0.776713; loss - 0.280880;\n",
    "Group g9: f1 - 0.772515; loss - 0.282874;\n",
    "===========================================================\n",
    "Epoch 062/096 - Mean training loss 0.083338; Mean training F1 0.937471; Mean validation loss 0.089019; Mean validation F1 0.938107; Learning rate 0.000143;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938107; loss - 0.089019;\n",
    "Group g4: f1 - 0.780361; loss - 0.278260;\n",
    "Group g9: f1 - 0.771636; loss - 0.280260;\n",
    "===========================================================\n",
    "Epoch 063/096 - Mean training loss 0.082970; Mean training F1 0.937806; Mean validation loss 0.089175; Mean validation F1 0.938276; Learning rate 0.000136;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938276; loss - 0.089175;\n",
    "Group g4: f1 - 0.769125; loss - 0.278780;\n",
    "Group g9: f1 - 0.748522; loss - 0.280803;\n",
    "===========================================================\n",
    "Epoch 064/096 - Mean training loss 0.083396; Mean training F1 0.937618; Mean validation loss 0.091122; Mean validation F1 0.936798; Learning rate 0.000129;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936798; loss - 0.091122;\n",
    "Group g4: f1 - 0.784790; loss - 0.283730;\n",
    "Group g9: f1 - 0.780894; loss - 0.286107;\n",
    "===========================================================\n",
    "Epoch 065/096 - Mean training loss 0.083661; Mean training F1 0.937653; Mean validation loss 0.088446; Mean validation F1 0.938526; Learning rate 0.000122;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938526; loss - 0.088446;\n",
    "Group g4: f1 - 0.774029; loss - 0.278186;\n",
    "Group g9: f1 - 0.759716; loss - 0.280015;\n",
    "===========================================================\n",
    "Epoch 066/096 - Mean training loss 0.083037; Mean training F1 0.937810; Mean validation loss 0.088144; Mean validation F1 0.938566; Learning rate 0.000115;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938566; loss - 0.088144;\n",
    "Group g4: f1 - 0.780458; loss - 0.278262;\n",
    "Group g9: f1 - 0.777077; loss - 0.279978;\n",
    "===========================================================\n",
    "Epoch 067/096 - Mean training loss 0.083020; Mean training F1 0.937511; Mean validation loss 0.089588; Mean validation F1 0.937396; Learning rate 0.000109;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937396; loss - 0.089588;\n",
    "Group g4: f1 - 0.781991; loss - 0.281695;\n",
    "Group g9: f1 - 0.782890; loss - 0.283932;\n",
    "===========================================================\n",
    "Epoch 068/096 - Mean training loss 0.082869; Mean training F1 0.937943; Mean validation loss 0.088554; Mean validation F1 0.938462; Learning rate 0.000102;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938462; loss - 0.088554;\n",
    "Group g4: f1 - 0.779313; loss - 0.278188;\n",
    "Group g9: f1 - 0.767753; loss - 0.279973;\n",
    "===========================================================\n",
    "Epoch 069/096 - Mean training loss 0.082815; Mean training F1 0.938133; Mean validation loss 0.089157; Mean validation F1 0.938166; Learning rate 0.000096;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938166; loss - 0.089157;\n",
    "Group g4: f1 - 0.775637; loss - 0.278205;\n",
    "Group g9: f1 - 0.766721; loss - 0.280176;\n",
    "===========================================================\n",
    "Epoch 070/096 - Mean training loss 0.082703; Mean training F1 0.937853; Mean validation loss 0.088766; Mean validation F1 0.938148; Learning rate 0.000090;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938148; loss - 0.088766;\n",
    "Group g4: f1 - 0.772895; loss - 0.278115;\n",
    "Group g9: f1 - 0.757657; loss - 0.280026;\n",
    "===========================================================\n",
    "Epoch 071/096 - Mean training loss 0.082904; Mean training F1 0.937869; Mean validation loss 0.088443; Mean validation F1 0.938618; Learning rate 0.000084;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938618; loss - 0.088443;\n",
    "Group g4: f1 - 0.785463; loss - 0.277990;\n",
    "Group g9: f1 - 0.784301; loss - 0.279750;\n",
    "===========================================================\n",
    "Epoch 072/096 - Mean training loss 0.082729; Mean training F1 0.938025; Mean validation loss 0.088626; Mean validation F1 0.938500; Learning rate 0.000078;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938500; loss - 0.088626;\n",
    "Group g4: f1 - 0.780509; loss - 0.278054;\n",
    "Group g9: f1 - 0.780898; loss - 0.279909;\n",
    "===========================================================\n",
    "Epoch 073/096 - Mean training loss 0.082417; Mean training F1 0.938092; Mean validation loss 0.088018; Mean validation F1 0.938827; Learning rate 0.000072;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938827; loss - 0.088018;\n",
    "Group g4: f1 - 0.789387; loss - 0.277915;\n",
    "Group g9: f1 - 0.787635; loss - 0.279594;\n",
    "===========================================================\n",
    "Epoch 074/096 - Mean training loss 0.082535; Mean training F1 0.938024; Mean validation loss 0.088057; Mean validation F1 0.938600; Learning rate 0.000067;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938600; loss - 0.088057;\n",
    "Group g4: f1 - 0.787885; loss - 0.277596;\n",
    "Group g9: f1 - 0.785559; loss - 0.279432;\n",
    "===========================================================\n",
    "Epoch 075/096 - Mean training loss 0.082582; Mean training F1 0.938039; Mean validation loss 0.088202; Mean validation F1 0.938563; Learning rate 0.000061;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938563; loss - 0.088202;\n",
    "Group g4: f1 - 0.783460; loss - 0.277826;\n",
    "Group g9: f1 - 0.781943; loss - 0.279616;\n",
    "===========================================================\n",
    "Epoch 076/096 - Mean training loss 0.082252; Mean training F1 0.938034; Mean validation loss 0.088510; Mean validation F1 0.938115; Learning rate 0.000056;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938115; loss - 0.088510;\n",
    "Group g4: f1 - 0.791024; loss - 0.278014;\n",
    "Group g9: f1 - 0.785787; loss - 0.279975;\n",
    "===========================================================\n",
    "Epoch 077/096 - Mean training loss 0.082206; Mean training F1 0.938256; Mean validation loss 0.088255; Mean validation F1 0.938100; Learning rate 0.000052;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938100; loss - 0.088255;\n",
    "Group g4: f1 - 0.784336; loss - 0.278167;\n",
    "Group g9: f1 - 0.779794; loss - 0.279921;\n",
    "===========================================================\n",
    "Epoch 078/096 - Mean training loss 0.082326; Mean training F1 0.938181; Mean validation loss 0.088183; Mean validation F1 0.938556; Learning rate 0.000047;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938556; loss - 0.088183;\n",
    "Group g4: f1 - 0.779660; loss - 0.278253;\n",
    "Group g9: f1 - 0.771718; loss - 0.279965;\n",
    "===========================================================\n",
    "Epoch 079/096 - Mean training loss 0.082982; Mean training F1 0.938048; Mean validation loss 0.087795; Mean validation F1 0.938634; Learning rate 0.000043;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938634; loss - 0.087795;\n",
    "Group g4: f1 - 0.782212; loss - 0.277722;\n",
    "Group g9: f1 - 0.779629; loss - 0.279546;\n",
    "===========================================================\n",
    "Epoch 080/096 - Mean training loss 0.082036; Mean training F1 0.938251; Mean validation loss 0.087922; Mean validation F1 0.938721; Learning rate 0.000038;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938721; loss - 0.087922;\n",
    "Group g4: f1 - 0.783821; loss - 0.277959;\n",
    "Group g9: f1 - 0.774979; loss - 0.279658;\n",
    "===========================================================\n",
    "Epoch 081/096 - Mean training loss 0.082285; Mean training F1 0.938274; Mean validation loss 0.087877; Mean validation F1 0.938712; Learning rate 0.000034;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938712; loss - 0.087877;\n",
    "Group g4: f1 - 0.786159; loss - 0.277589;\n",
    "Group g9: f1 - 0.782725; loss - 0.279308;\n",
    "===========================================================\n",
    "Epoch 082/096 - Mean training loss 0.082133; Mean training F1 0.938176; Mean validation loss 0.088275; Mean validation F1 0.938633; Learning rate 0.000031;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938633; loss - 0.088275;\n",
    "Group g4: f1 - 0.785716; loss - 0.277843;\n",
    "Group g9: f1 - 0.781262; loss - 0.279565;\n",
    "===========================================================\n",
    "Epoch 083/096 - Mean training loss 0.082025; Mean training F1 0.938262; Mean validation loss 0.088003; Mean validation F1 0.938586; Learning rate 0.000027;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938586; loss - 0.088003;\n",
    "Group g4: f1 - 0.786144; loss - 0.277791;\n",
    "Group g9: f1 - 0.783034; loss - 0.279470;\n",
    "===========================================================\n",
    "Epoch 084/096 - Mean training loss 0.082303; Mean training F1 0.938148; Mean validation loss 0.088064; Mean validation F1 0.938530; Learning rate 0.000024;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938530; loss - 0.088064;\n",
    "Group g4: f1 - 0.786844; loss - 0.277592;\n",
    "Group g9: f1 - 0.787932; loss - 0.279308;\n",
    "===========================================================\n",
    "Epoch 085/096 - Mean training loss 0.081695; Mean training F1 0.938373; Mean validation loss 0.087889; Mean validation F1 0.938754; Learning rate 0.000021;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938754; loss - 0.087889;\n",
    "Group g4: f1 - 0.786718; loss - 0.277450;\n",
    "Group g9: f1 - 0.783564; loss - 0.279162;\n",
    "===========================================================\n",
    "Epoch 086/096 - Mean training loss 0.081751; Mean training F1 0.938279; Mean validation loss 0.088063; Mean validation F1 0.938700; Learning rate 0.000018;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938700; loss - 0.088063;\n",
    "Group g4: f1 - 0.784767; loss - 0.277753;\n",
    "Group g9: f1 - 0.783923; loss - 0.279372;\n",
    "===========================================================\n",
    "Epoch 087/096 - Mean training loss 0.081984; Mean training F1 0.938154; Mean validation loss 0.088267; Mean validation F1 0.938532; Learning rate 0.000016;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938532; loss - 0.088267;\n",
    "Group g4: f1 - 0.788314; loss - 0.277560;\n",
    "Group g9: f1 - 0.785754; loss - 0.279266;\n",
    "===========================================================\n",
    "Epoch 088/096 - Mean training loss 0.082058; Mean training F1 0.938233; Mean validation loss 0.087943; Mean validation F1 0.938346; Learning rate 0.000014;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938346; loss - 0.087943;\n",
    "Group g4: f1 - 0.786225; loss - 0.277644;\n",
    "Group g9: f1 - 0.785752; loss - 0.279372;\n",
    "===========================================================\n",
    "Epoch 089/096 - Mean training loss 0.082137; Mean training F1 0.938226; Mean validation loss 0.087875; Mean validation F1 0.938603; Learning rate 0.000012;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938603; loss - 0.087875;\n",
    "Group g4: f1 - 0.785949; loss - 0.277587;\n",
    "Group g9: f1 - 0.781583; loss - 0.279252;\n",
    "===========================================================\n",
    "Epoch 090/096 - Mean training loss 0.082053; Mean training F1 0.938294; Mean validation loss 0.087877; Mean validation F1 0.938720; Learning rate 0.000010;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938720; loss - 0.087877;\n",
    "Group g4: f1 - 0.787009; loss - 0.277412;\n",
    "Group g9: f1 - 0.785793; loss - 0.279223;\n",
    "===========================================================\n",
    "Epoch 091/096 - Mean training loss 0.081935; Mean training F1 0.938281; Mean validation loss 0.087868; Mean validation F1 0.938864; Learning rate 0.000008;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938864; loss - 0.087868;\n",
    "Group g4: f1 - 0.787026; loss - 0.277353;\n",
    "Group g9: f1 - 0.782578; loss - 0.279112;\n",
    "===========================================================\n",
    "Epoch 092/096 - Mean training loss 0.082019; Mean training F1 0.938343; Mean validation loss 0.087902; Mean validation F1 0.938735; Learning rate 0.000007;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938735; loss - 0.087902;\n",
    "Group g4: f1 - 0.787359; loss - 0.277470;\n",
    "Group g9: f1 - 0.785847; loss - 0.279155;\n",
    "===========================================================\n",
    "Epoch 093/096 - Mean training loss 0.081957; Mean training F1 0.938357; Mean validation loss 0.087828; Mean validation F1 0.938846; Learning rate 0.000006;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938846; loss - 0.087828;\n",
    "Group g4: f1 - 0.785694; loss - 0.277580;\n",
    "Group g9: f1 - 0.781153; loss - 0.279258;\n",
    "===========================================================\n",
    "Epoch 094/096 - Mean training loss 0.081892; Mean training F1 0.938465; Mean validation loss 0.088089; Mean validation F1 0.938635; Learning rate 0.000006;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938635; loss - 0.088089;\n",
    "Group g4: f1 - 0.789170; loss - 0.277445;\n",
    "Group g9: f1 - 0.786984; loss - 0.279101;\n",
    "===========================================================\n",
    "Epoch 095/096 - Mean training loss 0.081771; Mean training F1 0.938432; Mean validation loss 0.087934; Mean validation F1 0.938657; Learning rate 0.000005;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938657; loss - 0.087934;\n",
    "Group g4: f1 - 0.788327; loss - 0.277394;\n",
    "Group g9: f1 - 0.785677; loss - 0.279110;\n",
    "===========================================================\n",
    "Epoch 096/096 - Mean training loss 0.081693; Mean training F1 0.938369; Mean validation loss 0.087847; Mean validation F1 0.938713; Learning rate 0.000005;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938713; loss - 0.087847;\n",
    "Group g4: f1 - 0.787281; loss - 0.277350;\n",
    "Group g9: f1 - 0.782503; loss - 0.279092;\n",
    "################################################################\n",
    "Training/validation for fold 2/5;\n",
    "===========================================================\n",
    "Epoch 001/096 - Mean training loss 0.767455; Mean training F1 0.639590; Mean validation loss 0.457595; Mean validation F1 0.799250; Learning rate 0.000500;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.799250; loss - 0.457595;\n",
    "Group g4: f1 - 0.362992; loss - 0.937461;\n",
    "Group g9: f1 - 0.361767; loss - 0.957744;\n",
    "===========================================================\n",
    "Epoch 002/096 - Mean training loss 0.294886; Mean training F1 0.853058; Mean validation loss 0.250473; Mean validation F1 0.889398; Learning rate 0.000500;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.889398; loss - 0.250473;\n",
    "Group g4: f1 - 0.464040; loss - 0.470476;\n",
    "Group g9: f1 - 0.464607; loss - 0.477973;\n",
    "===========================================================\n",
    "Epoch 003/096 - Mean training loss 0.179423; Mean training F1 0.902782; Mean validation loss 0.167612; Mean validation F1 0.913132; Learning rate 0.000499;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.913132; loss - 0.167612;\n",
    "Group g4: f1 - 0.534945; loss - 0.429408;\n",
    "Group g9: f1 - 0.531315; loss - 0.445851;\n",
    "===========================================================\n",
    "Epoch 004/096 - Mean training loss 0.153012; Mean training F1 0.909617; Mean validation loss 0.127788; Mean validation F1 0.926491; Learning rate 0.000498;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.926491; loss - 0.127788;\n",
    "Group g4: f1 - 0.587652; loss - 0.337670;\n",
    "Group g9: f1 - 0.589526; loss - 0.341840;\n",
    "===========================================================\n",
    "Epoch 005/096 - Mean training loss 0.121504; Mean training F1 0.924048; Mean validation loss 0.131403; Mean validation F1 0.923914; Learning rate 0.000497;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.923914; loss - 0.131403;\n",
    "Group g4: f1 - 0.617492; loss - 0.327490;\n",
    "Group g9: f1 - 0.616946; loss - 0.329844;\n",
    "===========================================================\n",
    "Epoch 006/096 - Mean training loss 0.130070; Mean training F1 0.919756; Mean validation loss 0.158904; Mean validation F1 0.912505; Learning rate 0.000496;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.912505; loss - 0.158904;\n",
    "Group g4: f1 - 0.626284; loss - 0.307888;\n",
    "Group g9: f1 - 0.626442; loss - 0.310955;\n",
    "===========================================================\n",
    "Epoch 007/096 - Mean training loss 0.117867; Mean training F1 0.923016; Mean validation loss 0.122131; Mean validation F1 0.925017; Learning rate 0.000494;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.925017; loss - 0.122131;\n",
    "Group g4: f1 - 0.661649; loss - 0.322419;\n",
    "Group g9: f1 - 0.657658; loss - 0.324672;\n",
    "===========================================================\n",
    "Epoch 008/096 - Mean training loss 0.132193; Mean training F1 0.919474; Mean validation loss 0.123665; Mean validation F1 0.926723; Learning rate 0.000492;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.926723; loss - 0.123665;\n",
    "Group g4: f1 - 0.654242; loss - 0.310409;\n",
    "Group g9: f1 - 0.650493; loss - 0.313333;\n",
    "===========================================================\n",
    "Epoch 009/096 - Mean training loss 0.109276; Mean training F1 0.927587; Mean validation loss 0.107237; Mean validation F1 0.931607; Learning rate 0.000490;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931607; loss - 0.107237;\n",
    "Group g4: f1 - 0.676557; loss - 0.297033;\n",
    "Group g9: f1 - 0.668605; loss - 0.300506;\n",
    "===========================================================\n",
    "Epoch 010/096 - Mean training loss 0.108817; Mean training F1 0.926329; Mean validation loss 0.111128; Mean validation F1 0.930957; Learning rate 0.000487;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.930957; loss - 0.111128;\n",
    "Group g4: f1 - 0.691645; loss - 0.304099;\n",
    "Group g9: f1 - 0.679926; loss - 0.306944;\n",
    "===========================================================\n",
    "Epoch 011/096 - Mean training loss 0.103725; Mean training F1 0.929350; Mean validation loss 0.115157; Mean validation F1 0.930975; Learning rate 0.000484;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.930975; loss - 0.115157;\n",
    "Group g4: f1 - 0.687923; loss - 0.302899;\n",
    "Group g9: f1 - 0.672907; loss - 0.307569;\n",
    "===========================================================\n",
    "Epoch 012/096 - Mean training loss 0.100236; Mean training F1 0.930743; Mean validation loss 0.106683; Mean validation F1 0.933651; Learning rate 0.000481;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933651; loss - 0.106683;\n",
    "Group g4: f1 - 0.695131; loss - 0.294411;\n",
    "Group g9: f1 - 0.681659; loss - 0.298825;\n",
    "===========================================================\n",
    "Epoch 013/096 - Mean training loss 0.101002; Mean training F1 0.930529; Mean validation loss 0.108693; Mean validation F1 0.931282; Learning rate 0.000478;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931282; loss - 0.108693;\n",
    "Group g4: f1 - 0.693105; loss - 0.295472;\n",
    "Group g9: f1 - 0.690533; loss - 0.297942;\n",
    "===========================================================\n",
    "Epoch 014/096 - Mean training loss 0.097831; Mean training F1 0.931887; Mean validation loss 0.103118; Mean validation F1 0.934280; Learning rate 0.000475;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934280; loss - 0.103118;\n",
    "Group g4: f1 - 0.715434; loss - 0.288954;\n",
    "Group g9: f1 - 0.701015; loss - 0.291927;\n",
    "===========================================================\n",
    "Epoch 015/096 - Mean training loss 0.099983; Mean training F1 0.931193; Mean validation loss 0.104215; Mean validation F1 0.932970; Learning rate 0.000471;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.932970; loss - 0.104215;\n",
    "Group g4: f1 - 0.703207; loss - 0.294690;\n",
    "Group g9: f1 - 0.699107; loss - 0.296799;\n",
    "===========================================================\n",
    "Epoch 016/096 - Mean training loss 0.097222; Mean training F1 0.931800; Mean validation loss 0.104477; Mean validation F1 0.933926; Learning rate 0.000467;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933926; loss - 0.104477;\n",
    "Group g4: f1 - 0.708486; loss - 0.287938;\n",
    "Group g9: f1 - 0.701171; loss - 0.290764;\n",
    "===========================================================\n",
    "Epoch 017/096 - Mean training loss 0.094865; Mean training F1 0.933265; Mean validation loss 2.473227; Mean validation F1 0.547947; Learning rate 0.000463;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.547947; loss - 2.473227;\n",
    "Group g4: f1 - 0.699808; loss - 0.295063;\n",
    "Group g9: f1 - 0.697508; loss - 0.297417;\n",
    "===========================================================\n",
    "Epoch 018/096 - Mean training loss 0.100333; Mean training F1 0.930619; Mean validation loss 0.104160; Mean validation F1 0.933063; Learning rate 0.000459;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933063; loss - 0.104160;\n",
    "Group g4: f1 - 0.706924; loss - 0.289112;\n",
    "Group g9: f1 - 0.701247; loss - 0.292049;\n",
    "===========================================================\n",
    "Epoch 019/096 - Mean training loss 0.094825; Mean training F1 0.932839; Mean validation loss 0.104812; Mean validation F1 0.932242; Learning rate 0.000454;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.932242; loss - 0.104812;\n",
    "Group g4: f1 - 0.715639; loss - 0.298614;\n",
    "Group g9: f1 - 0.695251; loss - 0.301347;\n",
    "===========================================================\n",
    "Epoch 020/096 - Mean training loss 0.092216; Mean training F1 0.934211; Mean validation loss 0.100596; Mean validation F1 0.935356; Learning rate 0.000449;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935356; loss - 0.100596;\n",
    "Group g4: f1 - 0.727374; loss - 0.283165;\n",
    "Group g9: f1 - 0.715682; loss - 0.285714;\n",
    "===========================================================\n",
    "Epoch 021/096 - Mean training loss 0.093169; Mean training F1 0.934137; Mean validation loss 0.100956; Mean validation F1 0.934775; Learning rate 0.000444;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934775; loss - 0.100956;\n",
    "Group g4: f1 - 0.719481; loss - 0.284662;\n",
    "Group g9: f1 - 0.703451; loss - 0.287424;\n",
    "===========================================================\n",
    "Epoch 022/096 - Mean training loss 0.090293; Mean training F1 0.935056; Mean validation loss 0.100442; Mean validation F1 0.934923; Learning rate 0.000439;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934923; loss - 0.100442;\n",
    "Group g4: f1 - 0.743023; loss - 0.286351;\n",
    "Group g9: f1 - 0.730424; loss - 0.289388;\n",
    "===========================================================\n",
    "Epoch 023/096 - Mean training loss 0.091370; Mean training F1 0.934682; Mean validation loss 0.099756; Mean validation F1 0.935114; Learning rate 0.000433;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935114; loss - 0.099756;\n",
    "Group g4: f1 - 0.719457; loss - 0.288058;\n",
    "Group g9: f1 - 0.709003; loss - 0.291057;\n",
    "===========================================================\n",
    "Epoch 024/096 - Mean training loss 0.092189; Mean training F1 0.934319; Mean validation loss 0.102692; Mean validation F1 0.933886; Learning rate 0.000428;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933886; loss - 0.102692;\n",
    "Group g4: f1 - 0.727485; loss - 0.288587;\n",
    "Group g9: f1 - 0.712811; loss - 0.290869;\n",
    "===========================================================\n",
    "Epoch 025/096 - Mean training loss 0.093378; Mean training F1 0.933487; Mean validation loss 0.099419; Mean validation F1 0.935021; Learning rate 0.000422;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935021; loss - 0.099419;\n",
    "Group g4: f1 - 0.732282; loss - 0.287021;\n",
    "Group g9: f1 - 0.716334; loss - 0.289112;\n",
    "===========================================================\n",
    "Epoch 026/096 - Mean training loss 0.090389; Mean training F1 0.934038; Mean validation loss 0.100089; Mean validation F1 0.934839; Learning rate 0.000416;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934839; loss - 0.100089;\n",
    "Group g4: f1 - 0.752058; loss - 0.285275;\n",
    "Group g9: f1 - 0.733685; loss - 0.288960;\n",
    "===========================================================\n",
    "Epoch 027/096 - Mean training loss 0.088287; Mean training F1 0.935444; Mean validation loss 0.101735; Mean validation F1 0.932710; Learning rate 0.000410;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.932710; loss - 0.101735;\n",
    "Group g4: f1 - 0.744027; loss - 0.301351;\n",
    "Group g9: f1 - 0.730466; loss - 0.303563;\n",
    "===========================================================\n",
    "Epoch 028/096 - Mean training loss 0.088488; Mean training F1 0.935047; Mean validation loss 0.102421; Mean validation F1 0.931408; Learning rate 0.000403;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931408; loss - 0.102421;\n",
    "Group g4: f1 - 0.735314; loss - 0.305851;\n",
    "Group g9: f1 - 0.716519; loss - 0.309377;\n",
    "===========================================================\n",
    "Epoch 029/096 - Mean training loss 0.090076; Mean training F1 0.934683; Mean validation loss 0.101714; Mean validation F1 0.932870; Learning rate 0.000397;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.932870; loss - 0.101714;\n",
    "Group g4: f1 - 0.741296; loss - 0.288775;\n",
    "Group g9: f1 - 0.725581; loss - 0.291762;\n",
    "===========================================================\n",
    "Epoch 030/096 - Mean training loss 0.087586; Mean training F1 0.935837; Mean validation loss 0.096481; Mean validation F1 0.936173; Learning rate 0.000390;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936173; loss - 0.096481;\n",
    "Group g4: f1 - 0.756690; loss - 0.282439;\n",
    "Group g9: f1 - 0.749811; loss - 0.285475;\n",
    "===========================================================\n",
    "Epoch 031/096 - Mean training loss 0.087020; Mean training F1 0.935992; Mean validation loss 0.098596; Mean validation F1 0.934823; Learning rate 0.000383;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934823; loss - 0.098596;\n",
    "Group g4: f1 - 0.747017; loss - 0.286359;\n",
    "Group g9: f1 - 0.728124; loss - 0.289080;\n",
    "===========================================================\n",
    "Epoch 032/096 - Mean training loss 0.087751; Mean training F1 0.935795; Mean validation loss 0.097727; Mean validation F1 0.935383; Learning rate 0.000377;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935383; loss - 0.097727;\n",
    "Group g4: f1 - 0.754052; loss - 0.282735;\n",
    "Group g9: f1 - 0.724855; loss - 0.286837;\n",
    "===========================================================\n",
    "Epoch 033/096 - Mean training loss 0.086720; Mean training F1 0.935943; Mean validation loss 0.097163; Mean validation F1 0.935377; Learning rate 0.000369;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935377; loss - 0.097163;\n",
    "Group g4: f1 - 0.746234; loss - 0.285404;\n",
    "Group g9: f1 - 0.735107; loss - 0.288694;\n",
    "===========================================================\n",
    "Epoch 034/096 - Mean training loss 0.086079; Mean training F1 0.936229; Mean validation loss 0.096746; Mean validation F1 0.936080; Learning rate 0.000362;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936080; loss - 0.096746;\n",
    "Group g4: f1 - 0.763885; loss - 0.281799;\n",
    "Group g9: f1 - 0.761583; loss - 0.284654;\n",
    "===========================================================\n",
    "Epoch 035/096 - Mean training loss 0.085584; Mean training F1 0.936579; Mean validation loss 0.096313; Mean validation F1 0.936020; Learning rate 0.000355;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936020; loss - 0.096313;\n",
    "Group g4: f1 - 0.759385; loss - 0.281918;\n",
    "Group g9: f1 - 0.745836; loss - 0.284427;\n",
    "===========================================================\n",
    "Epoch 036/096 - Mean training loss 0.085592; Mean training F1 0.936364; Mean validation loss 0.095345; Mean validation F1 0.936079; Learning rate 0.000347;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936079; loss - 0.095345;\n",
    "Group g4: f1 - 0.768925; loss - 0.283340;\n",
    "Group g9: f1 - 0.756616; loss - 0.285376;\n",
    "===========================================================\n",
    "Epoch 037/096 - Mean training loss 0.087616; Mean training F1 0.935866; Mean validation loss 0.337776; Mean validation F1 0.855325; Learning rate 0.000340;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.855325; loss - 0.337776;\n",
    "Group g4: f1 - 0.424821; loss - 1.159881;\n",
    "Group g9: f1 - 0.424336; loss - 1.208244;\n",
    "===========================================================\n",
    "Epoch 038/096 - Mean training loss 0.110556; Mean training F1 0.924734; Mean validation loss 0.114834; Mean validation F1 0.930403; Learning rate 0.000332;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.930403; loss - 0.114834;\n",
    "Group g4: f1 - 0.742269; loss - 0.286648;\n",
    "Group g9: f1 - 0.713303; loss - 0.289775;\n",
    "===========================================================\n",
    "Epoch 039/096 - Mean training loss 0.092230; Mean training F1 0.933844; Mean validation loss 0.100971; Mean validation F1 0.935251; Learning rate 0.000325;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935251; loss - 0.100971;\n",
    "Group g4: f1 - 0.750414; loss - 0.283476;\n",
    "Group g9: f1 - 0.712773; loss - 0.288655;\n",
    "===========================================================\n",
    "Epoch 040/096 - Mean training loss 0.088620; Mean training F1 0.935741; Mean validation loss 0.098142; Mean validation F1 0.935808; Learning rate 0.000317;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935808; loss - 0.098142;\n",
    "Group g4: f1 - 0.763253; loss - 0.282174;\n",
    "Group g9: f1 - 0.738046; loss - 0.285499;\n",
    "===========================================================\n",
    "Epoch 041/096 - Mean training loss 0.088531; Mean training F1 0.935706; Mean validation loss 0.105305; Mean validation F1 0.933238; Learning rate 0.000309;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933238; loss - 0.105305;\n",
    "Group g4: f1 - 0.739755; loss - 0.284278;\n",
    "Group g9: f1 - 0.701439; loss - 0.291406;\n",
    "===========================================================\n",
    "Epoch 042/096 - Mean training loss 0.086889; Mean training F1 0.935887; Mean validation loss 0.096701; Mean validation F1 0.936305; Learning rate 0.000301;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936305; loss - 0.096701;\n",
    "Group g4: f1 - 0.762331; loss - 0.281552;\n",
    "Group g9: f1 - 0.743631; loss - 0.283930;\n",
    "===========================================================\n",
    "Epoch 043/096 - Mean training loss 0.085595; Mean training F1 0.936602; Mean validation loss 0.096782; Mean validation F1 0.935881; Learning rate 0.000293;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935881; loss - 0.096782;\n",
    "Group g4: f1 - 0.763323; loss - 0.281738;\n",
    "Group g9: f1 - 0.742803; loss - 0.284680;\n",
    "===========================================================\n",
    "Epoch 044/096 - Mean training loss 0.085427; Mean training F1 0.936665; Mean validation loss 0.097790; Mean validation F1 0.935892; Learning rate 0.000285;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935892; loss - 0.097790;\n",
    "Group g4: f1 - 0.776576; loss - 0.283062;\n",
    "Group g9: f1 - 0.756507; loss - 0.285691;\n",
    "===========================================================\n",
    "Epoch 045/096 - Mean training loss 0.084774; Mean training F1 0.936892; Mean validation loss 0.095474; Mean validation F1 0.936615; Learning rate 0.000277;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936615; loss - 0.095474;\n",
    "Group g4: f1 - 0.770722; loss - 0.280105;\n",
    "Group g9: f1 - 0.754750; loss - 0.282733;\n",
    "===========================================================\n",
    "Epoch 046/096 - Mean training loss 0.085705; Mean training F1 0.936585; Mean validation loss 0.097180; Mean validation F1 0.935993; Learning rate 0.000269;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935993; loss - 0.097180;\n",
    "Group g4: f1 - 0.764111; loss - 0.282122;\n",
    "Group g9: f1 - 0.750678; loss - 0.284823;\n",
    "===========================================================\n",
    "Epoch 047/096 - Mean training loss 0.085045; Mean training F1 0.936983; Mean validation loss 0.096310; Mean validation F1 0.936431; Learning rate 0.000261;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936431; loss - 0.096310;\n",
    "Group g4: f1 - 0.775605; loss - 0.280968;\n",
    "Group g9: f1 - 0.756802; loss - 0.284030;\n",
    "===========================================================\n",
    "Epoch 048/096 - Mean training loss 0.084926; Mean training F1 0.936753; Mean validation loss 0.097122; Mean validation F1 0.935468; Learning rate 0.000253;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935468; loss - 0.097122;\n",
    "Group g4: f1 - 0.766713; loss - 0.286048;\n",
    "Group g9: f1 - 0.753681; loss - 0.288334;\n",
    "===========================================================\n",
    "Epoch 049/096 - Mean training loss 0.085126; Mean training F1 0.936690; Mean validation loss 0.096083; Mean validation F1 0.936400; Learning rate 0.000245;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936400; loss - 0.096083;\n",
    "Group g4: f1 - 0.758140; loss - 0.279847;\n",
    "Group g9: f1 - 0.730008; loss - 0.283902;\n",
    "===========================================================\n",
    "Epoch 050/096 - Mean training loss 0.084849; Mean training F1 0.936993; Mean validation loss 0.096645; Mean validation F1 0.935704; Learning rate 0.000237;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935704; loss - 0.096645;\n",
    "Group g4: f1 - 0.772152; loss - 0.286617;\n",
    "Group g9: f1 - 0.756273; loss - 0.288881;\n",
    "===========================================================\n",
    "Epoch 051/096 - Mean training loss 0.084320; Mean training F1 0.937139; Mean validation loss 0.095257; Mean validation F1 0.936853; Learning rate 0.000228;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936853; loss - 0.095257;\n",
    "Group g4: f1 - 0.769474; loss - 0.279581;\n",
    "Group g9: f1 - 0.752878; loss - 0.282694;\n",
    "===========================================================\n",
    "Epoch 052/096 - Mean training loss 0.083797; Mean training F1 0.937295; Mean validation loss 0.096883; Mean validation F1 0.935651; Learning rate 0.000220;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935651; loss - 0.096883;\n",
    "Group g4: f1 - 0.761780; loss - 0.280841;\n",
    "Group g9: f1 - 0.747747; loss - 0.284355;\n",
    "===========================================================\n",
    "Epoch 053/096 - Mean training loss 0.084281; Mean training F1 0.937147; Mean validation loss 0.096030; Mean validation F1 0.936517; Learning rate 0.000212;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936517; loss - 0.096030;\n",
    "Group g4: f1 - 0.772774; loss - 0.280722;\n",
    "Group g9: f1 - 0.758853; loss - 0.283415;\n",
    "===========================================================\n",
    "Epoch 054/096 - Mean training loss 0.083617; Mean training F1 0.937510; Mean validation loss 0.095735; Mean validation F1 0.935738; Learning rate 0.000204;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935738; loss - 0.095735;\n",
    "Group g4: f1 - 0.765342; loss - 0.281372;\n",
    "Group g9: f1 - 0.750873; loss - 0.284371;\n",
    "===========================================================\n",
    "Epoch 055/096 - Mean training loss 0.084005; Mean training F1 0.937508; Mean validation loss 0.094728; Mean validation F1 0.936933; Learning rate 0.000197;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936933; loss - 0.094728;\n",
    "Group g4: f1 - 0.767854; loss - 0.278949;\n",
    "Group g9: f1 - 0.748707; loss - 0.282157;\n",
    "===========================================================\n",
    "Epoch 056/096 - Mean training loss 0.084284; Mean training F1 0.937319; Mean validation loss 0.094889; Mean validation F1 0.936785; Learning rate 0.000189;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936785; loss - 0.094889;\n",
    "Group g4: f1 - 0.775214; loss - 0.280824;\n",
    "Group g9: f1 - 0.761044; loss - 0.283404;\n",
    "===========================================================\n",
    "Epoch 057/096 - Mean training loss 0.084083; Mean training F1 0.937464; Mean validation loss 0.095105; Mean validation F1 0.936303; Learning rate 0.000181;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936303; loss - 0.095105;\n",
    "Group g4: f1 - 0.781560; loss - 0.280946;\n",
    "Group g9: f1 - 0.765025; loss - 0.283818;\n",
    "===========================================================\n",
    "Epoch 058/096 - Mean training loss 0.083818; Mean training F1 0.937254; Mean validation loss 0.095519; Mean validation F1 0.936675; Learning rate 0.000173;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936675; loss - 0.095519;\n",
    "Group g4: f1 - 0.778119; loss - 0.279467;\n",
    "Group g9: f1 - 0.765609; loss - 0.281926;\n",
    "===========================================================\n",
    "Epoch 059/096 - Mean training loss 0.083642; Mean training F1 0.937432; Mean validation loss 0.094405; Mean validation F1 0.936711; Learning rate 0.000166;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936711; loss - 0.094405;\n",
    "Group g4: f1 - 0.786547; loss - 0.278870;\n",
    "Group g9: f1 - 0.772766; loss - 0.281638;\n",
    "===========================================================\n",
    "Epoch 060/096 - Mean training loss 0.083810; Mean training F1 0.937408; Mean validation loss 0.094616; Mean validation F1 0.936832; Learning rate 0.000158;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936832; loss - 0.094616;\n",
    "Group g4: f1 - 0.780888; loss - 0.279476;\n",
    "Group g9: f1 - 0.769558; loss - 0.282150;\n",
    "===========================================================\n",
    "Epoch 061/096 - Mean training loss 0.083607; Mean training F1 0.937372; Mean validation loss 0.094698; Mean validation F1 0.936791; Learning rate 0.000151;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936791; loss - 0.094698;\n",
    "Group g4: f1 - 0.781398; loss - 0.280326;\n",
    "Group g9: f1 - 0.762630; loss - 0.283026;\n",
    "===========================================================\n",
    "Epoch 062/096 - Mean training loss 0.083657; Mean training F1 0.937344; Mean validation loss 0.094788; Mean validation F1 0.936596; Learning rate 0.000143;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936596; loss - 0.094788;\n",
    "Group g4: f1 - 0.773113; loss - 0.279317;\n",
    "Group g9: f1 - 0.762279; loss - 0.281974;\n",
    "===========================================================\n",
    "Epoch 063/096 - Mean training loss 0.083876; Mean training F1 0.937623; Mean validation loss 0.095425; Mean validation F1 0.936659; Learning rate 0.000136;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936659; loss - 0.095425;\n",
    "Group g4: f1 - 0.773531; loss - 0.279322;\n",
    "Group g9: f1 - 0.767125; loss - 0.281714;\n",
    "===========================================================\n",
    "Epoch 064/096 - Mean training loss 0.082714; Mean training F1 0.937725; Mean validation loss 0.094102; Mean validation F1 0.937108; Learning rate 0.000129;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937108; loss - 0.094102;\n",
    "Group g4: f1 - 0.785112; loss - 0.278415;\n",
    "Group g9: f1 - 0.772139; loss - 0.281117;\n",
    "===========================================================\n",
    "Epoch 065/096 - Mean training loss 0.083418; Mean training F1 0.937595; Mean validation loss 0.094917; Mean validation F1 0.936542; Learning rate 0.000122;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936542; loss - 0.094917;\n",
    "Group g4: f1 - 0.788158; loss - 0.279533;\n",
    "Group g9: f1 - 0.773232; loss - 0.282104;\n",
    "===========================================================\n",
    "Epoch 066/096 - Mean training loss 0.083197; Mean training F1 0.937524; Mean validation loss 0.094275; Mean validation F1 0.937026; Learning rate 0.000115;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937026; loss - 0.094275;\n",
    "Group g4: f1 - 0.779089; loss - 0.278401;\n",
    "Group g9: f1 - 0.765053; loss - 0.281027;\n",
    "===========================================================\n",
    "Epoch 067/096 - Mean training loss 0.082843; Mean training F1 0.937713; Mean validation loss 0.094205; Mean validation F1 0.937068; Learning rate 0.000109;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937068; loss - 0.094205;\n",
    "Group g4: f1 - 0.777102; loss - 0.278301;\n",
    "Group g9: f1 - 0.762480; loss - 0.281036;\n",
    "===========================================================\n",
    "Epoch 068/096 - Mean training loss 0.082815; Mean training F1 0.937763; Mean validation loss 0.093941; Mean validation F1 0.936980; Learning rate 0.000102;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936980; loss - 0.093941;\n",
    "Group g4: f1 - 0.790123; loss - 0.278332;\n",
    "Group g9: f1 - 0.771024; loss - 0.280991;\n",
    "===========================================================\n",
    "Epoch 069/096 - Mean training loss 0.082724; Mean training F1 0.937846; Mean validation loss 0.094616; Mean validation F1 0.936832; Learning rate 0.000096;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936832; loss - 0.094616;\n",
    "Group g4: f1 - 0.780316; loss - 0.279126;\n",
    "Group g9: f1 - 0.763750; loss - 0.281535;\n",
    "===========================================================\n",
    "Epoch 070/096 - Mean training loss 0.082920; Mean training F1 0.937770; Mean validation loss 0.094418; Mean validation F1 0.936458; Learning rate 0.000090;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936458; loss - 0.094418;\n",
    "Group g4: f1 - 0.772877; loss - 0.279519;\n",
    "Group g9: f1 - 0.758192; loss - 0.282570;\n",
    "===========================================================\n",
    "Epoch 071/096 - Mean training loss 0.082636; Mean training F1 0.937784; Mean validation loss 0.094503; Mean validation F1 0.936871; Learning rate 0.000084;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936871; loss - 0.094503;\n",
    "Group g4: f1 - 0.773129; loss - 0.278685;\n",
    "Group g9: f1 - 0.759908; loss - 0.281257;\n",
    "===========================================================\n",
    "Epoch 072/096 - Mean training loss 0.082409; Mean training F1 0.937967; Mean validation loss 0.093823; Mean validation F1 0.936575; Learning rate 0.000078;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936575; loss - 0.093823;\n",
    "Group g4: f1 - 0.776995; loss - 0.278940;\n",
    "Group g9: f1 - 0.765301; loss - 0.281676;\n",
    "===========================================================\n",
    "Epoch 073/096 - Mean training loss 0.082304; Mean training F1 0.938019; Mean validation loss 0.093935; Mean validation F1 0.937082; Learning rate 0.000072;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937082; loss - 0.093935;\n",
    "Group g4: f1 - 0.782488; loss - 0.278313;\n",
    "Group g9: f1 - 0.772265; loss - 0.281075;\n",
    "===========================================================\n",
    "Epoch 074/096 - Mean training loss 0.082563; Mean training F1 0.937976; Mean validation loss 0.093823; Mean validation F1 0.936915; Learning rate 0.000067;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936915; loss - 0.093823;\n",
    "Group g4: f1 - 0.776109; loss - 0.278330;\n",
    "Group g9: f1 - 0.764209; loss - 0.281058;\n",
    "===========================================================\n",
    "Epoch 075/096 - Mean training loss 0.082440; Mean training F1 0.937953; Mean validation loss 0.093717; Mean validation F1 0.937261; Learning rate 0.000061;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937261; loss - 0.093717;\n",
    "Group g4: f1 - 0.778129; loss - 0.278028;\n",
    "Group g9: f1 - 0.766652; loss - 0.280667;\n",
    "===========================================================\n",
    "Epoch 076/096 - Mean training loss 0.082163; Mean training F1 0.938104; Mean validation loss 0.093766; Mean validation F1 0.937072; Learning rate 0.000056;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937072; loss - 0.093766;\n",
    "Group g4: f1 - 0.778516; loss - 0.278725;\n",
    "Group g9: f1 - 0.764315; loss - 0.281215;\n",
    "===========================================================\n",
    "Epoch 077/096 - Mean training loss 0.082668; Mean training F1 0.938062; Mean validation loss 0.093641; Mean validation F1 0.937036; Learning rate 0.000052;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937036; loss - 0.093641;\n",
    "Group g4: f1 - 0.785516; loss - 0.279068;\n",
    "Group g9: f1 - 0.771383; loss - 0.281642;\n",
    "===========================================================\n",
    "Epoch 078/096 - Mean training loss 0.082133; Mean training F1 0.938158; Mean validation loss 0.093596; Mean validation F1 0.937232; Learning rate 0.000047;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937232; loss - 0.093596;\n",
    "Group g4: f1 - 0.779626; loss - 0.277912;\n",
    "Group g9: f1 - 0.768404; loss - 0.280573;\n",
    "===========================================================\n",
    "Epoch 079/096 - Mean training loss 0.082052; Mean training F1 0.938124; Mean validation loss 0.094021; Mean validation F1 0.936914; Learning rate 0.000043;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936914; loss - 0.094021;\n",
    "Group g4: f1 - 0.786431; loss - 0.278243;\n",
    "Group g9: f1 - 0.772252; loss - 0.280938;\n",
    "===========================================================\n",
    "Epoch 080/096 - Mean training loss 0.082072; Mean training F1 0.938093; Mean validation loss 0.093451; Mean validation F1 0.937366; Learning rate 0.000038;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937366; loss - 0.093451;\n",
    "Group g4: f1 - 0.785429; loss - 0.277833;\n",
    "Group g9: f1 - 0.770293; loss - 0.280555;\n",
    "===========================================================\n",
    "Epoch 081/096 - Mean training loss 0.081896; Mean training F1 0.938147; Mean validation loss 0.093469; Mean validation F1 0.936902; Learning rate 0.000034;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936902; loss - 0.093469;\n",
    "Group g4: f1 - 0.784784; loss - 0.278152;\n",
    "Group g9: f1 - 0.770865; loss - 0.280966;\n",
    "===========================================================\n",
    "Epoch 082/096 - Mean training loss 0.082216; Mean training F1 0.938231; Mean validation loss 0.093677; Mean validation F1 0.936926; Learning rate 0.000031;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936926; loss - 0.093677;\n",
    "Group g4: f1 - 0.783346; loss - 0.278240;\n",
    "Group g9: f1 - 0.767361; loss - 0.281264;\n",
    "===========================================================\n",
    "Epoch 083/096 - Mean training loss 0.082308; Mean training F1 0.938312; Mean validation loss 0.093548; Mean validation F1 0.937267; Learning rate 0.000027;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937267; loss - 0.093548;\n",
    "Group g4: f1 - 0.782591; loss - 0.277780;\n",
    "Group g9: f1 - 0.767342; loss - 0.280558;\n",
    "===========================================================\n",
    "Epoch 084/096 - Mean training loss 0.081863; Mean training F1 0.938279; Mean validation loss 0.093245; Mean validation F1 0.937330; Learning rate 0.000024;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937330; loss - 0.093245;\n",
    "Group g4: f1 - 0.786358; loss - 0.277847;\n",
    "Group g9: f1 - 0.774353; loss - 0.280428;\n",
    "===========================================================\n",
    "Epoch 085/096 - Mean training loss 0.082186; Mean training F1 0.938291; Mean validation loss 0.093488; Mean validation F1 0.936983; Learning rate 0.000021;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936983; loss - 0.093488;\n",
    "Group g4: f1 - 0.783135; loss - 0.277853;\n",
    "Group g9: f1 - 0.768891; loss - 0.280649;\n",
    "===========================================================\n",
    "Epoch 086/096 - Mean training loss 0.082088; Mean training F1 0.938119; Mean validation loss 0.093331; Mean validation F1 0.937082; Learning rate 0.000018;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937082; loss - 0.093331;\n",
    "Group g4: f1 - 0.780842; loss - 0.277787;\n",
    "Group g9: f1 - 0.766310; loss - 0.280600;\n",
    "===========================================================\n",
    "Epoch 087/096 - Mean training loss 0.081906; Mean training F1 0.938251; Mean validation loss 0.093522; Mean validation F1 0.937114; Learning rate 0.000016;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937114; loss - 0.093522;\n",
    "Group g4: f1 - 0.785188; loss - 0.277824;\n",
    "Group g9: f1 - 0.769878; loss - 0.280751;\n",
    "===========================================================\n",
    "Epoch 088/096 - Mean training loss 0.081814; Mean training F1 0.938282; Mean validation loss 0.093209; Mean validation F1 0.937330; Learning rate 0.000014;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937330; loss - 0.093209;\n",
    "Group g4: f1 - 0.784121; loss - 0.277747;\n",
    "Group g9: f1 - 0.772818; loss - 0.280415;\n",
    "===========================================================\n",
    "Epoch 089/096 - Mean training loss 0.082022; Mean training F1 0.938378; Mean validation loss 0.093249; Mean validation F1 0.937191; Learning rate 0.000012;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937191; loss - 0.093249;\n",
    "Group g4: f1 - 0.784276; loss - 0.277725;\n",
    "Group g9: f1 - 0.773646; loss - 0.280348;\n",
    "===========================================================\n",
    "Epoch 090/096 - Mean training loss 0.082106; Mean training F1 0.938261; Mean validation loss 0.093332; Mean validation F1 0.937098; Learning rate 0.000010;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937098; loss - 0.093332;\n",
    "Group g4: f1 - 0.784168; loss - 0.277742;\n",
    "Group g9: f1 - 0.772200; loss - 0.280505;\n",
    "===========================================================\n",
    "Epoch 091/096 - Mean training loss 0.082060; Mean training F1 0.938209; Mean validation loss 0.093271; Mean validation F1 0.937174; Learning rate 0.000008;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937174; loss - 0.093271;\n",
    "Group g4: f1 - 0.787384; loss - 0.277720;\n",
    "Group g9: f1 - 0.773132; loss - 0.280322;\n",
    "===========================================================\n",
    "Epoch 092/096 - Mean training loss 0.081804; Mean training F1 0.938250; Mean validation loss 0.093299; Mean validation F1 0.937183; Learning rate 0.000007;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937183; loss - 0.093299;\n",
    "Group g4: f1 - 0.784592; loss - 0.277646;\n",
    "Group g9: f1 - 0.771839; loss - 0.280345;\n",
    "===========================================================\n",
    "Epoch 093/096 - Mean training loss 0.082024; Mean training F1 0.938258; Mean validation loss 0.093186; Mean validation F1 0.937114; Learning rate 0.000006;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937114; loss - 0.093186;\n",
    "Group g4: f1 - 0.787165; loss - 0.277632;\n",
    "Group g9: f1 - 0.775609; loss - 0.280294;\n",
    "===========================================================\n",
    "Epoch 094/096 - Mean training loss 0.081500; Mean training F1 0.938390; Mean validation loss 0.093232; Mean validation F1 0.937166; Learning rate 0.000006;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937166; loss - 0.093232;\n",
    "Group g4: f1 - 0.785115; loss - 0.277731;\n",
    "Group g9: f1 - 0.772650; loss - 0.280450;\n",
    "===========================================================\n",
    "Epoch 095/096 - Mean training loss 0.082024; Mean training F1 0.938224; Mean validation loss 0.093324; Mean validation F1 0.937077; Learning rate 0.000005;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937077; loss - 0.093324;\n",
    "Group g4: f1 - 0.783672; loss - 0.277665;\n",
    "Group g9: f1 - 0.771715; loss - 0.280457;\n",
    "===========================================================\n",
    "Epoch 096/096 - Mean training loss 0.081671; Mean training F1 0.938488; Mean validation loss 0.093132; Mean validation F1 0.937122; Learning rate 0.000005;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937122; loss - 0.093132;\n",
    "Group g4: f1 - 0.785461; loss - 0.277590;\n",
    "Group g9: f1 - 0.773601; loss - 0.280268;\n",
    "################################################################\n",
    "Training/validation for fold 3/5;\n",
    "===========================================================\n",
    "Epoch 001/096 - Mean training loss 0.763121; Mean training F1 0.651667; Mean validation loss 0.439208; Mean validation F1 0.818756; Learning rate 0.000500;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.818756; loss - 0.439208;\n",
    "Group g4: f1 - 0.368737; loss - 0.873856;\n",
    "Group g9: f1 - 0.367032; loss - 0.893864;\n",
    "===========================================================\n",
    "Epoch 002/096 - Mean training loss 0.282316; Mean training F1 0.865026; Mean validation loss 0.212589; Mean validation F1 0.889604; Learning rate 0.000500;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.889604; loss - 0.212589;\n",
    "Group g4: f1 - 0.452410; loss - 0.543957;\n",
    "Group g9: f1 - 0.448206; loss - 0.568592;\n",
    "===========================================================\n",
    "Epoch 003/096 - Mean training loss 0.187870; Mean training F1 0.899551; Mean validation loss 0.186499; Mean validation F1 0.891912; Learning rate 0.000499;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.891912; loss - 0.186499;\n",
    "Group g4: f1 - 0.539770; loss - 0.420241;\n",
    "Group g9: f1 - 0.533693; loss - 0.438170;\n",
    "===========================================================\n",
    "Epoch 004/096 - Mean training loss 0.168252; Mean training F1 0.906559; Mean validation loss 0.159783; Mean validation F1 0.912169; Learning rate 0.000498;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.912169; loss - 0.159783;\n",
    "Group g4: f1 - 0.598601; loss - 0.321097;\n",
    "Group g9: f1 - 0.598414; loss - 0.325421;\n",
    "===========================================================\n",
    "Epoch 005/096 - Mean training loss 0.161611; Mean training F1 0.907188; Mean validation loss 0.136787; Mean validation F1 0.919610; Learning rate 0.000497;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.919610; loss - 0.136787;\n",
    "Group g4: f1 - 0.566500; loss - 0.397347;\n",
    "Group g9: f1 - 0.561545; loss - 0.413932;\n",
    "===========================================================\n",
    "Epoch 006/096 - Mean training loss 0.139504; Mean training F1 0.915523; Mean validation loss 0.122223; Mean validation F1 0.927004; Learning rate 0.000496;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.927004; loss - 0.122223;\n",
    "Group g4: f1 - 0.589323; loss - 0.356764;\n",
    "Group g9: f1 - 0.585634; loss - 0.367656;\n",
    "===========================================================\n",
    "Epoch 007/096 - Mean training loss 0.129724; Mean training F1 0.920022; Mean validation loss 0.123147; Mean validation F1 0.924263; Learning rate 0.000494;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.924263; loss - 0.123147;\n",
    "Group g4: f1 - 0.624232; loss - 0.320478;\n",
    "Group g9: f1 - 0.622819; loss - 0.324413;\n",
    "===========================================================\n",
    "Epoch 008/096 - Mean training loss 0.126556; Mean training F1 0.921260; Mean validation loss 0.186368; Mean validation F1 0.904181; Learning rate 0.000492;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.904181; loss - 0.186368;\n",
    "Group g4: f1 - 0.610036; loss - 0.333681;\n",
    "Group g9: f1 - 0.606637; loss - 0.340709;\n",
    "===========================================================\n",
    "Epoch 009/096 - Mean training loss 0.129213; Mean training F1 0.920160; Mean validation loss 0.116067; Mean validation F1 0.928616; Learning rate 0.000490;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.928616; loss - 0.116067;\n",
    "Group g4: f1 - 0.636354; loss - 0.315635;\n",
    "Group g9: f1 - 0.634294; loss - 0.321603;\n",
    "===========================================================\n",
    "Epoch 010/096 - Mean training loss 0.127516; Mean training F1 0.921083; Mean validation loss 0.116430; Mean validation F1 0.926868; Learning rate 0.000487;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.926868; loss - 0.116430;\n",
    "Group g4: f1 - 0.617814; loss - 0.339946;\n",
    "Group g9: f1 - 0.612607; loss - 0.348987;\n",
    "===========================================================\n",
    "Epoch 011/096 - Mean training loss 0.119297; Mean training F1 0.924229; Mean validation loss 0.140841; Mean validation F1 0.920519; Learning rate 0.000484;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.920519; loss - 0.140841;\n",
    "Group g4: f1 - 0.628910; loss - 0.318926;\n",
    "Group g9: f1 - 0.626935; loss - 0.323802;\n",
    "===========================================================\n",
    "Epoch 012/096 - Mean training loss 0.119592; Mean training F1 0.924248; Mean validation loss 0.107431; Mean validation F1 0.931392; Learning rate 0.000481;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931392; loss - 0.107431;\n",
    "Group g4: f1 - 0.647982; loss - 0.307665;\n",
    "Group g9: f1 - 0.646025; loss - 0.312555;\n",
    "===========================================================\n",
    "Epoch 013/096 - Mean training loss 0.116346; Mean training F1 0.925138; Mean validation loss 0.115815; Mean validation F1 0.927936; Learning rate 0.000478;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.927936; loss - 0.115815;\n",
    "Group g4: f1 - 0.631011; loss - 0.332561;\n",
    "Group g9: f1 - 0.623329; loss - 0.343833;\n",
    "===========================================================\n",
    "Epoch 014/096 - Mean training loss 0.132605; Mean training F1 0.919430; Mean validation loss 0.107483; Mean validation F1 0.931709; Learning rate 0.000475;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931709; loss - 0.107483;\n",
    "Group g4: f1 - 0.641405; loss - 0.314489;\n",
    "Group g9: f1 - 0.639110; loss - 0.319983;\n",
    "===========================================================\n",
    "Epoch 015/096 - Mean training loss 0.115243; Mean training F1 0.926352; Mean validation loss 0.115345; Mean validation F1 0.927272; Learning rate 0.000471;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.927272; loss - 0.115345;\n",
    "Group g4: f1 - 0.666317; loss - 0.313022;\n",
    "Group g9: f1 - 0.662124; loss - 0.314270;\n",
    "===========================================================\n",
    "Epoch 016/096 - Mean training loss 0.105748; Mean training F1 0.929342; Mean validation loss 0.394229; Mean validation F1 0.802684; Learning rate 0.000467;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.802684; loss - 0.394229;\n",
    "Group g4: f1 - 0.678990; loss - 0.298350;\n",
    "Group g9: f1 - 0.675545; loss - 0.301330;\n",
    "===========================================================\n",
    "Epoch 017/096 - Mean training loss 0.103378; Mean training F1 0.930275; Mean validation loss 0.101326; Mean validation F1 0.932891; Learning rate 0.000463;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.932891; loss - 0.101326;\n",
    "Group g4: f1 - 0.693252; loss - 0.293312;\n",
    "Group g9: f1 - 0.683749; loss - 0.296256;\n",
    "===========================================================\n",
    "Epoch 018/096 - Mean training loss 0.099343; Mean training F1 0.931188; Mean validation loss 0.108995; Mean validation F1 0.930217; Learning rate 0.000459;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.930217; loss - 0.108995;\n",
    "Group g4: f1 - 0.695898; loss - 0.294831;\n",
    "Group g9: f1 - 0.687659; loss - 0.298409;\n",
    "===========================================================\n",
    "Epoch 019/096 - Mean training loss 0.107831; Mean training F1 0.928727; Mean validation loss 0.102767; Mean validation F1 0.931771; Learning rate 0.000454;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931771; loss - 0.102767;\n",
    "Group g4: f1 - 0.687896; loss - 0.296793;\n",
    "Group g9: f1 - 0.679876; loss - 0.300145;\n",
    "===========================================================\n",
    "Epoch 020/096 - Mean training loss 0.096623; Mean training F1 0.932942; Mean validation loss 0.099227; Mean validation F1 0.934775; Learning rate 0.000449;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934775; loss - 0.099227;\n",
    "Group g4: f1 - 0.708594; loss - 0.285521;\n",
    "Group g9: f1 - 0.703271; loss - 0.288325;\n",
    "===========================================================\n",
    "Epoch 021/096 - Mean training loss 0.094730; Mean training F1 0.932642; Mean validation loss 0.100734; Mean validation F1 0.931117; Learning rate 0.000444;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931117; loss - 0.100734;\n",
    "Group g4: f1 - 0.704017; loss - 0.299325;\n",
    "Group g9: f1 - 0.696257; loss - 0.302317;\n",
    "===========================================================\n",
    "Epoch 022/096 - Mean training loss 0.096006; Mean training F1 0.932115; Mean validation loss 0.100226; Mean validation F1 0.931210; Learning rate 0.000439;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931210; loss - 0.100226;\n",
    "Group g4: f1 - 0.704143; loss - 0.294030;\n",
    "Group g9: f1 - 0.699104; loss - 0.297427;\n",
    "===========================================================\n",
    "Epoch 023/096 - Mean training loss 0.094215; Mean training F1 0.933678; Mean validation loss 0.095137; Mean validation F1 0.935016; Learning rate 0.000433;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935016; loss - 0.095137;\n",
    "Group g4: f1 - 0.708215; loss - 0.287446;\n",
    "Group g9: f1 - 0.700964; loss - 0.290268;\n",
    "===========================================================\n",
    "Epoch 024/096 - Mean training loss 0.093915; Mean training F1 0.933854; Mean validation loss 0.097429; Mean validation F1 0.934220; Learning rate 0.000428;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934220; loss - 0.097429;\n",
    "Group g4: f1 - 0.693121; loss - 0.293853;\n",
    "Group g9: f1 - 0.686533; loss - 0.296263;\n",
    "===========================================================\n",
    "Epoch 025/096 - Mean training loss 0.093110; Mean training F1 0.934348; Mean validation loss 0.093093; Mean validation F1 0.935935; Learning rate 0.000422;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935935; loss - 0.093093;\n",
    "Group g4: f1 - 0.710746; loss - 0.283154;\n",
    "Group g9: f1 - 0.707929; loss - 0.285843;\n",
    "===========================================================\n",
    "Epoch 026/096 - Mean training loss 0.092065; Mean training F1 0.934043; Mean validation loss 0.096251; Mean validation F1 0.933936; Learning rate 0.000416;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933936; loss - 0.096251;\n",
    "Group g4: f1 - 0.716212; loss - 0.292726;\n",
    "Group g9: f1 - 0.708154; loss - 0.295684;\n",
    "===========================================================\n",
    "Epoch 027/096 - Mean training loss 0.091340; Mean training F1 0.934554; Mean validation loss 0.093307; Mean validation F1 0.935896; Learning rate 0.000410;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935896; loss - 0.093307;\n",
    "Group g4: f1 - 0.712156; loss - 0.284571;\n",
    "Group g9: f1 - 0.707662; loss - 0.286779;\n",
    "===========================================================\n",
    "Epoch 028/096 - Mean training loss 0.089714; Mean training F1 0.935395; Mean validation loss 0.093174; Mean validation F1 0.935538; Learning rate 0.000403;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935538; loss - 0.093174;\n",
    "Group g4: f1 - 0.710534; loss - 0.285474;\n",
    "Group g9: f1 - 0.708746; loss - 0.287728;\n",
    "===========================================================\n",
    "Epoch 029/096 - Mean training loss 0.090377; Mean training F1 0.934932; Mean validation loss 0.093497; Mean validation F1 0.936005; Learning rate 0.000397;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936005; loss - 0.093497;\n",
    "Group g4: f1 - 0.714713; loss - 0.282062;\n",
    "Group g9: f1 - 0.711131; loss - 0.284769;\n",
    "===========================================================\n",
    "Epoch 030/096 - Mean training loss 0.089126; Mean training F1 0.936015; Mean validation loss 0.092483; Mean validation F1 0.936064; Learning rate 0.000390;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936064; loss - 0.092483;\n",
    "Group g4: f1 - 0.711854; loss - 0.281855;\n",
    "Group g9: f1 - 0.707193; loss - 0.284326;\n",
    "===========================================================\n",
    "Epoch 031/096 - Mean training loss 0.089114; Mean training F1 0.935527; Mean validation loss 0.094139; Mean validation F1 0.934266; Learning rate 0.000383;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934266; loss - 0.094139;\n",
    "Group g4: f1 - 0.727105; loss - 0.284528;\n",
    "Group g9: f1 - 0.725811; loss - 0.287640;\n",
    "===========================================================\n",
    "Epoch 032/096 - Mean training loss 0.088792; Mean training F1 0.935752; Mean validation loss 0.095592; Mean validation F1 0.933836; Learning rate 0.000377;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933836; loss - 0.095592;\n",
    "Group g4: f1 - 0.711615; loss - 0.285606;\n",
    "Group g9: f1 - 0.708254; loss - 0.288770;\n",
    "===========================================================\n",
    "Epoch 033/096 - Mean training loss 0.088127; Mean training F1 0.935746; Mean validation loss 0.092883; Mean validation F1 0.935965; Learning rate 0.000369;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935965; loss - 0.092883;\n",
    "Group g4: f1 - 0.711570; loss - 0.282751;\n",
    "Group g9: f1 - 0.707583; loss - 0.285285;\n",
    "===========================================================\n",
    "Epoch 034/096 - Mean training loss 0.087335; Mean training F1 0.936338; Mean validation loss 0.092473; Mean validation F1 0.936186; Learning rate 0.000362;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936186; loss - 0.092473;\n",
    "Group g4: f1 - 0.717232; loss - 0.281465;\n",
    "Group g9: f1 - 0.712951; loss - 0.284027;\n",
    "===========================================================\n",
    "Epoch 035/096 - Mean training loss 0.088211; Mean training F1 0.935822; Mean validation loss 0.091986; Mean validation F1 0.936235; Learning rate 0.000355;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936235; loss - 0.091986;\n",
    "Group g4: f1 - 0.715165; loss - 0.280801;\n",
    "Group g9: f1 - 0.717951; loss - 0.283225;\n",
    "===========================================================\n",
    "Epoch 036/096 - Mean training loss 0.086668; Mean training F1 0.936531; Mean validation loss 0.091844; Mean validation F1 0.936065; Learning rate 0.000347;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936065; loss - 0.091844;\n",
    "Group g4: f1 - 0.724600; loss - 0.280832;\n",
    "Group g9: f1 - 0.721214; loss - 0.283492;\n",
    "===========================================================\n",
    "Epoch 037/096 - Mean training loss 0.087786; Mean training F1 0.935973; Mean validation loss 0.096714; Mean validation F1 0.934343; Learning rate 0.000340;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934343; loss - 0.096714;\n",
    "Group g4: f1 - 0.751414; loss - 0.289998;\n",
    "Group g9: f1 - 0.746021; loss - 0.292324;\n",
    "===========================================================\n",
    "Epoch 038/096 - Mean training loss 0.089766; Mean training F1 0.934609; Mean validation loss 0.094805; Mean validation F1 0.935155; Learning rate 0.000332;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935155; loss - 0.094805;\n",
    "Group g4: f1 - 0.715719; loss - 0.282764;\n",
    "Group g9: f1 - 0.714403; loss - 0.284958;\n",
    "===========================================================\n",
    "Epoch 039/096 - Mean training loss 0.089015; Mean training F1 0.935102; Mean validation loss 0.091925; Mean validation F1 0.935882; Learning rate 0.000325;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935882; loss - 0.091925;\n",
    "Group g4: f1 - 0.717465; loss - 0.280585;\n",
    "Group g9: f1 - 0.713416; loss - 0.283275;\n",
    "===========================================================\n",
    "Epoch 040/096 - Mean training loss 0.087428; Mean training F1 0.935816; Mean validation loss 0.097656; Mean validation F1 0.934533; Learning rate 0.000317;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934533; loss - 0.097656;\n",
    "Group g4: f1 - 0.714200; loss - 0.286712;\n",
    "Group g9: f1 - 0.702775; loss - 0.290294;\n",
    "===========================================================\n",
    "Epoch 041/096 - Mean training loss 0.086756; Mean training F1 0.936587; Mean validation loss 0.092496; Mean validation F1 0.935253; Learning rate 0.000309;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935253; loss - 0.092496;\n",
    "Group g4: f1 - 0.726321; loss - 0.284118;\n",
    "Group g9: f1 - 0.719890; loss - 0.286743;\n",
    "===========================================================\n",
    "Epoch 042/096 - Mean training loss 0.085489; Mean training F1 0.936924; Mean validation loss 0.092787; Mean validation F1 0.935810; Learning rate 0.000301;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935810; loss - 0.092787;\n",
    "Group g4: f1 - 0.713859; loss - 0.281602;\n",
    "Group g9: f1 - 0.710005; loss - 0.284251;\n",
    "===========================================================\n",
    "Epoch 043/096 - Mean training loss 0.085801; Mean training F1 0.936403; Mean validation loss 0.091789; Mean validation F1 0.935992; Learning rate 0.000293;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935992; loss - 0.091789;\n",
    "Group g4: f1 - 0.725210; loss - 0.281812;\n",
    "Group g9: f1 - 0.719397; loss - 0.284305;\n",
    "===========================================================\n",
    "Epoch 044/096 - Mean training loss 0.085651; Mean training F1 0.937095; Mean validation loss 0.092181; Mean validation F1 0.936086; Learning rate 0.000285;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936086; loss - 0.092181;\n",
    "Group g4: f1 - 0.715989; loss - 0.279924;\n",
    "Group g9: f1 - 0.713401; loss - 0.282530;\n",
    "===========================================================\n",
    "Epoch 045/096 - Mean training loss 0.085003; Mean training F1 0.937093; Mean validation loss 0.092563; Mean validation F1 0.935776; Learning rate 0.000277;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935776; loss - 0.092563;\n",
    "Group g4: f1 - 0.734201; loss - 0.281114;\n",
    "Group g9: f1 - 0.725760; loss - 0.283321;\n",
    "===========================================================\n",
    "Epoch 046/096 - Mean training loss 0.085175; Mean training F1 0.937069; Mean validation loss 0.093085; Mean validation F1 0.935551; Learning rate 0.000269;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935551; loss - 0.093085;\n",
    "Group g4: f1 - 0.742920; loss - 0.281643;\n",
    "Group g9: f1 - 0.732222; loss - 0.283836;\n",
    "===========================================================\n",
    "Epoch 047/096 - Mean training loss 0.085169; Mean training F1 0.937247; Mean validation loss 0.091469; Mean validation F1 0.935343; Learning rate 0.000261;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935343; loss - 0.091469;\n",
    "Group g4: f1 - 0.742591; loss - 0.282281;\n",
    "Group g9: f1 - 0.736273; loss - 0.284987;\n",
    "===========================================================\n",
    "Epoch 048/096 - Mean training loss 0.084743; Mean training F1 0.936985; Mean validation loss 0.091262; Mean validation F1 0.936372; Learning rate 0.000253;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936372; loss - 0.091262;\n",
    "Group g4: f1 - 0.758089; loss - 0.280420;\n",
    "Group g9: f1 - 0.747889; loss - 0.283227;\n",
    "===========================================================\n",
    "Epoch 049/096 - Mean training loss 0.085701; Mean training F1 0.936865; Mean validation loss 0.091528; Mean validation F1 0.936236; Learning rate 0.000245;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936236; loss - 0.091528;\n",
    "Group g4: f1 - 0.723169; loss - 0.281740;\n",
    "Group g9: f1 - 0.725987; loss - 0.284324;\n",
    "===========================================================\n",
    "Epoch 050/096 - Mean training loss 0.084871; Mean training F1 0.937122; Mean validation loss 0.090963; Mean validation F1 0.936594; Learning rate 0.000237;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936594; loss - 0.090963;\n",
    "Group g4: f1 - 0.754515; loss - 0.279256;\n",
    "Group g9: f1 - 0.746345; loss - 0.281676;\n",
    "===========================================================\n",
    "Epoch 051/096 - Mean training loss 0.084332; Mean training F1 0.937440; Mean validation loss 0.090908; Mean validation F1 0.936518; Learning rate 0.000228;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936518; loss - 0.090908;\n",
    "Group g4: f1 - 0.720564; loss - 0.279116;\n",
    "Group g9: f1 - 0.723478; loss - 0.281750;\n",
    "===========================================================\n",
    "Epoch 052/096 - Mean training loss 0.084592; Mean training F1 0.937289; Mean validation loss 0.090956; Mean validation F1 0.935929; Learning rate 0.000220;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935929; loss - 0.090956;\n",
    "Group g4: f1 - 0.743724; loss - 0.280022;\n",
    "Group g9: f1 - 0.731837; loss - 0.282433;\n",
    "===========================================================\n",
    "Epoch 053/096 - Mean training loss 0.084392; Mean training F1 0.937184; Mean validation loss 0.090715; Mean validation F1 0.936647; Learning rate 0.000212;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936647; loss - 0.090715;\n",
    "Group g4: f1 - 0.744029; loss - 0.278989;\n",
    "Group g9: f1 - 0.743503; loss - 0.281347;\n",
    "===========================================================\n",
    "Epoch 054/096 - Mean training loss 0.084835; Mean training F1 0.937524; Mean validation loss 0.091015; Mean validation F1 0.936567; Learning rate 0.000204;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936567; loss - 0.091015;\n",
    "Group g4: f1 - 0.738356; loss - 0.278523;\n",
    "Group g9: f1 - 0.726364; loss - 0.280844;\n",
    "===========================================================\n",
    "Epoch 055/096 - Mean training loss 0.084590; Mean training F1 0.937346; Mean validation loss 0.090732; Mean validation F1 0.936662; Learning rate 0.000197;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936662; loss - 0.090732;\n",
    "Group g4: f1 - 0.751382; loss - 0.280344;\n",
    "Group g9: f1 - 0.739551; loss - 0.282924;\n",
    "===========================================================\n",
    "Epoch 056/096 - Mean training loss 0.084276; Mean training F1 0.937465; Mean validation loss 0.090408; Mean validation F1 0.936439; Learning rate 0.000189;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936439; loss - 0.090408;\n",
    "Group g4: f1 - 0.756075; loss - 0.279476;\n",
    "Group g9: f1 - 0.750214; loss - 0.281789;\n",
    "===========================================================\n",
    "Epoch 057/096 - Mean training loss 0.084223; Mean training F1 0.937370; Mean validation loss 0.091209; Mean validation F1 0.936248; Learning rate 0.000181;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936248; loss - 0.091209;\n",
    "Group g4: f1 - 0.732439; loss - 0.281944;\n",
    "Group g9: f1 - 0.722680; loss - 0.284833;\n",
    "===========================================================\n",
    "Epoch 058/096 - Mean training loss 0.083964; Mean training F1 0.937634; Mean validation loss 0.090156; Mean validation F1 0.936546; Learning rate 0.000173;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936546; loss - 0.090156;\n",
    "Group g4: f1 - 0.730820; loss - 0.278500;\n",
    "Group g9: f1 - 0.729501; loss - 0.281198;\n",
    "===========================================================\n",
    "Epoch 059/096 - Mean training loss 0.083469; Mean training F1 0.937876; Mean validation loss 0.090849; Mean validation F1 0.936709; Learning rate 0.000166;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936709; loss - 0.090849;\n",
    "Group g4: f1 - 0.774300; loss - 0.278499;\n",
    "Group g9: f1 - 0.764758; loss - 0.280805;\n",
    "===========================================================\n",
    "Epoch 060/096 - Mean training loss 0.083261; Mean training F1 0.937955; Mean validation loss 0.090557; Mean validation F1 0.936648; Learning rate 0.000158;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936648; loss - 0.090557;\n",
    "Group g4: f1 - 0.733322; loss - 0.278596;\n",
    "Group g9: f1 - 0.729368; loss - 0.280986;\n",
    "===========================================================\n",
    "Epoch 061/096 - Mean training loss 0.083591; Mean training F1 0.937705; Mean validation loss 0.091256; Mean validation F1 0.935176; Learning rate 0.000151;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935176; loss - 0.091256;\n",
    "Group g4: f1 - 0.768677; loss - 0.282432;\n",
    "Group g9: f1 - 0.761013; loss - 0.285369;\n",
    "===========================================================\n",
    "Epoch 062/096 - Mean training loss 0.083197; Mean training F1 0.937961; Mean validation loss 0.090653; Mean validation F1 0.936640; Learning rate 0.000143;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936640; loss - 0.090653;\n",
    "Group g4: f1 - 0.770380; loss - 0.278204;\n",
    "Group g9: f1 - 0.758133; loss - 0.280378;\n",
    "===========================================================\n",
    "Epoch 063/096 - Mean training loss 0.082801; Mean training F1 0.938076; Mean validation loss 0.091017; Mean validation F1 0.936012; Learning rate 0.000136;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936012; loss - 0.091017;\n",
    "Group g4: f1 - 0.757073; loss - 0.279839;\n",
    "Group g9: f1 - 0.751203; loss - 0.282282;\n",
    "===========================================================\n",
    "Epoch 064/096 - Mean training loss 0.083138; Mean training F1 0.937628; Mean validation loss 0.091344; Mean validation F1 0.934535; Learning rate 0.000129;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934535; loss - 0.091344;\n",
    "Group g4: f1 - 0.752240; loss - 0.282839;\n",
    "Group g9: f1 - 0.749454; loss - 0.285341;\n",
    "===========================================================\n",
    "Epoch 065/096 - Mean training loss 0.083552; Mean training F1 0.937599; Mean validation loss 0.090180; Mean validation F1 0.936556; Learning rate 0.000122;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936556; loss - 0.090180;\n",
    "Group g4: f1 - 0.755304; loss - 0.279544;\n",
    "Group g9: f1 - 0.750759; loss - 0.281826;\n",
    "===========================================================\n",
    "Epoch 066/096 - Mean training loss 0.083203; Mean training F1 0.938064; Mean validation loss 0.089916; Mean validation F1 0.936573; Learning rate 0.000115;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936573; loss - 0.089916;\n",
    "Group g4: f1 - 0.755756; loss - 0.278072;\n",
    "Group g9: f1 - 0.752532; loss - 0.280517;\n",
    "===========================================================\n",
    "Epoch 067/096 - Mean training loss 0.083407; Mean training F1 0.937979; Mean validation loss 0.090944; Mean validation F1 0.936355; Learning rate 0.000109;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936355; loss - 0.090944;\n",
    "Group g4: f1 - 0.771388; loss - 0.279861;\n",
    "Group g9: f1 - 0.755444; loss - 0.281889;\n",
    "===========================================================\n",
    "Epoch 068/096 - Mean training loss 0.082854; Mean training F1 0.938158; Mean validation loss 0.090107; Mean validation F1 0.936771; Learning rate 0.000102;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936771; loss - 0.090107;\n",
    "Group g4: f1 - 0.754373; loss - 0.278021;\n",
    "Group g9: f1 - 0.746628; loss - 0.280334;\n",
    "===========================================================\n",
    "Epoch 069/096 - Mean training loss 0.082858; Mean training F1 0.937930; Mean validation loss 0.090889; Mean validation F1 0.936504; Learning rate 0.000096;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936504; loss - 0.090889;\n",
    "Group g4: f1 - 0.783718; loss - 0.278234;\n",
    "Group g9: f1 - 0.771671; loss - 0.280523;\n",
    "===========================================================\n",
    "Epoch 070/096 - Mean training loss 0.082711; Mean training F1 0.938289; Mean validation loss 0.090374; Mean validation F1 0.936853; Learning rate 0.000090;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936853; loss - 0.090374;\n",
    "Group g4: f1 - 0.752686; loss - 0.279016;\n",
    "Group g9: f1 - 0.748181; loss - 0.280924;\n",
    "===========================================================\n",
    "Epoch 071/096 - Mean training loss 0.082626; Mean training F1 0.938248; Mean validation loss 0.089997; Mean validation F1 0.936952; Learning rate 0.000084;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936952; loss - 0.089997;\n",
    "Group g4: f1 - 0.780429; loss - 0.277730;\n",
    "Group g9: f1 - 0.776273; loss - 0.280067;\n",
    "===========================================================\n",
    "Epoch 072/096 - Mean training loss 0.082625; Mean training F1 0.938292; Mean validation loss 0.089650; Mean validation F1 0.936859; Learning rate 0.000078;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936859; loss - 0.089650;\n",
    "Group g4: f1 - 0.755977; loss - 0.277983;\n",
    "Group g9: f1 - 0.747109; loss - 0.280282;\n",
    "===========================================================\n",
    "Epoch 073/096 - Mean training loss 0.081870; Mean training F1 0.938378; Mean validation loss 0.089480; Mean validation F1 0.936804; Learning rate 0.000072;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936804; loss - 0.089480;\n",
    "Group g4: f1 - 0.766774; loss - 0.277456;\n",
    "Group g9: f1 - 0.754243; loss - 0.279714;\n",
    "===========================================================\n",
    "Epoch 074/096 - Mean training loss 0.082178; Mean training F1 0.938322; Mean validation loss 0.089881; Mean validation F1 0.936714; Learning rate 0.000067;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936714; loss - 0.089881;\n",
    "Group g4: f1 - 0.751721; loss - 0.278111;\n",
    "Group g9: f1 - 0.750363; loss - 0.280579;\n",
    "===========================================================\n",
    "Epoch 075/096 - Mean training loss 0.081955; Mean training F1 0.938359; Mean validation loss 0.089601; Mean validation F1 0.936831; Learning rate 0.000061;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936831; loss - 0.089601;\n",
    "Group g4: f1 - 0.773679; loss - 0.277708;\n",
    "Group g9: f1 - 0.757559; loss - 0.280000;\n",
    "===========================================================\n",
    "Epoch 076/096 - Mean training loss 0.082182; Mean training F1 0.938111; Mean validation loss 0.090243; Mean validation F1 0.936768; Learning rate 0.000056;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936768; loss - 0.090243;\n",
    "Group g4: f1 - 0.754395; loss - 0.278543;\n",
    "Group g9: f1 - 0.750843; loss - 0.280620;\n",
    "===========================================================\n",
    "Epoch 077/096 - Mean training loss 0.082109; Mean training F1 0.938275; Mean validation loss 0.089808; Mean validation F1 0.936839; Learning rate 0.000052;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936839; loss - 0.089808;\n",
    "Group g4: f1 - 0.775652; loss - 0.277568;\n",
    "Group g9: f1 - 0.770004; loss - 0.279808;\n",
    "===========================================================\n",
    "Epoch 078/096 - Mean training loss 0.081843; Mean training F1 0.938506; Mean validation loss 0.089674; Mean validation F1 0.936999; Learning rate 0.000047;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936999; loss - 0.089674;\n",
    "Group g4: f1 - 0.773136; loss - 0.278315;\n",
    "Group g9: f1 - 0.758667; loss - 0.280300;\n",
    "===========================================================\n",
    "Epoch 079/096 - Mean training loss 0.081952; Mean training F1 0.938619; Mean validation loss 0.089442; Mean validation F1 0.937100; Learning rate 0.000043;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937100; loss - 0.089442;\n",
    "Group g4: f1 - 0.764251; loss - 0.277472;\n",
    "Group g9: f1 - 0.752675; loss - 0.279666;\n",
    "===========================================================\n",
    "Epoch 080/096 - Mean training loss 0.081843; Mean training F1 0.938560; Mean validation loss 0.089405; Mean validation F1 0.937219; Learning rate 0.000038;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937219; loss - 0.089405;\n",
    "Group g4: f1 - 0.781267; loss - 0.277192;\n",
    "Group g9: f1 - 0.773821; loss - 0.279453;\n",
    "===========================================================\n",
    "Epoch 081/096 - Mean training loss 0.081932; Mean training F1 0.938442; Mean validation loss 0.089455; Mean validation F1 0.937088; Learning rate 0.000034;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937088; loss - 0.089455;\n",
    "Group g4: f1 - 0.760891; loss - 0.277321;\n",
    "Group g9: f1 - 0.754650; loss - 0.279521;\n",
    "===========================================================\n",
    "Epoch 082/096 - Mean training loss 0.081946; Mean training F1 0.938520; Mean validation loss 0.089686; Mean validation F1 0.936787; Learning rate 0.000031;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936787; loss - 0.089686;\n",
    "Group g4: f1 - 0.768456; loss - 0.277504;\n",
    "Group g9: f1 - 0.754730; loss - 0.279650;\n",
    "===========================================================\n",
    "Epoch 083/096 - Mean training loss 0.081809; Mean training F1 0.938632; Mean validation loss 0.089661; Mean validation F1 0.936767; Learning rate 0.000027;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936767; loss - 0.089661;\n",
    "Group g4: f1 - 0.775076; loss - 0.277264;\n",
    "Group g9: f1 - 0.759358; loss - 0.279510;\n",
    "===========================================================\n",
    "Epoch 084/096 - Mean training loss 0.082025; Mean training F1 0.938617; Mean validation loss 0.089576; Mean validation F1 0.936804; Learning rate 0.000024;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936804; loss - 0.089576;\n",
    "Group g4: f1 - 0.766471; loss - 0.277215;\n",
    "Group g9: f1 - 0.754442; loss - 0.279575;\n",
    "===========================================================\n",
    "Epoch 085/096 - Mean training loss 0.081770; Mean training F1 0.938545; Mean validation loss 0.089482; Mean validation F1 0.937004; Learning rate 0.000021;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937004; loss - 0.089482;\n",
    "Group g4: f1 - 0.768192; loss - 0.277272;\n",
    "Group g9: f1 - 0.756775; loss - 0.279574;\n",
    "===========================================================\n",
    "Epoch 086/096 - Mean training loss 0.082049; Mean training F1 0.938675; Mean validation loss 0.089323; Mean validation F1 0.937247; Learning rate 0.000018;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937247; loss - 0.089323;\n",
    "Group g4: f1 - 0.766870; loss - 0.277343;\n",
    "Group g9: f1 - 0.755098; loss - 0.279549;\n",
    "===========================================================\n",
    "Epoch 087/096 - Mean training loss 0.081720; Mean training F1 0.938628; Mean validation loss 0.089366; Mean validation F1 0.937067; Learning rate 0.000016;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937067; loss - 0.089366;\n",
    "Group g4: f1 - 0.768210; loss - 0.277146;\n",
    "Group g9: f1 - 0.757358; loss - 0.279427;\n",
    "===========================================================\n",
    "Epoch 088/096 - Mean training loss 0.081698; Mean training F1 0.938520; Mean validation loss 0.089337; Mean validation F1 0.937125; Learning rate 0.000014;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937125; loss - 0.089337;\n",
    "Group g4: f1 - 0.777746; loss - 0.277042;\n",
    "Group g9: f1 - 0.765157; loss - 0.279262;\n",
    "===========================================================\n",
    "Epoch 089/096 - Mean training loss 0.081350; Mean training F1 0.938597; Mean validation loss 0.089308; Mean validation F1 0.937154; Learning rate 0.000012;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937154; loss - 0.089308;\n",
    "Group g4: f1 - 0.780909; loss - 0.277053;\n",
    "Group g9: f1 - 0.769567; loss - 0.279251;\n",
    "===========================================================\n",
    "Epoch 090/096 - Mean training loss 0.081429; Mean training F1 0.938712; Mean validation loss 0.089331; Mean validation F1 0.936999; Learning rate 0.000010;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936999; loss - 0.089331;\n",
    "Group g4: f1 - 0.772259; loss - 0.277096;\n",
    "Group g9: f1 - 0.759098; loss - 0.279333;\n",
    "===========================================================\n",
    "Epoch 091/096 - Mean training loss 0.081488; Mean training F1 0.938667; Mean validation loss 0.089301; Mean validation F1 0.937055; Learning rate 0.000008;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937055; loss - 0.089301;\n",
    "Group g4: f1 - 0.775225; loss - 0.277012;\n",
    "Group g9: f1 - 0.762479; loss - 0.279256;\n",
    "===========================================================\n",
    "Epoch 092/096 - Mean training loss 0.081629; Mean training F1 0.938743; Mean validation loss 0.089242; Mean validation F1 0.937133; Learning rate 0.000007;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937133; loss - 0.089242;\n",
    "Group g4: f1 - 0.776288; loss - 0.277087;\n",
    "Group g9: f1 - 0.759885; loss - 0.279289;\n",
    "===========================================================\n",
    "Epoch 093/096 - Mean training loss 0.081478; Mean training F1 0.938664; Mean validation loss 0.089282; Mean validation F1 0.937092; Learning rate 0.000006;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937092; loss - 0.089282;\n",
    "Group g4: f1 - 0.781195; loss - 0.277002;\n",
    "Group g9: f1 - 0.767320; loss - 0.279259;\n",
    "===========================================================\n",
    "Epoch 094/096 - Mean training loss 0.081592; Mean training F1 0.938732; Mean validation loss 0.089270; Mean validation F1 0.937224; Learning rate 0.000006;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937224; loss - 0.089270;\n",
    "Group g4: f1 - 0.777476; loss - 0.277021;\n",
    "Group g9: f1 - 0.762275; loss - 0.279261;\n",
    "===========================================================\n",
    "Epoch 095/096 - Mean training loss 0.081449; Mean training F1 0.938688; Mean validation loss 0.089372; Mean validation F1 0.936938; Learning rate 0.000005;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936938; loss - 0.089372;\n",
    "Group g4: f1 - 0.775657; loss - 0.277110;\n",
    "Group g9: f1 - 0.759711; loss - 0.279339;\n",
    "===========================================================\n",
    "Epoch 096/096 - Mean training loss 0.081612; Mean training F1 0.938587; Mean validation loss 0.089373; Mean validation F1 0.936973; Learning rate 0.000005;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936973; loss - 0.089373;\n",
    "Group g4: f1 - 0.769138; loss - 0.277306;\n",
    "Group g9: f1 - 0.756243; loss - 0.279592;\n",
    "################################################################\n",
    "Training/validation for fold 4/5;\n",
    "===========================================================\n",
    "Epoch 001/096 - Mean training loss 0.828376; Mean training F1 0.608460; Mean validation loss 0.440400; Mean validation F1 0.802206; Learning rate 0.000500;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.802206; loss - 0.440400;\n",
    "Group g4: f1 - 0.343679; loss - 1.084616;\n",
    "Group g9: f1 - 0.341812; loss - 1.108076;\n",
    "===========================================================\n",
    "Epoch 002/096 - Mean training loss 0.373437; Mean training F1 0.820623; Mean validation loss 0.348472; Mean validation F1 0.833253; Learning rate 0.000500;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.833253; loss - 0.348472;\n",
    "Group g4: f1 - 0.412482; loss - 0.884425;\n",
    "Group g9: f1 - 0.409672; loss - 0.927701;\n",
    "===========================================================\n",
    "Epoch 003/096 - Mean training loss 0.199103; Mean training F1 0.898350; Mean validation loss 0.139642; Mean validation F1 0.926736; Learning rate 0.000499;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.926736; loss - 0.139642;\n",
    "Group g4: f1 - 0.541499; loss - 0.358742;\n",
    "Group g9: f1 - 0.541085; loss - 0.363672;\n",
    "===========================================================\n",
    "Epoch 004/096 - Mean training loss 0.162731; Mean training F1 0.906045; Mean validation loss 0.151242; Mean validation F1 0.905035; Learning rate 0.000498;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.905035; loss - 0.151242;\n",
    "Group g4: f1 - 0.599907; loss - 0.361671;\n",
    "Group g9: f1 - 0.599514; loss - 0.364506;\n",
    "===========================================================\n",
    "Epoch 005/096 - Mean training loss 0.142507; Mean training F1 0.914643; Mean validation loss 0.129440; Mean validation F1 0.923343; Learning rate 0.000497;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.923343; loss - 0.129440;\n",
    "Group g4: f1 - 0.620804; loss - 0.320251;\n",
    "Group g9: f1 - 0.619406; loss - 0.323827;\n",
    "===========================================================\n",
    "Epoch 006/096 - Mean training loss 0.127031; Mean training F1 0.921668; Mean validation loss 0.106292; Mean validation F1 0.931646; Learning rate 0.000496;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931646; loss - 0.106292;\n",
    "Group g4: f1 - 0.642163; loss - 0.301685;\n",
    "Group g9: f1 - 0.638474; loss - 0.305116;\n",
    "===========================================================\n",
    "Epoch 007/096 - Mean training loss 0.120549; Mean training F1 0.924268; Mean validation loss 0.102646; Mean validation F1 0.931098; Learning rate 0.000494;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931098; loss - 0.102646;\n",
    "Group g4: f1 - 0.646372; loss - 0.321590;\n",
    "Group g9: f1 - 0.638554; loss - 0.325988;\n",
    "===========================================================\n",
    "Epoch 008/096 - Mean training loss 0.124866; Mean training F1 0.922359; Mean validation loss 0.135330; Mean validation F1 0.926101; Learning rate 0.000492;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.926101; loss - 0.135330;\n",
    "Group g4: f1 - 0.680779; loss - 0.301691;\n",
    "Group g9: f1 - 0.675560; loss - 0.304859;\n",
    "===========================================================\n",
    "Epoch 009/096 - Mean training loss 0.116918; Mean training F1 0.925602; Mean validation loss 0.114802; Mean validation F1 0.928012; Learning rate 0.000490;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.928012; loss - 0.114802;\n",
    "Group g4: f1 - 0.670434; loss - 0.305421;\n",
    "Group g9: f1 - 0.660841; loss - 0.309420;\n",
    "===========================================================\n",
    "Epoch 010/096 - Mean training loss 0.115021; Mean training F1 0.925952; Mean validation loss 2.404871; Mean validation F1 0.489846; Learning rate 0.000487;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.489846; loss - 2.404871;\n",
    "Group g4: f1 - 0.680490; loss - 0.325735;\n",
    "Group g9: f1 - 0.674325; loss - 0.328552;\n",
    "===========================================================\n",
    "Epoch 011/096 - Mean training loss 0.107227; Mean training F1 0.928963; Mean validation loss 0.097242; Mean validation F1 0.934442; Learning rate 0.000484;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934442; loss - 0.097242;\n",
    "Group g4: f1 - 0.713061; loss - 0.290957;\n",
    "Group g9: f1 - 0.707796; loss - 0.294117;\n",
    "===========================================================\n",
    "Epoch 012/096 - Mean training loss 0.109651; Mean training F1 0.928263; Mean validation loss 0.097253; Mean validation F1 0.934621; Learning rate 0.000481;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934621; loss - 0.097253;\n",
    "Group g4: f1 - 0.702873; loss - 0.291976;\n",
    "Group g9: f1 - 0.695107; loss - 0.295204;\n",
    "===========================================================\n",
    "Epoch 013/096 - Mean training loss 0.110779; Mean training F1 0.927550; Mean validation loss 0.102554; Mean validation F1 0.929709; Learning rate 0.000478;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.929709; loss - 0.102554;\n",
    "Group g4: f1 - 0.706475; loss - 0.313570;\n",
    "Group g9: f1 - 0.693699; loss - 0.317047;\n",
    "===========================================================\n",
    "Epoch 014/096 - Mean training loss 0.110215; Mean training F1 0.926437; Mean validation loss 0.170352; Mean validation F1 0.907000; Learning rate 0.000475;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.907000; loss - 0.170352;\n",
    "Group g4: f1 - 0.514842; loss - 0.587897;\n",
    "Group g9: f1 - 0.514606; loss - 0.589411;\n",
    "===========================================================\n",
    "Epoch 015/096 - Mean training loss 0.101766; Mean training F1 0.930120; Mean validation loss 0.091356; Mean validation F1 0.935484; Learning rate 0.000471;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935484; loss - 0.091356;\n",
    "Group g4: f1 - 0.712428; loss - 0.296605;\n",
    "Group g9: f1 - 0.701779; loss - 0.299067;\n",
    "===========================================================\n",
    "Epoch 016/096 - Mean training loss 0.098343; Mean training F1 0.932345; Mean validation loss 0.089654; Mean validation F1 0.936864; Learning rate 0.000467;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936864; loss - 0.089654;\n",
    "Group g4: f1 - 0.711002; loss - 0.289892;\n",
    "Group g9: f1 - 0.702850; loss - 0.292439;\n",
    "===========================================================\n",
    "Epoch 017/096 - Mean training loss 0.099583; Mean training F1 0.931819; Mean validation loss 0.093460; Mean validation F1 0.935579; Learning rate 0.000463;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935579; loss - 0.093460;\n",
    "Group g4: f1 - 0.725490; loss - 0.288695;\n",
    "Group g9: f1 - 0.717856; loss - 0.291942;\n",
    "===========================================================\n",
    "Epoch 018/096 - Mean training loss 0.100859; Mean training F1 0.930947; Mean validation loss 0.117047; Mean validation F1 0.926712; Learning rate 0.000459;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.926712; loss - 0.117047;\n",
    "Group g4: f1 - 0.692249; loss - 0.308851;\n",
    "Group g9: f1 - 0.688536; loss - 0.314350;\n",
    "===========================================================\n",
    "Epoch 019/096 - Mean training loss 0.103416; Mean training F1 0.928335; Mean validation loss 0.093287; Mean validation F1 0.934776; Learning rate 0.000454;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934776; loss - 0.093287;\n",
    "Group g4: f1 - 0.717024; loss - 0.299373;\n",
    "Group g9: f1 - 0.706566; loss - 0.301034;\n",
    "===========================================================\n",
    "Epoch 020/096 - Mean training loss 0.098919; Mean training F1 0.931361; Mean validation loss 0.099526; Mean validation F1 0.933095; Learning rate 0.000449;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.933095; loss - 0.099526;\n",
    "Group g4: f1 - 0.718908; loss - 0.293227;\n",
    "Group g9: f1 - 0.712206; loss - 0.295479;\n",
    "===========================================================\n",
    "Epoch 021/096 - Mean training loss 0.097177; Mean training F1 0.932304; Mean validation loss 0.091287; Mean validation F1 0.935421; Learning rate 0.000444;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935421; loss - 0.091287;\n",
    "Group g4: f1 - 0.735125; loss - 0.292373;\n",
    "Group g9: f1 - 0.721373; loss - 0.295048;\n",
    "===========================================================\n",
    "Epoch 022/096 - Mean training loss 0.094180; Mean training F1 0.933789; Mean validation loss 0.094847; Mean validation F1 0.934689; Learning rate 0.000439;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934689; loss - 0.094847;\n",
    "Group g4: f1 - 0.731815; loss - 0.290206;\n",
    "Group g9: f1 - 0.717216; loss - 0.293181;\n",
    "===========================================================\n",
    "Epoch 023/096 - Mean training loss 0.094780; Mean training F1 0.933268; Mean validation loss 0.095626; Mean validation F1 0.932719; Learning rate 0.000433;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.932719; loss - 0.095626;\n",
    "Group g4: f1 - 0.739740; loss - 0.300241;\n",
    "Group g9: f1 - 0.718689; loss - 0.303552;\n",
    "===========================================================\n",
    "Epoch 024/096 - Mean training loss 0.093577; Mean training F1 0.933893; Mean validation loss 0.088495; Mean validation F1 0.937003; Learning rate 0.000428;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937003; loss - 0.088495;\n",
    "Group g4: f1 - 0.737394; loss - 0.284402;\n",
    "Group g9: f1 - 0.719529; loss - 0.287231;\n",
    "===========================================================\n",
    "Epoch 025/096 - Mean training loss 0.093720; Mean training F1 0.933924; Mean validation loss 0.098426; Mean validation F1 0.934389; Learning rate 0.000422;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934389; loss - 0.098426;\n",
    "Group g4: f1 - 0.723612; loss - 0.287197;\n",
    "Group g9: f1 - 0.706482; loss - 0.290484;\n",
    "===========================================================\n",
    "Epoch 026/096 - Mean training loss 0.094228; Mean training F1 0.933200; Mean validation loss 0.137893; Mean validation F1 0.916006; Learning rate 0.000416;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.916006; loss - 0.137893;\n",
    "Group g4: f1 - 0.654074; loss - 0.339767;\n",
    "Group g9: f1 - 0.653633; loss - 0.345256;\n",
    "===========================================================\n",
    "Epoch 027/096 - Mean training loss 0.094479; Mean training F1 0.933297; Mean validation loss 0.087432; Mean validation F1 0.937607; Learning rate 0.000410;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937607; loss - 0.087432;\n",
    "Group g4: f1 - 0.755222; loss - 0.282933;\n",
    "Group g9: f1 - 0.742345; loss - 0.285895;\n",
    "===========================================================\n",
    "Epoch 028/096 - Mean training loss 0.090814; Mean training F1 0.934794; Mean validation loss 0.086897; Mean validation F1 0.938149; Learning rate 0.000403;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938149; loss - 0.086897;\n",
    "Group g4: f1 - 0.756935; loss - 0.282302;\n",
    "Group g9: f1 - 0.738813; loss - 0.284975;\n",
    "===========================================================\n",
    "Epoch 029/096 - Mean training loss 0.089442; Mean training F1 0.935321; Mean validation loss 0.087365; Mean validation F1 0.937725; Learning rate 0.000397;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937725; loss - 0.087365;\n",
    "Group g4: f1 - 0.743678; loss - 0.282739;\n",
    "Group g9: f1 - 0.730569; loss - 0.285794;\n",
    "===========================================================\n",
    "Epoch 030/096 - Mean training loss 0.090245; Mean training F1 0.934920; Mean validation loss 0.088026; Mean validation F1 0.937327; Learning rate 0.000390;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937327; loss - 0.088026;\n",
    "Group g4: f1 - 0.728622; loss - 0.282234;\n",
    "Group g9: f1 - 0.719682; loss - 0.284920;\n",
    "===========================================================\n",
    "Epoch 031/096 - Mean training loss 0.090473; Mean training F1 0.934403; Mean validation loss 0.100122; Mean validation F1 0.932622; Learning rate 0.000383;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.932622; loss - 0.100122;\n",
    "Group g4: f1 - 0.703344; loss - 0.292989;\n",
    "Group g9: f1 - 0.692193; loss - 0.296439;\n",
    "===========================================================\n",
    "Epoch 032/096 - Mean training loss 0.091783; Mean training F1 0.934491; Mean validation loss 0.095310; Mean validation F1 0.934462; Learning rate 0.000377;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.934462; loss - 0.095310;\n",
    "Group g4: f1 - 0.733006; loss - 0.291397;\n",
    "Group g9: f1 - 0.717239; loss - 0.293482;\n",
    "===========================================================\n",
    "Epoch 033/096 - Mean training loss 0.092651; Mean training F1 0.934390; Mean validation loss 0.104866; Mean validation F1 0.931324; Learning rate 0.000369;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931324; loss - 0.104866;\n",
    "Group g4: f1 - 0.739362; loss - 0.287242;\n",
    "Group g9: f1 - 0.726360; loss - 0.289947;\n",
    "===========================================================\n",
    "Epoch 034/096 - Mean training loss 0.088995; Mean training F1 0.935152; Mean validation loss 0.088715; Mean validation F1 0.937509; Learning rate 0.000362;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937509; loss - 0.088715;\n",
    "Group g4: f1 - 0.740544; loss - 0.283257;\n",
    "Group g9: f1 - 0.721466; loss - 0.285741;\n",
    "===========================================================\n",
    "Epoch 035/096 - Mean training loss 0.088420; Mean training F1 0.935386; Mean validation loss 0.086983; Mean validation F1 0.937841; Learning rate 0.000355;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937841; loss - 0.086983;\n",
    "Group g4: f1 - 0.762707; loss - 0.282150;\n",
    "Group g9: f1 - 0.748288; loss - 0.284975;\n",
    "===========================================================\n",
    "Epoch 036/096 - Mean training loss 0.087188; Mean training F1 0.936351; Mean validation loss 0.090161; Mean validation F1 0.936892; Learning rate 0.000347;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936892; loss - 0.090161;\n",
    "Group g4: f1 - 0.736244; loss - 0.285868;\n",
    "Group g9: f1 - 0.719937; loss - 0.288863;\n",
    "===========================================================\n",
    "Epoch 037/096 - Mean training loss 0.088649; Mean training F1 0.935136; Mean validation loss 0.087971; Mean validation F1 0.937307; Learning rate 0.000340;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937307; loss - 0.087971;\n",
    "Group g4: f1 - 0.750111; loss - 0.282686;\n",
    "Group g9: f1 - 0.737386; loss - 0.285514;\n",
    "===========================================================\n",
    "Epoch 038/096 - Mean training loss 0.087702; Mean training F1 0.935922; Mean validation loss 0.090684; Mean validation F1 0.936600; Learning rate 0.000332;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936600; loss - 0.090684;\n",
    "Group g4: f1 - 0.746063; loss - 0.287718;\n",
    "Group g9: f1 - 0.735456; loss - 0.290850;\n",
    "===========================================================\n",
    "Epoch 039/096 - Mean training loss 0.088065; Mean training F1 0.935978; Mean validation loss 0.087109; Mean validation F1 0.937678; Learning rate 0.000325;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937678; loss - 0.087109;\n",
    "Group g4: f1 - 0.766433; loss - 0.280920;\n",
    "Group g9: f1 - 0.759310; loss - 0.283913;\n",
    "===========================================================\n",
    "Epoch 040/096 - Mean training loss 0.087166; Mean training F1 0.936266; Mean validation loss 0.086332; Mean validation F1 0.938094; Learning rate 0.000317;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938094; loss - 0.086332;\n",
    "Group g4: f1 - 0.755231; loss - 0.280599;\n",
    "Group g9: f1 - 0.739341; loss - 0.283861;\n",
    "===========================================================\n",
    "Epoch 041/096 - Mean training loss 0.086903; Mean training F1 0.936356; Mean validation loss 0.087416; Mean validation F1 0.937073; Learning rate 0.000309;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937073; loss - 0.087416;\n",
    "Group g4: f1 - 0.750294; loss - 0.281785;\n",
    "Group g9: f1 - 0.740994; loss - 0.284332;\n",
    "===========================================================\n",
    "Epoch 042/096 - Mean training loss 0.087332; Mean training F1 0.935760; Mean validation loss 0.087173; Mean validation F1 0.936812; Learning rate 0.000301;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936812; loss - 0.087173;\n",
    "Group g4: f1 - 0.770723; loss - 0.283496;\n",
    "Group g9: f1 - 0.762861; loss - 0.286455;\n",
    "===========================================================\n",
    "Epoch 043/096 - Mean training loss 0.086717; Mean training F1 0.936469; Mean validation loss 0.085518; Mean validation F1 0.938513; Learning rate 0.000293;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938513; loss - 0.085518;\n",
    "Group g4: f1 - 0.760095; loss - 0.280506;\n",
    "Group g9: f1 - 0.754954; loss - 0.283219;\n",
    "===========================================================\n",
    "Epoch 044/096 - Mean training loss 0.086163; Mean training F1 0.936667; Mean validation loss 0.087563; Mean validation F1 0.937911; Learning rate 0.000285;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937911; loss - 0.087563;\n",
    "Group g4: f1 - 0.753694; loss - 0.281690;\n",
    "Group g9: f1 - 0.741345; loss - 0.284648;\n",
    "===========================================================\n",
    "Epoch 045/096 - Mean training loss 0.087472; Mean training F1 0.935941; Mean validation loss 0.086045; Mean validation F1 0.937937; Learning rate 0.000277;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937937; loss - 0.086045;\n",
    "Group g4: f1 - 0.749625; loss - 0.281642;\n",
    "Group g9: f1 - 0.735262; loss - 0.284616;\n",
    "===========================================================\n",
    "Epoch 046/096 - Mean training loss 0.086613; Mean training F1 0.936322; Mean validation loss 0.087488; Mean validation F1 0.937775; Learning rate 0.000269;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937775; loss - 0.087488;\n",
    "Group g4: f1 - 0.733131; loss - 0.284237;\n",
    "Group g9: f1 - 0.723455; loss - 0.287511;\n",
    "===========================================================\n",
    "Epoch 047/096 - Mean training loss 0.086167; Mean training F1 0.936517; Mean validation loss 0.085623; Mean validation F1 0.938456; Learning rate 0.000261;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938456; loss - 0.085623;\n",
    "Group g4: f1 - 0.769135; loss - 0.279103;\n",
    "Group g9: f1 - 0.762429; loss - 0.282024;\n",
    "===========================================================\n",
    "Epoch 048/096 - Mean training loss 0.086643; Mean training F1 0.936672; Mean validation loss 0.087728; Mean validation F1 0.937762; Learning rate 0.000253;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937762; loss - 0.087728;\n",
    "Group g4: f1 - 0.778670; loss - 0.280579;\n",
    "Group g9: f1 - 0.779678; loss - 0.282919;\n",
    "===========================================================\n",
    "Epoch 049/096 - Mean training loss 0.086075; Mean training F1 0.936532; Mean validation loss 0.086300; Mean validation F1 0.937657; Learning rate 0.000245;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937657; loss - 0.086300;\n",
    "Group g4: f1 - 0.761645; loss - 0.281932;\n",
    "Group g9: f1 - 0.755490; loss - 0.284771;\n",
    "===========================================================\n",
    "Epoch 050/096 - Mean training loss 0.085732; Mean training F1 0.936443; Mean validation loss 0.085411; Mean validation F1 0.938407; Learning rate 0.000237;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938407; loss - 0.085411;\n",
    "Group g4: f1 - 0.760762; loss - 0.279232;\n",
    "Group g9: f1 - 0.751932; loss - 0.282112;\n",
    "===========================================================\n",
    "Epoch 051/096 - Mean training loss 0.085109; Mean training F1 0.937090; Mean validation loss 0.085870; Mean validation F1 0.938157; Learning rate 0.000228;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938157; loss - 0.085870;\n",
    "Group g4: f1 - 0.768599; loss - 0.281529;\n",
    "Group g9: f1 - 0.765603; loss - 0.284592;\n",
    "===========================================================\n",
    "Epoch 052/096 - Mean training loss 0.085128; Mean training F1 0.937066; Mean validation loss 0.086412; Mean validation F1 0.937913; Learning rate 0.000220;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937913; loss - 0.086412;\n",
    "Group g4: f1 - 0.778488; loss - 0.281503;\n",
    "Group g9: f1 - 0.771481; loss - 0.284725;\n",
    "===========================================================\n",
    "Epoch 053/096 - Mean training loss 0.084827; Mean training F1 0.937225; Mean validation loss 0.085234; Mean validation F1 0.938475; Learning rate 0.000212;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938475; loss - 0.085234;\n",
    "Group g4: f1 - 0.775659; loss - 0.278931;\n",
    "Group g9: f1 - 0.777545; loss - 0.281821;\n",
    "===========================================================\n",
    "Epoch 054/096 - Mean training loss 0.085315; Mean training F1 0.936951; Mean validation loss 0.085768; Mean validation F1 0.937992; Learning rate 0.000204;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937992; loss - 0.085768;\n",
    "Group g4: f1 - 0.769022; loss - 0.281596;\n",
    "Group g9: f1 - 0.763662; loss - 0.284633;\n",
    "===========================================================\n",
    "Epoch 055/096 - Mean training loss 0.085617; Mean training F1 0.936820; Mean validation loss 0.086157; Mean validation F1 0.938143; Learning rate 0.000197;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938143; loss - 0.086157;\n",
    "Group g4: f1 - 0.773388; loss - 0.280368;\n",
    "Group g9: f1 - 0.765624; loss - 0.282975;\n",
    "===========================================================\n",
    "Epoch 056/096 - Mean training loss 0.084118; Mean training F1 0.937479; Mean validation loss 0.085094; Mean validation F1 0.938559; Learning rate 0.000189;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938559; loss - 0.085094;\n",
    "Group g4: f1 - 0.778183; loss - 0.280294;\n",
    "Group g9: f1 - 0.779217; loss - 0.282834;\n",
    "===========================================================\n",
    "Epoch 057/096 - Mean training loss 0.085055; Mean training F1 0.937097; Mean validation loss 0.085441; Mean validation F1 0.938512; Learning rate 0.000181;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938512; loss - 0.085441;\n",
    "Group g4: f1 - 0.759269; loss - 0.280303;\n",
    "Group g9: f1 - 0.749727; loss - 0.283076;\n",
    "===========================================================\n",
    "Epoch 058/096 - Mean training loss 0.084277; Mean training F1 0.937339; Mean validation loss 0.085528; Mean validation F1 0.938348; Learning rate 0.000173;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938348; loss - 0.085528;\n",
    "Group g4: f1 - 0.776594; loss - 0.279428;\n",
    "Group g9: f1 - 0.771821; loss - 0.281967;\n",
    "===========================================================\n",
    "Epoch 059/096 - Mean training loss 0.084251; Mean training F1 0.937300; Mean validation loss 0.085153; Mean validation F1 0.938357; Learning rate 0.000166;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938357; loss - 0.085153;\n",
    "Group g4: f1 - 0.781441; loss - 0.279376;\n",
    "Group g9: f1 - 0.781209; loss - 0.282035;\n",
    "===========================================================\n",
    "Epoch 060/096 - Mean training loss 0.083886; Mean training F1 0.937542; Mean validation loss 0.085566; Mean validation F1 0.938544; Learning rate 0.000158;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938544; loss - 0.085566;\n",
    "Group g4: f1 - 0.772280; loss - 0.280207;\n",
    "Group g9: f1 - 0.767989; loss - 0.282795;\n",
    "===========================================================\n",
    "Epoch 061/096 - Mean training loss 0.084108; Mean training F1 0.937602; Mean validation loss 0.086061; Mean validation F1 0.938213; Learning rate 0.000151;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938213; loss - 0.086061;\n",
    "Group g4: f1 - 0.776371; loss - 0.279735;\n",
    "Group g9: f1 - 0.769024; loss - 0.282276;\n",
    "===========================================================\n",
    "Epoch 062/096 - Mean training loss 0.084097; Mean training F1 0.937476; Mean validation loss 0.085517; Mean validation F1 0.938526; Learning rate 0.000143;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938526; loss - 0.085517;\n",
    "Group g4: f1 - 0.775341; loss - 0.278346;\n",
    "Group g9: f1 - 0.774471; loss - 0.281198;\n",
    "===========================================================\n",
    "Epoch 063/096 - Mean training loss 0.084091; Mean training F1 0.937433; Mean validation loss 0.085208; Mean validation F1 0.938806; Learning rate 0.000136;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938806; loss - 0.085208;\n",
    "Group g4: f1 - 0.785944; loss - 0.278450;\n",
    "Group g9: f1 - 0.781310; loss - 0.281249;\n",
    "===========================================================\n",
    "Epoch 064/096 - Mean training loss 0.083447; Mean training F1 0.937755; Mean validation loss 0.084868; Mean validation F1 0.938724; Learning rate 0.000129;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938724; loss - 0.084868;\n",
    "Group g4: f1 - 0.789052; loss - 0.279053;\n",
    "Group g9: f1 - 0.782612; loss - 0.281726;\n",
    "===========================================================\n",
    "Epoch 065/096 - Mean training loss 0.083602; Mean training F1 0.937523; Mean validation loss 0.084810; Mean validation F1 0.938778; Learning rate 0.000122;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938778; loss - 0.084810;\n",
    "Group g4: f1 - 0.784390; loss - 0.278967;\n",
    "Group g9: f1 - 0.782253; loss - 0.281777;\n",
    "===========================================================\n",
    "Epoch 066/096 - Mean training loss 0.084223; Mean training F1 0.937323; Mean validation loss 0.085028; Mean validation F1 0.938272; Learning rate 0.000115;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938272; loss - 0.085028;\n",
    "Group g4: f1 - 0.776178; loss - 0.279587;\n",
    "Group g9: f1 - 0.776761; loss - 0.282265;\n",
    "===========================================================\n",
    "Epoch 067/096 - Mean training loss 0.083848; Mean training F1 0.937526; Mean validation loss 0.084909; Mean validation F1 0.938674; Learning rate 0.000109;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938674; loss - 0.084909;\n",
    "Group g4: f1 - 0.785551; loss - 0.278135;\n",
    "Group g9: f1 - 0.782090; loss - 0.280882;\n",
    "===========================================================\n",
    "Epoch 068/096 - Mean training loss 0.083687; Mean training F1 0.937668; Mean validation loss 0.085199; Mean validation F1 0.938296; Learning rate 0.000102;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938296; loss - 0.085199;\n",
    "Group g4: f1 - 0.785257; loss - 0.280024;\n",
    "Group g9: f1 - 0.781609; loss - 0.282648;\n",
    "===========================================================\n",
    "Epoch 069/096 - Mean training loss 0.083265; Mean training F1 0.937892; Mean validation loss 0.084666; Mean validation F1 0.938777; Learning rate 0.000096;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938777; loss - 0.084666;\n",
    "Group g4: f1 - 0.785877; loss - 0.278664;\n",
    "Group g9: f1 - 0.780476; loss - 0.281448;\n",
    "===========================================================\n",
    "Epoch 070/096 - Mean training loss 0.083358; Mean training F1 0.937690; Mean validation loss 0.084515; Mean validation F1 0.938757; Learning rate 0.000090;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938757; loss - 0.084515;\n",
    "Group g4: f1 - 0.784436; loss - 0.278635;\n",
    "Group g9: f1 - 0.781293; loss - 0.281236;\n",
    "===========================================================\n",
    "Epoch 071/096 - Mean training loss 0.083324; Mean training F1 0.937900; Mean validation loss 0.084495; Mean validation F1 0.938676; Learning rate 0.000084;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938676; loss - 0.084495;\n",
    "Group g4: f1 - 0.784894; loss - 0.277811;\n",
    "Group g9: f1 - 0.782472; loss - 0.280532;\n",
    "===========================================================\n",
    "Epoch 072/096 - Mean training loss 0.083556; Mean training F1 0.937710; Mean validation loss 0.085285; Mean validation F1 0.938390; Learning rate 0.000078;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938390; loss - 0.085285;\n",
    "Group g4: f1 - 0.780280; loss - 0.279706;\n",
    "Group g9: f1 - 0.779551; loss - 0.282252;\n",
    "===========================================================\n",
    "Epoch 073/096 - Mean training loss 0.083376; Mean training F1 0.937684; Mean validation loss 0.084703; Mean validation F1 0.938649; Learning rate 0.000072;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938649; loss - 0.084703;\n",
    "Group g4: f1 - 0.779311; loss - 0.278000;\n",
    "Group g9: f1 - 0.776967; loss - 0.280857;\n",
    "===========================================================\n",
    "Epoch 074/096 - Mean training loss 0.083676; Mean training F1 0.937795; Mean validation loss 0.084381; Mean validation F1 0.938838; Learning rate 0.000067;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938838; loss - 0.084381;\n",
    "Group g4: f1 - 0.781805; loss - 0.277780;\n",
    "Group g9: f1 - 0.781110; loss - 0.280622;\n",
    "===========================================================\n",
    "Epoch 075/096 - Mean training loss 0.082879; Mean training F1 0.938086; Mean validation loss 0.084463; Mean validation F1 0.938432; Learning rate 0.000061;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938432; loss - 0.084463;\n",
    "Group g4: f1 - 0.783683; loss - 0.278319;\n",
    "Group g9: f1 - 0.780469; loss - 0.281143;\n",
    "===========================================================\n",
    "Epoch 076/096 - Mean training loss 0.082735; Mean training F1 0.938079; Mean validation loss 0.084443; Mean validation F1 0.938853; Learning rate 0.000056;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938853; loss - 0.084443;\n",
    "Group g4: f1 - 0.783079; loss - 0.277537;\n",
    "Group g9: f1 - 0.778288; loss - 0.280346;\n",
    "===========================================================\n",
    "Epoch 077/096 - Mean training loss 0.083050; Mean training F1 0.937956; Mean validation loss 0.084424; Mean validation F1 0.938834; Learning rate 0.000052;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938834; loss - 0.084424;\n",
    "Group g4: f1 - 0.786344; loss - 0.277735;\n",
    "Group g9: f1 - 0.781882; loss - 0.280450;\n",
    "===========================================================\n",
    "Epoch 078/096 - Mean training loss 0.082931; Mean training F1 0.938151; Mean validation loss 0.084659; Mean validation F1 0.938501; Learning rate 0.000047;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938501; loss - 0.084659;\n",
    "Group g4: f1 - 0.785237; loss - 0.278455;\n",
    "Group g9: f1 - 0.779484; loss - 0.281354;\n",
    "===========================================================\n",
    "Epoch 079/096 - Mean training loss 0.083704; Mean training F1 0.937950; Mean validation loss 0.084332; Mean validation F1 0.938759; Learning rate 0.000043;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938759; loss - 0.084332;\n",
    "Group g4: f1 - 0.785787; loss - 0.277595;\n",
    "Group g9: f1 - 0.781515; loss - 0.280346;\n",
    "===========================================================\n",
    "Epoch 080/096 - Mean training loss 0.082652; Mean training F1 0.938057; Mean validation loss 0.084257; Mean validation F1 0.938990; Learning rate 0.000038;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938990; loss - 0.084257;\n",
    "Group g4: f1 - 0.787578; loss - 0.277399;\n",
    "Group g9: f1 - 0.782087; loss - 0.280228;\n",
    "===========================================================\n",
    "Epoch 081/096 - Mean training loss 0.082725; Mean training F1 0.938156; Mean validation loss 0.084208; Mean validation F1 0.938835; Learning rate 0.000034;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938835; loss - 0.084208;\n",
    "Group g4: f1 - 0.787273; loss - 0.277531;\n",
    "Group g9: f1 - 0.782497; loss - 0.280220;\n",
    "===========================================================\n",
    "Epoch 082/096 - Mean training loss 0.082534; Mean training F1 0.938348; Mean validation loss 0.084128; Mean validation F1 0.939026; Learning rate 0.000031;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939026; loss - 0.084128;\n",
    "Group g4: f1 - 0.785810; loss - 0.277289;\n",
    "Group g9: f1 - 0.781504; loss - 0.280091;\n",
    "===========================================================\n",
    "Epoch 083/096 - Mean training loss 0.082947; Mean training F1 0.938039; Mean validation loss 0.084173; Mean validation F1 0.938953; Learning rate 0.000027;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938953; loss - 0.084173;\n",
    "Group g4: f1 - 0.785834; loss - 0.277402;\n",
    "Group g9: f1 - 0.780187; loss - 0.280119;\n",
    "===========================================================\n",
    "Epoch 084/096 - Mean training loss 0.082653; Mean training F1 0.938146; Mean validation loss 0.084313; Mean validation F1 0.938890; Learning rate 0.000024;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938890; loss - 0.084313;\n",
    "Group g4: f1 - 0.782721; loss - 0.277708;\n",
    "Group g9: f1 - 0.779235; loss - 0.280502;\n",
    "===========================================================\n",
    "Epoch 085/096 - Mean training loss 0.082315; Mean training F1 0.938281; Mean validation loss 0.084111; Mean validation F1 0.938954; Learning rate 0.000021;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938954; loss - 0.084111;\n",
    "Group g4: f1 - 0.784384; loss - 0.277414;\n",
    "Group g9: f1 - 0.780349; loss - 0.280042;\n",
    "===========================================================\n",
    "Epoch 086/096 - Mean training loss 0.082220; Mean training F1 0.938328; Mean validation loss 0.084181; Mean validation F1 0.938894; Learning rate 0.000018;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938894; loss - 0.084181;\n",
    "Group g4: f1 - 0.785521; loss - 0.277489;\n",
    "Group g9: f1 - 0.781167; loss - 0.280129;\n",
    "===========================================================\n",
    "Epoch 087/096 - Mean training loss 0.082571; Mean training F1 0.938208; Mean validation loss 0.084171; Mean validation F1 0.939015; Learning rate 0.000016;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939015; loss - 0.084171;\n",
    "Group g4: f1 - 0.785547; loss - 0.277296;\n",
    "Group g9: f1 - 0.781538; loss - 0.280064;\n",
    "===========================================================\n",
    "Epoch 088/096 - Mean training loss 0.082506; Mean training F1 0.938316; Mean validation loss 0.084111; Mean validation F1 0.938995; Learning rate 0.000014;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938995; loss - 0.084111;\n",
    "Group g4: f1 - 0.787596; loss - 0.277191;\n",
    "Group g9: f1 - 0.782514; loss - 0.279971;\n",
    "===========================================================\n",
    "Epoch 089/096 - Mean training loss 0.082322; Mean training F1 0.938271; Mean validation loss 0.084097; Mean validation F1 0.938870; Learning rate 0.000012;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938870; loss - 0.084097;\n",
    "Group g4: f1 - 0.786815; loss - 0.277338;\n",
    "Group g9: f1 - 0.781919; loss - 0.280076;\n",
    "===========================================================\n",
    "Epoch 090/096 - Mean training loss 0.082298; Mean training F1 0.938242; Mean validation loss 0.084236; Mean validation F1 0.938933; Learning rate 0.000010;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938933; loss - 0.084236;\n",
    "Group g4: f1 - 0.785724; loss - 0.277398;\n",
    "Group g9: f1 - 0.780982; loss - 0.280179;\n",
    "===========================================================\n",
    "Epoch 091/096 - Mean training loss 0.082510; Mean training F1 0.938259; Mean validation loss 0.084109; Mean validation F1 0.938925; Learning rate 0.000008;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938925; loss - 0.084109;\n",
    "Group g4: f1 - 0.787394; loss - 0.277268;\n",
    "Group g9: f1 - 0.781174; loss - 0.279956;\n",
    "===========================================================\n",
    "Epoch 092/096 - Mean training loss 0.082251; Mean training F1 0.938225; Mean validation loss 0.084135; Mean validation F1 0.938817; Learning rate 0.000007;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938817; loss - 0.084135;\n",
    "Group g4: f1 - 0.786250; loss - 0.277336;\n",
    "Group g9: f1 - 0.780782; loss - 0.280134;\n",
    "===========================================================\n",
    "Epoch 093/096 - Mean training loss 0.082791; Mean training F1 0.938199; Mean validation loss 0.084181; Mean validation F1 0.938910; Learning rate 0.000006;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938910; loss - 0.084181;\n",
    "Group g4: f1 - 0.786771; loss - 0.277564;\n",
    "Group g9: f1 - 0.782277; loss - 0.280171;\n",
    "===========================================================\n",
    "Epoch 094/096 - Mean training loss 0.082220; Mean training F1 0.938203; Mean validation loss 0.084108; Mean validation F1 0.938956; Learning rate 0.000006;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938956; loss - 0.084108;\n",
    "Group g4: f1 - 0.787427; loss - 0.277244;\n",
    "Group g9: f1 - 0.782651; loss - 0.279986;\n",
    "===========================================================\n",
    "Epoch 095/096 - Mean training loss 0.082316; Mean training F1 0.938287; Mean validation loss 0.084085; Mean validation F1 0.939013; Learning rate 0.000005;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.939013; loss - 0.084085;\n",
    "Group g4: f1 - 0.787304; loss - 0.277262;\n",
    "Group g9: f1 - 0.781566; loss - 0.279992;\n",
    "===========================================================\n",
    "Epoch 096/096 - Mean training loss 0.082662; Mean training F1 0.938171; Mean validation loss 0.084059; Mean validation F1 0.938969; Learning rate 0.000005;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938969; loss - 0.084059;\n",
    "Group g4: f1 - 0.786394; loss - 0.277261;\n",
    "Group g9: f1 - 0.781229; loss - 0.279963;\n",
    "################################################################\n",
    "Training/validation for fold 5/5;\n",
    "===========================================================\n",
    "Epoch 001/096 - Mean training loss 0.800548; Mean training F1 0.629282; Mean validation loss 0.416050; Mean validation F1 0.818935; Learning rate 0.000500;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.818935; loss - 0.416050;\n",
    "Group g4: f1 - 0.347898; loss - 1.104749;\n",
    "Group g9: f1 - 0.346212; loss - 1.129152;\n",
    "===========================================================\n",
    "Epoch 002/096 - Mean training loss 0.336249; Mean training F1 0.843611; Mean validation loss 0.461732; Mean validation F1 0.745215; Learning rate 0.000500;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.745215; loss - 0.461732;\n",
    "Group g4: f1 - 0.441388; loss - 0.570159;\n",
    "Group g9: f1 - 0.442009; loss - 0.581138;\n",
    "===========================================================\n",
    "Epoch 003/096 - Mean training loss 0.209880; Mean training F1 0.891944; Mean validation loss 0.227745; Mean validation F1 0.879912; Learning rate 0.000499;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.879912; loss - 0.227745;\n",
    "Group g4: f1 - 0.442768; loss - 0.793730;\n",
    "Group g9: f1 - 0.439896; loss - 0.849435;\n",
    "===========================================================\n",
    "Epoch 004/096 - Mean training loss 0.191312; Mean training F1 0.898865; Mean validation loss 0.151676; Mean validation F1 0.910112; Learning rate 0.000498;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.910112; loss - 0.151676;\n",
    "Group g4: f1 - 0.539970; loss - 0.411177;\n",
    "Group g9: f1 - 0.535631; loss - 0.422998;\n",
    "===========================================================\n",
    "Epoch 005/096 - Mean training loss 0.156647; Mean training F1 0.907477; Mean validation loss 0.132471; Mean validation F1 0.920890; Learning rate 0.000497;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.920890; loss - 0.132471;\n",
    "Group g4: f1 - 0.549881; loss - 0.420711;\n",
    "Group g9: f1 - 0.541450; loss - 0.450333;\n",
    "===========================================================\n",
    "Epoch 006/096 - Mean training loss 0.140766; Mean training F1 0.914932; Mean validation loss 0.121113; Mean validation F1 0.925246; Learning rate 0.000496;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.925246; loss - 0.121113;\n",
    "Group g4: f1 - 0.572234; loss - 0.379531;\n",
    "Group g9: f1 - 0.565533; loss - 0.396220;\n",
    "===========================================================\n",
    "Epoch 007/096 - Mean training loss 0.143598; Mean training F1 0.913422; Mean validation loss 0.107893; Mean validation F1 0.930101; Learning rate 0.000494;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.930101; loss - 0.107893;\n",
    "Group g4: f1 - 0.591723; loss - 0.345200;\n",
    "Group g9: f1 - 0.587968; loss - 0.354292;\n",
    "===========================================================\n",
    "Epoch 008/096 - Mean training loss 0.134866; Mean training F1 0.918319; Mean validation loss 0.112854; Mean validation F1 0.925934; Learning rate 0.000492;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.925934; loss - 0.112854;\n",
    "Group g4: f1 - 0.600506; loss - 0.354112;\n",
    "Group g9: f1 - 0.597463; loss - 0.358394;\n",
    "===========================================================\n",
    "Epoch 009/096 - Mean training loss 0.124580; Mean training F1 0.921762; Mean validation loss 0.106995; Mean validation F1 0.928476; Learning rate 0.000490;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.928476; loss - 0.106995;\n",
    "Group g4: f1 - 0.605254; loss - 0.344393;\n",
    "Group g9: f1 - 0.599436; loss - 0.355147;\n",
    "===========================================================\n",
    "Epoch 010/096 - Mean training loss 0.124945; Mean training F1 0.922453; Mean validation loss 0.102129; Mean validation F1 0.931521; Learning rate 0.000487;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931521; loss - 0.102129;\n",
    "Group g4: f1 - 0.624092; loss - 0.327453;\n",
    "Group g9: f1 - 0.618514; loss - 0.334145;\n",
    "===========================================================\n",
    "Epoch 011/096 - Mean training loss 0.114190; Mean training F1 0.927005; Mean validation loss 0.105698; Mean validation F1 0.930404; Learning rate 0.000484;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.930404; loss - 0.105698;\n",
    "Group g4: f1 - 0.619339; loss - 0.326157;\n",
    "Group g9: f1 - 0.614210; loss - 0.335059;\n",
    "===========================================================\n",
    "Epoch 012/096 - Mean training loss 0.123384; Mean training F1 0.922951; Mean validation loss 0.103092; Mean validation F1 0.931897; Learning rate 0.000481;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931897; loss - 0.103092;\n",
    "Group g4: f1 - 0.621288; loss - 0.327764;\n",
    "Group g9: f1 - 0.618245; loss - 0.334565;\n",
    "===========================================================\n",
    "Epoch 013/096 - Mean training loss 0.119744; Mean training F1 0.924037; Mean validation loss 0.131121; Mean validation F1 0.921201; Learning rate 0.000478;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.921201; loss - 0.131121;\n",
    "Group g4: f1 - 0.661750; loss - 0.326583;\n",
    "Group g9: f1 - 0.659221; loss - 0.328510;\n",
    "===========================================================\n",
    "Epoch 014/096 - Mean training loss 0.113512; Mean training F1 0.927194; Mean validation loss 0.109329; Mean validation F1 0.928210; Learning rate 0.000475;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.928210; loss - 0.109329;\n",
    "Group g4: f1 - 0.689399; loss - 0.321243;\n",
    "Group g9: f1 - 0.675798; loss - 0.322300;\n",
    "===========================================================\n",
    "Epoch 015/096 - Mean training loss 0.105409; Mean training F1 0.929806; Mean validation loss 0.096255; Mean validation F1 0.929934; Learning rate 0.000471;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.929934; loss - 0.096255;\n",
    "Group g4: f1 - 0.694096; loss - 0.302041;\n",
    "Group g9: f1 - 0.681685; loss - 0.305160;\n",
    "===========================================================\n",
    "Epoch 016/096 - Mean training loss 0.107943; Mean training F1 0.928241; Mean validation loss 0.101792; Mean validation F1 0.927786; Learning rate 0.000467;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.927786; loss - 0.101792;\n",
    "Group g4: f1 - 0.672433; loss - 0.323068;\n",
    "Group g9: f1 - 0.662042; loss - 0.325977;\n",
    "===========================================================\n",
    "Epoch 017/096 - Mean training loss 0.102597; Mean training F1 0.930506; Mean validation loss 0.113534; Mean validation F1 0.926265; Learning rate 0.000463;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.926265; loss - 0.113534;\n",
    "Group g4: f1 - 0.708720; loss - 0.291317;\n",
    "Group g9: f1 - 0.695952; loss - 0.294361;\n",
    "===========================================================\n",
    "Epoch 018/096 - Mean training loss 0.100749; Mean training F1 0.931695; Mean validation loss 0.090838; Mean validation F1 0.935626; Learning rate 0.000459;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935626; loss - 0.090838;\n",
    "Group g4: f1 - 0.715570; loss - 0.286477;\n",
    "Group g9: f1 - 0.701798; loss - 0.289669;\n",
    "===========================================================\n",
    "Epoch 019/096 - Mean training loss 0.096704; Mean training F1 0.933205; Mean validation loss 0.094211; Mean validation F1 0.931554; Learning rate 0.000454;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.931554; loss - 0.094211;\n",
    "Group g4: f1 - 0.730760; loss - 0.300042;\n",
    "Group g9: f1 - 0.709440; loss - 0.303099;\n",
    "===========================================================\n",
    "Epoch 020/096 - Mean training loss 0.099054; Mean training F1 0.932539; Mean validation loss 0.092060; Mean validation F1 0.935024; Learning rate 0.000449;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935024; loss - 0.092060;\n",
    "Group g4: f1 - 0.708770; loss - 0.287484;\n",
    "Group g9: f1 - 0.700735; loss - 0.290326;\n",
    "===========================================================\n",
    "Epoch 021/096 - Mean training loss 0.097327; Mean training F1 0.933024; Mean validation loss 0.092079; Mean validation F1 0.932972; Learning rate 0.000444;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.932972; loss - 0.092079;\n",
    "Group g4: f1 - 0.705210; loss - 0.289867;\n",
    "Group g9: f1 - 0.702544; loss - 0.292758;\n",
    "===========================================================\n",
    "Epoch 022/096 - Mean training loss 0.095770; Mean training F1 0.933361; Mean validation loss 0.088573; Mean validation F1 0.936175; Learning rate 0.000439;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936175; loss - 0.088573;\n",
    "Group g4: f1 - 0.712622; loss - 0.285241;\n",
    "Group g9: f1 - 0.703186; loss - 0.287995;\n",
    "===========================================================\n",
    "Epoch 023/096 - Mean training loss 0.095654; Mean training F1 0.933913; Mean validation loss 0.088354; Mean validation F1 0.936472; Learning rate 0.000433;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936472; loss - 0.088354;\n",
    "Group g4: f1 - 0.735385; loss - 0.284508;\n",
    "Group g9: f1 - 0.713065; loss - 0.287150;\n",
    "===========================================================\n",
    "Epoch 024/096 - Mean training loss 0.094004; Mean training F1 0.934294; Mean validation loss 0.090740; Mean validation F1 0.935953; Learning rate 0.000428;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935953; loss - 0.090740;\n",
    "Group g4: f1 - 0.708596; loss - 0.287230;\n",
    "Group g9: f1 - 0.703546; loss - 0.289806;\n",
    "===========================================================\n",
    "Epoch 025/096 - Mean training loss 0.091645; Mean training F1 0.934904; Mean validation loss 0.087896; Mean validation F1 0.936836; Learning rate 0.000422;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936836; loss - 0.087896;\n",
    "Group g4: f1 - 0.709914; loss - 0.287772;\n",
    "Group g9: f1 - 0.693851; loss - 0.290491;\n",
    "===========================================================\n",
    "Epoch 026/096 - Mean training loss 0.091891; Mean training F1 0.935015; Mean validation loss 0.089669; Mean validation F1 0.936088; Learning rate 0.000416;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936088; loss - 0.089669;\n",
    "Group g4: f1 - 0.744616; loss - 0.286188;\n",
    "Group g9: f1 - 0.728084; loss - 0.288323;\n",
    "===========================================================\n",
    "Epoch 027/096 - Mean training loss 0.091996; Mean training F1 0.934807; Mean validation loss 0.090261; Mean validation F1 0.935714; Learning rate 0.000410;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935714; loss - 0.090261;\n",
    "Group g4: f1 - 0.747598; loss - 0.286326;\n",
    "Group g9: f1 - 0.740744; loss - 0.289195;\n",
    "===========================================================\n",
    "Epoch 028/096 - Mean training loss 0.091376; Mean training F1 0.935158; Mean validation loss 0.087466; Mean validation F1 0.936272; Learning rate 0.000403;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936272; loss - 0.087466;\n",
    "Group g4: f1 - 0.733646; loss - 0.284180;\n",
    "Group g9: f1 - 0.722817; loss - 0.286754;\n",
    "===========================================================\n",
    "Epoch 029/096 - Mean training loss 0.091059; Mean training F1 0.935057; Mean validation loss 0.088725; Mean validation F1 0.935993; Learning rate 0.000397;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935993; loss - 0.088725;\n",
    "Group g4: f1 - 0.733615; loss - 0.285777;\n",
    "Group g9: f1 - 0.710797; loss - 0.288426;\n",
    "===========================================================\n",
    "Epoch 030/096 - Mean training loss 0.090780; Mean training F1 0.935247; Mean validation loss 0.089080; Mean validation F1 0.936178; Learning rate 0.000390;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936178; loss - 0.089080;\n",
    "Group g4: f1 - 0.742949; loss - 0.285766;\n",
    "Group g9: f1 - 0.733612; loss - 0.288060;\n",
    "===========================================================\n",
    "Epoch 031/096 - Mean training loss 0.090412; Mean training F1 0.935427; Mean validation loss 0.086180; Mean validation F1 0.936918; Learning rate 0.000383;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936918; loss - 0.086180;\n",
    "Group g4: f1 - 0.754784; loss - 0.282425;\n",
    "Group g9: f1 - 0.746877; loss - 0.285079;\n",
    "===========================================================\n",
    "Epoch 032/096 - Mean training loss 0.089857; Mean training F1 0.935754; Mean validation loss 0.087389; Mean validation F1 0.936753; Learning rate 0.000377;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936753; loss - 0.087389;\n",
    "Group g4: f1 - 0.747518; loss - 0.282467;\n",
    "Group g9: f1 - 0.741551; loss - 0.285180;\n",
    "===========================================================\n",
    "Epoch 033/096 - Mean training loss 0.090160; Mean training F1 0.935366; Mean validation loss 0.089410; Mean validation F1 0.935809; Learning rate 0.000369;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935809; loss - 0.089410;\n",
    "Group g4: f1 - 0.757127; loss - 0.288866;\n",
    "Group g9: f1 - 0.753141; loss - 0.291688;\n",
    "===========================================================\n",
    "Epoch 034/096 - Mean training loss 0.098253; Mean training F1 0.931858; Mean validation loss 0.118085; Mean validation F1 0.923073; Learning rate 0.000362;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.923073; loss - 0.118085;\n",
    "Group g4: f1 - 0.676173; loss - 0.341056;\n",
    "Group g9: f1 - 0.666395; loss - 0.343120;\n",
    "===========================================================\n",
    "Epoch 035/096 - Mean training loss 0.094484; Mean training F1 0.933248; Mean validation loss 0.094982; Mean validation F1 0.932335; Learning rate 0.000355;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.932335; loss - 0.094982;\n",
    "Group g4: f1 - 0.730818; loss - 0.297284;\n",
    "Group g9: f1 - 0.709172; loss - 0.300829;\n",
    "===========================================================\n",
    "Epoch 036/096 - Mean training loss 0.089826; Mean training F1 0.935134; Mean validation loss 0.087054; Mean validation F1 0.936531; Learning rate 0.000347;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936531; loss - 0.087054;\n",
    "Group g4: f1 - 0.745338; loss - 0.282380;\n",
    "Group g9: f1 - 0.727082; loss - 0.285283;\n",
    "===========================================================\n",
    "Epoch 037/096 - Mean training loss 0.089259; Mean training F1 0.935619; Mean validation loss 0.089138; Mean validation F1 0.935536; Learning rate 0.000340;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935536; loss - 0.089138;\n",
    "Group g4: f1 - 0.763911; loss - 0.285197;\n",
    "Group g9: f1 - 0.759087; loss - 0.288614;\n",
    "===========================================================\n",
    "Epoch 038/096 - Mean training loss 0.088617; Mean training F1 0.936175; Mean validation loss 0.087514; Mean validation F1 0.936336; Learning rate 0.000332;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936336; loss - 0.087514;\n",
    "Group g4: f1 - 0.736120; loss - 0.285554;\n",
    "Group g9: f1 - 0.722535; loss - 0.288068;\n",
    "===========================================================\n",
    "Epoch 039/096 - Mean training loss 0.088434; Mean training F1 0.935908; Mean validation loss 0.088504; Mean validation F1 0.935588; Learning rate 0.000325;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.935588; loss - 0.088504;\n",
    "Group g4: f1 - 0.733212; loss - 0.292293;\n",
    "Group g9: f1 - 0.719167; loss - 0.293840;\n",
    "===========================================================\n",
    "Epoch 040/096 - Mean training loss 0.088800; Mean training F1 0.935803; Mean validation loss 0.086611; Mean validation F1 0.937216; Learning rate 0.000317;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937216; loss - 0.086611;\n",
    "Group g4: f1 - 0.748333; loss - 0.283036;\n",
    "Group g9: f1 - 0.732114; loss - 0.285596;\n",
    "===========================================================\n",
    "Epoch 041/096 - Mean training loss 0.087936; Mean training F1 0.936420; Mean validation loss 0.086178; Mean validation F1 0.936856; Learning rate 0.000309;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936856; loss - 0.086178;\n",
    "Group g4: f1 - 0.733311; loss - 0.281506;\n",
    "Group g9: f1 - 0.720323; loss - 0.284326;\n",
    "===========================================================\n",
    "Epoch 042/096 - Mean training loss 0.087751; Mean training F1 0.936195; Mean validation loss 0.086122; Mean validation F1 0.936986; Learning rate 0.000301;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936986; loss - 0.086122;\n",
    "Group g4: f1 - 0.742667; loss - 0.283610;\n",
    "Group g9: f1 - 0.737763; loss - 0.286771;\n",
    "===========================================================\n",
    "Epoch 043/096 - Mean training loss 0.088240; Mean training F1 0.936470; Mean validation loss 0.085572; Mean validation F1 0.937549; Learning rate 0.000293;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937549; loss - 0.085572;\n",
    "Group g4: f1 - 0.760677; loss - 0.280177;\n",
    "Group g9: f1 - 0.755838; loss - 0.282613;\n",
    "===========================================================\n",
    "Epoch 044/096 - Mean training loss 0.086954; Mean training F1 0.936688; Mean validation loss 0.085209; Mean validation F1 0.937514; Learning rate 0.000285;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937514; loss - 0.085209;\n",
    "Group g4: f1 - 0.756655; loss - 0.281206;\n",
    "Group g9: f1 - 0.750262; loss - 0.283811;\n",
    "===========================================================\n",
    "Epoch 045/096 - Mean training loss 0.086866; Mean training F1 0.936816; Mean validation loss 0.085694; Mean validation F1 0.936943; Learning rate 0.000277;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936943; loss - 0.085694;\n",
    "Group g4: f1 - 0.742848; loss - 0.280484;\n",
    "Group g9: f1 - 0.730473; loss - 0.283202;\n",
    "===========================================================\n",
    "Epoch 046/096 - Mean training loss 0.086344; Mean training F1 0.937051; Mean validation loss 0.085557; Mean validation F1 0.937456; Learning rate 0.000269;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937456; loss - 0.085557;\n",
    "Group g4: f1 - 0.764042; loss - 0.280971;\n",
    "Group g9: f1 - 0.764851; loss - 0.283366;\n",
    "===========================================================\n",
    "Epoch 047/096 - Mean training loss 0.086849; Mean training F1 0.936955; Mean validation loss 0.085330; Mean validation F1 0.937604; Learning rate 0.000261;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937604; loss - 0.085330;\n",
    "Group g4: f1 - 0.760802; loss - 0.281024;\n",
    "Group g9: f1 - 0.755792; loss - 0.283414;\n",
    "===========================================================\n",
    "Epoch 048/096 - Mean training loss 0.086039; Mean training F1 0.937183; Mean validation loss 0.084895; Mean validation F1 0.937473; Learning rate 0.000253;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937473; loss - 0.084895;\n",
    "Group g4: f1 - 0.749662; loss - 0.280489;\n",
    "Group g9: f1 - 0.743478; loss - 0.283062;\n",
    "===========================================================\n",
    "Epoch 049/096 - Mean training loss 0.086478; Mean training F1 0.937008; Mean validation loss 0.085430; Mean validation F1 0.936962; Learning rate 0.000245;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936962; loss - 0.085430;\n",
    "Group g4: f1 - 0.763332; loss - 0.281778;\n",
    "Group g9: f1 - 0.757589; loss - 0.284538;\n",
    "===========================================================\n",
    "Epoch 050/096 - Mean training loss 0.085681; Mean training F1 0.937188; Mean validation loss 0.085452; Mean validation F1 0.937629; Learning rate 0.000237;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937629; loss - 0.085452;\n",
    "Group g4: f1 - 0.759659; loss - 0.280808;\n",
    "Group g9: f1 - 0.757836; loss - 0.283068;\n",
    "===========================================================\n",
    "Epoch 051/096 - Mean training loss 0.085741; Mean training F1 0.937254; Mean validation loss 0.086593; Mean validation F1 0.936728; Learning rate 0.000228;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936728; loss - 0.086593;\n",
    "Group g4: f1 - 0.765819; loss - 0.283882;\n",
    "Group g9: f1 - 0.770623; loss - 0.287228;\n",
    "===========================================================\n",
    "Epoch 052/096 - Mean training loss 0.086061; Mean training F1 0.936998; Mean validation loss 0.085692; Mean validation F1 0.937045; Learning rate 0.000220;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937045; loss - 0.085692;\n",
    "Group g4: f1 - 0.765134; loss - 0.281850;\n",
    "Group g9: f1 - 0.760187; loss - 0.284592;\n",
    "===========================================================\n",
    "Epoch 053/096 - Mean training loss 0.085780; Mean training F1 0.937178; Mean validation loss 0.086666; Mean validation F1 0.936727; Learning rate 0.000212;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936727; loss - 0.086666;\n",
    "Group g4: f1 - 0.759624; loss - 0.282986;\n",
    "Group g9: f1 - 0.755014; loss - 0.286017;\n",
    "===========================================================\n",
    "Epoch 054/096 - Mean training loss 0.086070; Mean training F1 0.937009; Mean validation loss 0.085072; Mean validation F1 0.937916; Learning rate 0.000204;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937916; loss - 0.085072;\n",
    "Group g4: f1 - 0.767620; loss - 0.279756;\n",
    "Group g9: f1 - 0.762393; loss - 0.282229;\n",
    "===========================================================\n",
    "Epoch 055/096 - Mean training loss 0.085468; Mean training F1 0.937461; Mean validation loss 0.086067; Mean validation F1 0.937344; Learning rate 0.000197;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937344; loss - 0.086067;\n",
    "Group g4: f1 - 0.770771; loss - 0.280640;\n",
    "Group g9: f1 - 0.774559; loss - 0.282789;\n",
    "===========================================================\n",
    "Epoch 056/096 - Mean training loss 0.085378; Mean training F1 0.937337; Mean validation loss 0.084498; Mean validation F1 0.937963; Learning rate 0.000189;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937963; loss - 0.084498;\n",
    "Group g4: f1 - 0.749836; loss - 0.278979;\n",
    "Group g9: f1 - 0.737581; loss - 0.281521;\n",
    "===========================================================\n",
    "Epoch 057/096 - Mean training loss 0.085540; Mean training F1 0.937503; Mean validation loss 0.085038; Mean validation F1 0.937511; Learning rate 0.000181;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937511; loss - 0.085038;\n",
    "Group g4: f1 - 0.777864; loss - 0.280709;\n",
    "Group g9: f1 - 0.771893; loss - 0.283014;\n",
    "===========================================================\n",
    "Epoch 058/096 - Mean training loss 0.085322; Mean training F1 0.937438; Mean validation loss 0.084474; Mean validation F1 0.937928; Learning rate 0.000173;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937928; loss - 0.084474;\n",
    "Group g4: f1 - 0.762326; loss - 0.278951;\n",
    "Group g9: f1 - 0.759344; loss - 0.281354;\n",
    "===========================================================\n",
    "Epoch 059/096 - Mean training loss 0.085107; Mean training F1 0.937278; Mean validation loss 0.084490; Mean validation F1 0.937841; Learning rate 0.000166;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937841; loss - 0.084490;\n",
    "Group g4: f1 - 0.763615; loss - 0.279380;\n",
    "Group g9: f1 - 0.759680; loss - 0.281880;\n",
    "===========================================================\n",
    "Epoch 060/096 - Mean training loss 0.085009; Mean training F1 0.937609; Mean validation loss 0.085284; Mean validation F1 0.936953; Learning rate 0.000158;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936953; loss - 0.085284;\n",
    "Group g4: f1 - 0.770848; loss - 0.279824;\n",
    "Group g9: f1 - 0.779769; loss - 0.282507;\n",
    "===========================================================\n",
    "Epoch 061/096 - Mean training loss 0.084672; Mean training F1 0.937477; Mean validation loss 0.084689; Mean validation F1 0.937837; Learning rate 0.000151;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937837; loss - 0.084689;\n",
    "Group g4: f1 - 0.775605; loss - 0.279624;\n",
    "Group g9: f1 - 0.773629; loss - 0.282075;\n",
    "===========================================================\n",
    "Epoch 062/096 - Mean training loss 0.085299; Mean training F1 0.937476; Mean validation loss 0.084567; Mean validation F1 0.937738; Learning rate 0.000143;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937738; loss - 0.084567;\n",
    "Group g4: f1 - 0.767689; loss - 0.279455;\n",
    "Group g9: f1 - 0.755026; loss - 0.281975;\n",
    "===========================================================\n",
    "Epoch 063/096 - Mean training loss 0.084430; Mean training F1 0.937734; Mean validation loss 0.084247; Mean validation F1 0.937703; Learning rate 0.000136;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937703; loss - 0.084247;\n",
    "Group g4: f1 - 0.761405; loss - 0.278634;\n",
    "Group g9: f1 - 0.755207; loss - 0.281182;\n",
    "===========================================================\n",
    "Epoch 064/096 - Mean training loss 0.084168; Mean training F1 0.937773; Mean validation loss 0.084460; Mean validation F1 0.937193; Learning rate 0.000129;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937193; loss - 0.084460;\n",
    "Group g4: f1 - 0.764790; loss - 0.279959;\n",
    "Group g9: f1 - 0.755136; loss - 0.282668;\n",
    "===========================================================\n",
    "Epoch 065/096 - Mean training loss 0.084346; Mean training F1 0.937731; Mean validation loss 0.084133; Mean validation F1 0.937970; Learning rate 0.000122;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937970; loss - 0.084133;\n",
    "Group g4: f1 - 0.774972; loss - 0.278835;\n",
    "Group g9: f1 - 0.769199; loss - 0.281438;\n",
    "===========================================================\n",
    "Epoch 066/096 - Mean training loss 0.084152; Mean training F1 0.937974; Mean validation loss 0.084147; Mean validation F1 0.937776; Learning rate 0.000115;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937776; loss - 0.084147;\n",
    "Group g4: f1 - 0.775159; loss - 0.278349;\n",
    "Group g9: f1 - 0.769863; loss - 0.280912;\n",
    "===========================================================\n",
    "Epoch 067/096 - Mean training loss 0.083851; Mean training F1 0.937831; Mean validation loss 0.084050; Mean validation F1 0.938083; Learning rate 0.000109;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938083; loss - 0.084050;\n",
    "Group g4: f1 - 0.757883; loss - 0.278328;\n",
    "Group g9: f1 - 0.754015; loss - 0.280823;\n",
    "===========================================================\n",
    "Epoch 068/096 - Mean training loss 0.083716; Mean training F1 0.937832; Mean validation loss 0.085639; Mean validation F1 0.936936; Learning rate 0.000102;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.936936; loss - 0.085639;\n",
    "Group g4: f1 - 0.774135; loss - 0.282469;\n",
    "Group g9: f1 - 0.771537; loss - 0.284752;\n",
    "===========================================================\n",
    "Epoch 069/096 - Mean training loss 0.084130; Mean training F1 0.937634; Mean validation loss 0.084614; Mean validation F1 0.937670; Learning rate 0.000096;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937670; loss - 0.084614;\n",
    "Group g4: f1 - 0.762606; loss - 0.278866;\n",
    "Group g9: f1 - 0.754328; loss - 0.281419;\n",
    "===========================================================\n",
    "Epoch 070/096 - Mean training loss 0.083924; Mean training F1 0.937879; Mean validation loss 0.084334; Mean validation F1 0.937830; Learning rate 0.000090;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937830; loss - 0.084334;\n",
    "Group g4: f1 - 0.772476; loss - 0.279365;\n",
    "Group g9: f1 - 0.767100; loss - 0.281837;\n",
    "===========================================================\n",
    "Epoch 071/096 - Mean training loss 0.084158; Mean training F1 0.937988; Mean validation loss 0.084453; Mean validation F1 0.937971; Learning rate 0.000084;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937971; loss - 0.084453;\n",
    "Group g4: f1 - 0.765206; loss - 0.279647;\n",
    "Group g9: f1 - 0.769791; loss - 0.281862;\n",
    "===========================================================\n",
    "Epoch 072/096 - Mean training loss 0.084256; Mean training F1 0.937774; Mean validation loss 0.084518; Mean validation F1 0.937899; Learning rate 0.000078;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937899; loss - 0.084518;\n",
    "Group g4: f1 - 0.778047; loss - 0.277975;\n",
    "Group g9: f1 - 0.781031; loss - 0.280479;\n",
    "===========================================================\n",
    "Epoch 073/096 - Mean training loss 0.083322; Mean training F1 0.938108; Mean validation loss 0.084028; Mean validation F1 0.937960; Learning rate 0.000072;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937960; loss - 0.084028;\n",
    "Group g4: f1 - 0.761330; loss - 0.278144;\n",
    "Group g9: f1 - 0.753850; loss - 0.280699;\n",
    "===========================================================\n",
    "Epoch 074/096 - Mean training loss 0.083455; Mean training F1 0.938083; Mean validation loss 0.083939; Mean validation F1 0.938187; Learning rate 0.000067;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938187; loss - 0.083939;\n",
    "Group g4: f1 - 0.778865; loss - 0.277970;\n",
    "Group g9: f1 - 0.778065; loss - 0.280350;\n",
    "===========================================================\n",
    "Epoch 075/096 - Mean training loss 0.083642; Mean training F1 0.938003; Mean validation loss 0.083918; Mean validation F1 0.938200; Learning rate 0.000061;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938200; loss - 0.083918;\n",
    "Group g4: f1 - 0.773895; loss - 0.277933;\n",
    "Group g9: f1 - 0.765006; loss - 0.280476;\n",
    "===========================================================\n",
    "Epoch 076/096 - Mean training loss 0.083391; Mean training F1 0.938159; Mean validation loss 0.083968; Mean validation F1 0.938146; Learning rate 0.000056;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938146; loss - 0.083968;\n",
    "Group g4: f1 - 0.774823; loss - 0.277869;\n",
    "Group g9: f1 - 0.774743; loss - 0.280356;\n",
    "===========================================================\n",
    "Epoch 077/096 - Mean training loss 0.084052; Mean training F1 0.938129; Mean validation loss 0.084031; Mean validation F1 0.937683; Learning rate 0.000052;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937683; loss - 0.084031;\n",
    "Group g4: f1 - 0.772532; loss - 0.278596;\n",
    "Group g9: f1 - 0.769564; loss - 0.281243;\n",
    "===========================================================\n",
    "Epoch 078/096 - Mean training loss 0.083375; Mean training F1 0.938123; Mean validation loss 0.083931; Mean validation F1 0.938237; Learning rate 0.000047;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938237; loss - 0.083931;\n",
    "Group g4: f1 - 0.774364; loss - 0.278006;\n",
    "Group g9: f1 - 0.764122; loss - 0.280611;\n",
    "===========================================================\n",
    "Epoch 079/096 - Mean training loss 0.083345; Mean training F1 0.938291; Mean validation loss 0.083806; Mean validation F1 0.938185; Learning rate 0.000043;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938185; loss - 0.083806;\n",
    "Group g4: f1 - 0.779935; loss - 0.277801;\n",
    "Group g9: f1 - 0.776570; loss - 0.280366;\n",
    "===========================================================\n",
    "Epoch 080/096 - Mean training loss 0.083448; Mean training F1 0.938252; Mean validation loss 0.083860; Mean validation F1 0.938138; Learning rate 0.000038;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938138; loss - 0.083860;\n",
    "Group g4: f1 - 0.773959; loss - 0.277854;\n",
    "Group g9: f1 - 0.775799; loss - 0.280359;\n",
    "===========================================================\n",
    "Epoch 081/096 - Mean training loss 0.083128; Mean training F1 0.938287; Mean validation loss 0.083815; Mean validation F1 0.938083; Learning rate 0.000034;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938083; loss - 0.083815;\n",
    "Group g4: f1 - 0.772621; loss - 0.277761;\n",
    "Group g9: f1 - 0.764720; loss - 0.280383;\n",
    "===========================================================\n",
    "Epoch 082/096 - Mean training loss 0.083385; Mean training F1 0.938354; Mean validation loss 0.083832; Mean validation F1 0.937814; Learning rate 0.000031;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.937814; loss - 0.083832;\n",
    "Group g4: f1 - 0.773486; loss - 0.277954;\n",
    "Group g9: f1 - 0.766107; loss - 0.280527;\n",
    "===========================================================\n",
    "Epoch 083/096 - Mean training loss 0.083230; Mean training F1 0.938244; Mean validation loss 0.083853; Mean validation F1 0.938284; Learning rate 0.000027;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938284; loss - 0.083853;\n",
    "Group g4: f1 - 0.774659; loss - 0.277769;\n",
    "Group g9: f1 - 0.766798; loss - 0.280299;\n",
    "===========================================================\n",
    "Epoch 084/096 - Mean training loss 0.083093; Mean training F1 0.938326; Mean validation loss 0.083765; Mean validation F1 0.938223; Learning rate 0.000024;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938223; loss - 0.083765;\n",
    "Group g4: f1 - 0.777124; loss - 0.277559;\n",
    "Group g9: f1 - 0.775675; loss - 0.280113;\n",
    "===========================================================\n",
    "Epoch 085/096 - Mean training loss 0.083159; Mean training F1 0.938290; Mean validation loss 0.083768; Mean validation F1 0.938173; Learning rate 0.000021;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938173; loss - 0.083768;\n",
    "Group g4: f1 - 0.771187; loss - 0.277879;\n",
    "Group g9: f1 - 0.767978; loss - 0.280401;\n",
    "===========================================================\n",
    "Epoch 086/096 - Mean training loss 0.083082; Mean training F1 0.938239; Mean validation loss 0.083749; Mean validation F1 0.938148; Learning rate 0.000018;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938148; loss - 0.083749;\n",
    "Group g4: f1 - 0.770377; loss - 0.277869;\n",
    "Group g9: f1 - 0.768392; loss - 0.280374;\n",
    "===========================================================\n",
    "Epoch 087/096 - Mean training loss 0.082825; Mean training F1 0.938301; Mean validation loss 0.083725; Mean validation F1 0.938094; Learning rate 0.000016;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938094; loss - 0.083725;\n",
    "Group g4: f1 - 0.771646; loss - 0.277672;\n",
    "Group g9: f1 - 0.767456; loss - 0.280301;\n",
    "===========================================================\n",
    "Epoch 088/096 - Mean training loss 0.082908; Mean training F1 0.938461; Mean validation loss 0.083798; Mean validation F1 0.938207; Learning rate 0.000014;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938207; loss - 0.083798;\n",
    "Group g4: f1 - 0.773457; loss - 0.277747;\n",
    "Group g9: f1 - 0.769503; loss - 0.280301;\n",
    "===========================================================\n",
    "Epoch 089/096 - Mean training loss 0.083114; Mean training F1 0.938396; Mean validation loss 0.083661; Mean validation F1 0.938274; Learning rate 0.000012;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938274; loss - 0.083661;\n",
    "Group g4: f1 - 0.777599; loss - 0.277600;\n",
    "Group g9: f1 - 0.773491; loss - 0.280161;\n",
    "===========================================================\n",
    "Epoch 090/096 - Mean training loss 0.083209; Mean training F1 0.938382; Mean validation loss 0.083689; Mean validation F1 0.938289; Learning rate 0.000010;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938289; loss - 0.083689;\n",
    "Group g4: f1 - 0.774134; loss - 0.277573;\n",
    "Group g9: f1 - 0.767897; loss - 0.280158;\n",
    "===========================================================\n",
    "Epoch 091/096 - Mean training loss 0.083216; Mean training F1 0.938348; Mean validation loss 0.083714; Mean validation F1 0.938344; Learning rate 0.000008;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938344; loss - 0.083714;\n",
    "Group g4: f1 - 0.771757; loss - 0.277754;\n",
    "Group g9: f1 - 0.764126; loss - 0.280203;\n",
    "===========================================================\n",
    "Epoch 092/096 - Mean training loss 0.082676; Mean training F1 0.938436; Mean validation loss 0.083648; Mean validation F1 0.938266; Learning rate 0.000007;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938266; loss - 0.083648;\n",
    "Group g4: f1 - 0.773130; loss - 0.277530;\n",
    "Group g9: f1 - 0.768257; loss - 0.280151;\n",
    "===========================================================\n",
    "Epoch 093/096 - Mean training loss 0.082799; Mean training F1 0.938479; Mean validation loss 0.083806; Mean validation F1 0.938097; Learning rate 0.000006;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938097; loss - 0.083806;\n",
    "Group g4: f1 - 0.772243; loss - 0.277733;\n",
    "Group g9: f1 - 0.761323; loss - 0.280431;\n",
    "===========================================================\n",
    "Epoch 094/096 - Mean training loss 0.083057; Mean training F1 0.938321; Mean validation loss 0.083670; Mean validation F1 0.938193; Learning rate 0.000006;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938193; loss - 0.083670;\n",
    "Group g4: f1 - 0.773603; loss - 0.277569;\n",
    "Group g9: f1 - 0.767906; loss - 0.280092;\n",
    "===========================================================\n",
    "Epoch 095/096 - Mean training loss 0.083088; Mean training F1 0.938416; Mean validation loss 0.083688; Mean validation F1 0.938158; Learning rate 0.000005;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938158; loss - 0.083688;\n",
    "Group g4: f1 - 0.776612; loss - 0.277528;\n",
    "Group g9: f1 - 0.775687; loss - 0.280014;\n",
    "===========================================================\n",
    "Epoch 096/096 - Mean training loss 0.083092; Mean training F1 0.938408; Mean validation loss 0.083665; Mean validation F1 0.938177; Learning rate 0.000005;\n",
    "Validation metrics:\n",
    "Group vld: f1 - 0.938177; loss - 0.083665;\n",
    "Group g4: f1 - 0.774731; loss - 0.277592;\n",
    "Group g9: f1 - 0.765596; loss - 0.280194;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-------- fold 0 --------\n",
    "model validation loss: 0.095; validation f1: 0.939;\n",
    "-------- fold 1 --------\n",
    "model validation loss: 0.062; validation f1: 0.937;\n",
    "-------- fold 2 --------\n",
    "model validation loss: 0.095; validation f1: 0.937;\n",
    "-------- fold 3 --------\n",
    "model validation loss: 0.061; validation f1: 0.939;\n",
    "-------- fold 4 --------\n",
    "model validation loss: 0.061; validation f1: 0.939;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "################################################################\n",
    "Training/validation for fold 1/5;\n",
    "===========================================================\n",
    "Epoch 001/096 - Mean training loss 0.427053; Mean training F1 0.719997; Mean validation loss 0.157788; Mean validation F1 0.904941; Learning rate 0.000500;\n",
    "===========================================================\n",
    "Epoch 002/096 - Mean training loss 0.159833; Mean training F1 0.882014; Mean validation loss 0.146290; Mean validation F1 0.914156; Learning rate 0.000500;\n",
    "===========================================================\n",
    "Epoch 003/096 - Mean training loss 0.133551; Mean training F1 0.897157; Mean validation loss 0.134820; Mean validation F1 0.924612; Learning rate 0.000499;\n",
    "===========================================================\n",
    "Epoch 004/096 - Mean training loss 0.178729; Mean training F1 0.875723; Mean validation loss 0.163564; Mean validation F1 0.927975; Learning rate 0.000498;\n",
    "===========================================================\n",
    "Epoch 005/096 - Mean training loss 0.113420; Mean training F1 0.916307; Mean validation loss 0.087535; Mean validation F1 0.933290; Learning rate 0.000497;\n",
    "===========================================================\n",
    "Epoch 006/096 - Mean training loss 0.103833; Mean training F1 0.923584; Mean validation loss 0.115553; Mean validation F1 0.929277; Learning rate 0.000496;\n",
    "===========================================================\n",
    "Epoch 007/096 - Mean training loss 0.100111; Mean training F1 0.927184; Mean validation loss 0.089827; Mean validation F1 0.933929; Learning rate 0.000494;\n",
    "===========================================================\n",
    "Epoch 008/096 - Mean training loss 0.097609; Mean training F1 0.927080; Mean validation loss 0.089039; Mean validation F1 0.934180; Learning rate 0.000492;\n",
    "===========================================================\n",
    "Epoch 009/096 - Mean training loss 0.093451; Mean training F1 0.930878; Mean validation loss 0.095206; Mean validation F1 0.934936; Learning rate 0.000490;\n",
    "===========================================================\n",
    "Epoch 010/096 - Mean training loss 0.092379; Mean training F1 0.931282; Mean validation loss 0.070450; Mean validation F1 0.932966; Learning rate 0.000487;\n",
    "===========================================================\n",
    "Epoch 011/096 - Mean training loss 0.092845; Mean training F1 0.929958; Mean validation loss 0.096474; Mean validation F1 0.937538; Learning rate 0.000484;\n",
    "===========================================================\n",
    "Epoch 012/096 - Mean training loss 0.089828; Mean training F1 0.932747; Mean validation loss 0.075376; Mean validation F1 0.936033; Learning rate 0.000481;\n",
    "===========================================================\n",
    "Epoch 013/096 - Mean training loss 0.102658; Mean training F1 0.925116; Mean validation loss 0.102938; Mean validation F1 0.933750; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 014/096 - Mean training loss 0.093856; Mean training F1 0.929904; Mean validation loss 0.106239; Mean validation F1 0.936274; Learning rate 0.000475;\n",
    "===========================================================\n",
    "Epoch 015/096 - Mean training loss 0.088703; Mean training F1 0.933483; Mean validation loss 0.035435; Mean validation F1 0.936063; Learning rate 0.000471;\n",
    "===========================================================\n",
    "Epoch 016/096 - Mean training loss 0.088990; Mean training F1 0.933346; Mean validation loss 0.076228; Mean validation F1 0.935749; Learning rate 0.000467;\n",
    "===========================================================\n",
    "Epoch 017/096 - Mean training loss 0.088518; Mean training F1 0.933790; Mean validation loss 0.054120; Mean validation F1 0.937558; Learning rate 0.000463;\n",
    "===========================================================\n",
    "Epoch 018/096 - Mean training loss 0.087423; Mean training F1 0.933960; Mean validation loss 0.078350; Mean validation F1 0.936952; Learning rate 0.000459;\n",
    "===========================================================\n",
    "Epoch 019/096 - Mean training loss 0.087172; Mean training F1 0.934101; Mean validation loss 0.138057; Mean validation F1 0.937080; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 020/096 - Mean training loss 0.087445; Mean training F1 0.933746; Mean validation loss 0.089963; Mean validation F1 0.936028; Learning rate 0.000449;\n",
    "===========================================================\n",
    "Epoch 021/096 - Mean training loss 0.086702; Mean training F1 0.934803; Mean validation loss 0.076772; Mean validation F1 0.937813; Learning rate 0.000444;\n",
    "===========================================================\n",
    "Epoch 022/096 - Mean training loss 0.086272; Mean training F1 0.935037; Mean validation loss 0.098796; Mean validation F1 0.933390; Learning rate 0.000439;\n",
    "===========================================================\n",
    "Epoch 023/096 - Mean training loss 0.086216; Mean training F1 0.934881; Mean validation loss 0.073814; Mean validation F1 0.934886; Learning rate 0.000433;\n",
    "===========================================================\n",
    "Epoch 024/096 - Mean training loss 0.085960; Mean training F1 0.935237; Mean validation loss 0.057394; Mean validation F1 0.938733; Learning rate 0.000428;\n",
    "===========================================================\n",
    "Epoch 025/096 - Mean training loss 0.085656; Mean training F1 0.935277; Mean validation loss 0.072783; Mean validation F1 0.936911; Learning rate 0.000422;\n",
    "===========================================================\n",
    "Epoch 026/096 - Mean training loss 0.085557; Mean training F1 0.935096; Mean validation loss 0.066365; Mean validation F1 0.938019; Learning rate 0.000416;\n",
    "===========================================================\n",
    "Epoch 027/096 - Mean training loss 0.085018; Mean training F1 0.935841; Mean validation loss 0.104756; Mean validation F1 0.938541; Learning rate 0.000410;\n",
    "===========================================================\n",
    "Epoch 028/096 - Mean training loss 0.084766; Mean training F1 0.936099; Mean validation loss 0.100022; Mean validation F1 0.937945; Learning rate 0.000403;\n",
    "===========================================================\n",
    "Epoch 029/096 - Mean training loss 0.084439; Mean training F1 0.935783; Mean validation loss 0.079025; Mean validation F1 0.938278; Learning rate 0.000397;\n",
    "===========================================================\n",
    "Epoch 030/096 - Mean training loss 0.084524; Mean training F1 0.935966; Mean validation loss 0.073444; Mean validation F1 0.938573; Learning rate 0.000390;\n",
    "===========================================================\n",
    "Epoch 031/096 - Mean training loss 0.140982; Mean training F1 0.913847; Mean validation loss 0.102051; Mean validation F1 0.933927; Learning rate 0.000383;\n",
    "===========================================================\n",
    "Epoch 032/096 - Mean training loss 0.092145; Mean training F1 0.932633; Mean validation loss 0.060174; Mean validation F1 0.937985; Learning rate 0.000377;\n",
    "===========================================================\n",
    "Epoch 033/096 - Mean training loss 0.088860; Mean training F1 0.934066; Mean validation loss 0.078800; Mean validation F1 0.937688; Learning rate 0.000369;\n",
    "===========================================================\n",
    "Epoch 034/096 - Mean training loss 0.086768; Mean training F1 0.935209; Mean validation loss 0.106463; Mean validation F1 0.938499; Learning rate 0.000362;\n",
    "===========================================================\n",
    "Epoch 035/096 - Mean training loss 0.085537; Mean training F1 0.935786; Mean validation loss 0.059723; Mean validation F1 0.937111; Learning rate 0.000355;\n",
    "===========================================================\n",
    "Epoch 036/096 - Mean training loss 0.085092; Mean training F1 0.935989; Mean validation loss 0.124292; Mean validation F1 0.938608; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 037/096 - Mean training loss 0.084409; Mean training F1 0.936276; Mean validation loss 0.062715; Mean validation F1 0.936547; Learning rate 0.000340;\n",
    "===========================================================\n",
    "Epoch 038/096 - Mean training loss 0.084186; Mean training F1 0.936331; Mean validation loss 0.114687; Mean validation F1 0.937705; Learning rate 0.000332;\n",
    "===========================================================\n",
    "Epoch 039/096 - Mean training loss 0.083773; Mean training F1 0.936739; Mean validation loss 0.085199; Mean validation F1 0.938155; Learning rate 0.000325;\n",
    "===========================================================\n",
    "Epoch 040/096 - Mean training loss 0.083843; Mean training F1 0.936492; Mean validation loss 0.100507; Mean validation F1 0.938745; Learning rate 0.000317;\n",
    "===========================================================\n",
    "Epoch 041/096 - Mean training loss 0.083590; Mean training F1 0.936474; Mean validation loss 0.079642; Mean validation F1 0.937720; Learning rate 0.000309;\n",
    "===========================================================\n",
    "Epoch 042/096 - Mean training loss 0.083267; Mean training F1 0.937112; Mean validation loss 0.071169; Mean validation F1 0.939145; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 043/096 - Mean training loss 0.083049; Mean training F1 0.937181; Mean validation loss 0.064106; Mean validation F1 0.938129; Learning rate 0.000293;\n",
    "===========================================================\n",
    "Epoch 044/096 - Mean training loss 0.083053; Mean training F1 0.936971; Mean validation loss 0.036235; Mean validation F1 0.937409; Learning rate 0.000285;\n",
    "===========================================================\n",
    "Epoch 045/096 - Mean training loss 0.082816; Mean training F1 0.937394; Mean validation loss 0.097111; Mean validation F1 0.939006; Learning rate 0.000277;\n",
    "===========================================================\n",
    "Epoch 046/096 - Mean training loss 0.082792; Mean training F1 0.937166; Mean validation loss 0.052730; Mean validation F1 0.938573; Learning rate 0.000269;\n",
    "===========================================================\n",
    "Epoch 047/096 - Mean training loss 0.082568; Mean training F1 0.937257; Mean validation loss 0.073013; Mean validation F1 0.939228; Learning rate 0.000261;\n",
    "===========================================================\n",
    "Epoch 048/096 - Mean training loss 0.082373; Mean training F1 0.937369; Mean validation loss 0.064467; Mean validation F1 0.938997; Learning rate 0.000253;\n",
    "===========================================================\n",
    "Epoch 049/096 - Mean training loss 0.082196; Mean training F1 0.937192; Mean validation loss 0.091947; Mean validation F1 0.938309; Learning rate 0.000245;\n",
    "===========================================================\n",
    "Epoch 050/096 - Mean training loss 0.082383; Mean training F1 0.937407; Mean validation loss 0.085980; Mean validation F1 0.938829; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 051/096 - Mean training loss 0.082000; Mean training F1 0.937640; Mean validation loss 0.062079; Mean validation F1 0.938568; Learning rate 0.000228;\n",
    "===========================================================\n",
    "Epoch 052/096 - Mean training loss 0.082181; Mean training F1 0.937411; Mean validation loss 0.103885; Mean validation F1 0.939069; Learning rate 0.000220;\n",
    "===========================================================\n",
    "Epoch 053/096 - Mean training loss 0.081724; Mean training F1 0.937835; Mean validation loss 0.078203; Mean validation F1 0.936569; Learning rate 0.000212;\n",
    "===========================================================\n",
    "Epoch 054/096 - Mean training loss 0.081705; Mean training F1 0.937742; Mean validation loss 0.082344; Mean validation F1 0.939143; Learning rate 0.000204;\n",
    "===========================================================\n",
    "Epoch 055/096 - Mean training loss 0.081430; Mean training F1 0.937836; Mean validation loss 0.071595; Mean validation F1 0.938641; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 056/096 - Mean training loss 0.081252; Mean training F1 0.938185; Mean validation loss 0.091750; Mean validation F1 0.939077; Learning rate 0.000189;\n",
    "===========================================================\n",
    "Epoch 057/096 - Mean training loss 0.081271; Mean training F1 0.938033; Mean validation loss 0.101835; Mean validation F1 0.938982; Learning rate 0.000181;\n",
    "===========================================================\n",
    "Epoch 058/096 - Mean training loss 0.081336; Mean training F1 0.937800; Mean validation loss 0.073870; Mean validation F1 0.938589; Learning rate 0.000173;\n",
    "===========================================================\n",
    "Epoch 059/096 - Mean training loss 0.080945; Mean training F1 0.938287; Mean validation loss 0.104467; Mean validation F1 0.938332; Learning rate 0.000166;\n",
    "===========================================================\n",
    "Epoch 060/096 - Mean training loss 0.080587; Mean training F1 0.938380; Mean validation loss 0.094439; Mean validation F1 0.939167; Learning rate 0.000158;\n",
    "===========================================================\n",
    "Epoch 061/096 - Mean training loss 0.080563; Mean training F1 0.938343; Mean validation loss 0.100542; Mean validation F1 0.939267; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 062/096 - Mean training loss 0.080689; Mean training F1 0.938280; Mean validation loss 0.091423; Mean validation F1 0.938577; Learning rate 0.000143;\n",
    "===========================================================\n",
    "Epoch 063/096 - Mean training loss 0.080386; Mean training F1 0.938559; Mean validation loss 0.064779; Mean validation F1 0.937854; Learning rate 0.000136;\n",
    "===========================================================\n",
    "Epoch 064/096 - Mean training loss 0.080038; Mean training F1 0.938737; Mean validation loss 0.062872; Mean validation F1 0.938968; Learning rate 0.000129;\n",
    "===========================================================\n",
    "Epoch 065/096 - Mean training loss 0.079928; Mean training F1 0.938700; Mean validation loss 0.086492; Mean validation F1 0.938900; Learning rate 0.000122;\n",
    "===========================================================\n",
    "Epoch 066/096 - Mean training loss 0.079768; Mean training F1 0.938822; Mean validation loss 0.064734; Mean validation F1 0.938078; Learning rate 0.000115;\n",
    "===========================================================\n",
    "Epoch 067/096 - Mean training loss 0.079658; Mean training F1 0.938908; Mean validation loss 0.094464; Mean validation F1 0.939153; Learning rate 0.000109;\n",
    "===========================================================\n",
    "Epoch 068/096 - Mean training loss 0.079413; Mean training F1 0.939119; Mean validation loss 0.087999; Mean validation F1 0.938944; Learning rate 0.000102;\n",
    "===========================================================\n",
    "Epoch 069/096 - Mean training loss 0.079194; Mean training F1 0.939229; Mean validation loss 0.077751; Mean validation F1 0.937806; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 070/096 - Mean training loss 0.079150; Mean training F1 0.939050; Mean validation loss 0.086330; Mean validation F1 0.937580; Learning rate 0.000090;\n",
    "===========================================================\n",
    "Epoch 071/096 - Mean training loss 0.078945; Mean training F1 0.939189; Mean validation loss 0.068755; Mean validation F1 0.938088; Learning rate 0.000084;\n",
    "===========================================================\n",
    "Epoch 072/096 - Mean training loss 0.078783; Mean training F1 0.939353; Mean validation loss 0.097753; Mean validation F1 0.938867; Learning rate 0.000078;\n",
    "===========================================================\n",
    "Epoch 073/096 - Mean training loss 0.078493; Mean training F1 0.939647; Mean validation loss 0.095341; Mean validation F1 0.939313; Learning rate 0.000072;\n",
    "===========================================================\n",
    "Epoch 074/096 - Mean training loss 0.078424; Mean training F1 0.939519; Mean validation loss 0.087711; Mean validation F1 0.938544; Learning rate 0.000067;\n",
    "===========================================================\n",
    "Epoch 075/096 - Mean training loss 0.078302; Mean training F1 0.939767; Mean validation loss 0.102267; Mean validation F1 0.939069; Learning rate 0.000061;\n",
    "===========================================================\n",
    "Epoch 076/096 - Mean training loss 0.078059; Mean training F1 0.939793; Mean validation loss 0.097352; Mean validation F1 0.939130; Learning rate 0.000056;\n",
    "===========================================================\n",
    "Epoch 077/096 - Mean training loss 0.077920; Mean training F1 0.939886; Mean validation loss 0.065793; Mean validation F1 0.938948; Learning rate 0.000052;\n",
    "===========================================================\n",
    "Epoch 078/096 - Mean training loss 0.077786; Mean training F1 0.939878; Mean validation loss 0.077632; Mean validation F1 0.938600; Learning rate 0.000047;\n",
    "===========================================================\n",
    "Epoch 079/096 - Mean training loss 0.077649; Mean training F1 0.939812; Mean validation loss 0.099055; Mean validation F1 0.939241; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 080/096 - Mean training loss 0.077464; Mean training F1 0.939970; Mean validation loss 0.061416; Mean validation F1 0.938914; Learning rate 0.000038;\n",
    "===========================================================\n",
    "Epoch 081/096 - Mean training loss 0.077311; Mean training F1 0.940158; Mean validation loss 0.037914; Mean validation F1 0.939046; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 082/096 - Mean training loss 0.077134; Mean training F1 0.940301; Mean validation loss 0.079193; Mean validation F1 0.938498; Learning rate 0.000031;\n",
    "===========================================================\n",
    "Epoch 083/096 - Mean training loss 0.077121; Mean training F1 0.940207; Mean validation loss 0.067838; Mean validation F1 0.938606; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 084/096 - Mean training loss 0.076957; Mean training F1 0.940244; Mean validation loss 0.092256; Mean validation F1 0.938543; Learning rate 0.000024;\n",
    "===========================================================\n",
    "Epoch 085/096 - Mean training loss 0.076814; Mean training F1 0.940351; Mean validation loss 0.082783; Mean validation F1 0.938892; Learning rate 0.000021;\n",
    "===========================================================\n",
    "Epoch 086/096 - Mean training loss 0.076797; Mean training F1 0.940323; Mean validation loss 0.132158; Mean validation F1 0.938965; Learning rate 0.000018;\n",
    "===========================================================\n",
    "Epoch 087/096 - Mean training loss 0.076689; Mean training F1 0.940489; Mean validation loss 0.067002; Mean validation F1 0.939108; Learning rate 0.000016;\n",
    "===========================================================\n",
    "Epoch 088/096 - Mean training loss 0.076573; Mean training F1 0.940598; Mean validation loss 0.087865; Mean validation F1 0.939129; Learning rate 0.000014;\n",
    "===========================================================\n",
    "Epoch 089/096 - Mean training loss 0.076520; Mean training F1 0.940560; Mean validation loss 0.033237; Mean validation F1 0.939008; Learning rate 0.000012;\n",
    "===========================================================\n",
    "Epoch 090/096 - Mean training loss 0.076405; Mean training F1 0.940549; Mean validation loss 0.075173; Mean validation F1 0.938916; Learning rate 0.000010;\n",
    "===========================================================\n",
    "Epoch 091/096 - Mean training loss 0.076427; Mean training F1 0.940589; Mean validation loss 0.116932; Mean validation F1 0.938898; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 092/096 - Mean training loss 0.076372; Mean training F1 0.940665; Mean validation loss 0.060591; Mean validation F1 0.939045; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 093/096 - Mean training loss 0.076287; Mean training F1 0.940701; Mean validation loss 0.056117; Mean validation F1 0.939090; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 094/096 - Mean training loss 0.076316; Mean training F1 0.940691; Mean validation loss 0.093555; Mean validation F1 0.938944; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 095/096 - Mean training loss 0.076290; Mean training F1 0.940723; Mean validation loss 0.095410; Mean validation F1 0.939016; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 096/096 - Mean training loss 0.076241; Mean training F1 0.940822; Mean validation loss 0.084339; Mean validation F1 0.938990; Learning rate 0.000005;\n",
    "################################################################\n",
    "Training/validation for fold 2/5;\n",
    "===========================================================\n",
    "Epoch 001/096 - Mean training loss 0.447238; Mean training F1 0.703941; Mean validation loss 0.226672; Mean validation F1 0.903899; Learning rate 0.000500;\n",
    "===========================================================\n",
    "Epoch 002/096 - Mean training loss 0.188791; Mean training F1 0.866313; Mean validation loss 0.142585; Mean validation F1 0.908550; Learning rate 0.000500;\n",
    "===========================================================\n",
    "Epoch 003/096 - Mean training loss 0.141775; Mean training F1 0.900405; Mean validation loss 0.127600; Mean validation F1 0.923941; Learning rate 0.000499;\n",
    "===========================================================\n",
    "Epoch 004/096 - Mean training loss 0.117152; Mean training F1 0.912546; Mean validation loss 0.119064; Mean validation F1 0.901711; Learning rate 0.000498;\n",
    "===========================================================\n",
    "Epoch 005/096 - Mean training loss 0.122020; Mean training F1 0.912916; Mean validation loss 0.124747; Mean validation F1 0.925980; Learning rate 0.000497;\n",
    "===========================================================\n",
    "Epoch 006/096 - Mean training loss 0.103119; Mean training F1 0.922138; Mean validation loss 0.106640; Mean validation F1 0.909917; Learning rate 0.000496;\n",
    "===========================================================\n",
    "Epoch 007/096 - Mean training loss 0.097523; Mean training F1 0.926290; Mean validation loss 0.108097; Mean validation F1 0.900425; Learning rate 0.000494;\n",
    "===========================================================\n",
    "Epoch 008/096 - Mean training loss 0.093031; Mean training F1 0.929270; Mean validation loss 0.082286; Mean validation F1 0.923465; Learning rate 0.000492;\n",
    "===========================================================\n",
    "Epoch 009/096 - Mean training loss 0.101458; Mean training F1 0.924438; Mean validation loss 0.105697; Mean validation F1 0.932299; Learning rate 0.000490;\n",
    "===========================================================\n",
    "Epoch 010/096 - Mean training loss 0.091094; Mean training F1 0.931042; Mean validation loss 0.082979; Mean validation F1 0.931369; Learning rate 0.000487;\n",
    "===========================================================\n",
    "Epoch 011/096 - Mean training loss 0.089671; Mean training F1 0.931983; Mean validation loss 0.109314; Mean validation F1 0.932828; Learning rate 0.000484;\n",
    "===========================================================\n",
    "Epoch 012/096 - Mean training loss 0.088955; Mean training F1 0.932331; Mean validation loss 0.063286; Mean validation F1 0.931966; Learning rate 0.000481;\n",
    "===========================================================\n",
    "Epoch 013/096 - Mean training loss 0.088572; Mean training F1 0.932156; Mean validation loss 0.101764; Mean validation F1 0.932465; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 014/096 - Mean training loss 0.087665; Mean training F1 0.932890; Mean validation loss 0.085685; Mean validation F1 0.933209; Learning rate 0.000475;\n",
    "===========================================================\n",
    "Epoch 015/096 - Mean training loss 0.087389; Mean training F1 0.933152; Mean validation loss 0.112142; Mean validation F1 0.932909; Learning rate 0.000471;\n",
    "===========================================================\n",
    "Epoch 016/096 - Mean training loss 0.086112; Mean training F1 0.934355; Mean validation loss 0.088221; Mean validation F1 0.932576; Learning rate 0.000467;\n",
    "===========================================================\n",
    "Epoch 017/096 - Mean training loss 0.087107; Mean training F1 0.933515; Mean validation loss 0.095407; Mean validation F1 0.932008; Learning rate 0.000463;\n",
    "===========================================================\n",
    "Epoch 018/096 - Mean training loss 0.088312; Mean training F1 0.932106; Mean validation loss 0.095500; Mean validation F1 0.934943; Learning rate 0.000459;\n",
    "===========================================================\n",
    "Epoch 019/096 - Mean training loss 0.087562; Mean training F1 0.932979; Mean validation loss 0.069770; Mean validation F1 0.935518; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 020/096 - Mean training loss 0.085155; Mean training F1 0.935097; Mean validation loss 0.092726; Mean validation F1 0.933120; Learning rate 0.000449;\n",
    "===========================================================\n",
    "Epoch 021/096 - Mean training loss 0.086912; Mean training F1 0.933644; Mean validation loss 0.091351; Mean validation F1 0.934052; Learning rate 0.000444;\n",
    "===========================================================\n",
    "Epoch 022/096 - Mean training loss 0.084936; Mean training F1 0.935221; Mean validation loss 0.054688; Mean validation F1 0.935185; Learning rate 0.000439;\n",
    "===========================================================\n",
    "Epoch 023/096 - Mean training loss 0.085977; Mean training F1 0.933377; Mean validation loss 0.081577; Mean validation F1 0.934360; Learning rate 0.000433;\n",
    "===========================================================\n",
    "Epoch 024/096 - Mean training loss 0.084307; Mean training F1 0.936028; Mean validation loss 0.092105; Mean validation F1 0.935900; Learning rate 0.000428;\n",
    "===========================================================\n",
    "Epoch 025/096 - Mean training loss 0.084407; Mean training F1 0.935525; Mean validation loss 0.062688; Mean validation F1 0.935435; Learning rate 0.000422;\n",
    "===========================================================\n",
    "Epoch 026/096 - Mean training loss 0.084478; Mean training F1 0.935339; Mean validation loss 0.085214; Mean validation F1 0.925770; Learning rate 0.000416;\n",
    "===========================================================\n",
    "Epoch 027/096 - Mean training loss 0.204767; Mean training F1 0.884674; Mean validation loss 0.098937; Mean validation F1 0.931841; Learning rate 0.000410;\n",
    "===========================================================\n",
    "Epoch 028/096 - Mean training loss 0.092571; Mean training F1 0.931827; Mean validation loss 0.121501; Mean validation F1 0.932730; Learning rate 0.000403;\n",
    "===========================================================\n",
    "Epoch 029/096 - Mean training loss 0.090339; Mean training F1 0.932750; Mean validation loss 0.085485; Mean validation F1 0.935119; Learning rate 0.000397;\n",
    "===========================================================\n",
    "Epoch 030/096 - Mean training loss 0.087645; Mean training F1 0.934171; Mean validation loss 0.089760; Mean validation F1 0.935378; Learning rate 0.000390;\n",
    "===========================================================\n",
    "Epoch 031/096 - Mean training loss 0.087147; Mean training F1 0.934164; Mean validation loss 0.061809; Mean validation F1 0.931797; Learning rate 0.000383;\n",
    "===========================================================\n",
    "Epoch 032/096 - Mean training loss 0.086092; Mean training F1 0.934770; Mean validation loss 0.098906; Mean validation F1 0.935870; Learning rate 0.000377;\n",
    "===========================================================\n",
    "Epoch 033/096 - Mean training loss 0.084880; Mean training F1 0.935655; Mean validation loss 0.106161; Mean validation F1 0.933484; Learning rate 0.000369;\n",
    "===========================================================\n",
    "Epoch 034/096 - Mean training loss 0.084787; Mean training F1 0.935562; Mean validation loss 0.081289; Mean validation F1 0.935658; Learning rate 0.000362;\n",
    "===========================================================\n",
    "Epoch 035/096 - Mean training loss 0.086431; Mean training F1 0.935159; Mean validation loss 0.080151; Mean validation F1 0.929606; Learning rate 0.000355;\n",
    "===========================================================\n",
    "Epoch 036/096 - Mean training loss 0.084078; Mean training F1 0.935801; Mean validation loss 0.070599; Mean validation F1 0.935246; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 037/096 - Mean training loss 0.083559; Mean training F1 0.936190; Mean validation loss 0.089681; Mean validation F1 0.935851; Learning rate 0.000340;\n",
    "===========================================================\n",
    "Epoch 038/096 - Mean training loss 0.083026; Mean training F1 0.936657; Mean validation loss 0.087491; Mean validation F1 0.935755; Learning rate 0.000332;\n",
    "===========================================================\n",
    "Epoch 039/096 - Mean training loss 0.082916; Mean training F1 0.936597; Mean validation loss 0.077491; Mean validation F1 0.935752; Learning rate 0.000325;\n",
    "===========================================================\n",
    "Epoch 040/096 - Mean training loss 0.082692; Mean training F1 0.936952; Mean validation loss 0.091577; Mean validation F1 0.936321; Learning rate 0.000317;\n",
    "===========================================================\n",
    "Epoch 041/096 - Mean training loss 0.082542; Mean training F1 0.937006; Mean validation loss 0.085207; Mean validation F1 0.935471; Learning rate 0.000309;\n",
    "===========================================================\n",
    "Epoch 042/096 - Mean training loss 0.082881; Mean training F1 0.936428; Mean validation loss 0.102303; Mean validation F1 0.936241; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 043/096 - Mean training loss 0.082126; Mean training F1 0.937049; Mean validation loss 0.061887; Mean validation F1 0.935962; Learning rate 0.000293;\n",
    "===========================================================\n",
    "Epoch 044/096 - Mean training loss 0.082489; Mean training F1 0.936670; Mean validation loss 0.091209; Mean validation F1 0.936800; Learning rate 0.000285;\n",
    "===========================================================\n",
    "Epoch 045/096 - Mean training loss 0.081909; Mean training F1 0.937288; Mean validation loss 0.068194; Mean validation F1 0.936523; Learning rate 0.000277;\n",
    "===========================================================\n",
    "Epoch 046/096 - Mean training loss 0.081980; Mean training F1 0.937293; Mean validation loss 0.074694; Mean validation F1 0.936680; Learning rate 0.000269;\n",
    "===========================================================\n",
    "Epoch 047/096 - Mean training loss 0.081775; Mean training F1 0.937092; Mean validation loss 0.069949; Mean validation F1 0.936111; Learning rate 0.000261;\n",
    "===========================================================\n",
    "Epoch 048/096 - Mean training loss 0.081644; Mean training F1 0.937254; Mean validation loss 0.069965; Mean validation F1 0.936795; Learning rate 0.000253;\n",
    "===========================================================\n",
    "Epoch 049/096 - Mean training loss 0.081376; Mean training F1 0.937467; Mean validation loss 0.068728; Mean validation F1 0.936365; Learning rate 0.000245;\n",
    "===========================================================\n",
    "Epoch 050/096 - Mean training loss 0.081104; Mean training F1 0.937775; Mean validation loss 0.103270; Mean validation F1 0.936227; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 051/096 - Mean training loss 0.081303; Mean training F1 0.937410; Mean validation loss 0.084964; Mean validation F1 0.936125; Learning rate 0.000228;\n",
    "===========================================================\n",
    "Epoch 052/096 - Mean training loss 0.080975; Mean training F1 0.937474; Mean validation loss 0.092626; Mean validation F1 0.932641; Learning rate 0.000220;\n",
    "===========================================================\n",
    "Epoch 053/096 - Mean training loss 0.081294; Mean training F1 0.937584; Mean validation loss 0.051567; Mean validation F1 0.936628; Learning rate 0.000212;\n",
    "===========================================================\n",
    "Epoch 054/096 - Mean training loss 0.080627; Mean training F1 0.937975; Mean validation loss 0.071407; Mean validation F1 0.937140; Learning rate 0.000204;\n",
    "===========================================================\n",
    "Epoch 055/096 - Mean training loss 0.080581; Mean training F1 0.937976; Mean validation loss 0.054307; Mean validation F1 0.935930; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 056/096 - Mean training loss 0.080420; Mean training F1 0.937983; Mean validation loss 0.056378; Mean validation F1 0.937192; Learning rate 0.000189;\n",
    "===========================================================\n",
    "Epoch 057/096 - Mean training loss 0.080181; Mean training F1 0.938324; Mean validation loss 0.084305; Mean validation F1 0.936992; Learning rate 0.000181;\n",
    "===========================================================\n",
    "Epoch 058/096 - Mean training loss 0.080268; Mean training F1 0.938054; Mean validation loss 0.086820; Mean validation F1 0.936260; Learning rate 0.000173;\n",
    "===========================================================\n",
    "Epoch 059/096 - Mean training loss 0.080730; Mean training F1 0.937944; Mean validation loss 0.062478; Mean validation F1 0.937489; Learning rate 0.000166;\n",
    "===========================================================\n",
    "Epoch 060/096 - Mean training loss 0.079605; Mean training F1 0.938598; Mean validation loss 0.100206; Mean validation F1 0.935960; Learning rate 0.000158;\n",
    "===========================================================\n",
    "Epoch 061/096 - Mean training loss 0.079594; Mean training F1 0.938593; Mean validation loss 0.051889; Mean validation F1 0.936914; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 062/096 - Mean training loss 0.079777; Mean training F1 0.938684; Mean validation loss 0.099512; Mean validation F1 0.936839; Learning rate 0.000143;\n",
    "===========================================================\n",
    "Epoch 063/096 - Mean training loss 0.079307; Mean training F1 0.938930; Mean validation loss 0.047814; Mean validation F1 0.936629; Learning rate 0.000136;\n",
    "===========================================================\n",
    "Epoch 064/096 - Mean training loss 0.079092; Mean training F1 0.938972; Mean validation loss 0.055922; Mean validation F1 0.937470; Learning rate 0.000129;\n",
    "===========================================================\n",
    "Epoch 065/096 - Mean training loss 0.079078; Mean training F1 0.938922; Mean validation loss 0.078243; Mean validation F1 0.936831; Learning rate 0.000122;\n",
    "===========================================================\n",
    "Epoch 066/096 - Mean training loss 0.079067; Mean training F1 0.938911; Mean validation loss 0.080439; Mean validation F1 0.936678; Learning rate 0.000115;\n",
    "===========================================================\n",
    "Epoch 067/096 - Mean training loss 0.078703; Mean training F1 0.939153; Mean validation loss 0.052012; Mean validation F1 0.937065; Learning rate 0.000109;\n",
    "===========================================================\n",
    "Epoch 068/096 - Mean training loss 0.078665; Mean training F1 0.939128; Mean validation loss 0.107762; Mean validation F1 0.937165; Learning rate 0.000102;\n",
    "===========================================================\n",
    "Epoch 069/096 - Mean training loss 0.078450; Mean training F1 0.939219; Mean validation loss 0.089202; Mean validation F1 0.937081; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 070/096 - Mean training loss 0.078171; Mean training F1 0.939499; Mean validation loss 0.074147; Mean validation F1 0.936061; Learning rate 0.000090;\n",
    "===========================================================\n",
    "Epoch 071/096 - Mean training loss 0.078106; Mean training F1 0.939351; Mean validation loss 0.123576; Mean validation F1 0.936876; Learning rate 0.000084;\n",
    "===========================================================\n",
    "Epoch 072/096 - Mean training loss 0.077986; Mean training F1 0.939490; Mean validation loss 0.114138; Mean validation F1 0.937175; Learning rate 0.000078;\n",
    "===========================================================\n",
    "Epoch 073/096 - Mean training loss 0.078021; Mean training F1 0.939418; Mean validation loss 0.075832; Mean validation F1 0.937100; Learning rate 0.000072;\n",
    "===========================================================\n",
    "Epoch 074/096 - Mean training loss 0.077627; Mean training F1 0.939886; Mean validation loss 0.089303; Mean validation F1 0.936812; Learning rate 0.000067;\n",
    "===========================================================\n",
    "Epoch 075/096 - Mean training loss 0.077602; Mean training F1 0.939699; Mean validation loss 0.056519; Mean validation F1 0.937195; Learning rate 0.000061;\n",
    "===========================================================\n",
    "Epoch 076/096 - Mean training loss 0.077421; Mean training F1 0.939830; Mean validation loss 0.078585; Mean validation F1 0.937303; Learning rate 0.000056;\n",
    "===========================================================\n",
    "Epoch 077/096 - Mean training loss 0.077193; Mean training F1 0.940026; Mean validation loss 0.043926; Mean validation F1 0.937175; Learning rate 0.000052;\n",
    "===========================================================\n",
    "Epoch 078/096 - Mean training loss 0.077145; Mean training F1 0.939934; Mean validation loss 0.074533; Mean validation F1 0.937176; Learning rate 0.000047;\n",
    "===========================================================\n",
    "Epoch 079/096 - Mean training loss 0.076951; Mean training F1 0.940083; Mean validation loss 0.076999; Mean validation F1 0.936838; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 080/096 - Mean training loss 0.076904; Mean training F1 0.940118; Mean validation loss 0.062151; Mean validation F1 0.936609; Learning rate 0.000038;\n",
    "===========================================================\n",
    "Epoch 081/096 - Mean training loss 0.076785; Mean training F1 0.940105; Mean validation loss 0.055443; Mean validation F1 0.937253; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 082/096 - Mean training loss 0.076637; Mean training F1 0.940294; Mean validation loss 0.087298; Mean validation F1 0.937110; Learning rate 0.000031;\n",
    "===========================================================\n",
    "Epoch 083/096 - Mean training loss 0.076503; Mean training F1 0.940373; Mean validation loss 0.077609; Mean validation F1 0.937071; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 084/096 - Mean training loss 0.076548; Mean training F1 0.940267; Mean validation loss 0.087293; Mean validation F1 0.937073; Learning rate 0.000024;\n",
    "===========================================================\n",
    "Epoch 085/096 - Mean training loss 0.076292; Mean training F1 0.940507; Mean validation loss 0.046334; Mean validation F1 0.936598; Learning rate 0.000021;\n",
    "################################################################\n",
    "Training/validation for fold 3/5;\n",
    "===========================================================\n",
    "Epoch 001/096 - Mean training loss 0.386741; Mean training F1 0.736764; Mean validation loss 0.118273; Mean validation F1 0.816454; Learning rate 0.000500;\n",
    "===========================================================\n",
    "Epoch 002/096 - Mean training loss 0.188411; Mean training F1 0.866210; Mean validation loss 0.222886; Mean validation F1 0.884324; Learning rate 0.000500;\n",
    "===========================================================\n",
    "Epoch 003/096 - Mean training loss 0.131499; Mean training F1 0.903157; Mean validation loss 0.102930; Mean validation F1 0.925685; Learning rate 0.000499;\n",
    "===========================================================\n",
    "Epoch 004/096 - Mean training loss 0.113387; Mean training F1 0.917142; Mean validation loss 0.103496; Mean validation F1 0.930899; Learning rate 0.000498;\n",
    "===========================================================\n",
    "Epoch 005/096 - Mean training loss 0.106419; Mean training F1 0.920815; Mean validation loss 0.145311; Mean validation F1 0.914454; Learning rate 0.000497;\n",
    "===========================================================\n",
    "Epoch 006/096 - Mean training loss 0.100427; Mean training F1 0.924775; Mean validation loss 0.099799; Mean validation F1 0.933429; Learning rate 0.000496;\n",
    "===========================================================\n",
    "Epoch 007/096 - Mean training loss 0.095311; Mean training F1 0.929032; Mean validation loss 0.138243; Mean validation F1 0.929763; Learning rate 0.000494;\n",
    "===========================================================\n",
    "Epoch 008/096 - Mean training loss 0.093026; Mean training F1 0.930453; Mean validation loss 0.130162; Mean validation F1 0.934509; Learning rate 0.000492;\n",
    "===========================================================\n",
    "Epoch 009/096 - Mean training loss 0.090907; Mean training F1 0.932021; Mean validation loss 0.109671; Mean validation F1 0.933612; Learning rate 0.000490;\n",
    "===========================================================\n",
    "Epoch 010/096 - Mean training loss 0.091396; Mean training F1 0.930911; Mean validation loss 0.090825; Mean validation F1 0.932833; Learning rate 0.000487;\n",
    "===========================================================\n",
    "Epoch 011/096 - Mean training loss 0.090690; Mean training F1 0.931915; Mean validation loss 0.076071; Mean validation F1 0.934728; Learning rate 0.000484;\n",
    "===========================================================\n",
    "Epoch 012/096 - Mean training loss 0.090415; Mean training F1 0.932128; Mean validation loss 0.068898; Mean validation F1 0.933748; Learning rate 0.000481;\n",
    "===========================================================\n",
    "Epoch 013/096 - Mean training loss 0.087703; Mean training F1 0.934003; Mean validation loss 0.145958; Mean validation F1 0.933824; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 014/096 - Mean training loss 0.090090; Mean training F1 0.932977; Mean validation loss 0.088726; Mean validation F1 0.934383; Learning rate 0.000475;\n",
    "===========================================================\n",
    "Epoch 015/096 - Mean training loss 0.090013; Mean training F1 0.932448; Mean validation loss 0.066544; Mean validation F1 0.919194; Learning rate 0.000471;\n",
    "===========================================================\n",
    "Epoch 016/096 - Mean training loss 0.087776; Mean training F1 0.933601; Mean validation loss 0.090740; Mean validation F1 0.932882; Learning rate 0.000467;\n",
    "===========================================================\n",
    "Epoch 017/096 - Mean training loss 0.086535; Mean training F1 0.935152; Mean validation loss 0.085349; Mean validation F1 0.934282; Learning rate 0.000463;\n",
    "===========================================================\n",
    "Epoch 018/096 - Mean training loss 0.086589; Mean training F1 0.934735; Mean validation loss 0.117302; Mean validation F1 0.934961; Learning rate 0.000459;\n",
    "===========================================================\n",
    "Epoch 019/096 - Mean training loss 0.087578; Mean training F1 0.933971; Mean validation loss 0.100979; Mean validation F1 0.935826; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 020/096 - Mean training loss 0.085588; Mean training F1 0.935513; Mean validation loss 0.079383; Mean validation F1 0.933476; Learning rate 0.000449;\n",
    "===========================================================\n",
    "Epoch 021/096 - Mean training loss 0.085224; Mean training F1 0.935718; Mean validation loss 0.092992; Mean validation F1 0.936811; Learning rate 0.000444;\n",
    "===========================================================\n",
    "Epoch 022/096 - Mean training loss 0.084786; Mean training F1 0.935974; Mean validation loss 0.057754; Mean validation F1 0.932338; Learning rate 0.000439;\n",
    "===========================================================\n",
    "Epoch 023/096 - Mean training loss 0.084913; Mean training F1 0.935591; Mean validation loss 0.072394; Mean validation F1 0.935425; Learning rate 0.000433;\n",
    "===========================================================\n",
    "Epoch 024/096 - Mean training loss 0.085918; Mean training F1 0.934871; Mean validation loss 0.061548; Mean validation F1 0.934320; Learning rate 0.000428;\n",
    "===========================================================\n",
    "Epoch 025/096 - Mean training loss 0.084411; Mean training F1 0.936206; Mean validation loss 0.045827; Mean validation F1 0.935977; Learning rate 0.000422;\n",
    "===========================================================\n",
    "Epoch 026/096 - Mean training loss 0.084914; Mean training F1 0.935659; Mean validation loss 0.130147; Mean validation F1 0.936351; Learning rate 0.000416;\n",
    "===========================================================\n",
    "Epoch 027/096 - Mean training loss 0.083570; Mean training F1 0.936716; Mean validation loss 0.060627; Mean validation F1 0.934802; Learning rate 0.000410;\n",
    "===========================================================\n",
    "Epoch 028/096 - Mean training loss 0.083608; Mean training F1 0.936587; Mean validation loss 0.078445; Mean validation F1 0.932646; Learning rate 0.000403;\n",
    "===========================================================\n",
    "Epoch 029/096 - Mean training loss 0.083905; Mean training F1 0.936101; Mean validation loss 0.087578; Mean validation F1 0.935871; Learning rate 0.000397;\n",
    "===========================================================\n",
    "Epoch 030/096 - Mean training loss 0.083017; Mean training F1 0.937324; Mean validation loss 0.094818; Mean validation F1 0.935404; Learning rate 0.000390;\n",
    "===========================================================\n",
    "Epoch 031/096 - Mean training loss 0.083334; Mean training F1 0.936878; Mean validation loss 0.083195; Mean validation F1 0.936709; Learning rate 0.000383;\n",
    "===========================================================\n",
    "Epoch 032/096 - Mean training loss 0.082910; Mean training F1 0.937129; Mean validation loss 0.061211; Mean validation F1 0.935534; Learning rate 0.000377;\n",
    "===========================================================\n",
    "Epoch 033/096 - Mean training loss 0.083542; Mean training F1 0.936212; Mean validation loss 0.101371; Mean validation F1 0.937067; Learning rate 0.000369;\n",
    "===========================================================\n",
    "Epoch 034/096 - Mean training loss 0.082352; Mean training F1 0.937451; Mean validation loss 0.091002; Mean validation F1 0.935939; Learning rate 0.000362;\n",
    "===========================================================\n",
    "Epoch 035/096 - Mean training loss 0.082026; Mean training F1 0.937902; Mean validation loss 0.064401; Mean validation F1 0.935856; Learning rate 0.000355;\n",
    "===========================================================\n",
    "Epoch 036/096 - Mean training loss 0.082083; Mean training F1 0.937524; Mean validation loss 0.072726; Mean validation F1 0.935239; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 037/096 - Mean training loss 0.081739; Mean training F1 0.937798; Mean validation loss 0.058031; Mean validation F1 0.935871; Learning rate 0.000340;\n",
    "===========================================================\n",
    "Epoch 038/096 - Mean training loss 0.081605; Mean training F1 0.938057; Mean validation loss 0.085712; Mean validation F1 0.936704; Learning rate 0.000332;\n",
    "===========================================================\n",
    "Epoch 039/096 - Mean training loss 0.081500; Mean training F1 0.938096; Mean validation loss 0.093674; Mean validation F1 0.936554; Learning rate 0.000325;\n",
    "===========================================================\n",
    "Epoch 040/096 - Mean training loss 0.081275; Mean training F1 0.938076; Mean validation loss 0.106722; Mean validation F1 0.936853; Learning rate 0.000317;\n",
    "===========================================================\n",
    "Epoch 041/096 - Mean training loss 0.084725; Mean training F1 0.936998; Mean validation loss 0.095913; Mean validation F1 0.928812; Learning rate 0.000309;\n",
    "===========================================================\n",
    "Epoch 042/096 - Mean training loss 0.089112; Mean training F1 0.933256; Mean validation loss 0.083344; Mean validation F1 0.936829; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 043/096 - Mean training loss 0.081969; Mean training F1 0.937955; Mean validation loss 0.071107; Mean validation F1 0.937203; Learning rate 0.000293;\n",
    "===========================================================\n",
    "Epoch 044/096 - Mean training loss 0.080951; Mean training F1 0.938349; Mean validation loss 0.066768; Mean validation F1 0.937092; Learning rate 0.000285;\n",
    "===========================================================\n",
    "Epoch 045/096 - Mean training loss 0.080788; Mean training F1 0.938600; Mean validation loss 0.075408; Mean validation F1 0.935834; Learning rate 0.000277;\n",
    "===========================================================\n",
    "Epoch 046/096 - Mean training loss 0.080582; Mean training F1 0.938629; Mean validation loss 0.094911; Mean validation F1 0.937450; Learning rate 0.000269;\n",
    "===========================================================\n",
    "Epoch 047/096 - Mean training loss 0.080181; Mean training F1 0.938706; Mean validation loss 0.068942; Mean validation F1 0.937115; Learning rate 0.000261;\n",
    "===========================================================\n",
    "Epoch 048/096 - Mean training loss 0.080045; Mean training F1 0.938915; Mean validation loss 0.082657; Mean validation F1 0.937323; Learning rate 0.000253;\n",
    "===========================================================\n",
    "Epoch 049/096 - Mean training loss 0.079770; Mean training F1 0.939163; Mean validation loss 0.082774; Mean validation F1 0.936741; Learning rate 0.000245;\n",
    "===========================================================\n",
    "Epoch 050/096 - Mean training loss 0.079616; Mean training F1 0.938994; Mean validation loss 0.056779; Mean validation F1 0.937293; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 051/096 - Mean training loss 0.079480; Mean training F1 0.939103; Mean validation loss 0.059870; Mean validation F1 0.936919; Learning rate 0.000228;\n",
    "===========================================================\n",
    "Epoch 052/096 - Mean training loss 0.079338; Mean training F1 0.938977; Mean validation loss 0.052876; Mean validation F1 0.936884; Learning rate 0.000220;\n",
    "===========================================================\n",
    "Epoch 053/096 - Mean training loss 0.079089; Mean training F1 0.939189; Mean validation loss 0.066937; Mean validation F1 0.937180; Learning rate 0.000212;\n",
    "===========================================================\n",
    "Epoch 054/096 - Mean training loss 0.078843; Mean training F1 0.939362; Mean validation loss 0.076504; Mean validation F1 0.937288; Learning rate 0.000204;\n",
    "===========================================================\n",
    "Epoch 055/096 - Mean training loss 0.078458; Mean training F1 0.939694; Mean validation loss 0.072863; Mean validation F1 0.937039; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 056/096 - Mean training loss 0.078392; Mean training F1 0.939690; Mean validation loss 0.099493; Mean validation F1 0.936954; Learning rate 0.000189;\n",
    "===========================================================\n",
    "Epoch 057/096 - Mean training loss 0.078076; Mean training F1 0.939807; Mean validation loss 0.075798; Mean validation F1 0.937394; Learning rate 0.000181;\n",
    "===========================================================\n",
    "Epoch 058/096 - Mean training loss 0.077700; Mean training F1 0.940240; Mean validation loss 0.111666; Mean validation F1 0.937041; Learning rate 0.000173;\n",
    "===========================================================\n",
    "Epoch 059/096 - Mean training loss 0.077352; Mean training F1 0.940160; Mean validation loss 0.093771; Mean validation F1 0.937181; Learning rate 0.000166;\n",
    "===========================================================\n",
    "Epoch 060/096 - Mean training loss 0.077166; Mean training F1 0.940314; Mean validation loss 0.090949; Mean validation F1 0.937077; Learning rate 0.000158;\n",
    "===========================================================\n",
    "Epoch 061/096 - Mean training loss 0.076553; Mean training F1 0.940682; Mean validation loss 0.115603; Mean validation F1 0.936791; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 062/096 - Mean training loss 0.076215; Mean training F1 0.940631; Mean validation loss 0.053371; Mean validation F1 0.936946; Learning rate 0.000143;\n",
    "===========================================================\n",
    "Epoch 063/096 - Mean training loss 0.075775; Mean training F1 0.941024; Mean validation loss 0.087847; Mean validation F1 0.936977; Learning rate 0.000136;\n",
    "===========================================================\n",
    "Epoch 064/096 - Mean training loss 0.075268; Mean training F1 0.941349; Mean validation loss 0.069507; Mean validation F1 0.936481; Learning rate 0.000129;\n",
    "===========================================================\n",
    "Epoch 065/096 - Mean training loss 0.074862; Mean training F1 0.941355; Mean validation loss 0.064998; Mean validation F1 0.936190; Learning rate 0.000122;\n",
    "===========================================================\n",
    "Epoch 066/096 - Mean training loss 0.074394; Mean training F1 0.941739; Mean validation loss 0.112326; Mean validation F1 0.936386; Learning rate 0.000115;\n",
    "===========================================================\n",
    "Epoch 067/096 - Mean training loss 0.074057; Mean training F1 0.941894; Mean validation loss 0.087862; Mean validation F1 0.936734; Learning rate 0.000109;\n",
    "===========================================================\n",
    "Epoch 068/096 - Mean training loss 0.073466; Mean training F1 0.942150; Mean validation loss 0.088765; Mean validation F1 0.936653; Learning rate 0.000102;\n",
    "===========================================================\n",
    "Epoch 069/096 - Mean training loss 0.072891; Mean training F1 0.942505; Mean validation loss 0.064257; Mean validation F1 0.936523; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 070/096 - Mean training loss 0.072985; Mean training F1 0.942476; Mean validation loss 0.078676; Mean validation F1 0.936328; Learning rate 0.000090;\n",
    "===========================================================\n",
    "Epoch 071/096 - Mean training loss 0.072313; Mean training F1 0.942802; Mean validation loss 0.100130; Mean validation F1 0.936472; Learning rate 0.000084;\n",
    "===========================================================\n",
    "Epoch 072/096 - Mean training loss 0.071439; Mean training F1 0.943227; Mean validation loss 0.082740; Mean validation F1 0.936385; Learning rate 0.000078;\n",
    "################################################################\n",
    "Training/validation for fold 4/5;\n",
    "===========================================================\n",
    "Epoch 001/096 - Mean training loss 0.468247; Mean training F1 0.695626; Mean validation loss 0.148862; Mean validation F1 0.878318; Learning rate 0.000500;\n",
    "===========================================================\n",
    "Epoch 002/096 - Mean training loss 0.154216; Mean training F1 0.884165; Mean validation loss 0.166866; Mean validation F1 0.923247; Learning rate 0.000500;\n",
    "===========================================================\n",
    "Epoch 003/096 - Mean training loss 0.163407; Mean training F1 0.880759; Mean validation loss 0.182524; Mean validation F1 0.926844; Learning rate 0.000499;\n",
    "===========================================================\n",
    "Epoch 004/096 - Mean training loss 0.122262; Mean training F1 0.908862; Mean validation loss 0.071858; Mean validation F1 0.930002; Learning rate 0.000498;\n",
    "===========================================================\n",
    "Epoch 005/096 - Mean training loss 0.124608; Mean training F1 0.909490; Mean validation loss 0.128145; Mean validation F1 0.910437; Learning rate 0.000497;\n",
    "===========================================================\n",
    "Epoch 006/096 - Mean training loss 0.105042; Mean training F1 0.922395; Mean validation loss 0.064732; Mean validation F1 0.929936; Learning rate 0.000496;\n",
    "===========================================================\n",
    "Epoch 007/096 - Mean training loss 0.098456; Mean training F1 0.926693; Mean validation loss 0.112110; Mean validation F1 0.932937; Learning rate 0.000494;\n",
    "===========================================================\n",
    "Epoch 008/096 - Mean training loss 0.144435; Mean training F1 0.901713; Mean validation loss 0.115783; Mean validation F1 0.907063; Learning rate 0.000492;\n",
    "===========================================================\n",
    "Epoch 009/096 - Mean training loss 0.112347; Mean training F1 0.917595; Mean validation loss 0.083614; Mean validation F1 0.935280; Learning rate 0.000490;\n",
    "===========================================================\n",
    "Epoch 010/096 - Mean training loss 0.099399; Mean training F1 0.926243; Mean validation loss 0.103708; Mean validation F1 0.931922; Learning rate 0.000487;\n",
    "===========================================================\n",
    "Epoch 011/096 - Mean training loss 0.093184; Mean training F1 0.930873; Mean validation loss 0.093006; Mean validation F1 0.935858; Learning rate 0.000484;\n",
    "===========================================================\n",
    "Epoch 012/096 - Mean training loss 0.092070; Mean training F1 0.931946; Mean validation loss 0.072437; Mean validation F1 0.930672; Learning rate 0.000481;\n",
    "===========================================================\n",
    "Epoch 013/096 - Mean training loss 0.090356; Mean training F1 0.932490; Mean validation loss 0.097022; Mean validation F1 0.935351; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 014/096 - Mean training loss 0.090580; Mean training F1 0.932196; Mean validation loss 0.082745; Mean validation F1 0.934821; Learning rate 0.000475;\n",
    "===========================================================\n",
    "Epoch 015/096 - Mean training loss 0.089961; Mean training F1 0.932998; Mean validation loss 0.086287; Mean validation F1 0.929596; Learning rate 0.000471;\n",
    "===========================================================\n",
    "Epoch 016/096 - Mean training loss 0.088905; Mean training F1 0.933454; Mean validation loss 0.089752; Mean validation F1 0.936202; Learning rate 0.000467;\n",
    "===========================================================\n",
    "Epoch 017/096 - Mean training loss 0.087987; Mean training F1 0.934289; Mean validation loss 0.082151; Mean validation F1 0.936151; Learning rate 0.000463;\n",
    "===========================================================\n",
    "Epoch 018/096 - Mean training loss 0.224467; Mean training F1 0.873526; Mean validation loss 0.079244; Mean validation F1 0.920186; Learning rate 0.000459;\n",
    "===========================================================\n",
    "Epoch 019/096 - Mean training loss 0.112394; Mean training F1 0.917209; Mean validation loss 0.143339; Mean validation F1 0.934580; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 020/096 - Mean training loss 0.100308; Mean training F1 0.926798; Mean validation loss 0.127285; Mean validation F1 0.934023; Learning rate 0.000449;\n",
    "===========================================================\n",
    "Epoch 021/096 - Mean training loss 0.094181; Mean training F1 0.930750; Mean validation loss 0.083397; Mean validation F1 0.936212; Learning rate 0.000444;\n",
    "===========================================================\n",
    "Epoch 022/096 - Mean training loss 0.092305; Mean training F1 0.931701; Mean validation loss 0.081337; Mean validation F1 0.936807; Learning rate 0.000439;\n",
    "===========================================================\n",
    "Epoch 023/096 - Mean training loss 0.090205; Mean training F1 0.933134; Mean validation loss 0.086724; Mean validation F1 0.937531; Learning rate 0.000433;\n",
    "===========================================================\n",
    "Epoch 024/096 - Mean training loss 0.089272; Mean training F1 0.934031; Mean validation loss 0.072074; Mean validation F1 0.937209; Learning rate 0.000428;\n",
    "===========================================================\n",
    "Epoch 025/096 - Mean training loss 0.091899; Mean training F1 0.932383; Mean validation loss 0.176115; Mean validation F1 0.935158; Learning rate 0.000422;\n",
    "===========================================================\n",
    "Epoch 026/096 - Mean training loss 0.089180; Mean training F1 0.933829; Mean validation loss 0.091414; Mean validation F1 0.937017; Learning rate 0.000416;\n",
    "===========================================================\n",
    "Epoch 027/096 - Mean training loss 0.087755; Mean training F1 0.934956; Mean validation loss 0.050236; Mean validation F1 0.932113; Learning rate 0.000410;\n",
    "===========================================================\n",
    "Epoch 028/096 - Mean training loss 0.087690; Mean training F1 0.934547; Mean validation loss 0.067214; Mean validation F1 0.936565; Learning rate 0.000403;\n",
    "===========================================================\n",
    "Epoch 029/096 - Mean training loss 0.087848; Mean training F1 0.934801; Mean validation loss 0.108922; Mean validation F1 0.935772; Learning rate 0.000397;\n",
    "===========================================================\n",
    "Epoch 030/096 - Mean training loss 0.086607; Mean training F1 0.935651; Mean validation loss 0.077772; Mean validation F1 0.937859; Learning rate 0.000390;\n",
    "===========================================================\n",
    "Epoch 031/096 - Mean training loss 0.132557; Mean training F1 0.912650; Mean validation loss 0.138219; Mean validation F1 0.904174; Learning rate 0.000383;\n",
    "===========================================================\n",
    "Epoch 032/096 - Mean training loss 0.100125; Mean training F1 0.925124; Mean validation loss 0.089982; Mean validation F1 0.936051; Learning rate 0.000377;\n",
    "===========================================================\n",
    "Epoch 033/096 - Mean training loss 0.092271; Mean training F1 0.930931; Mean validation loss 0.143568; Mean validation F1 0.937000; Learning rate 0.000369;\n",
    "===========================================================\n",
    "Epoch 034/096 - Mean training loss 0.089250; Mean training F1 0.933993; Mean validation loss 0.067623; Mean validation F1 0.937494; Learning rate 0.000362;\n",
    "===========================================================\n",
    "Epoch 035/096 - Mean training loss 0.087965; Mean training F1 0.934994; Mean validation loss 0.063228; Mean validation F1 0.937587; Learning rate 0.000355;\n",
    "===========================================================\n",
    "Epoch 036/096 - Mean training loss 0.087150; Mean training F1 0.935213; Mean validation loss 0.063169; Mean validation F1 0.936813; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 037/096 - Mean training loss 0.086775; Mean training F1 0.935148; Mean validation loss 0.066981; Mean validation F1 0.937336; Learning rate 0.000340;\n",
    "===========================================================\n",
    "Epoch 038/096 - Mean training loss 0.086479; Mean training F1 0.935394; Mean validation loss 0.088013; Mean validation F1 0.937750; Learning rate 0.000332;\n",
    "===========================================================\n",
    "Epoch 039/096 - Mean training loss 0.086380; Mean training F1 0.935849; Mean validation loss 0.079139; Mean validation F1 0.937982; Learning rate 0.000325;\n",
    "===========================================================\n",
    "Epoch 040/096 - Mean training loss 0.086005; Mean training F1 0.935908; Mean validation loss 0.084300; Mean validation F1 0.936325; Learning rate 0.000317;\n",
    "===========================================================\n",
    "Epoch 041/096 - Mean training loss 0.086000; Mean training F1 0.935865; Mean validation loss 0.121064; Mean validation F1 0.937439; Learning rate 0.000309;\n",
    "===========================================================\n",
    "Epoch 042/096 - Mean training loss 0.085510; Mean training F1 0.936062; Mean validation loss 0.060799; Mean validation F1 0.937323; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 043/096 - Mean training loss 0.085069; Mean training F1 0.936477; Mean validation loss 0.069724; Mean validation F1 0.934288; Learning rate 0.000293;\n",
    "===========================================================\n",
    "Epoch 044/096 - Mean training loss 0.085069; Mean training F1 0.936446; Mean validation loss 0.108287; Mean validation F1 0.934868; Learning rate 0.000285;\n",
    "===========================================================\n",
    "Epoch 045/096 - Mean training loss 0.084875; Mean training F1 0.936419; Mean validation loss 0.093401; Mean validation F1 0.938201; Learning rate 0.000277;\n",
    "===========================================================\n",
    "Epoch 046/096 - Mean training loss 0.084551; Mean training F1 0.936865; Mean validation loss 0.067599; Mean validation F1 0.938036; Learning rate 0.000269;\n",
    "===========================================================\n",
    "Epoch 047/096 - Mean training loss 0.084370; Mean training F1 0.936576; Mean validation loss 0.062899; Mean validation F1 0.936764; Learning rate 0.000261;\n",
    "===========================================================\n",
    "Epoch 048/096 - Mean training loss 0.084408; Mean training F1 0.936683; Mean validation loss 0.056256; Mean validation F1 0.938350; Learning rate 0.000253;\n",
    "===========================================================\n",
    "Epoch 049/096 - Mean training loss 0.084184; Mean training F1 0.936653; Mean validation loss 0.087441; Mean validation F1 0.937790; Learning rate 0.000245;\n",
    "===========================================================\n",
    "Epoch 050/096 - Mean training loss 0.083865; Mean training F1 0.937206; Mean validation loss 0.066268; Mean validation F1 0.937628; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 051/096 - Mean training loss 0.083604; Mean training F1 0.937274; Mean validation loss 0.098379; Mean validation F1 0.937401; Learning rate 0.000228;\n",
    "===========================================================\n",
    "Epoch 052/096 - Mean training loss 0.083545; Mean training F1 0.937234; Mean validation loss 0.096024; Mean validation F1 0.938340; Learning rate 0.000220;\n",
    "===========================================================\n",
    "Epoch 053/096 - Mean training loss 0.083610; Mean training F1 0.937002; Mean validation loss 0.024589; Mean validation F1 0.938447; Learning rate 0.000212;\n",
    "===========================================================\n",
    "Epoch 054/096 - Mean training loss 0.083151; Mean training F1 0.937244; Mean validation loss 0.102062; Mean validation F1 0.938119; Learning rate 0.000204;\n",
    "===========================================================\n",
    "Epoch 055/096 - Mean training loss 0.083214; Mean training F1 0.937285; Mean validation loss 0.067166; Mean validation F1 0.938239; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 056/096 - Mean training loss 0.082818; Mean training F1 0.937720; Mean validation loss 0.090207; Mean validation F1 0.938273; Learning rate 0.000189;\n",
    "===========================================================\n",
    "Epoch 057/096 - Mean training loss 0.082648; Mean training F1 0.937811; Mean validation loss 0.093418; Mean validation F1 0.938217; Learning rate 0.000181;\n",
    "===========================================================\n",
    "Epoch 058/096 - Mean training loss 0.082728; Mean training F1 0.937558; Mean validation loss 0.070299; Mean validation F1 0.938508; Learning rate 0.000173;\n",
    "===========================================================\n",
    "Epoch 059/096 - Mean training loss 0.082385; Mean training F1 0.937872; Mean validation loss 0.089938; Mean validation F1 0.936796; Learning rate 0.000166;\n",
    "===========================================================\n",
    "Epoch 060/096 - Mean training loss 0.082225; Mean training F1 0.937927; Mean validation loss 0.074861; Mean validation F1 0.937790; Learning rate 0.000158;\n",
    "===========================================================\n",
    "Epoch 061/096 - Mean training loss 0.082218; Mean training F1 0.937972; Mean validation loss 0.040343; Mean validation F1 0.938527; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 062/096 - Mean training loss 0.081964; Mean training F1 0.938122; Mean validation loss 0.073448; Mean validation F1 0.938326; Learning rate 0.000143;\n",
    "===========================================================\n",
    "Epoch 063/096 - Mean training loss 0.081771; Mean training F1 0.938238; Mean validation loss 0.103909; Mean validation F1 0.938520; Learning rate 0.000136;\n",
    "===========================================================\n",
    "Epoch 064/096 - Mean training loss 0.081600; Mean training F1 0.938349; Mean validation loss 0.075131; Mean validation F1 0.937480; Learning rate 0.000129;\n",
    "===========================================================\n",
    "Epoch 065/096 - Mean training loss 0.081558; Mean training F1 0.938171; Mean validation loss 0.071703; Mean validation F1 0.938577; Learning rate 0.000122;\n",
    "===========================================================\n",
    "Epoch 066/096 - Mean training loss 0.081373; Mean training F1 0.938564; Mean validation loss 0.088940; Mean validation F1 0.938449; Learning rate 0.000115;\n",
    "===========================================================\n",
    "Epoch 067/096 - Mean training loss 0.081235; Mean training F1 0.938427; Mean validation loss 0.076877; Mean validation F1 0.938442; Learning rate 0.000109;\n",
    "===========================================================\n",
    "Epoch 068/096 - Mean training loss 0.081072; Mean training F1 0.938665; Mean validation loss 0.060540; Mean validation F1 0.938954; Learning rate 0.000102;\n",
    "===========================================================\n",
    "Epoch 069/096 - Mean training loss 0.081001; Mean training F1 0.938727; Mean validation loss 0.055466; Mean validation F1 0.938918; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 070/096 - Mean training loss 0.080812; Mean training F1 0.938746; Mean validation loss 0.083094; Mean validation F1 0.938754; Learning rate 0.000090;\n",
    "===========================================================\n",
    "Epoch 071/096 - Mean training loss 0.080734; Mean training F1 0.938886; Mean validation loss 0.059881; Mean validation F1 0.938455; Learning rate 0.000084;\n",
    "===========================================================\n",
    "Epoch 072/096 - Mean training loss 0.080638; Mean training F1 0.938833; Mean validation loss 0.061259; Mean validation F1 0.938763; Learning rate 0.000078;\n",
    "===========================================================\n",
    "Epoch 073/096 - Mean training loss 0.080458; Mean training F1 0.938860; Mean validation loss 0.088120; Mean validation F1 0.938765; Learning rate 0.000072;\n",
    "===========================================================\n",
    "Epoch 074/096 - Mean training loss 0.080435; Mean training F1 0.938821; Mean validation loss 0.061832; Mean validation F1 0.938528; Learning rate 0.000067;\n",
    "===========================================================\n",
    "Epoch 075/096 - Mean training loss 0.080263; Mean training F1 0.939122; Mean validation loss 0.058044; Mean validation F1 0.938719; Learning rate 0.000061;\n",
    "===========================================================\n",
    "Epoch 076/096 - Mean training loss 0.080128; Mean training F1 0.939105; Mean validation loss 0.107880; Mean validation F1 0.938901; Learning rate 0.000056;\n",
    "===========================================================\n",
    "Epoch 077/096 - Mean training loss 0.079979; Mean training F1 0.939121; Mean validation loss 0.065004; Mean validation F1 0.938777; Learning rate 0.000052;\n",
    "===========================================================\n",
    "Epoch 078/096 - Mean training loss 0.079904; Mean training F1 0.939211; Mean validation loss 0.072946; Mean validation F1 0.938707; Learning rate 0.000047;\n",
    "===========================================================\n",
    "Epoch 079/096 - Mean training loss 0.079767; Mean training F1 0.939227; Mean validation loss 0.088512; Mean validation F1 0.938618; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 080/096 - Mean training loss 0.079728; Mean training F1 0.939418; Mean validation loss 0.111239; Mean validation F1 0.938820; Learning rate 0.000038;\n",
    "===========================================================\n",
    "Epoch 081/096 - Mean training loss 0.079675; Mean training F1 0.939305; Mean validation loss 0.097376; Mean validation F1 0.938578; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 082/096 - Mean training loss 0.079571; Mean training F1 0.939410; Mean validation loss 0.066402; Mean validation F1 0.938619; Learning rate 0.000031;\n",
    "===========================================================\n",
    "Epoch 083/096 - Mean training loss 0.079447; Mean training F1 0.939525; Mean validation loss 0.060601; Mean validation F1 0.938783; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 084/096 - Mean training loss 0.079349; Mean training F1 0.939518; Mean validation loss 0.103994; Mean validation F1 0.938879; Learning rate 0.000024;\n",
    "===========================================================\n",
    "Epoch 085/096 - Mean training loss 0.079331; Mean training F1 0.939495; Mean validation loss 0.093670; Mean validation F1 0.938798; Learning rate 0.000021;\n",
    "===========================================================\n",
    "Epoch 086/096 - Mean training loss 0.079228; Mean training F1 0.939608; Mean validation loss 0.073624; Mean validation F1 0.938612; Learning rate 0.000018;\n",
    "===========================================================\n",
    "Epoch 087/096 - Mean training loss 0.079163; Mean training F1 0.939673; Mean validation loss 0.097390; Mean validation F1 0.938700; Learning rate 0.000016;\n",
    "===========================================================\n",
    "Epoch 088/096 - Mean training loss 0.079116; Mean training F1 0.939746; Mean validation loss 0.068161; Mean validation F1 0.938897; Learning rate 0.000014;\n",
    "===========================================================\n",
    "Epoch 089/096 - Mean training loss 0.079125; Mean training F1 0.939729; Mean validation loss 0.098399; Mean validation F1 0.938831; Learning rate 0.000012;\n",
    "===========================================================\n",
    "Epoch 090/096 - Mean training loss 0.078988; Mean training F1 0.939872; Mean validation loss 0.077353; Mean validation F1 0.938756; Learning rate 0.000010;\n",
    "===========================================================\n",
    "Epoch 091/096 - Mean training loss 0.078972; Mean training F1 0.939748; Mean validation loss 0.076436; Mean validation F1 0.938684; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 092/096 - Mean training loss 0.078973; Mean training F1 0.939759; Mean validation loss 0.063999; Mean validation F1 0.938857; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 093/096 - Mean training loss 0.078927; Mean training F1 0.939676; Mean validation loss 0.085634; Mean validation F1 0.938737; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 094/096 - Mean training loss 0.078878; Mean training F1 0.939791; Mean validation loss 0.056370; Mean validation F1 0.938809; Learning rate 0.000006;\n",
    "################################################################\n",
    "Training/validation for fold 5/5;\n",
    "===========================================================\n",
    "Epoch 001/096 - Mean training loss 0.403289; Mean training F1 0.728635; Mean validation loss 0.182789; Mean validation F1 0.841891; Learning rate 0.000500;\n",
    "===========================================================\n",
    "Epoch 002/096 - Mean training loss 0.153397; Mean training F1 0.888508; Mean validation loss 0.099083; Mean validation F1 0.920793; Learning rate 0.000500;\n",
    "===========================================================\n",
    "Epoch 003/096 - Mean training loss 0.126706; Mean training F1 0.905005; Mean validation loss 0.082065; Mean validation F1 0.907120; Learning rate 0.000499;\n",
    "===========================================================\n",
    "Epoch 004/096 - Mean training loss 0.189652; Mean training F1 0.877120; Mean validation loss 0.132715; Mean validation F1 0.920028; Learning rate 0.000498;\n",
    "===========================================================\n",
    "Epoch 005/096 - Mean training loss 0.118515; Mean training F1 0.913921; Mean validation loss 0.132710; Mean validation F1 0.932225; Learning rate 0.000497;\n",
    "===========================================================\n",
    "Epoch 006/096 - Mean training loss 0.108855; Mean training F1 0.919712; Mean validation loss 0.108250; Mean validation F1 0.933738; Learning rate 0.000496;\n",
    "===========================================================\n",
    "Epoch 007/096 - Mean training loss 0.102039; Mean training F1 0.924265; Mean validation loss 0.079190; Mean validation F1 0.933867; Learning rate 0.000494;\n",
    "===========================================================\n",
    "Epoch 008/096 - Mean training loss 0.170327; Mean training F1 0.887061; Mean validation loss 0.134430; Mean validation F1 0.925545; Learning rate 0.000492;\n",
    "===========================================================\n",
    "Epoch 009/096 - Mean training loss 0.122283; Mean training F1 0.909557; Mean validation loss 0.114469; Mean validation F1 0.931941; Learning rate 0.000490;\n",
    "===========================================================\n",
    "Epoch 010/096 - Mean training loss 0.105728; Mean training F1 0.923373; Mean validation loss 0.112680; Mean validation F1 0.932990; Learning rate 0.000487;\n",
    "===========================================================\n",
    "Epoch 011/096 - Mean training loss 0.097721; Mean training F1 0.928269; Mean validation loss 0.074055; Mean validation F1 0.936415; Learning rate 0.000484;\n",
    "===========================================================\n",
    "Epoch 012/096 - Mean training loss 0.095549; Mean training F1 0.929017; Mean validation loss 0.057172; Mean validation F1 0.932068; Learning rate 0.000481;\n",
    "===========================================================\n",
    "Epoch 013/096 - Mean training loss 0.093732; Mean training F1 0.930587; Mean validation loss 0.126646; Mean validation F1 0.936865; Learning rate 0.000478;\n",
    "===========================================================\n",
    "Epoch 014/096 - Mean training loss 0.093008; Mean training F1 0.930593; Mean validation loss 0.121231; Mean validation F1 0.935523; Learning rate 0.000475;\n",
    "===========================================================\n",
    "Epoch 015/096 - Mean training loss 0.124921; Mean training F1 0.917638; Mean validation loss 0.092577; Mean validation F1 0.936678; Learning rate 0.000471;\n",
    "===========================================================\n",
    "Epoch 016/096 - Mean training loss 0.095800; Mean training F1 0.928625; Mean validation loss 0.046008; Mean validation F1 0.932759; Learning rate 0.000467;\n",
    "===========================================================\n",
    "Epoch 017/096 - Mean training loss 0.091840; Mean training F1 0.932043; Mean validation loss 0.062049; Mean validation F1 0.936405; Learning rate 0.000463;\n",
    "===========================================================\n",
    "Epoch 018/096 - Mean training loss 0.090488; Mean training F1 0.932595; Mean validation loss 0.072554; Mean validation F1 0.937326; Learning rate 0.000459;\n",
    "===========================================================\n",
    "Epoch 019/096 - Mean training loss 0.089439; Mean training F1 0.933628; Mean validation loss 0.100985; Mean validation F1 0.935657; Learning rate 0.000454;\n",
    "===========================================================\n",
    "Epoch 020/096 - Mean training loss 0.090376; Mean training F1 0.932365; Mean validation loss 0.085422; Mean validation F1 0.935725; Learning rate 0.000449;\n",
    "===========================================================\n",
    "Epoch 021/096 - Mean training loss 0.094421; Mean training F1 0.930879; Mean validation loss 0.082558; Mean validation F1 0.936663; Learning rate 0.000444;\n",
    "===========================================================\n",
    "Epoch 022/096 - Mean training loss 0.091042; Mean training F1 0.932525; Mean validation loss 0.125101; Mean validation F1 0.936739; Learning rate 0.000439;\n",
    "===========================================================\n",
    "Epoch 023/096 - Mean training loss 0.088138; Mean training F1 0.934401; Mean validation loss 0.096564; Mean validation F1 0.936659; Learning rate 0.000433;\n",
    "===========================================================\n",
    "Epoch 024/096 - Mean training loss 0.087889; Mean training F1 0.934595; Mean validation loss 0.104145; Mean validation F1 0.934741; Learning rate 0.000428;\n",
    "===========================================================\n",
    "Epoch 025/096 - Mean training loss 0.088213; Mean training F1 0.933849; Mean validation loss 0.078123; Mean validation F1 0.928905; Learning rate 0.000422;\n",
    "===========================================================\n",
    "Epoch 026/096 - Mean training loss 0.087530; Mean training F1 0.934522; Mean validation loss 0.099645; Mean validation F1 0.936772; Learning rate 0.000416;\n",
    "===========================================================\n",
    "Epoch 027/096 - Mean training loss 0.088356; Mean training F1 0.934241; Mean validation loss 0.102125; Mean validation F1 0.937658; Learning rate 0.000410;\n",
    "===========================================================\n",
    "Epoch 028/096 - Mean training loss 0.087135; Mean training F1 0.934699; Mean validation loss 0.096726; Mean validation F1 0.922936; Learning rate 0.000403;\n",
    "===========================================================\n",
    "Epoch 029/096 - Mean training loss 0.087001; Mean training F1 0.935112; Mean validation loss 0.088309; Mean validation F1 0.936602; Learning rate 0.000397;\n",
    "===========================================================\n",
    "Epoch 030/096 - Mean training loss 0.103108; Mean training F1 0.925724; Mean validation loss 0.127312; Mean validation F1 0.928475; Learning rate 0.000390;\n",
    "===========================================================\n",
    "Epoch 031/096 - Mean training loss 0.092777; Mean training F1 0.931604; Mean validation loss 0.076712; Mean validation F1 0.933764; Learning rate 0.000383;\n",
    "===========================================================\n",
    "Epoch 032/096 - Mean training loss 0.088037; Mean training F1 0.934089; Mean validation loss 0.099781; Mean validation F1 0.936835; Learning rate 0.000377;\n",
    "===========================================================\n",
    "Epoch 033/096 - Mean training loss 0.128099; Mean training F1 0.913590; Mean validation loss 0.186934; Mean validation F1 0.920729; Learning rate 0.000369;\n",
    "===========================================================\n",
    "Epoch 034/096 - Mean training loss 0.107335; Mean training F1 0.920731; Mean validation loss 0.090630; Mean validation F1 0.933732; Learning rate 0.000362;\n",
    "===========================================================\n",
    "Epoch 035/096 - Mean training loss 0.103342; Mean training F1 0.924097; Mean validation loss 0.084266; Mean validation F1 0.936554; Learning rate 0.000355;\n",
    "===========================================================\n",
    "Epoch 036/096 - Mean training loss 0.090179; Mean training F1 0.932446; Mean validation loss 0.083200; Mean validation F1 0.936052; Learning rate 0.000347;\n",
    "===========================================================\n",
    "Epoch 037/096 - Mean training loss 0.088725; Mean training F1 0.933515; Mean validation loss 0.088710; Mean validation F1 0.937914; Learning rate 0.000340;\n",
    "===========================================================\n",
    "Epoch 038/096 - Mean training loss 0.087537; Mean training F1 0.934544; Mean validation loss 0.076579; Mean validation F1 0.937759; Learning rate 0.000332;\n",
    "===========================================================\n",
    "Epoch 039/096 - Mean training loss 0.086807; Mean training F1 0.935308; Mean validation loss 0.088426; Mean validation F1 0.936659; Learning rate 0.000325;\n",
    "===========================================================\n",
    "Epoch 040/096 - Mean training loss 0.086399; Mean training F1 0.935513; Mean validation loss 0.045925; Mean validation F1 0.938137; Learning rate 0.000317;\n",
    "===========================================================\n",
    "Epoch 041/096 - Mean training loss 0.086194; Mean training F1 0.935664; Mean validation loss 0.086938; Mean validation F1 0.938062; Learning rate 0.000309;\n",
    "===========================================================\n",
    "Epoch 042/096 - Mean training loss 0.086005; Mean training F1 0.935676; Mean validation loss 0.108081; Mean validation F1 0.937202; Learning rate 0.000301;\n",
    "===========================================================\n",
    "Epoch 043/096 - Mean training loss 0.085550; Mean training F1 0.936071; Mean validation loss 0.062914; Mean validation F1 0.937233; Learning rate 0.000293;\n",
    "===========================================================\n",
    "Epoch 044/096 - Mean training loss 0.085910; Mean training F1 0.935859; Mean validation loss 0.056322; Mean validation F1 0.937755; Learning rate 0.000285;\n",
    "===========================================================\n",
    "Epoch 045/096 - Mean training loss 0.085190; Mean training F1 0.936404; Mean validation loss 0.089039; Mean validation F1 0.936934; Learning rate 0.000277;\n",
    "===========================================================\n",
    "Epoch 046/096 - Mean training loss 0.085846; Mean training F1 0.935716; Mean validation loss 0.087558; Mean validation F1 0.938315; Learning rate 0.000269;\n",
    "===========================================================\n",
    "Epoch 047/096 - Mean training loss 0.085013; Mean training F1 0.936184; Mean validation loss 0.092824; Mean validation F1 0.937118; Learning rate 0.000261;\n",
    "===========================================================\n",
    "Epoch 048/096 - Mean training loss 0.084828; Mean training F1 0.936446; Mean validation loss 0.109956; Mean validation F1 0.938237; Learning rate 0.000253;\n",
    "===========================================================\n",
    "Epoch 049/096 - Mean training loss 0.084333; Mean training F1 0.936895; Mean validation loss 0.053222; Mean validation F1 0.938484; Learning rate 0.000245;\n",
    "===========================================================\n",
    "Epoch 050/096 - Mean training loss 0.084341; Mean training F1 0.936928; Mean validation loss 0.073815; Mean validation F1 0.937163; Learning rate 0.000237;\n",
    "===========================================================\n",
    "Epoch 051/096 - Mean training loss 0.084392; Mean training F1 0.936571; Mean validation loss 0.091626; Mean validation F1 0.937526; Learning rate 0.000228;\n",
    "===========================================================\n",
    "Epoch 052/096 - Mean training loss 0.084163; Mean training F1 0.936861; Mean validation loss 0.089541; Mean validation F1 0.938296; Learning rate 0.000220;\n",
    "===========================================================\n",
    "Epoch 053/096 - Mean training loss 0.084115; Mean training F1 0.936756; Mean validation loss 0.085697; Mean validation F1 0.937912; Learning rate 0.000212;\n",
    "===========================================================\n",
    "Epoch 054/096 - Mean training loss 0.083661; Mean training F1 0.937223; Mean validation loss 0.099795; Mean validation F1 0.938266; Learning rate 0.000204;\n",
    "===========================================================\n",
    "Epoch 055/096 - Mean training loss 0.083835; Mean training F1 0.936968; Mean validation loss 0.111670; Mean validation F1 0.937375; Learning rate 0.000197;\n",
    "===========================================================\n",
    "Epoch 056/096 - Mean training loss 0.083465; Mean training F1 0.937338; Mean validation loss 0.072594; Mean validation F1 0.938131; Learning rate 0.000189;\n",
    "===========================================================\n",
    "Epoch 057/096 - Mean training loss 0.083517; Mean training F1 0.937134; Mean validation loss 0.114835; Mean validation F1 0.938063; Learning rate 0.000181;\n",
    "===========================================================\n",
    "Epoch 058/096 - Mean training loss 0.089697; Mean training F1 0.931760; Mean validation loss 0.086797; Mean validation F1 0.937012; Learning rate 0.000173;\n",
    "===========================================================\n",
    "Epoch 059/096 - Mean training loss 0.084059; Mean training F1 0.936726; Mean validation loss 0.034449; Mean validation F1 0.938677; Learning rate 0.000166;\n",
    "===========================================================\n",
    "Epoch 060/096 - Mean training loss 0.083408; Mean training F1 0.937385; Mean validation loss 0.098053; Mean validation F1 0.937788; Learning rate 0.000158;\n",
    "===========================================================\n",
    "Epoch 061/096 - Mean training loss 0.083237; Mean training F1 0.937335; Mean validation loss 0.059769; Mean validation F1 0.938231; Learning rate 0.000151;\n",
    "===========================================================\n",
    "Epoch 062/096 - Mean training loss 0.082874; Mean training F1 0.937670; Mean validation loss 0.071147; Mean validation F1 0.938114; Learning rate 0.000143;\n",
    "===========================================================\n",
    "Epoch 063/096 - Mean training loss 0.082713; Mean training F1 0.937793; Mean validation loss 0.078543; Mean validation F1 0.938836; Learning rate 0.000136;\n",
    "===========================================================\n",
    "Epoch 064/096 - Mean training loss 0.082556; Mean training F1 0.937838; Mean validation loss 0.066737; Mean validation F1 0.938766; Learning rate 0.000129;\n",
    "===========================================================\n",
    "Epoch 065/096 - Mean training loss 0.082360; Mean training F1 0.938078; Mean validation loss 0.059624; Mean validation F1 0.938647; Learning rate 0.000122;\n",
    "===========================================================\n",
    "Epoch 066/096 - Mean training loss 0.082457; Mean training F1 0.937949; Mean validation loss 0.041977; Mean validation F1 0.938808; Learning rate 0.000115;\n",
    "===========================================================\n",
    "Epoch 067/096 - Mean training loss 0.082300; Mean training F1 0.937879; Mean validation loss 0.088944; Mean validation F1 0.938367; Learning rate 0.000109;\n",
    "===========================================================\n",
    "Epoch 068/096 - Mean training loss 0.082195; Mean training F1 0.937925; Mean validation loss 0.075779; Mean validation F1 0.938676; Learning rate 0.000102;\n",
    "===========================================================\n",
    "Epoch 069/096 - Mean training loss 0.081941; Mean training F1 0.938394; Mean validation loss 0.104990; Mean validation F1 0.938939; Learning rate 0.000096;\n",
    "===========================================================\n",
    "Epoch 070/096 - Mean training loss 0.081924; Mean training F1 0.938236; Mean validation loss 0.120648; Mean validation F1 0.938647; Learning rate 0.000090;\n",
    "===========================================================\n",
    "Epoch 071/096 - Mean training loss 0.081812; Mean training F1 0.938186; Mean validation loss 0.087816; Mean validation F1 0.938892; Learning rate 0.000084;\n",
    "===========================================================\n",
    "Epoch 072/096 - Mean training loss 0.081694; Mean training F1 0.938365; Mean validation loss 0.132233; Mean validation F1 0.938459; Learning rate 0.000078;\n",
    "===========================================================\n",
    "Epoch 073/096 - Mean training loss 0.081434; Mean training F1 0.938516; Mean validation loss 0.049486; Mean validation F1 0.938325; Learning rate 0.000072;\n",
    "===========================================================\n",
    "Epoch 074/096 - Mean training loss 0.081405; Mean training F1 0.938369; Mean validation loss 0.043687; Mean validation F1 0.938893; Learning rate 0.000067;\n",
    "===========================================================\n",
    "Epoch 075/096 - Mean training loss 0.081265; Mean training F1 0.938607; Mean validation loss 0.088706; Mean validation F1 0.938786; Learning rate 0.000061;\n",
    "===========================================================\n",
    "Epoch 076/096 - Mean training loss 0.081189; Mean training F1 0.938564; Mean validation loss 0.065307; Mean validation F1 0.938616; Learning rate 0.000056;\n",
    "===========================================================\n",
    "Epoch 077/096 - Mean training loss 0.081065; Mean training F1 0.938779; Mean validation loss 0.078908; Mean validation F1 0.938880; Learning rate 0.000052;\n",
    "===========================================================\n",
    "Epoch 078/096 - Mean training loss 0.081375; Mean training F1 0.938375; Mean validation loss 0.059555; Mean validation F1 0.938847; Learning rate 0.000047;\n",
    "===========================================================\n",
    "Epoch 079/096 - Mean training loss 0.080865; Mean training F1 0.938701; Mean validation loss 0.074071; Mean validation F1 0.938760; Learning rate 0.000043;\n",
    "===========================================================\n",
    "Epoch 080/096 - Mean training loss 0.080764; Mean training F1 0.938870; Mean validation loss 0.070719; Mean validation F1 0.938913; Learning rate 0.000038;\n",
    "===========================================================\n",
    "Epoch 081/096 - Mean training loss 0.080693; Mean training F1 0.939000; Mean validation loss 0.060973; Mean validation F1 0.938936; Learning rate 0.000034;\n",
    "===========================================================\n",
    "Epoch 082/096 - Mean training loss 0.080627; Mean training F1 0.938894; Mean validation loss 0.070682; Mean validation F1 0.939013; Learning rate 0.000031;\n",
    "===========================================================\n",
    "Epoch 083/096 - Mean training loss 0.080578; Mean training F1 0.939045; Mean validation loss 0.113393; Mean validation F1 0.939005; Learning rate 0.000027;\n",
    "===========================================================\n",
    "Epoch 084/096 - Mean training loss 0.080465; Mean training F1 0.939149; Mean validation loss 0.061118; Mean validation F1 0.939136; Learning rate 0.000024;\n",
    "===========================================================\n",
    "Epoch 085/096 - Mean training loss 0.080501; Mean training F1 0.939097; Mean validation loss 0.114638; Mean validation F1 0.939045; Learning rate 0.000021;\n",
    "===========================================================\n",
    "Epoch 086/096 - Mean training loss 0.080329; Mean training F1 0.939020; Mean validation loss 0.089038; Mean validation F1 0.938909; Learning rate 0.000018;\n",
    "===========================================================\n",
    "Epoch 087/096 - Mean training loss 0.080279; Mean training F1 0.939148; Mean validation loss 0.090417; Mean validation F1 0.938985; Learning rate 0.000016;\n",
    "===========================================================\n",
    "Epoch 088/096 - Mean training loss 0.080237; Mean training F1 0.939113; Mean validation loss 0.089974; Mean validation F1 0.938832; Learning rate 0.000014;\n",
    "===========================================================\n",
    "Epoch 089/096 - Mean training loss 0.080184; Mean training F1 0.939252; Mean validation loss 0.092096; Mean validation F1 0.939001; Learning rate 0.000012;\n",
    "===========================================================\n",
    "Epoch 090/096 - Mean training loss 0.080206; Mean training F1 0.939216; Mean validation loss 0.098374; Mean validation F1 0.938885; Learning rate 0.000010;\n",
    "===========================================================\n",
    "Epoch 091/096 - Mean training loss 0.080129; Mean training F1 0.939132; Mean validation loss 0.052961; Mean validation F1 0.939053; Learning rate 0.000008;\n",
    "===========================================================\n",
    "Epoch 092/096 - Mean training loss 0.080131; Mean training F1 0.939273; Mean validation loss 0.050002; Mean validation F1 0.938929; Learning rate 0.000007;\n",
    "===========================================================\n",
    "Epoch 093/096 - Mean training loss 0.080111; Mean training F1 0.939168; Mean validation loss 0.101090; Mean validation F1 0.938803; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 094/096 - Mean training loss 0.080058; Mean training F1 0.939310; Mean validation loss 0.083516; Mean validation F1 0.938850; Learning rate 0.000006;\n",
    "===========================================================\n",
    "Epoch 095/096 - Mean training loss 0.080162; Mean training F1 0.939163; Mean validation loss 0.068058; Mean validation F1 0.938939; Learning rate 0.000005;\n",
    "===========================================================\n",
    "Epoch 096/096 - Mean training loss 0.080062; Mean training F1 0.939180; Mean validation loss 0.076037; Mean validation F1 0.939021; Learning rate 0.000005;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
