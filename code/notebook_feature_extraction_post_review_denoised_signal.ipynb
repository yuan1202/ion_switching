{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "pd.set_option('display.max_columns', 10000)\n",
    "pd.set_option('display.max_rows', 10000)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.signal import hilbert\n",
    "from scipy.signal import hann\n",
    "from scipy.signal import convolve\n",
    "from scipy.signal import welch, find_peaks\n",
    "from scipy import stats\n",
    "from scipy.special import entr\n",
    "from scipy.stats import entropy\n",
    "from scipy.stats import percentileofscore\n",
    "from tsfresh.feature_extraction import feature_calculators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_trn = pd.read_pickle('../input/train.pkl')\n",
    "pdf_tst = pd.read_pickle('../input/test.pkl')\n",
    "\n",
    "batch_id_trn = {i: range(i * 500000, (i + 1) * 500000) for i in range(10)}\n",
    "batch_id_tst = {i: range(i * 100000, (i + 1) * 100000) for i in range(20)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_trn.drop(columns=['signal', 'batch', 'is_filtered',\t'model',\t'signal_processed_denoised',\t'time_scaled',\t'signal_processed_kalman'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_trn.rename(columns={'signal_processed': 'signal'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dat = pdf_trn['signal'].values\n",
    "trn_lbl = pdf_trn['open_channels'].values\n",
    "\n",
    "b0_dat = trn_dat[batch_id_trn[0]]\n",
    "b0_lbl = trn_lbl[batch_id_trn[0]]\n",
    "b1_dat = trn_dat[batch_id_trn[1]]\n",
    "b1_lbl = trn_lbl[batch_id_trn[1]]\n",
    "b2_dat = trn_dat[batch_id_trn[2]]\n",
    "b2_lbl = trn_lbl[batch_id_trn[2]]\n",
    "b3_dat = trn_dat[batch_id_trn[3]]\n",
    "b3_lbl = trn_lbl[batch_id_trn[3]]\n",
    "b4_dat = trn_dat[batch_id_trn[4]]\n",
    "b4_lbl = trn_lbl[batch_id_trn[4]]\n",
    "b5_dat = trn_dat[batch_id_trn[5]]\n",
    "b5_lbl = trn_lbl[batch_id_trn[5]]\n",
    "b6_dat = trn_dat[batch_id_trn[6]]\n",
    "b6_lbl = trn_lbl[batch_id_trn[6]]\n",
    "b7_dat = trn_dat[batch_id_trn[7]]\n",
    "b7_lbl = trn_lbl[batch_id_trn[7]]\n",
    "b8_dat = trn_dat[batch_id_trn[8]]\n",
    "b8_lbl = trn_lbl[batch_id_trn[8]]\n",
    "b9_dat = trn_dat[batch_id_trn[9]]\n",
    "b9_lbl = trn_lbl[batch_id_trn[9]]\n",
    "\n",
    "target_encode_dict = {}\n",
    "for i, (b_d, b_l) in enumerate(\n",
    "    zip(\n",
    "        [b0_dat, b1_dat, b2_dat, b3_dat, b4_dat, b5_dat, b6_dat, b7_dat, b8_dat, b9_dat], \n",
    "        [b0_lbl, b1_lbl, b2_lbl, b3_lbl, b4_lbl, b5_lbl, b6_lbl, b7_lbl, b8_lbl, b9_lbl]\n",
    "    )\n",
    "):\n",
    "    unq_ls = np.unique(b_l)\n",
    "    for l in unq_ls:\n",
    "        target_encode_dict.update({str(i) + '_' + str(l): b_d[b_l == l]})\n",
    "        \n",
    "with open('../input/target_codes.pkl', 'wb') as f:\n",
    "    pickle.dump(target_encode_dict, f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "backward_1_states = {}\n",
    "\n",
    "for i in range(100):\n",
    "    backward_1_states.update(\n",
    "        {\n",
    "            i: g_pdf.shift(1).loc[g_pdf['100cuts'] == i, 'signal'].values\n",
    "        }\n",
    "    )\n",
    "    \n",
    "backward_2_states = {}\n",
    "\n",
    "for i in range(100):\n",
    "    backward_2_states.update(\n",
    "        {\n",
    "            i: g_pdf.shift(2).loc[g_pdf['100cuts'] == i, 'signal'].values\n",
    "        }\n",
    "    )\n",
    "\n",
    "backward_3_states = {}\n",
    "for i in range(100):\n",
    "    backward_3_states.update(\n",
    "        {\n",
    "            i: g_pdf.shift(3).loc[g_pdf['100cuts'] == i, 'signal'].values\n",
    "        }\n",
    "    )\n",
    "    \n",
    "backward_4_states = {}\n",
    "for i in range(100):\n",
    "    backward_4_states.update(\n",
    "        {\n",
    "            i: g_pdf.shift(4).loc[g_pdf['100cuts'] == i, 'signal'].values\n",
    "        }\n",
    "    )\n",
    "    \n",
    "backward_5_states = {}\n",
    "for i in range(100):\n",
    "    backward_5_states.update(\n",
    "        {\n",
    "            i: g_pdf.shift(5).loc[g_pdf['100cuts'] == i, 'signal'].values\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bp.pack_ndarray_to_file(pre_train[features].values, '../input/trn_dat_orig_all.bp')\n",
    "bp.pack_ndarray_to_file(pre_train[target].values, '../input/trn_lbl_orig_all.bp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
